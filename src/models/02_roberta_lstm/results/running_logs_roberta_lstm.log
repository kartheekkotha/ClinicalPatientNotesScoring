[2024-04-20 15:13:04,748: INFO: 3051437145: Epoch: 1/10]
[2024-04-20 15:13:26,794: INFO: 3051437145: Training : batch 0 Loss: 0.7043297051433094]
[2024-04-20 15:13:49,728: INFO: 3051437145: Training : batch 1 Loss: 0.6670677749672587]
[2024-04-20 15:14:07,603: INFO: 3051437145: Training : batch 2 Loss: 0.6317735246786813]
[2024-04-20 15:14:24,705: INFO: 3051437145: Training : batch 3 Loss: 0.6001182171779823]
[2024-04-20 15:14:40,298: INFO: 3051437145: Training : batch 4 Loss: 0.5740020827844557]
[2024-04-20 15:14:55,210: INFO: 3051437145: Training : batch 5 Loss: 0.5454400020998389]
[2024-04-20 15:15:10,004: INFO: 3051437145: Training : batch 6 Loss: 0.5108826939838336]
[2024-04-20 15:15:25,609: INFO: 3051437145: Training : batch 7 Loss: 0.48375889400863115]
[2024-04-20 15:15:43,292: INFO: 3051437145: Training : batch 8 Loss: 0.4478633317973083]
[2024-04-20 15:15:58,784: INFO: 3051437145: Training : batch 9 Loss: 0.4167595760969957]
[2024-04-20 15:16:14,342: INFO: 3051437145: Training : batch 10 Loss: 0.3958309350057553]
[2024-04-20 15:16:30,092: INFO: 3051437145: Training : batch 11 Loss: 0.3593943850404915]
[2024-04-20 15:26:42,157: INFO: 625199155: Epoch: 1/5]
[2024-04-20 15:27:27,271: INFO: 3013262975: Training : batch 0 Loss: 0.6540285923245721]
[2024-04-20 15:30:57,953: INFO: 625199155: Epoch: 1/5]
[2024-04-20 15:31:49,245: INFO: 3013262975: Training : batch 0 Loss: 0.6693024706362416]
[2024-04-20 11:43:04,955: INFO: utils: NumExpr defaulting to 2 threads.]
[2024-04-20 11:43:23,068: INFO: roberta_kFold_initial_lstm: Fold 1/3]
[2024-04-20 11:43:23,073: INFO: roberta_kFold_initial_lstm: Fold 1/3 , Epoch: 1/3]
[2024-04-20 11:43:26,012: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.7132221769434097]
[2024-04-20 11:43:26,602: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.6977880996656969]
[2024-04-20 11:43:27,200: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.6831798617302743]
[2024-04-20 11:43:27,789: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.6669301977965978]
[2024-04-20 11:43:28,389: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.6533926626495717]
[2024-04-20 11:43:28,983: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.6385056675597021]
[2024-04-20 11:43:29,573: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.6181999510877272]
[2024-04-20 11:43:30,170: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.5999749002991863]
[2024-04-20 11:43:30,765: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.5778826514731099]
[2024-04-20 11:43:31,358: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.552090747767519]
[2024-04-20 11:43:31,952: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.5234170356039274]
[2024-04-20 11:43:32,541: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.5112643172211856]
[2024-04-20 11:43:33,135: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.47470998965286887]
[2024-04-20 11:43:33,734: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.4568144090140044]
[2024-04-20 11:43:34,326: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.4302682116095509]
[2024-04-20 11:43:34,925: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.42914141395757366]
[2024-04-20 11:43:35,521: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.4074310169500463]
[2024-04-20 11:43:36,124: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.39001606549504847]
[2024-04-20 11:43:36,725: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.3890707095769172]
[2024-04-20 11:43:37,332: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.35973922073986825]
[2024-04-20 11:43:37,938: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.34418780275063304]
[2024-04-20 11:43:38,546: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.3286621904056562]
[2024-04-20 11:43:39,154: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.3202158358426543]
[2024-04-20 11:43:39,752: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.2992080771316612]
[2024-04-20 11:43:40,348: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.3003498694222224]
[2024-04-20 11:43:40,948: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.2802643182246309]
[2024-04-20 11:43:41,548: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.2689151401486465]
[2024-04-20 11:43:42,151: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.2593062969945545]
[2024-04-20 11:43:42,751: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.24937282245177808]
[2024-04-20 11:43:43,350: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.2379027677174262]
[2024-04-20 11:43:43,954: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.2414835525945348]
[2024-04-20 11:43:44,560: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.21191163463748383]
[2024-04-20 11:43:45,163: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.2072870967095792]
[2024-04-20 11:43:45,766: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.2136144993850599]
[2024-04-20 11:43:46,368: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.18976544766072082]
[2024-04-20 11:43:46,973: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.17053489301873137]
[2024-04-20 11:43:47,573: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.19419077661576875]
[2024-04-20 11:43:48,176: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.1678054597102679]
[2024-04-20 11:43:48,783: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.1704297965542438]
[2024-04-20 11:43:49,390: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.16483879267618168]
[2024-04-20 11:43:50,002: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.1519258381191145]
[2024-04-20 11:43:50,617: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.15411185854122983]
[2024-04-20 11:43:51,230: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.1528732647078275]
[2024-04-20 11:43:51,845: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.12051047878230318]
[2024-04-20 11:43:52,455: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.11890104860540011]
[2024-04-20 11:43:53,061: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.11412047594339281]
[2024-04-20 11:43:53,667: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.12782349222766354]
[2024-04-20 11:43:54,276: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.11156667187757227]
[2024-04-20 11:43:54,882: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.11075751110693388]
[2024-04-20 11:43:55,497: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.12125304278383314]
[2024-04-20 11:43:56,107: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.11518235072403789]
[2024-04-20 11:43:56,714: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.10823203080168395]
[2024-04-20 11:43:57,323: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.12559869878549826]
[2024-04-20 11:43:57,931: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.09595642120077989]
[2024-04-20 11:43:58,541: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.11537106927767853]
[2024-04-20 11:43:59,154: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.10199626658147978]
[2024-04-20 11:43:59,763: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.10426155723530812]
[2024-04-20 11:44:00,374: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.10972052883510248]
[2024-04-20 11:44:00,984: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.11400394366030174]
[2024-04-20 11:44:01,594: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.10262208324481056]
[2024-04-20 11:44:02,206: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.08158149846655992]
[2024-04-20 11:44:02,830: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.1133775188852508]
[2024-04-20 11:44:03,457: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.11600682691376936]
[2024-04-20 11:44:04,077: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.0749850399552996]
[2024-04-20 11:44:04,703: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.07166558248194312]
[2024-04-20 11:44:05,321: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.07655760108419044]
[2024-04-20 11:44:05,937: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.11220541410793029]
[2024-04-20 11:44:06,549: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.05256480427628607]
[2024-04-20 11:44:07,162: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.06851681795735062]
[2024-04-20 11:44:07,778: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.08600651725220396]
[2024-04-20 11:44:08,392: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.08024186366605326]
[2024-04-20 11:44:09,002: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.07043490424551876]
[2024-04-20 11:44:09,620: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.07036836502333003]
[2024-04-20 11:44:10,234: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.13227328729449178]
[2024-04-20 11:44:10,848: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.09388405096837878]
[2024-04-20 11:44:11,470: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.1121920164215724]
[2024-04-20 11:44:12,082: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.08596552475973]
[2024-04-20 11:44:12,699: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.09784205327086341]
[2024-04-20 11:44:13,316: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.04972536343300815]
[2024-04-20 11:44:13,937: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.10018400982972593]
[2024-04-20 11:44:14,552: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.06812802445987363]
[2024-04-20 11:44:15,171: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.04741396077409935]
[2024-04-20 11:44:15,795: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.046765623112666486]
[2024-04-20 11:44:16,422: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.07447661666137664]
[2024-04-20 11:44:17,051: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.0812895452149573]
[2024-04-20 11:44:17,680: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.06527775437226693]
[2024-04-20 11:44:18,306: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.057205137054408245]
[2024-04-20 11:44:18,929: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.05507651266534497]
[2024-04-20 11:44:19,554: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.06625033030128043]
[2024-04-20 11:44:20,177: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.05762150498804847]
[2024-04-20 11:44:20,800: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.06483744880990644]
[2024-04-20 11:44:21,420: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.08901794363424433]
[2024-04-20 11:44:22,049: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.04335455027251239]
[2024-04-20 11:44:22,673: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.07143771218767007]
[2024-04-20 11:44:23,303: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.10747181825894864]
[2024-04-20 11:44:23,928: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.0697767678308885]
[2024-04-20 11:44:24,557: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.051333842074156165]
[2024-04-20 11:44:25,183: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.06189712904260471]
[2024-04-20 11:44:25,812: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.08359194877253308]
[2024-04-20 11:44:26,437: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.07637958457513584]
[2024-04-20 11:44:27,068: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.06232125331704673]
[2024-04-20 11:44:27,696: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.056123275982422956]
[2024-04-20 11:44:28,326: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.057539816070164285]
[2024-04-20 11:44:28,963: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.05675228843111111]
[2024-04-20 11:44:29,604: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.06749950605313561]
[2024-04-20 11:44:30,244: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.08277338949583699]
[2024-04-20 11:44:30,881: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.049672351706024145]
[2024-04-20 11:44:31,517: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.07157535864835508]
[2024-04-20 11:44:32,149: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.06002554670614126]
[2024-04-20 11:44:32,780: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.04617618178872414]
[2024-04-20 11:44:33,416: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.0700562794566593]
[2024-04-20 11:44:34,050: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.10057357700022225]
[2024-04-20 11:44:34,685: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.0739854980907324]
[2024-04-20 11:44:35,320: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.06422964244404017]
[2024-04-20 11:44:35,959: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.10832639026921242]
[2024-04-20 11:44:36,595: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.06214241881220843]
[2024-04-20 11:44:37,239: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.07651005332375978]
[2024-04-20 11:44:37,876: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.08410528653795354]
[2024-04-20 11:44:38,515: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.0647574079465064]
[2024-04-20 11:44:39,149: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.051568939976582455]
[2024-04-20 11:44:39,788: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.06276869461781592]
[2024-04-20 11:44:40,428: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.04234392298552804]
[2024-04-20 11:44:41,061: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.05164241675496092]
[2024-04-20 11:44:41,705: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.10043073704826366]
[2024-04-20 11:44:42,352: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.04774795840795842]
[2024-04-20 11:44:42,996: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.060945798846749506]
[2024-04-20 11:44:43,640: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.08431603223620178]
[2024-04-20 11:44:44,286: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.11632873627503489]
[2024-04-20 11:44:44,925: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.03984913189659888]
[2024-04-20 11:44:45,562: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.0338897128001047]
[2024-04-20 11:44:46,205: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.05847244631399988]
[2024-04-20 11:44:46,845: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.060232403203877835]
[2024-04-20 11:44:47,489: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.05262804532171876]
[2024-04-20 11:44:48,136: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.05551183228753166]
[2024-04-20 11:44:48,781: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.07144721294364771]
[2024-04-20 11:44:49,423: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.06836038961704405]
[2024-04-20 11:44:50,068: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.11160093971357493]
[2024-04-20 11:44:50,713: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.07167908208993884]
[2024-04-20 11:44:51,359: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.0519780550510138]
[2024-04-20 11:44:52,005: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.07852176603909654]
[2024-04-20 11:44:52,654: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.10329703457489339]
[2024-04-20 11:44:53,306: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.0822720030837055]
[2024-04-20 11:44:53,958: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.05659020881119913]
[2024-04-20 11:44:54,614: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.07891575000164831]
[2024-04-20 11:44:55,274: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.06577026505838499]
[2024-04-20 11:44:55,939: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.09515688639231516]
[2024-04-20 11:44:56,598: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.05480770971175663]
[2024-04-20 11:44:57,257: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.08037070043503519]
[2024-04-20 11:44:57,911: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.04166033016686004]
[2024-04-20 11:44:58,565: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.06113960314991698]
[2024-04-20 11:44:59,220: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.0845409684543403]
[2024-04-20 11:44:59,877: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.06902067397255184]
[2024-04-20 11:45:00,533: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.060229631720447596]
[2024-04-20 11:45:01,194: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.04678199961087419]
[2024-04-20 11:45:01,850: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.03602498161831479]
[2024-04-20 11:45:02,510: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.05603558477411577]
[2024-04-20 11:45:03,172: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.05190237575413448]
[2024-04-20 11:45:03,831: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.0641927008565507]
[2024-04-20 11:45:04,497: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.08417150264204407]
[2024-04-20 11:45:05,164: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.049222424094745205]
[2024-04-20 11:45:05,833: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.07555721562692444]
[2024-04-20 11:45:06,502: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.0831092931946391]
[2024-04-20 11:45:07,171: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.05166480258549228]
[2024-04-20 11:45:07,849: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.025938077244603605]
[2024-04-20 11:45:08,533: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.06837275521717177]
[2024-04-20 11:45:09,202: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.07380088235348724]
[2024-04-20 11:45:09,878: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.0487664696150108]
[2024-04-20 11:45:10,558: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.062258556200743796]
[2024-04-20 11:45:11,226: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.0979504539350852]
[2024-04-20 11:45:11,897: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.1371607612153695]
[2024-04-20 11:45:12,567: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.03981570413677813]
[2024-04-20 11:45:13,239: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.09764571228510582]
[2024-04-20 11:45:13,912: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.05161347419455432]
[2024-04-20 11:45:14,584: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.08266579452219215]
[2024-04-20 11:45:15,253: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.062094646342680436]
[2024-04-20 11:45:15,927: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.07379783160966019]
[2024-04-20 11:45:16,595: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.07727619634902107]
[2024-04-20 11:45:17,265: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.1022276589151852]
[2024-04-20 11:45:17,938: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.05928980729405282]
[2024-04-20 11:45:18,613: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.07568593865581055]
[2024-04-20 11:45:19,284: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.07685595860475122]
[2024-04-20 11:45:19,957: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.04294141734010854]
[2024-04-20 11:45:20,627: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.05581650812734173]
[2024-04-20 11:45:21,308: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.05162298282518413]
[2024-04-20 11:45:21,992: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.08201168299707419]
[2024-04-20 11:45:22,665: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.06447704444302642]
[2024-04-20 11:45:23,343: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.03706256112748864]
[2024-04-20 11:45:24,008: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.07730890464933202]
[2024-04-20 11:45:24,686: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.06785756993415337]
[2024-04-20 11:45:25,363: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.07309974733669217]
[2024-04-20 11:45:26,031: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.07020497170220422]
[2024-04-20 11:45:26,700: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.07370443712693384]
[2024-04-20 11:45:27,360: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.059809096207784296]
[2024-04-20 11:45:28,020: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.11282883629488884]
[2024-04-20 11:45:28,679: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.054836754461575765]
[2024-04-20 11:45:29,339: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.04519783422334253]
[2024-04-20 11:45:29,998: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.1064647834142825]
[2024-04-20 11:45:30,655: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.06141621526518044]
[2024-04-20 11:45:31,314: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.056897689400368046]
[2024-04-20 11:45:31,971: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.13790668355963695]
[2024-04-20 11:45:32,629: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.0547789501066765]
[2024-04-20 11:45:33,284: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.02645393449017544]
[2024-04-20 11:45:33,946: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.0688650310794016]
[2024-04-20 11:45:34,609: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.11951322992599131]
[2024-04-20 11:45:35,273: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.02602822800027616]
[2024-04-20 11:45:35,935: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.05313589556069364]
[2024-04-20 11:45:36,595: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.0575276521589542]
[2024-04-20 11:45:37,249: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.10057958990314864]
[2024-04-20 11:45:37,898: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.045687533321129625]
[2024-04-20 11:45:38,552: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.049381981208828064]
[2024-04-20 11:45:39,206: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.06975361466306637]
[2024-04-20 11:45:39,856: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.07465737515894777]
[2024-04-20 11:45:40,505: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.09797470317064388]
[2024-04-20 11:45:41,152: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.047570013429120594]
[2024-04-20 11:45:41,806: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.0682490647979093]
[2024-04-20 11:45:42,457: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.06848322138794062]
[2024-04-20 11:45:43,109: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.1562808308743841]
[2024-04-20 11:45:43,759: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.08277182627632965]
[2024-04-20 11:45:44,409: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.04997500649041697]
[2024-04-20 11:45:45,057: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.11188952781485752]
[2024-04-20 11:45:45,704: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.052919687782098324]
[2024-04-20 11:45:46,355: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.0746577835740126]
[2024-04-20 11:45:47,011: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.083012664002128]
[2024-04-20 11:45:47,670: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.07485351976706099]
[2024-04-20 11:45:48,323: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.06699844766744466]
[2024-04-20 11:45:48,980: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.08026889064018294]
[2024-04-20 11:45:49,635: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.08783305246979901]
[2024-04-20 11:45:50,282: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.036644694057222524]
[2024-04-20 11:45:50,929: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.055900222940566735]
[2024-04-20 11:45:51,581: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.08748580383044614]
[2024-04-20 11:45:52,224: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.13033408798249985]
[2024-04-20 11:45:52,873: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.13160081262388743]
[2024-04-20 11:45:53,520: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.060251234056784606]
[2024-04-20 11:45:54,164: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.061552666100089096]
[2024-04-20 11:45:54,811: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.07969596202244751]
[2024-04-20 11:45:55,458: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.05452772810964847]
[2024-04-20 11:45:56,106: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.05139671472337796]
[2024-04-20 11:45:56,755: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.04408182070360401]
[2024-04-20 11:45:57,406: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.0855885895012825]
[2024-04-20 11:45:58,054: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.053175541592735645]
[2024-04-20 11:45:58,701: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.0683546955616767]
[2024-04-20 11:45:59,352: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.11537075197487612]
[2024-04-20 11:46:00,002: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.1268213449369304]
[2024-04-20 11:46:00,654: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.05691052065987395]
[2024-04-20 11:46:01,309: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.10017381007308067]
[2024-04-20 11:46:01,963: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.04372653885813499]
[2024-04-20 11:46:02,617: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.10078230141172644]
[2024-04-20 11:46:03,260: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.044727276696551445]
[2024-04-20 11:46:03,908: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.08321116203606235]
[2024-04-20 11:46:04,557: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.043489257303963594]
[2024-04-20 11:46:05,206: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.08413941279308651]
[2024-04-20 11:46:05,852: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.07116506471566564]
[2024-04-20 11:46:06,501: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.06782697626255244]
[2024-04-20 11:46:07,149: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.0820449522002723]
[2024-04-20 11:46:07,796: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.046540664177519765]
[2024-04-20 11:46:08,446: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.0855775653921884]
[2024-04-20 11:46:09,095: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.036328450587223955]
[2024-04-20 11:46:09,740: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.09418733233450889]
[2024-04-20 11:46:10,388: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.0763680944364104]
[2024-04-20 11:46:11,037: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.08022808932417302]
[2024-04-20 11:46:11,687: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.07600617215806572]
[2024-04-20 11:46:12,336: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.16491674249465285]
[2024-04-20 11:46:12,985: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.10127717952141232]
[2024-04-20 11:46:13,642: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.09838198032398147]
[2024-04-20 11:46:14,305: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.10087164571609245]
[2024-04-20 11:46:14,961: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.08497082560350672]
[2024-04-20 11:46:15,623: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.09754462645020838]
[2024-04-20 11:46:16,273: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.05160747394914137]
[2024-04-20 11:46:16,925: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.09379176092606753]
[2024-04-20 11:46:17,573: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.0684591537270497]
[2024-04-20 11:46:18,223: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.058667731508921656]
[2024-04-20 11:46:18,869: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.0619295031613524]
[2024-04-20 11:46:19,521: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.05847174686868074]
[2024-04-20 11:46:20,169: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.04090803514430762]
[2024-04-20 11:46:20,819: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.11533653875242078]
[2024-04-20 11:46:21,470: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.056079960778293546]
[2024-04-20 11:46:22,116: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.043913450600802484]
[2024-04-20 11:46:22,769: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.07838468380799411]
[2024-04-20 11:46:23,421: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.08661893651149441]
[2024-04-20 11:46:24,070: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.05891392594822441]
[2024-04-20 11:46:24,721: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.0995961640055999]
[2024-04-20 11:46:25,373: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.04275539948730104]
[2024-04-20 11:46:26,024: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.04020228324481971]
[2024-04-20 11:46:26,685: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.10513340352359293]
[2024-04-20 11:46:27,347: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.08622012648465835]
[2024-04-20 11:46:28,011: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.06941445686059113]
[2024-04-20 11:46:28,676: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.056979165245589304]
[2024-04-20 11:46:29,335: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.08927183207352139]
[2024-04-20 11:46:29,985: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.07360667265924534]
[2024-04-20 11:46:30,641: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.10571547592973106]
[2024-04-20 11:46:31,297: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.04868805284906781]
[2024-04-20 11:46:31,952: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.10610381460847668]
[2024-04-20 11:46:32,606: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.041035506917953844]
[2024-04-20 11:46:33,262: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.09358352894811489]
[2024-04-20 11:46:33,918: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.10018734273486084]
[2024-04-20 11:46:34,568: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.06675671672844602]
[2024-04-20 11:46:35,222: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.0524680305568224]
[2024-04-20 11:46:35,876: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.08193694378777146]
[2024-04-20 11:46:36,535: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.055005081933995385]
[2024-04-20 11:46:37,188: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.07497456742017057]
[2024-04-20 11:46:37,846: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.0754651619555791]
[2024-04-20 11:46:38,504: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.07779591359512679]
[2024-04-20 11:46:39,160: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.09135172289873998]
[2024-04-20 11:46:39,824: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.07052261762132514]
[2024-04-20 11:46:40,493: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.07475407150492523]
[2024-04-20 11:46:41,154: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.11976250732455453]
[2024-04-20 11:46:41,816: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.07743338058207032]
[2024-04-20 11:46:42,469: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.06924726289538514]
[2024-04-20 11:46:43,125: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.06436191673264528]
[2024-04-20 11:46:43,782: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.11128818865907698]
[2024-04-20 11:46:44,438: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.06469809954181527]
[2024-04-20 11:46:45,097: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.08539747679824956]
[2024-04-20 11:46:45,748: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.11601759767297135]
[2024-04-20 11:46:46,405: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.03335359664597772]
[2024-04-20 11:46:47,062: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.05229347753297549]
[2024-04-20 11:46:47,718: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.11580119078924235]
[2024-04-20 11:46:48,371: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.0954546595992566]
[2024-04-20 11:46:49,026: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.0611235192697816]
[2024-04-20 11:46:49,683: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.07287164536187386]
[2024-04-20 11:46:50,339: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.12161293148011541]
[2024-04-20 11:46:50,991: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.040415560979279626]
[2024-04-20 11:46:51,646: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.0979567752832759]
[2024-04-20 11:46:52,312: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.05026069287149453]
[2024-04-20 11:46:52,982: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.0610709321410478]
[2024-04-20 11:46:53,648: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.04150266512575437]
[2024-04-20 11:46:54,311: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.12317157541870101]
[2024-04-20 11:46:54,973: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.08457813915228753]
[2024-04-20 11:46:55,623: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.10620863041054071]
[2024-04-20 11:46:56,278: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.0887386222915333]
[2024-04-20 11:46:56,932: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.08880418684841253]
[2024-04-20 11:46:57,587: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.05477074349708614]
[2024-04-20 11:46:58,240: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.043686695306838864]
[2024-04-20 11:46:58,893: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.049986884095194785]
[2024-04-20 11:46:59,545: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.07809812530644415]
[2024-04-20 11:47:00,200: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.050290528462449115]
[2024-04-20 11:47:00,852: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.0748538196770896]
[2024-04-20 11:47:01,507: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.06531426680723032]
[2024-04-20 11:47:02,159: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.11599567729510474]
[2024-04-20 11:47:02,815: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.06839347825442231]
[2024-04-20 11:47:03,470: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.10097519379670505]
[2024-04-20 11:47:04,122: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.05619126540515733]
[2024-04-20 11:47:04,776: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.05264407834524439]
[2024-04-20 11:47:05,446: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.06390280060642006]
[2024-04-20 11:47:06,111: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.0848939570412878]
[2024-04-20 11:47:06,776: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.07270621377489933]
[2024-04-20 11:47:07,440: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.06812304221363003]
[2024-04-20 11:47:08,106: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.08603464002406831]
[2024-04-20 11:47:08,756: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.07831167179591408]
[2024-04-20 11:47:09,410: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.060645405955204804]
[2024-04-20 11:47:10,062: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.055018400097755896]
[2024-04-20 11:47:10,715: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.09089033753522807]
[2024-04-20 11:47:11,369: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.05569128216203968]
[2024-04-20 11:47:12,022: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.04492869887749201]
[2024-04-20 11:47:12,677: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.08225742898657008]
[2024-04-20 11:47:13,332: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.06998237407755516]
[2024-04-20 11:47:13,986: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.11880585095057283]
[2024-04-20 11:47:14,648: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.20152164122653016]
[2024-04-20 11:47:15,301: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.06132398873431705]
[2024-04-20 11:47:15,953: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.12007200550516671]
[2024-04-20 11:47:16,605: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.03959061666010016]
[2024-04-20 11:47:17,253: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.08549692869760175]
[2024-04-20 11:47:17,906: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.08003826978790753]
[2024-04-20 11:47:18,572: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.07363926732725751]
[2024-04-20 11:47:19,238: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.05018176508211606]
[2024-04-20 11:47:19,904: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.07183343681308578]
[2024-04-20 11:47:20,566: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.07139680029331953]
[2024-04-20 11:47:21,222: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.06652357852648991]
[2024-04-20 11:47:21,875: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.04553558168795885]
[2024-04-20 11:47:22,527: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.06648778047398238]
[2024-04-20 11:47:23,176: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.06680690324985564]
[2024-04-20 11:47:23,828: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.14817484269541428]
[2024-04-20 11:47:24,476: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.04862034207448126]
[2024-04-20 11:47:25,128: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.06749538157413838]
[2024-04-20 11:47:25,781: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.07736515075223144]
[2024-04-20 11:47:26,434: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.08229140504516652]
[2024-04-20 11:47:27,085: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.08719412474430532]
[2024-04-20 11:47:27,734: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.09063912623984653]
[2024-04-20 11:47:28,380: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.06960476929346075]
[2024-04-20 11:47:29,030: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.03944433257125583]
[2024-04-20 11:47:29,681: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.07614526925243711]
[2024-04-20 11:47:30,333: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.056933615555252184]
[2024-04-20 11:47:30,987: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.06647935985536321]
[2024-04-20 11:47:31,647: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.09609132984449388]
[2024-04-20 11:47:32,306: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.12595633744784376]
[2024-04-20 11:47:32,964: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.07604324271266527]
[2024-04-20 11:47:33,622: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.10695365304592176]
[2024-04-20 11:47:34,280: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.09371396395105185]
[2024-04-20 11:47:34,930: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.08059107230406512]
[2024-04-20 11:47:35,578: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.05900228877035327]
[2024-04-20 11:47:36,231: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.12000010405350929]
[2024-04-20 11:47:36,882: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.03435867390173094]
[2024-04-20 11:47:37,533: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.07049764848210745]
[2024-04-20 11:47:38,185: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.05119470317066585]
[2024-04-20 11:47:38,836: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.0691864313651594]
[2024-04-20 11:47:39,487: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.047103631285062654]
[2024-04-20 11:47:40,137: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.054882915917126296]
[2024-04-20 11:47:40,783: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.09181295181005299]
[2024-04-20 11:47:41,433: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.037993373504717085]
[2024-04-20 11:47:42,082: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.08296908411820215]
[2024-04-20 11:47:42,731: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.10810086891177068]
[2024-04-20 11:47:43,379: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.10094677884865634]
[2024-04-20 11:47:44,029: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.04579901404848153]
[2024-04-20 11:47:44,689: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.05727450728168707]
[2024-04-20 11:47:45,351: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.13689176367078512]
[2024-04-20 11:47:46,014: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.13725652857045026]
[2024-04-20 11:47:46,680: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.04462808574798909]
[2024-04-20 11:47:47,338: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.07215979238085093]
[2024-04-20 11:47:47,988: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.10045958487002085]
[2024-04-20 11:47:48,639: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.06808880270979437]
[2024-04-20 11:47:49,287: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.09589514544142656]
[2024-04-20 11:47:49,931: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.10008505924895642]
[2024-04-20 11:47:50,583: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.0834356796302364]
[2024-04-20 11:47:51,231: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.05671567547592974]
[2024-04-20 11:47:51,879: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.09886496313788658]
[2024-04-20 11:47:52,526: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.05305787551112942]
[2024-04-20 11:47:53,175: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.06803975421225741]
[2024-04-20 11:47:53,823: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.08996105978357166]
[2024-04-20 11:47:54,472: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.0508720650278303]
[2024-04-20 11:47:55,122: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.06435310772459006]
[2024-04-20 11:47:55,773: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.04347662569960618]
[2024-04-20 11:47:56,425: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.04781205573006595]
[2024-04-20 11:47:57,075: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.06771707286643439]
[2024-04-20 11:47:57,734: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.10136581643553004]
[2024-04-20 11:47:58,398: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.04152793993895081]
[2024-04-20 11:47:59,057: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.06230617934713099]
[2024-04-20 11:47:59,718: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.07292714521950372]
[2024-04-20 11:48:00,380: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.0685707318512187]
[2024-04-20 11:48:01,031: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.04718136578838255]
[2024-04-20 11:48:01,680: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.06103205459928789]
[2024-04-20 11:48:02,329: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.06716702556519281]
[2024-04-20 11:48:02,982: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.04672115289430165]
[2024-04-20 11:48:03,635: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.07926381865273352]
[2024-04-20 11:48:04,286: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.10784136854900836]
[2024-04-20 11:48:04,937: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.06848313027690343]
[2024-04-20 11:48:05,588: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.06698461235033541]
[2024-04-20 11:48:06,237: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.053503791329403506]
[2024-04-20 11:48:06,892: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.10290570973521547]
[2024-04-20 11:48:07,541: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.07398240517261845]
[2024-04-20 11:48:08,193: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.04859504707069843]
[2024-04-20 11:48:08,842: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.11895173881905821]
[2024-04-20 11:48:09,496: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.07102383968355401]
[2024-04-20 11:48:10,154: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.09941733655280653]
[2024-04-20 11:48:10,817: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.11057675071223382]
[2024-04-20 11:48:11,485: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.04452274454000347]
[2024-04-20 11:48:12,148: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.07861429498139999]
[2024-04-20 11:48:12,817: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.054121094344752166]
[2024-04-20 11:48:13,480: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.09582903371115992]
[2024-04-20 11:48:14,143: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.11239316763355206]
[2024-04-20 11:48:14,806: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.061714517072273406]
[2024-04-20 11:48:15,471: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.06387639438012747]
[2024-04-20 11:48:16,122: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.0910403473120495]
[2024-04-20 11:48:16,777: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.11371759181472282]
[2024-04-20 11:48:17,433: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.08958826500174946]
[2024-04-20 11:48:18,084: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.0534834780003462]
[2024-04-20 11:48:18,737: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.06684870806276443]
[2024-04-20 11:48:19,391: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.06558553359152026]
[2024-04-20 11:48:20,043: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.1237636378592593]
[2024-04-20 11:48:20,693: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.052675210256365824]
[2024-04-20 11:48:21,346: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.06822748491408975]
[2024-04-20 11:48:21,997: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.07606268933114319]
[2024-04-20 11:48:22,647: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.0622307745916272]
[2024-04-20 11:48:23,302: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.0325071385953171]
[2024-04-20 11:48:23,954: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.052095879612452524]
[2024-04-20 11:48:24,606: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.10992805673158071]
[2024-04-20 11:48:25,259: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.0806630541499818]
[2024-04-20 11:48:25,933: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.08458485448917141]
[2024-04-20 11:48:26,595: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.0865393764989499]
[2024-04-20 11:48:27,257: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.0567521638906655]
[2024-04-20 11:48:27,934: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.051418002452529324]
[2024-04-20 11:48:28,605: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.041136710252274576]
[2024-04-20 11:48:29,281: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.04890242392414755]
[2024-04-20 11:48:29,939: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.07141211776736212]
[2024-04-20 11:48:30,601: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.06470063058803226]
[2024-04-20 11:48:31,268: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.048362068306830534]
[2024-04-20 11:48:31,926: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.05985909056210058]
[2024-04-20 11:48:32,578: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.05256212079040728]
[2024-04-20 11:48:33,227: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.11711715664474194]
[2024-04-20 11:48:33,880: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.04156678492791919]
[2024-04-20 11:48:34,535: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.0718529540891513]
[2024-04-20 11:48:35,191: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.08495528353819357]
[2024-04-20 11:48:35,845: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.059399264721472694]
[2024-04-20 11:48:36,501: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.08699117082925335]
[2024-04-20 11:48:37,157: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.07819676033465162]
[2024-04-20 11:48:37,808: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.08828436252434703]
[2024-04-20 11:48:38,464: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.06363477499070103]
[2024-04-20 11:48:39,120: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.0946317437734537]
[2024-04-20 11:48:39,779: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.05062357653585383]
[2024-04-20 11:48:40,439: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.027102682403869694]
[2024-04-20 11:48:41,099: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.08362161202343009]
[2024-04-20 11:48:41,757: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.03990212117912033]
[2024-04-20 11:48:42,420: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.07158310795390851]
[2024-04-20 11:48:43,070: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.04225258673199022]
[2024-04-20 11:48:43,725: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.04977612369609913]
[2024-04-20 11:48:44,377: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.06102572319009198]
[2024-04-20 11:48:45,033: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.0914972383541983]
[2024-04-20 11:48:45,684: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.059895998655948274]
[2024-04-20 11:48:46,340: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.06364738525475531]
[2024-04-20 11:48:46,996: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.03626458375379507]
[2024-04-20 11:48:47,649: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.19232827934315136]
[2024-04-20 11:48:48,306: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.04538596936589162]
[2024-04-20 11:48:48,961: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.09745675475826039]
[2024-04-20 11:48:49,616: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.05710724398767107]
[2024-04-20 11:48:50,269: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.0675530000935396]
[2024-04-20 11:48:50,920: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.03691169873694533]
[2024-04-20 11:48:51,573: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.06429538448130367]
[2024-04-20 11:48:52,229: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.08875038358495564]
[2024-04-20 11:48:52,890: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.059505039465295693]
[2024-04-20 11:48:53,553: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.03985048620661272]
[2024-04-20 11:48:54,213: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.06752961742890846]
[2024-04-20 11:48:54,876: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.05779618786438468]
[2024-04-20 11:48:55,545: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.04303918536346142]
[2024-04-20 11:48:56,198: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.08301204410112745]
[2024-04-20 11:48:56,860: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.05746190427528941]
[2024-04-20 11:48:57,519: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.07039507363210866]
[2024-04-20 11:48:58,170: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.03817854206959801]
[2024-04-20 11:48:58,824: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.03630853520184191]
[2024-04-20 11:48:59,483: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.05726646060572753]
[2024-04-20 11:49:00,136: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.0611514572810491]
[2024-04-20 11:49:00,791: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.05828433915177059]
[2024-04-20 11:49:01,446: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.0437663859727651]
[2024-04-20 11:49:02,104: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.024895678797275222]
[2024-04-20 11:49:02,760: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.084848263313094]
[2024-04-20 11:49:03,415: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.038015980321676704]
[2024-04-20 11:49:04,071: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.08641203428644674]
[2024-04-20 11:49:04,725: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.0738119592548019]
[2024-04-20 11:49:05,382: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.06499666625157034]
[2024-04-20 11:49:06,043: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.08094795367378643]
[2024-04-20 11:49:06,712: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.05503182731666036]
[2024-04-20 11:49:07,377: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.05889444656832801]
[2024-04-20 11:49:08,036: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.11742924599422504]
[2024-04-20 11:49:08,695: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.04099214398601686]
[2024-04-20 11:49:09,349: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.11917416525910114]
[2024-04-20 11:49:10,011: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.05580136553355485]
[2024-04-20 11:49:10,661: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.04261855867274246]
[2024-04-20 11:49:11,315: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.055491196849538925]
[2024-04-20 11:49:11,972: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.04485883949967348]
[2024-04-20 11:49:12,626: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.10301877246866241]
[2024-04-20 11:49:13,282: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.03485862846870072]
[2024-04-20 11:49:13,936: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.030381352478963515]
[2024-04-20 11:49:14,595: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.023745411855918917]
[2024-04-20 11:49:15,246: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.08245877526025973]
[2024-04-20 11:49:15,898: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.05020277485146639]
[2024-04-20 11:49:16,552: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.04845649515736452]
[2024-04-20 11:49:17,204: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.06125834950633788]
[2024-04-20 11:49:17,858: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.06166461075176726]
[2024-04-20 11:49:18,513: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.046494697255517616]
[2024-04-20 11:49:19,175: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.05535679789528129]
[2024-04-20 11:49:19,840: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.042540063254103075]
[2024-04-20 11:49:20,505: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.04235789035831949]
[2024-04-20 11:49:21,168: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.02977543996537369]
[2024-04-20 11:49:21,822: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.021832321167205165]
[2024-04-20 11:49:22,476: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.04786915247909566]
[2024-04-20 11:49:23,128: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.030016924630662096]
[2024-04-20 11:49:23,780: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.03888257685929223]
[2024-04-20 11:49:24,432: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.04944352492779821]
[2024-04-20 11:49:25,084: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.02253281213791689]
[2024-04-20 11:49:25,738: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.0669979007702898]
[2024-04-20 11:49:26,392: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.04109108131129614]
[2024-04-20 11:49:27,044: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.032659707655081874]
[2024-04-20 11:49:27,693: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.0391305113581891]
[2024-04-20 11:49:28,350: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.03607008465005063]
[2024-04-20 11:49:29,005: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.050549693962234875]
[2024-04-20 11:49:29,658: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.030659785338285242]
[2024-04-20 11:49:30,310: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.03332911968814961]
[2024-04-20 11:49:30,966: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.019450625503589725]
[2024-04-20 11:49:31,617: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.03851368898459827]
[2024-04-20 11:49:32,278: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.08625581068774105]
[2024-04-20 11:49:32,940: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.034638795466290194]
[2024-04-20 11:49:33,598: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.035069712858840925]
[2024-04-20 11:49:34,255: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.023228961112043773]
[2024-04-20 11:49:34,912: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.03719181504345019]
[2024-04-20 11:49:35,563: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.13381506741200722]
[2024-04-20 11:49:36,215: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.020742221289953913]
[2024-04-20 11:49:36,865: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.03204993222366648]
[2024-04-20 11:49:37,518: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.04431452377378439]
[2024-04-20 11:49:38,171: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.04080917877398969]
[2024-04-20 11:49:38,821: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.05701519203942803]
[2024-04-20 11:49:39,474: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.08436177970063281]
[2024-04-20 11:49:40,126: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.022330846291413724]
[2024-04-20 11:49:40,778: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.05410988648116009]
[2024-04-20 11:49:41,429: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.055821619366173275]
[2024-04-20 11:49:42,082: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.028609214793950163]
[2024-04-20 11:49:42,731: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.03441183593119244]
[2024-04-20 11:49:43,378: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.034636325109185975]
[2024-04-20 11:49:44,027: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.05532796556313054]
[2024-04-20 11:49:44,687: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.07118178940277815]
[2024-04-20 11:49:45,348: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.02985658535530274]
[2024-04-20 11:49:46,020: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.02381871632411175]
[2024-04-20 11:49:46,682: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.06769096380270387]
[2024-04-20 11:49:47,344: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.05067371579921908]
[2024-04-20 11:49:47,999: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.0767893548254461]
[2024-04-20 11:49:48,654: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.02182334565215303]
[2024-04-20 11:49:49,307: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.05826531201241561]
[2024-04-20 11:49:49,960: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.024246408771481907]
[2024-04-20 11:49:50,612: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.02230377762970153]
[2024-04-20 11:49:51,265: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.02305099264294334]
[2024-04-20 11:49:51,918: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.025989234399759455]
[2024-04-20 11:49:52,569: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.02893257647986454]
[2024-04-20 11:49:53,220: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.02150751544175524]
[2024-04-20 11:49:53,875: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.025830873053541967]
[2024-04-20 11:49:54,527: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.025895559901090444]
[2024-04-20 11:49:55,178: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.027710557128395093]
[2024-04-20 11:49:55,831: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.01596615633274515]
[2024-04-20 11:49:56,480: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.026563889850893873]
[2024-04-20 11:49:57,134: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.04597206181222671]
[2024-04-20 11:49:57,797: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.02060775308830555]
[2024-04-20 11:49:58,458: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.03931770585948786]
[2024-04-20 11:49:59,117: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.057148899477715155]
[2024-04-20 11:49:59,780: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.04788421229352568]
[2024-04-20 11:50:00,447: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.041207703207665564]
[2024-04-20 11:50:01,103: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.021014717447592188]
[2024-04-20 11:50:01,754: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.044494012184941034]
[2024-04-20 11:50:02,407: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.046889259114864024]
[2024-04-20 11:50:03,059: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.012775069366521922]
[2024-04-20 11:50:03,711: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.06875509246430794]
[2024-04-20 11:50:04,364: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.08125440952398208]
[2024-04-20 11:50:05,011: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.060399890170918145]
[2024-04-20 11:50:05,661: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.026647900804181564]
[2024-04-20 11:50:06,315: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.02106244955768419]
[2024-04-20 11:50:06,963: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.028029147982353866]
[2024-04-20 11:50:07,616: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.04108238261799585]
[2024-04-20 11:50:08,268: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.04602218822378082]
[2024-04-20 11:50:08,922: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.04254803871536879]
[2024-04-20 11:50:09,570: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.021399649053092492]
[2024-04-20 11:50:10,222: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.03722000043528685]
[2024-04-20 11:50:10,881: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.13910247275873827]
[2024-04-20 11:50:11,539: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.05716103294083043]
[2024-04-20 11:50:12,198: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.06932592667951475]
[2024-04-20 11:50:12,860: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.024582425813516773]
[2024-04-20 11:50:13,525: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.05309910899870719]
[2024-04-20 11:50:14,179: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.033273628222315096]
[2024-04-20 11:50:14,835: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.06687006730790261]
[2024-04-20 11:50:15,482: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.025131473440204225]
[2024-04-20 11:50:16,137: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.027887782286473334]
[2024-04-20 11:50:16,789: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.020077297297365532]
[2024-04-20 11:50:17,445: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.013331798599054225]
[2024-04-20 11:50:18,097: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.0543001826037104]
[2024-04-20 11:50:18,751: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.06942102683564047]
[2024-04-20 11:50:19,403: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.026569053374347656]
[2024-04-20 11:50:20,057: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.03732406410304033]
[2024-04-20 11:50:20,710: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.013871535633628898]
[2024-04-20 11:50:21,365: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.04508558540134674]
[2024-04-20 11:50:22,018: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.0476836186467946]
[2024-04-20 11:50:22,666: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.027335882793558183]
[2024-04-20 11:50:23,315: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.033751626080795225]
[2024-04-20 11:50:23,979: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.02197345931033254]
[2024-04-20 11:50:24,643: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.0961566286707074]
[2024-04-20 11:50:25,304: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.01671773904749781]
[2024-04-20 11:50:25,966: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.050095856153471036]
[2024-04-20 11:50:26,628: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.02331481415496801]
[2024-04-20 11:50:27,281: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.03192865636917743]
[2024-04-20 11:50:27,935: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.03440935291674723]
[2024-04-20 11:50:28,590: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.02193886736868559]
[2024-04-20 11:50:29,239: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.03128269377538898]
[2024-04-20 11:50:29,896: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.06412381488844403]
[2024-04-20 11:50:30,551: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.07367295751090742]
[2024-04-20 11:50:31,201: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.07710796452521254]
[2024-04-20 11:50:31,852: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.04251035324472793]
[2024-04-20 11:50:32,506: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.035084894214464764]
[2024-04-20 11:50:33,163: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.04847036269032133]
[2024-04-20 11:50:33,812: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.015474374687208902]
[2024-04-20 11:50:34,464: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.03467506087328558]
[2024-04-20 11:50:35,118: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.061037017040689534]
[2024-04-20 11:50:35,772: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.02587036749363538]
[2024-04-20 11:50:36,423: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.029386037686778624]
[2024-04-20 11:50:37,088: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.028684957551320844]
[2024-04-20 11:50:37,748: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.029579599288430593]
[2024-04-20 11:50:38,410: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.04236607085465089]
[2024-04-20 11:50:39,069: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.02818003642665055]
[2024-04-20 11:50:39,736: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.039824398755240846]
[2024-04-20 11:50:40,388: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.026637856715477658]
[2024-04-20 11:50:41,039: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.017324383276026506]
[2024-04-20 11:50:41,692: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.03032020580509474]
[2024-04-20 11:50:42,344: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.03451551474907659]
[2024-04-20 11:50:42,998: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.019007371924703954]
[2024-04-20 11:50:43,652: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.02739390574114514]
[2024-04-20 11:50:44,307: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.03803246338370413]
[2024-04-20 11:50:44,962: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.02341553887216497]
[2024-04-20 11:50:45,618: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.019101725502738774]
[2024-04-20 11:50:46,269: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.02534006905328277]
[2024-04-20 11:50:46,925: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.01911288859961277]
[2024-04-20 11:50:47,581: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.05703756963425525]
[2024-04-20 11:50:48,231: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.044707442713466126]
[2024-04-20 11:50:48,881: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.03267333015683107]
[2024-04-20 11:50:49,536: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.025369560099912716]
[2024-04-20 11:50:50,193: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.031954141616731276]
[2024-04-20 11:50:50,861: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.02901760010992338]
[2024-04-20 11:50:51,520: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.04029122595461884]
[2024-04-20 11:50:52,179: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.021017248531101956]
[2024-04-20 11:50:52,845: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.037665180570517875]
[2024-04-20 11:50:53,501: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.015881945237312286]
[2024-04-20 11:50:54,152: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.019349544923544862]
[2024-04-20 11:50:54,806: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.04491625228547492]
[2024-04-20 11:50:55,468: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.04419940459586339]
[2024-04-20 11:50:56,126: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.036685472569429806]
[2024-04-20 11:50:56,778: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.04137142318997694]
[2024-04-20 11:50:57,433: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.053729650186074736]
[2024-04-20 11:50:58,091: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.02674515210658038]
[2024-04-20 11:50:58,747: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.018893279872579553]
[2024-04-20 11:50:59,398: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.02789018362793785]
[2024-04-20 11:51:00,055: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.03999349631673947]
[2024-04-20 11:51:00,709: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.04481783439075052]
[2024-04-20 11:51:01,365: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.05223625011151104]
[2024-04-20 11:51:02,014: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.022956327670448515]
[2024-04-20 11:51:02,664: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.008562127386964002]
[2024-04-20 11:51:03,330: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.0483272128408399]
[2024-04-20 11:51:03,989: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.032888974486205105]
[2024-04-20 11:51:04,652: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.03208364228824993]
[2024-04-20 11:51:05,321: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.02735072805632448]
[2024-04-20 11:51:05,989: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.009918221167077693]
[2024-04-20 11:51:06,641: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.02482509316916042]
[2024-04-20 11:51:07,296: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.03158594194667068]
[2024-04-20 11:51:07,952: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.04344758020656933]
[2024-04-20 11:51:08,600: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.02202945407167121]
[2024-04-20 11:51:09,253: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.013472498769606697]
[2024-04-20 11:51:09,909: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.013821134774458836]
[2024-04-20 11:51:10,564: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.016771018365366753]
[2024-04-20 11:51:11,220: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.0782794264403587]
[2024-04-20 11:51:11,873: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.01518276451860567]
[2024-04-20 11:51:12,530: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.049174298572816307]
[2024-04-20 11:51:13,183: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.06056588696907363]
[2024-04-20 11:51:13,835: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.046021800441810166]
[2024-04-20 11:51:14,495: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.01978979970812777]
[2024-04-20 11:51:15,155: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.01123847600292782]
[2024-04-20 11:51:15,826: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.038391622190829366]
[2024-04-20 11:51:16,488: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.014313441246637009]
[2024-04-20 11:51:17,164: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.03431115300738846]
[2024-04-20 11:51:17,842: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.043550173098214365]
[2024-04-20 11:51:18,509: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.059516666770135736]
[2024-04-20 11:51:19,173: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.01173329361836644]
[2024-04-20 11:51:19,836: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.021040237214406524]
[2024-04-20 11:51:20,490: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.022093501900700904]
[2024-04-20 11:51:21,143: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.028860913149785884]
[2024-04-20 11:51:21,797: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.01951262075674723]
[2024-04-20 11:51:22,452: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.055691509037446824]
[2024-04-20 11:51:23,103: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.03319797791873153]
[2024-04-20 11:51:23,758: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.03138478490877213]
[2024-04-20 11:51:24,411: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.007884569953248608]
[2024-04-20 11:51:25,066: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.04766965461822198]
[2024-04-20 11:51:25,720: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.01901305201239115]
[2024-04-20 11:51:26,371: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.027002740279501867]
[2024-04-20 11:51:27,025: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.01956729589821368]
[2024-04-20 11:51:27,677: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.03770999219131861]
[2024-04-20 11:51:28,329: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.031807914909373784]
[2024-04-20 11:51:28,985: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.01588117251043048]
[2024-04-20 11:51:29,641: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.024911855334183487]
[2024-04-20 11:51:30,299: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.01697112593824483]
[2024-04-20 11:51:30,967: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.1506944975819214]
[2024-04-20 11:51:31,630: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.05687533813648793]
[2024-04-20 11:51:32,296: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.05294588238014825]
[2024-04-20 11:51:32,972: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.011691532737360342]
[2024-04-20 11:51:33,653: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.04687229065958554]
[2024-04-20 11:51:34,318: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.029236122152431165]
[2024-04-20 11:51:34,980: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.03921817251060854]
[2024-04-20 11:51:35,644: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.030312854711232767]
[2024-04-20 11:51:36,299: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.020165437940156933]
[2024-04-20 11:51:36,955: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.03593378797766207]
[2024-04-20 11:51:37,608: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.021325771165278867]
[2024-04-20 11:51:38,257: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.0262418669157871]
[2024-04-20 11:51:38,911: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.052165616406478904]
[2024-04-20 11:51:39,566: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.0260524077006163]
[2024-04-20 11:51:40,224: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.0286683879653316]
[2024-04-20 11:51:40,882: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.027145842204624765]
[2024-04-20 11:51:41,538: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.02049501867787218]
[2024-04-20 11:51:42,189: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.041829517332564514]
[2024-04-20 11:51:42,843: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.014649503830497176]
[2024-04-20 11:51:43,495: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.03082978816064581]
[2024-04-20 11:51:44,159: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.03427178734231902]
[2024-04-20 11:51:44,825: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.02872395355732971]
[2024-04-20 11:51:45,486: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.03274738795869865]
[2024-04-20 11:51:46,147: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.02021336466602889]
[2024-04-20 11:51:46,817: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.020485173135583703]
[2024-04-20 11:51:47,470: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.01234444000470128]
[2024-04-20 11:51:48,128: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.037450808437517476]
[2024-04-20 11:51:48,783: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.012729104646673196]
[2024-04-20 11:51:49,433: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.01777841419271962]
[2024-04-20 11:51:50,087: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.029919350875454866]
[2024-04-20 11:51:50,739: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.020617441548127495]
[2024-04-20 11:51:51,392: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.00847247523430992]
[2024-04-20 11:51:52,051: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.022111049408812367]
[2024-04-20 11:51:52,701: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.013166080740813327]
[2024-04-20 11:51:53,357: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.017805460770743648]
[2024-04-20 11:51:54,014: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.04486021647979908]
[2024-04-20 11:51:54,671: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.013052770361016324]
[2024-04-20 11:51:55,322: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.03683674847442572]
[2024-04-20 11:51:55,978: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.038427123073073076]
[2024-04-20 11:51:56,632: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.029516016872988594]
[2024-04-20 11:51:57,296: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.1157885178235882]
[2024-04-20 11:51:57,966: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.015254961882473092]
[2024-04-20 11:51:58,627: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.046334098270789735]
[2024-04-20 11:51:59,299: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.049168422056482856]
[2024-04-20 11:51:59,966: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.022992106563489476]
[2024-04-20 11:52:00,621: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.028720523736833967]
[2024-04-20 11:52:01,273: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.034543157412280395]
[2024-04-20 11:52:01,935: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.02234645089439072]
[2024-04-20 11:52:02,587: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.02452598141896644]
[2024-04-20 11:52:03,245: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.020704399431674632]
[2024-04-20 11:52:03,898: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.02440558512071965]
[2024-04-20 11:52:04,551: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.07175151946761443]
[2024-04-20 11:52:05,209: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.019919916126630747]
[2024-04-20 11:52:05,861: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.01772814079890891]
[2024-04-20 11:52:06,515: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.04839368299837238]
[2024-04-20 11:52:07,170: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.08066433100834083]
[2024-04-20 11:52:07,824: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.033950877997202734]
[2024-04-20 11:52:08,480: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.015608552608020444]
[2024-04-20 11:52:09,135: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.013442588106163602]
[2024-04-20 11:52:09,789: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.02941904725691588]
[2024-04-20 11:52:10,452: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.050246388507921624]
[2024-04-20 11:52:11,117: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.01609740611030631]
[2024-04-20 11:52:11,778: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.029488186676853406]
[2024-04-20 11:52:12,439: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.030465037155590215]
[2024-04-20 11:52:13,100: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.02698621687300201]
[2024-04-20 11:52:13,757: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.01726816124943836]
[2024-04-20 11:52:14,411: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.023083748236031026]
[2024-04-20 11:52:15,064: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.02170015438659791]
[2024-04-20 11:52:15,720: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.013803291041119523]
[2024-04-20 11:52:16,374: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.025247864233585028]
[2024-04-20 11:52:17,026: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.03583233132397259]
[2024-04-20 11:52:17,683: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.030213612312378322]
[2024-04-20 11:52:18,335: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.019901339299697212]
[2024-04-20 11:52:18,989: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.02081662775017321]
[2024-04-20 11:52:19,643: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.08168113092723786]
[2024-04-20 11:52:20,296: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.009682988401280217]
[2024-04-20 11:52:20,950: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.010859502520986703]
[2024-04-20 11:52:21,602: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.021631096461405454]
[2024-04-20 11:52:22,255: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.03746575232271955]
[2024-04-20 11:52:22,909: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.0490015026937811]
[2024-04-20 11:52:23,570: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.011608383523935764]
[2024-04-20 11:52:24,243: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.019549141942718114]
[2024-04-20 11:52:24,904: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.0288172127610558]
[2024-04-20 11:52:25,572: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.023284125896048564]
[2024-04-20 11:52:26,233: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.023544909834344416]
[2024-04-20 11:52:26,891: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.09904661759335207]
[2024-04-20 11:52:27,545: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.011479048479821629]
[2024-04-20 11:52:28,200: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.01169831320209459]
[2024-04-20 11:52:28,859: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.027725724878888115]
[2024-04-20 11:52:29,513: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.04843561245963615]
[2024-04-20 11:52:30,168: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.013272727963169828]
[2024-04-20 11:52:30,821: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.04125539610059693]
[2024-04-20 11:52:31,474: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.02343677997158011]
[2024-04-20 11:52:32,129: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.039768858471549186]
[2024-04-20 11:52:32,783: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.031131580063106658]
[2024-04-20 11:52:33,442: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.024207307991692222]
[2024-04-20 11:52:34,094: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.027374651345256427]
[2024-04-20 11:52:34,749: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.030218519273378056]
[2024-04-20 11:52:35,402: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.04743523233935194]
[2024-04-20 11:52:36,060: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.05962312329749167]
[2024-04-20 11:52:36,727: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.05921162172124448]
[2024-04-20 11:52:37,393: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.022618637001026756]
[2024-04-20 11:52:38,059: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.007788170089293801]
[2024-04-20 11:52:38,721: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.020391323781033668]
[2024-04-20 11:52:39,373: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.02279859046343168]
[2024-04-20 11:52:40,025: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.007390461174786187]
[2024-04-20 11:52:40,680: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.03870626834655891]
[2024-04-20 11:52:41,333: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.02383012300447535]
[2024-04-20 11:52:41,988: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.041598583400860485]
[2024-04-20 11:52:42,640: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.024100943660618872]
[2024-04-20 11:52:43,290: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.01590879589126598]
[2024-04-20 11:52:43,948: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.024123423295581304]
[2024-04-20 11:52:44,603: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.016334638801404164]
[2024-04-20 11:52:45,262: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.018479418083614193]
[2024-04-20 11:52:45,915: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.0352414337120503]
[2024-04-20 11:52:46,567: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.047716636184363906]
[2024-04-20 11:52:47,218: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.023600402550529143]
[2024-04-20 11:52:47,869: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.018277732093245656]
[2024-04-20 11:52:48,520: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.02461767292601376]
[2024-04-20 11:52:49,174: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.015681532060969026]
[2024-04-20 11:52:49,834: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.019856134214407947]
[2024-04-20 11:52:50,493: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.03632478856182643]
[2024-04-20 11:52:51,152: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.01992156305383105]
[2024-04-20 11:52:51,816: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.02830577062649519]
[2024-04-20 11:52:52,475: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.03554875087211169]
[2024-04-20 11:52:53,127: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.043952838244172995]
[2024-04-20 11:52:53,779: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.005796512627245394]
[2024-04-20 11:52:54,435: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.016495785677057624]
[2024-04-20 11:52:55,086: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.028816177183486766]
[2024-04-20 11:52:55,739: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.04395119376747292]
[2024-04-20 11:52:56,396: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.04508795943839451]
[2024-04-20 11:52:57,054: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.015306333321905083]
[2024-04-20 11:52:57,708: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.025637710157021817]
[2024-04-20 11:52:58,359: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.02059200960817967]
[2024-04-20 11:52:59,014: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.025727807010041685]
[2024-04-20 11:52:59,667: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.030114938441592697]
[2024-04-20 11:53:00,320: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.02226586840771338]
[2024-04-20 11:53:00,971: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.03561720921851793]
[2024-04-20 11:53:01,623: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.011519199864128587]
[2024-04-20 11:53:02,280: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.017228710490760094]
[2024-04-20 11:53:02,939: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.02648174322646724]
[2024-04-20 11:53:03,603: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.008368396249878422]
[2024-04-20 11:53:04,270: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.009825556993151529]
[2024-04-20 11:53:04,937: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.022505709441916155]
[2024-04-20 11:53:05,597: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.010777749753114586]
[2024-04-20 11:53:06,252: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.026359167650005597]
[2024-04-20 11:53:06,903: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.01678833274112001]
[2024-04-20 11:53:07,557: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.04018440047927652]
[2024-04-20 11:53:08,213: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.014769321347540318]
[2024-04-20 11:53:08,860: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.05275238910677855]
[2024-04-20 11:53:09,513: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.013229040763139889]
[2024-04-20 11:53:10,168: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.0065433540618929]
[2024-04-20 11:53:10,829: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.024296911398213494]
[2024-04-20 11:53:11,486: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.01909271705354809]
[2024-04-20 11:53:12,138: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.027313049740968806]
[2024-04-20 11:53:12,798: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.01164620038920473]
[2024-04-20 11:53:13,450: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.03241568808886176]
[2024-04-20 11:53:14,105: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.08195172610914397]
[2024-04-20 11:53:14,755: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.012238358661639644]
[2024-04-20 11:53:15,412: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.011049987791945734]
[2024-04-20 11:53:16,073: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.028525236100148944]
[2024-04-20 11:53:16,736: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.007571105257653613]
[2024-04-20 11:53:17,397: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.06207646434018267]
[2024-04-20 11:53:18,064: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.023349520065931263]
[2024-04-20 11:53:18,722: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.012715698388068401]
[2024-04-20 11:53:19,379: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.014289621004361097]
[2024-04-20 11:53:20,032: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.014801474693073373]
[2024-04-20 11:53:20,687: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.044157620923070656]
[2024-04-20 11:53:21,338: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.008761873747498213]
[2024-04-20 11:53:21,992: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.02218880890526138]
[2024-04-20 11:53:22,647: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.03521169193457054]
[2024-04-20 11:53:23,300: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.033649934936835144]
[2024-04-20 11:53:23,954: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.011116188445967809]
[2024-04-20 11:53:24,606: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.035893176656482964]
[2024-04-20 11:53:25,256: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.00658877079051689]
[2024-04-20 11:53:25,910: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.024576592315632986]
[2024-04-20 11:53:26,564: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.011854758376150418]
[2024-04-20 11:53:27,217: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.024877545696999855]
[2024-04-20 11:53:27,869: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.017360091730416492]
[2024-04-20 11:53:28,520: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.0348041227229759]
[2024-04-20 11:53:29,185: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.031423373639782724]
[2024-04-20 11:53:29,848: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.005627648894316902]
[2024-04-20 11:53:30,516: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.053549953932716804]
[2024-04-20 11:53:31,178: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.03550613320662171]
[2024-04-20 11:53:31,837: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.02642108038204994]
[2024-04-20 11:53:32,493: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.02842153880652788]
[2024-04-20 11:53:33,149: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.014112104141497344]
[2024-04-20 11:53:33,804: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.01144668292061682]
[2024-04-20 11:53:34,456: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.025842435005960448]
[2024-04-20 11:53:35,111: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.024086263741227302]
[2024-04-20 11:53:35,762: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.03494054287725537]
[2024-04-20 11:53:36,414: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.018708842451764233]
[2024-04-20 11:53:37,066: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.011154621820400662]
[2024-04-20 11:53:37,722: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.019097202527424292]
[2024-04-20 11:53:38,378: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.022817679084442356]
[2024-04-20 11:53:39,034: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.061644901148401376]
[2024-04-20 11:53:39,685: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.038594792541763616]
[2024-04-20 11:53:40,340: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.036919608692995036]
[2024-04-20 11:53:40,991: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.007568616036290874]
[2024-04-20 11:53:41,655: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.03420034902037998]
[2024-04-20 11:53:42,319: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.026693464143697256]
[2024-04-20 11:53:42,983: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.018286038144091063]
[2024-04-20 11:53:43,645: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.03323350083715781]
[2024-04-20 11:53:44,301: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.03156851129157831]
[2024-04-20 11:53:44,954: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.012913588600366633]
[2024-04-20 11:53:45,609: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.027806674982308696]
[2024-04-20 11:53:46,260: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.03561102472483457]
[2024-04-20 11:53:46,923: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.02279638215634689]
[2024-04-20 11:53:47,578: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.029303896296549333]
[2024-04-20 11:53:48,236: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.02919524380208726]
[2024-04-20 11:53:48,894: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.04261521459045672]
[2024-04-20 11:53:49,549: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.018434789338116143]
[2024-04-20 11:53:50,206: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.014669243144871903]
[2024-04-20 11:53:50,861: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.008615545751476337]
[2024-04-20 11:53:51,516: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.005950538036444037]
[2024-04-20 11:53:52,169: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.014309249230112894]
[2024-04-20 11:53:52,823: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.01761731786863326]
[2024-04-20 11:53:53,482: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.023765110083459322]
[2024-04-20 11:53:54,134: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.013255232588394013]
[2024-04-20 11:53:54,789: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.04517556574278328]
[2024-04-20 11:53:55,453: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.025672265791151297]
[2024-04-20 11:53:56,114: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.01855348055709497]
[2024-04-20 11:53:56,769: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.009211507973412329]
[2024-04-20 11:53:57,428: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.013892263910039077]
[2024-04-20 11:53:58,078: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.014228825899533136]
[2024-04-20 11:53:58,731: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.0261942448144317]
[2024-04-20 11:53:59,385: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.036546292075389036]
[2024-04-20 11:54:00,039: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.010607187892249353]
[2024-04-20 11:54:00,691: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.015422889935339728]
[2024-04-20 11:54:01,345: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.007881190645794301]
[2024-04-20 11:54:01,999: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.031256751231488]
[2024-04-20 11:54:02,648: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.03101406816598567]
[2024-04-20 11:54:03,303: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.024928173113045102]
[2024-04-20 11:54:03,954: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.049036286248854505]
[2024-04-20 11:54:04,604: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.042407627563603265]
[2024-04-20 11:54:05,256: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.025039137516073482]
[2024-04-20 11:54:05,908: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.01680243912122342]
[2024-04-20 11:54:06,560: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.019849696225572974]
[2024-04-20 11:54:07,213: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.02515516289394772]
[2024-04-20 11:54:07,870: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.023829204211812404]
[2024-04-20 11:54:08,538: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.024216964458217225]
[2024-04-20 11:54:09,202: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.018127310238739716]
[2024-04-20 11:54:09,876: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.02054507460032275]
[2024-04-20 11:54:10,540: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.009434396771797138]
[2024-04-20 11:54:11,191: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.02815212087861656]
[2024-04-20 11:54:11,846: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.05602689740262707]
[2024-04-20 11:54:12,500: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.05665847099498532]
[2024-04-20 11:54:13,153: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.040948373277073395]
[2024-04-20 11:54:13,806: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.02150354610979223]
[2024-04-20 11:54:14,467: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.025613165763381903]
[2024-04-20 11:54:15,119: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.022401094188826118]
[2024-04-20 11:54:15,778: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.028667379244335538]
[2024-04-20 11:54:16,433: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.0225070690105332]
[2024-04-20 11:54:17,087: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.028714608321528654]
[2024-04-20 11:54:17,741: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.014711808376900257]
[2024-04-20 11:54:18,397: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.02090292044890313]
[2024-04-20 11:54:19,055: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.024469166189470284]
[2024-04-20 11:54:19,724: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.025432625269857595]
[2024-04-20 11:54:20,380: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.03080030602050583]
[2024-04-20 11:54:21,044: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.02881752329616625]
[2024-04-20 11:54:21,705: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.013934489092295903]
[2024-04-20 11:54:22,368: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.008842946000571904]
[2024-04-20 11:54:23,032: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.01980626415624903]
[2024-04-20 11:54:23,690: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.03352265075789206]
[2024-04-20 11:54:24,356: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.014613371366859798]
[2024-04-20 11:54:25,008: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.035190761394086875]
[2024-04-20 11:54:25,661: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.02837572303243203]
[2024-04-20 11:54:26,317: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.017409541423635978]
[2024-04-20 11:54:26,969: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.02913928414150052]
[2024-04-20 11:54:27,621: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.0654643470113946]
[2024-04-20 11:54:28,275: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.034760795487087576]
[2024-04-20 11:54:28,928: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.0038693178239549795]
[2024-04-20 11:54:29,588: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.02417941638869976]
[2024-04-20 11:54:30,239: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.026017603612234423]
[2024-04-20 11:54:30,892: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.050740490189693906]
[2024-04-20 11:54:31,543: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.024952744033131437]
[2024-04-20 11:54:32,191: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.021771631848838416]
[2024-04-20 11:54:32,847: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.04774880492423066]
[2024-04-20 11:54:33,499: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.01809308195802879]
[2024-04-20 11:54:34,152: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.011029086994504875]
[2024-04-20 11:54:34,802: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.018659510723658013]
[2024-04-20 11:54:35,459: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.025405411712177545]
[2024-04-20 11:54:36,117: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.04205699936413732]
[2024-04-20 11:54:36,785: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.015461980758651848]
[2024-04-20 11:54:37,464: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.017916256053217946]
[2024-04-20 11:54:38,134: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.02986902315576896]
[2024-04-20 11:54:38,799: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.011834879165516387]
[2024-04-20 11:54:39,472: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.010762782977204469]
[2024-04-20 11:54:40,134: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.01477566165167381]
[2024-04-20 11:54:40,794: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.02214500377687602]
[2024-04-20 11:54:41,448: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.02095753855547336]
[2024-04-20 11:54:42,105: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.012547976396789168]
[2024-04-20 11:54:42,754: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.02247037544612044]
[2024-04-20 11:54:43,411: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.06238824397964675]
[2024-04-20 11:54:44,064: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.01652667003848243]
[2024-04-20 11:54:44,715: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.02838664171420267]
[2024-04-20 11:54:45,366: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.02247774106677035]
[2024-04-20 11:54:46,017: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.03861449680398238]
[2024-04-20 11:54:46,670: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.022224109177795815]
[2024-04-20 11:54:47,324: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.014139426159114711]
[2024-04-20 11:54:47,981: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.006603283634383157]
[2024-04-20 11:54:48,634: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.011104362169741847]
[2024-04-20 11:54:49,298: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.013793230413051255]
[2024-04-20 11:54:49,964: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.01453590964509995]
[2024-04-20 11:54:50,626: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.029055116669076234]
[2024-04-20 11:54:51,297: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.014802156733296065]
[2024-04-20 11:54:51,949: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.01242932357774232]
[2024-04-20 11:54:52,605: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.031361407187375366]
[2024-04-20 11:54:53,262: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.015070137278962647]
[2024-04-20 11:54:53,916: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.011165463062047914]
[2024-04-20 11:54:54,569: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.021435453591831306]
[2024-04-20 11:54:55,221: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.057457108923898235]
[2024-04-20 11:54:55,874: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.0175657581643858]
[2024-04-20 11:54:56,525: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.012597432262076349]
[2024-04-20 11:54:57,172: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.01620660945451219]
[2024-04-20 11:54:57,823: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.03419494091665044]
[2024-04-20 11:54:58,480: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.07369887701918583]
[2024-04-20 11:54:59,138: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.012621161240461606]
[2024-04-20 11:54:59,786: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.016486652532090855]
[2024-04-20 11:55:00,436: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.03378818903500154]
[2024-04-20 11:55:01,090: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.042255267783975724]
[2024-04-20 11:55:01,751: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.020361460563107357]
[2024-04-20 11:55:02,411: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.020783495975525465]
[2024-04-20 11:55:03,071: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.04315804622398884]
[2024-04-20 11:55:03,735: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.030749147979165094]
[2024-04-20 11:55:04,395: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.043352997154601274]
[2024-04-20 11:55:05,049: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.023879688943327322]
[2024-04-20 11:55:05,704: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.015087857125808684]
[2024-04-20 11:55:06,357: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.028801542568117323]
[2024-04-20 11:55:07,010: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.016038175659675025]
[2024-04-20 11:55:07,662: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.016554165977536194]
[2024-04-20 11:55:08,310: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.015301537972856579]
[2024-04-20 11:55:08,964: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.02578989026526845]
[2024-04-20 11:55:09,615: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.014026924162600495]
[2024-04-20 11:55:10,269: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.043654126036115584]
[2024-04-20 11:55:10,927: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.011788705203204469]
[2024-04-20 11:55:11,577: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.007962796528861314]
[2024-04-20 11:55:12,234: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.012572537909033964]
[2024-04-20 11:55:12,891: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.03222458919551146]
[2024-04-20 11:55:13,539: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.03646661287699361]
[2024-04-20 11:55:14,191: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.021884736905461822]
[2024-04-20 11:55:14,849: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.020452177542886914]
[2024-04-20 11:55:15,507: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.026485420680487707]
[2024-04-20 11:55:16,164: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.01831135558945043]
[2024-04-20 11:55:16,821: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.013999677127544095]
[2024-04-20 11:55:17,485: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.00677443602359633]
[2024-04-20 11:55:18,144: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.020702192315424327]
[2024-04-20 11:55:18,796: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.0338877494810202]
[2024-04-20 11:55:19,449: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.014217242268835136]
[2024-04-20 11:55:20,098: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.02311745450355201]
[2024-04-20 11:55:20,749: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.013718049406833854]
[2024-04-20 11:55:21,404: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.028192271497680683]
[2024-04-20 11:55:22,058: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.045924603968692704]
[2024-04-20 11:55:22,709: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.004177543666383044]
[2024-04-20 11:55:23,359: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.01304934246293473]
[2024-04-20 11:55:24,007: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.014516641672641837]
[2024-04-20 11:55:24,663: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.03163395928826128]
[2024-04-20 11:55:25,318: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.025170742158051266]
[2024-04-20 11:55:25,970: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.018183261217981396]
[2024-04-20 11:55:26,620: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.00840799806003052]
[2024-04-20 11:55:27,276: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.02519328236745733]
[2024-04-20 11:55:27,930: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.014291338108277917]
[2024-04-20 11:55:28,589: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.05141405054358763]
[2024-04-20 11:55:29,254: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.022062458985804563]
[2024-04-20 11:55:29,916: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.03874699195535678]
[2024-04-20 11:55:30,575: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.023800723889931482]
[2024-04-20 11:55:31,233: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.04514520570368188]
[2024-04-20 11:55:31,888: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.01748592016141839]
[2024-04-20 11:55:32,543: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.008448637912513513]
[2024-04-20 11:55:33,196: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.03521671354901445]
[2024-04-20 11:55:33,851: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.03389919999363374]
[2024-04-20 11:55:34,503: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.013684785306903017]
[2024-04-20 11:55:35,158: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.020815905267203172]
[2024-04-20 11:55:35,808: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.01697313604311298]
[2024-04-20 11:55:36,461: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.036257323310109654]
[2024-04-20 11:55:37,112: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.026849125619006094]
[2024-04-20 11:55:37,765: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.009105975196349876]
[2024-04-20 11:55:38,417: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.010714577672155171]
[2024-04-20 11:55:39,070: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.02203053931133786]
[2024-04-20 11:55:39,731: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.022754344079896037]
[2024-04-20 11:55:40,386: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.027057701482468752]
[2024-04-20 11:55:41,051: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.03088490998704731]
[2024-04-20 11:55:41,713: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.013639281972095213]
[2024-04-20 11:55:42,372: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.052695649844137826]
[2024-04-20 11:55:43,033: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.011418087339065755]
[2024-04-20 11:55:43,693: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.01825317638242404]
[2024-04-20 11:55:44,352: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.011054743709796668]
[2024-04-20 11:55:45,002: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.016493764937399014]
[2024-04-20 11:55:45,658: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.004472897393699136]
[2024-04-20 11:55:46,315: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.004667294873501071]
[2024-04-20 11:55:46,972: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.02843471661005591]
[2024-04-20 11:55:47,627: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.032613280879952716]
[2024-04-20 11:55:48,281: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.014803523242917288]
[2024-04-20 11:55:48,934: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.010025134394073333]
[2024-04-20 11:55:49,590: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.04202474904333151]
[2024-04-20 11:55:50,244: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.021376494899304235]
[2024-04-20 11:55:50,898: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.019167266963855723]
[2024-04-20 11:55:51,554: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.0734810177134316]
[2024-04-20 11:55:52,205: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.012069538582711339]
[2024-04-20 11:55:52,861: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.019044575879038118]
[2024-04-20 11:55:53,515: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.013508002894645585]
[2024-04-20 11:55:54,185: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.026632587533701773]
[2024-04-20 11:55:54,849: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.016371712994860486]
[2024-04-20 11:55:55,515: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.03284259476896862]
[2024-04-20 11:55:56,190: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.04983105390406047]
[2024-04-20 11:55:56,853: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.018669594173962484]
[2024-04-20 11:55:57,507: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.049507386478779426]
[2024-04-20 11:55:58,160: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.010824874735782785]
[2024-04-20 11:55:58,813: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.025247402416971144]
[2024-04-20 11:55:59,465: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.017859821518619458]
[2024-04-20 11:56:00,117: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.015574997168061981]
[2024-04-20 11:56:00,770: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.01933808208183327]
[2024-04-20 11:56:01,427: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.006092233599818647]
[2024-04-20 11:56:02,078: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.011528173250856272]
[2024-04-20 11:56:02,732: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.024125149593879472]
[2024-04-20 11:56:03,385: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.04108110395620014]
[2024-04-20 11:56:04,044: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.03303234975392631]
[2024-04-20 11:56:04,699: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.03317759886362953]
[2024-04-20 11:56:05,354: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.014771748647922776]
[2024-04-20 11:56:06,006: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.009923991279805276]
[2024-04-20 11:56:06,659: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.009663237316036405]
[2024-04-20 11:56:07,345: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.010348690398697435]
[2024-04-20 11:56:08,012: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.0567024735506581]
[2024-04-20 11:56:08,673: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.0138523346369514]
[2024-04-20 11:56:09,341: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.013486429009997341]
[2024-04-20 11:56:10,006: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.0345071595246403]
[2024-04-20 11:56:10,662: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.03185078121515007]
[2024-04-20 11:56:11,319: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.020411341441393765]
[2024-04-20 11:56:11,972: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.02298383607375176]
[2024-04-20 11:56:12,628: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.07630204380388642]
[2024-04-20 11:56:13,278: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.02780433254782179]
[2024-04-20 11:56:13,928: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.01004401114741562]
[2024-04-20 11:56:14,582: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.009397665077604037]
[2024-04-20 11:56:15,235: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.010983943727142736]
[2024-04-20 11:56:15,887: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.014728246801210125]
[2024-04-20 11:56:16,538: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.012731023570683076]
[2024-04-20 11:56:17,188: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.015358628733788134]
[2024-04-20 11:56:17,838: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.01030815023731191]
[2024-04-20 11:56:18,488: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.007810989255227689]
[2024-04-20 11:56:19,143: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.028918371397144354]
[2024-04-20 11:56:19,795: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.014480862863961911]
[2024-04-20 11:56:20,460: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.023113274194547905]
[2024-04-20 11:56:21,123: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.009011274527836018]
[2024-04-20 11:56:21,791: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.039288882388249916]
[2024-04-20 11:56:22,246: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.05182438796671009]
[2024-04-20 11:56:22,463: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.010528411657474626]
[2024-04-20 11:56:22,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.020946589802412745]
[2024-04-20 11:56:22,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.008263425335861514]
[2024-04-20 11:56:23,099: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.008774186629743132]
[2024-04-20 11:56:23,303: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.01773573581913229]
[2024-04-20 11:56:23,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.010271869282116985]
[2024-04-20 11:56:23,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.010355785887665274]
[2024-04-20 11:56:23,925: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.01910299935344456]
[2024-04-20 11:56:24,128: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.021527828560645883]
[2024-04-20 11:56:24,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.016979943582971967]
[2024-04-20 11:56:24,539: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.015427876235832225]
[2024-04-20 11:56:24,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.029301927038666447]
[2024-04-20 11:56:24,954: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.02905427864655643]
[2024-04-20 11:56:25,161: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.004421318709925496]
[2024-04-20 11:56:25,372: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.014568286778041022]
[2024-04-20 11:56:25,578: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.012308834825544098]
[2024-04-20 11:56:25,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.01096460131472839]
[2024-04-20 11:56:25,989: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.03142444209603707]
[2024-04-20 11:56:26,194: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.014788473336154425]
[2024-04-20 11:56:26,401: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.024986325263945515]
[2024-04-20 11:56:26,608: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.013464716893210152]
[2024-04-20 11:56:26,815: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.010892803489574969]
[2024-04-20 11:56:27,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.02167057956190693]
[2024-04-20 11:56:27,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.01412496320963679]
[2024-04-20 11:56:27,432: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.008025884891695442]
[2024-04-20 11:56:27,639: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.005576688867215818]
[2024-04-20 11:56:27,846: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.014087430075881497]
[2024-04-20 11:56:28,053: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.02518914971467261]
[2024-04-20 11:56:28,258: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.03885196714531048]
[2024-04-20 11:56:28,459: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.005734284500651644]
[2024-04-20 11:56:28,662: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.020709509096390397]
[2024-04-20 11:56:28,870: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.011260703354513759]
[2024-04-20 11:56:29,081: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.011619907159474679]
[2024-04-20 11:56:29,287: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.017895426405599612]
[2024-04-20 11:56:29,491: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.03445846009398814]
[2024-04-20 11:56:29,698: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.012483838893387004]
[2024-04-20 11:56:29,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.022719293336815237]
[2024-04-20 11:56:30,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.01690819089445169]
[2024-04-20 11:56:30,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.022516044619907107]
[2024-04-20 11:56:30,528: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.009539602327750358]
[2024-04-20 11:56:30,736: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.0051519119791189495]
[2024-04-20 11:56:30,944: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.00703907146191115]
[2024-04-20 11:56:31,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.012816298216073828]
[2024-04-20 11:56:31,356: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.035190222430624134]
[2024-04-20 11:56:31,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.015600930424820995]
[2024-04-20 11:56:31,768: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.01519457941499019]
[2024-04-20 11:56:31,974: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.010369644403326012]
[2024-04-20 11:56:32,179: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.02553467892991627]
[2024-04-20 11:56:32,386: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.03651072643889326]
[2024-04-20 11:56:32,594: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.013122245715185778]
[2024-04-20 11:56:32,804: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.0071176954091815795]
[2024-04-20 11:56:33,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.028920242463349642]
[2024-04-20 11:56:33,221: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.020899217307756568]
[2024-04-20 11:56:33,432: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.006039334794546536]
[2024-04-20 11:56:33,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.031365300568690385]
[2024-04-20 11:56:33,852: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.031078801632913225]
[2024-04-20 11:56:34,066: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.010113103437254335]
[2024-04-20 11:56:34,277: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.01254390369423451]
[2024-04-20 11:56:34,485: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.012419764877227036]
[2024-04-20 11:56:34,694: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.00823503535070146]
[2024-04-20 11:56:34,908: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.007081528887465748]
[2024-04-20 11:56:35,118: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.021092205922664267]
[2024-04-20 11:56:35,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.011775308370124549]
[2024-04-20 11:56:35,539: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.011318543025944936]
[2024-04-20 11:56:35,752: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.008941784370288846]
[2024-04-20 11:56:35,962: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.02876599946901755]
[2024-04-20 11:56:36,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.05712672866378942]
[2024-04-20 11:56:36,377: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.01675321805184534]
[2024-04-20 11:56:36,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.013559103269275403]
[2024-04-20 11:56:36,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.013638306252584881]
[2024-04-20 11:56:36,997: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.010589715235240204]
[2024-04-20 11:56:37,204: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.008306074543464123]
[2024-04-20 11:56:37,411: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.01785508338697792]
[2024-04-20 11:56:37,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.03991567107283196]
[2024-04-20 11:56:37,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.007511749349160267]
[2024-04-20 11:56:38,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.039165524900893534]
[2024-04-20 11:56:38,242: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.019044996943030044]
[2024-04-20 11:56:38,450: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.021546795115075023]
[2024-04-20 11:56:38,657: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.011838200882618527]
[2024-04-20 11:56:38,865: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.02243899556367794]
[2024-04-20 11:56:39,072: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.013375026399862119]
[2024-04-20 11:56:39,276: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.014640338996617925]
[2024-04-20 11:56:39,481: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.014283710371916674]
[2024-04-20 11:56:39,689: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.024193675441394304]
[2024-04-20 11:56:39,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.006664153097701969]
[2024-04-20 11:56:40,101: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.03021578834267665]
[2024-04-20 11:56:40,308: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.010068231179898354]
[2024-04-20 11:56:40,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.023616331982794305]
[2024-04-20 11:56:40,728: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.005079469333987874]
[2024-04-20 11:56:40,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.013660828381715177]
[2024-04-20 11:56:41,146: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.016039341211399005]
[2024-04-20 11:56:41,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.0218183748754564]
[2024-04-20 11:56:41,563: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.01460461770048436]
[2024-04-20 11:56:41,772: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.016270253274260616]
[2024-04-20 11:56:41,979: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.05976532207498001]
[2024-04-20 11:56:42,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.029804464497312583]
[2024-04-20 11:56:42,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.00503667261809329]
[2024-04-20 11:56:42,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.014733611342490623]
[2024-04-20 11:56:42,803: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.010749631615505443]
[2024-04-20 11:56:43,010: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.023417435936955815]
[2024-04-20 11:56:43,217: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.0197653087006791]
[2024-04-20 11:56:43,424: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.013268694479274657]
[2024-04-20 11:56:43,629: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.022778615970993947]
[2024-04-20 11:56:43,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.010451307524586057]
[2024-04-20 11:56:44,050: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.007619165663098944]
[2024-04-20 11:56:44,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.019741488918923352]
[2024-04-20 11:56:44,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.015865763718793786]
[2024-04-20 11:56:44,671: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.018054053671368506]
[2024-04-20 11:56:44,880: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.03627770173451445]
[2024-04-20 11:56:45,088: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.012586432601872751]
[2024-04-20 11:56:45,295: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.00938470017637773]
[2024-04-20 11:56:45,500: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.017804375822242577]
[2024-04-20 11:56:45,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.032883172297617155]
[2024-04-20 11:56:45,917: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.004445527127132745]
[2024-04-20 11:56:46,125: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.01000624745751377]
[2024-04-20 11:56:46,331: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.027728192101510292]
[2024-04-20 11:56:46,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.015203594944223629]
[2024-04-20 11:56:46,758: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.01689300376491802]
[2024-04-20 11:56:46,969: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.030238783830850605]
[2024-04-20 11:56:47,181: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.03830581435186618]
[2024-04-20 11:56:47,400: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.07398117104797815]
[2024-04-20 11:56:47,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.020272780207143747]
[2024-04-20 11:56:47,824: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.010327467485065182]
[2024-04-20 11:56:48,037: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.041089342101049]
[2024-04-20 11:56:48,250: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.007527891122600353]
[2024-04-20 11:56:48,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.02160518179427652]
[2024-04-20 11:56:48,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.030460272929044848]
[2024-04-20 11:56:48,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.003319753152281787]
[2024-04-20 11:56:49,099: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.026080403773544515]
[2024-04-20 11:56:49,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.06457283330036083]
[2024-04-20 11:56:49,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.015104190316586]
[2024-04-20 11:56:49,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.02187935311088783]
[2024-04-20 11:56:49,940: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.061668309702631915]
[2024-04-20 11:56:50,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.02546285809427368]
[2024-04-20 11:56:50,359: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.009969605562259787]
[2024-04-20 11:56:50,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.031084594761262765]
[2024-04-20 11:56:50,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.0425663276778482]
[2024-04-20 11:56:50,978: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.019271797881024427]
[2024-04-20 11:56:51,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.014446016422344133]
[2024-04-20 11:56:51,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.08941513132095621]
[2024-04-20 11:56:51,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.011487764478213177]
[2024-04-20 11:56:51,805: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.003913154554423024]
[2024-04-20 11:56:52,013: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.016459659236499658]
[2024-04-20 11:56:52,218: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.03119578565269957]
[2024-04-20 11:56:52,426: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.015259500159008569]
[2024-04-20 11:56:52,641: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.01697159132047752]
[2024-04-20 11:56:52,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.021364347539523414]
[2024-04-20 11:56:53,055: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.0084084194946788]
[2024-04-20 11:56:53,261: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.024728742156346427]
[2024-04-20 11:56:53,471: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.011069266547470126]
[2024-04-20 11:56:53,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.028997238128020728]
[2024-04-20 11:56:53,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.011355566643148013]
[2024-04-20 11:56:54,092: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.016922953833975143]
[2024-04-20 11:56:54,297: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.004898880670558355]
[2024-04-20 11:56:54,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.011226126664093236]
[2024-04-20 11:56:54,713: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.011030530157212531]
[2024-04-20 11:56:54,920: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.00962712233733612]
[2024-04-20 11:56:55,127: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.002372268561720859]
[2024-04-20 11:56:55,332: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.005413369130110368]
[2024-04-20 11:56:55,538: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.01152204497308769]
[2024-04-20 11:56:55,746: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.024974092292897498]
[2024-04-20 11:56:55,951: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.03931051374552568]
[2024-04-20 11:56:56,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.009546318109041937]
[2024-04-20 11:56:56,362: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.032804823732824444]
[2024-04-20 11:56:56,567: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.014328572780943393]
[2024-04-20 11:56:56,772: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.0075676060598444915]
[2024-04-20 11:56:56,976: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.0020181523059847133]
[2024-04-20 11:56:57,183: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.018669788022506906]
[2024-04-20 11:56:57,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.05522461745987496]
[2024-04-20 11:56:57,600: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.05770803214726725]
[2024-04-20 11:56:57,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.022751032781534855]
[2024-04-20 11:56:58,013: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.027770273819300098]
[2024-04-20 11:56:58,219: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.022747014500852432]
[2024-04-20 11:56:58,424: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.06789680799943403]
[2024-04-20 11:56:58,628: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.04497984440853918]
[2024-04-20 11:56:58,834: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.01151829764751077]
[2024-04-20 11:56:59,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.005198268358384659]
[2024-04-20 11:56:59,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.10815639510195107]
[2024-04-20 11:56:59,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.009417146515758874]
[2024-04-20 11:56:59,666: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.037697079408679265]
[2024-04-20 11:56:59,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.03774885779036369]
[2024-04-20 11:57:00,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.011588394883891146]
[2024-04-20 11:57:00,302: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.00826474318677135]
[2024-04-20 11:57:00,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.022426908808413356]
[2024-04-20 11:57:00,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.014645194865899871]
[2024-04-20 11:57:00,945: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.006755062757974883]
[2024-04-20 11:57:01,154: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.012898264287141843]
[2024-04-20 11:57:01,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.003983537385825319]
[2024-04-20 11:57:01,570: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 0.01334858765431287]
[2024-04-20 11:57:01,781: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.04104187312161895]
[2024-04-20 11:57:01,992: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.007165831523190932]
[2024-04-20 11:57:02,207: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.004587789945905437]
[2024-04-20 11:57:02,421: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.04033447373584789]
[2024-04-20 11:57:02,638: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.012749915917035929]
[2024-04-20 11:57:02,850: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.006844461659111508]
[2024-04-20 11:57:03,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.04545346187046456]
[2024-04-20 11:57:03,260: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.0195482078247466]
[2024-04-20 11:57:03,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.008759471402006074]
[2024-04-20 11:57:03,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.002610730559862066]
[2024-04-20 11:57:03,886: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.048465495821469286]
[2024-04-20 11:57:04,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.024062085560117207]
[2024-04-20 11:57:04,295: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.027819037392655812]
[2024-04-20 11:57:04,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.011609259383788283]
[2024-04-20 11:57:04,708: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.00908327839447312]
[2024-04-20 11:57:04,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.027380459754309777]
[2024-04-20 11:57:05,123: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.012792717544188764]
[2024-04-20 11:57:05,335: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.035537945043112584]
[2024-04-20 11:57:05,541: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.019888973498563653]
[2024-04-20 11:57:05,751: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.05022590537437896]
[2024-04-20 11:57:05,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.013077767709548768]
[2024-04-20 11:57:06,167: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.0342808373896231]
[2024-04-20 11:57:06,374: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.005263701935049167]
[2024-04-20 11:57:06,581: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.03258186995417093]
[2024-04-20 11:57:06,787: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.00414157694948884]
[2024-04-20 11:57:06,994: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.03686401638289103]
[2024-04-20 11:57:07,200: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.0033797826998738264]
[2024-04-20 11:57:07,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.020280866625389277]
[2024-04-20 11:57:07,610: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.024563727803057236]
[2024-04-20 11:57:07,817: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.015110614758935404]
[2024-04-20 11:57:08,023: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.005557866112278645]
[2024-04-20 11:57:08,224: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.05078960046224399]
[2024-04-20 11:57:08,429: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.009016539353033787]
[2024-04-20 11:57:08,633: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.01996767536499419]
[2024-04-20 11:57:08,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.019035005570702535]
[2024-04-20 11:57:09,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.007014030471331348]
[2024-04-20 11:57:09,258: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.009052471434583098]
[2024-04-20 11:57:09,466: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.01498218372770403]
[2024-04-20 11:57:09,672: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.0209659919234874]
[2024-04-20 11:57:09,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.018240340010100733]
[2024-04-20 11:57:10,089: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 0.007242526700394685]
[2024-04-20 11:57:10,293: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.004192566017221064]
[2024-04-20 11:57:10,496: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 0.012043615253722651]
[2024-04-20 11:57:10,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.02056688492825341]
[2024-04-20 11:57:10,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.00963338495830787]
[2024-04-20 11:57:11,115: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.010125384360389044]
[2024-04-20 11:57:11,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.027816957651626638]
[2024-04-20 11:57:11,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.025029631726418995]
[2024-04-20 11:57:11,732: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.0024535262873173914]
[2024-04-20 11:57:11,942: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.008758636891339789]
[2024-04-20 11:57:12,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.013546611645599988]
[2024-04-20 11:57:12,361: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 0.007356748215204999]
[2024-04-20 11:57:12,565: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.013985065737167382]
[2024-04-20 11:57:12,772: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.038317040875692245]
[2024-04-20 11:57:12,984: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.012863271284934268]
[2024-04-20 11:57:13,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.008474625437026057]
[2024-04-20 11:57:13,405: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.009459397679132632]
[2024-04-20 11:57:13,615: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.0022308257370255292]
[2024-04-20 11:57:13,826: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.00943837663339591]
[2024-04-20 11:57:14,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.018749521512546025]
[2024-04-20 11:57:14,251: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.004878462194644201]
[2024-04-20 11:57:14,472: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.019223032249778747]
[2024-04-20 11:57:14,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.011812290398677545]
[2024-04-20 11:57:14,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.02015670942251754]
[2024-04-20 11:57:15,098: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.011431081299007018]
[2024-04-20 11:57:15,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.01197976145089619]
[2024-04-20 11:57:15,521: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.022264896121797183]
[2024-04-20 11:57:15,733: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.006657343418749394]
[2024-04-20 11:57:15,945: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.01743804021873058]
[2024-04-20 11:57:16,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.03677820101632009]
[2024-04-20 11:57:16,355: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.019789681335646646]
[2024-04-20 11:57:16,561: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.024010928668130205]
[2024-04-20 11:57:16,768: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.014705623407821012]
[2024-04-20 11:57:16,974: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.024122294562175867]
[2024-04-20 11:57:17,180: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.009144601244580977]
[2024-04-20 11:57:17,387: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.023899801352754838]
[2024-04-20 11:57:17,593: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.01559239492427057]
[2024-04-20 11:57:17,804: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.02843381407715457]
[2024-04-20 11:57:18,010: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.012076685616872347]
[2024-04-20 11:57:18,217: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.03681349298564636]
[2024-04-20 11:57:18,425: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.029261447752901]
[2024-04-20 11:57:18,631: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.014433891570215098]
[2024-04-20 11:57:18,836: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.012430933305605175]
[2024-04-20 11:57:19,042: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.022873589469051044]
[2024-04-20 11:57:19,251: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.018406477064927033]
[2024-04-20 11:57:19,458: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.00923571253930084]
[2024-04-20 11:57:19,664: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.011952254220945717]
[2024-04-20 11:57:19,871: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.02982436689363281]
[2024-04-20 11:57:20,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.013444489861364534]
[2024-04-20 11:57:20,286: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.010172406131484813]
[2024-04-20 11:57:20,492: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 0.005439168056978335]
[2024-04-20 11:57:20,698: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.02621799983212769]
[2024-04-20 11:57:20,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.015700321662253477]
[2024-04-20 11:57:21,113: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.013507839344412178]
[2024-04-20 11:57:21,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.014991888199911539]
[2024-04-20 11:57:21,524: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.06791846503857192]
[2024-04-20 11:57:21,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.016204467917666717]
[2024-04-20 11:57:21,936: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.0035745160787817674]
[2024-04-20 11:57:22,142: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.06483238003984286]
[2024-04-20 11:57:22,347: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.021217271263089463]
[2024-04-20 11:57:22,553: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.010392834395210668]
[2024-04-20 11:57:22,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.017888101610041562]
[2024-04-20 11:57:22,966: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.013452454910940909]
[2024-04-20 11:57:23,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.020851467700602068]
[2024-04-20 11:57:23,383: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.013063059829049475]
[2024-04-20 11:57:23,591: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.0405609375322763]
[2024-04-20 11:57:23,798: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.04786129527209226]
[2024-04-20 11:57:24,004: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.013278112795229308]
[2024-04-20 11:57:24,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.03271879714494122]
[2024-04-20 11:57:24,421: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.021434918648065678]
[2024-04-20 11:57:24,634: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.014893800436812255]
[2024-04-20 11:57:24,845: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.01434712689481224]
[2024-04-20 11:57:25,057: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.01677059622815662]
[2024-04-20 11:57:25,269: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.009191156822726143]
[2024-04-20 11:57:25,482: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.02286503098061142]
[2024-04-20 11:57:25,695: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.01953356770546374]
[2024-04-20 11:57:25,910: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.06521607670753131]
[2024-04-20 11:57:26,127: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.023683909876935992]
[2024-04-20 11:57:26,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.015481411745893297]
[2024-04-20 11:57:26,570: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.005209813497061174]
[2024-04-20 11:57:26,786: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.004279508649874589]
[2024-04-20 11:57:27,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.07577682271316864]
[2024-04-20 11:57:27,237: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.022428602842495326]
[2024-04-20 11:57:27,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.03231632946369594]
[2024-04-20 11:57:27,670: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.030199963000013916]
[2024-04-20 11:57:27,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.026437320038837222]
[2024-04-20 11:57:28,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.051090679044484034]
[2024-04-20 11:57:28,320: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.02661962866549967]
[2024-04-20 11:57:28,537: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.01565906951357453]
[2024-04-20 11:57:28,752: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.04225536699360454]
[2024-04-20 11:57:28,974: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.026820478911383193]
[2024-04-20 11:57:29,188: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.034980583995809604]
[2024-04-20 11:57:29,414: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.01642927029970898]
[2024-04-20 11:57:29,625: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.03605421300315423]
[2024-04-20 11:57:29,840: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.02745975863765668]
[2024-04-20 11:57:30,052: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.022260965451745766]
[2024-04-20 11:57:30,272: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.011580500010274369]
[2024-04-20 11:57:30,482: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.013802488166965391]
[2024-04-20 11:57:30,693: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.04386915838384788]
[2024-04-20 11:57:30,898: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.028640770692690866]
[2024-04-20 11:57:31,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.008666545267159117]
[2024-04-20 11:57:31,314: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.030842425204313198]
[2024-04-20 11:57:31,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.02578458190322682]
[2024-04-20 11:57:31,727: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.04287692903145837]
[2024-04-20 11:57:31,933: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.016687859889542137]
[2024-04-20 11:57:32,139: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.0359213173102648]
[2024-04-20 11:57:32,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.03662273239366431]
[2024-04-20 11:57:32,558: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.0656054860143103]
[2024-04-20 11:57:32,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.013025871849231407]
[2024-04-20 11:57:32,979: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.005864417534292811]
[2024-04-20 11:57:33,183: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.020410701860404164]
[2024-04-20 11:57:33,386: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.09187148270586883]
[2024-04-20 11:57:33,589: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.008738468905315077]
[2024-04-20 11:57:33,793: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.009922997327943748]
[2024-04-20 11:57:34,001: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.070622329083947]
[2024-04-20 11:57:34,206: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.026297400515409953]
[2024-04-20 11:57:34,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.00989405163169251]
[2024-04-20 11:57:34,618: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.03738001351986005]
[2024-04-20 11:57:34,823: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.052685000388652446]
[2024-04-20 11:57:35,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.05181084360299914]
[2024-04-20 11:57:35,235: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.12898113081096277]
[2024-04-20 11:57:35,445: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.022788526278998245]
[2024-04-20 11:57:35,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.028242645193567523]
[2024-04-20 11:57:35,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.01755810181591217]
[2024-04-20 11:57:36,064: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.042899768930495394]
[2024-04-20 11:57:36,272: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.06506234701704493]
[2024-04-20 11:57:36,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.011099038738490772]
[2024-04-20 11:57:36,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.03809562781351937]
[2024-04-20 11:57:36,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.013540133191751362]
[2024-04-20 11:57:37,099: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.04059232101834714]
[2024-04-20 11:57:37,309: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.03902263193684954]
[2024-04-20 11:57:37,514: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.01918784602592508]
[2024-04-20 11:57:37,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.026576665095179388]
[2024-04-20 11:57:37,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.023535265472304674]
[2024-04-20 11:57:38,135: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.017782073736128164]
[2024-04-20 11:57:38,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.022241379001595004]
[2024-04-20 11:57:38,543: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.010779713548820236]
[2024-04-20 11:57:38,746: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.017444076350354637]
[2024-04-20 11:57:38,956: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.017218820631830684]
[2024-04-20 11:57:39,163: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.021764200077806314]
[2024-04-20 11:57:39,371: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.014972776527817753]
[2024-04-20 11:57:39,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.031598082602171965]
[2024-04-20 11:57:39,783: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.007797559226740298]
[2024-04-20 11:57:39,990: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.035458752618156425]
[2024-04-20 11:57:40,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.01451645438377352]
[2024-04-20 11:57:40,406: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.015324484330796067]
[2024-04-20 11:57:40,614: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.005924827848349247]
[2024-04-20 11:57:40,825: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.009494945311228816]
[2024-04-20 11:57:41,034: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.010039629061255512]
[2024-04-20 11:57:41,245: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.01651696770270707]
[2024-04-20 11:57:41,461: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.006820397494401835]
[2024-04-20 11:57:41,676: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.03638706367411684]
[2024-04-20 11:57:41,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.03513224390928554]
[2024-04-20 11:57:42,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.007791535213262512]
[2024-04-20 11:57:42,314: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.016812742572027365]
[2024-04-20 11:57:42,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.014117161064216911]
[2024-04-20 11:57:42,742: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.0267018999357783]
[2024-04-20 11:57:42,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 0.00992754279283498]
[2024-04-20 11:57:43,181: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.03775381917507248]
[2024-04-20 11:57:43,392: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.014365235142595217]
[2024-04-20 11:57:43,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.0463779161589025]
[2024-04-20 11:57:43,823: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.028701559713629306]
[2024-04-20 11:57:44,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.019377320784293838]
[2024-04-20 11:57:44,258: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.05805345733642996]
[2024-04-20 11:57:44,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.03595223709834113]
[2024-04-20 11:57:44,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.005719199172578875]
[2024-04-20 11:57:44,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.03290036767240932]
[2024-04-20 11:57:45,118: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.013965871955123043]
[2024-04-20 11:57:45,335: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.011703454067943628]
[2024-04-20 11:57:45,546: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.04882935862594311]
[2024-04-20 11:57:45,758: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.01576475910083207]
[2024-04-20 11:57:45,976: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.010018224896331737]
[2024-04-20 11:57:46,192: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.009953826910410156]
[2024-04-20 11:57:46,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.0054938908418050375]
[2024-04-20 11:57:46,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.027760481032509204]
[2024-04-20 11:57:46,841: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.03347937332927998]
[2024-04-20 11:57:47,053: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.00957776218246391]
[2024-04-20 11:57:47,255: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.003243866305624944]
[2024-04-20 11:57:47,460: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.009760999035751046]
[2024-04-20 11:57:47,673: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.024524269825067814]
[2024-04-20 11:57:47,881: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.01624227030628806]
[2024-04-20 11:57:48,085: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.015535648451007616]
[2024-04-20 11:57:48,289: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.04448440935325497]
[2024-04-20 11:57:48,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.0076381058313747365]
[2024-04-20 11:57:48,700: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.02965442775404732]
[2024-04-20 11:57:48,908: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.027067403273256237]
[2024-04-20 11:57:49,111: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.005461565600055065]
[2024-04-20 11:57:49,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.011225462367928256]
[2024-04-20 11:57:49,523: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.013433349714070585]
[2024-04-20 11:57:49,728: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.01780975938819449]
[2024-04-20 11:57:49,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.022767877647556736]
[2024-04-20 11:57:50,147: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.022420434581666388]
[2024-04-20 11:57:50,355: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.008037064011462194]
[2024-04-20 11:57:50,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.012906535879335436]
[2024-04-20 11:57:50,767: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.03612565534931922]
[2024-04-20 11:57:50,971: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.03656687030247627]
[2024-04-20 11:57:51,178: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.01564508623757582]
[2024-04-20 11:57:51,388: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.04624013767281389]
[2024-04-20 11:57:51,595: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.021347918916794963]
[2024-04-20 11:57:51,800: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.029767734592852597]
[2024-04-20 11:57:52,004: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.016814468366653124]
[2024-04-20 11:57:52,208: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.019002646316360384]
[2024-04-20 11:57:52,414: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.0329012350410962]
[2024-04-20 11:57:52,620: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.05179276148331925]
[2024-04-20 11:57:52,827: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.00993746383026209]
[2024-04-20 11:57:53,036: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.0432912974307826]
[2024-04-20 11:57:53,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.03254908518274555]
[2024-04-20 11:57:53,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.007209778503284793]
[2024-04-20 11:57:53,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.012189282013010462]
[2024-04-20 11:57:53,867: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.03183036275198848]
[2024-04-20 11:57:54,073: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.007850438649801218]
[2024-04-20 11:57:54,282: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.04358123589831953]
[2024-04-20 11:57:54,488: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.06261086291477042]
[2024-04-20 11:57:54,693: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.01414157759269666]
[2024-04-20 11:57:54,899: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.028955062204243702]
[2024-04-20 11:57:55,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.026137422522229566]
[2024-04-20 11:57:55,312: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.050526630475923894]
[2024-04-20 11:57:55,519: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.009177214681952527]
[2024-04-20 11:57:55,726: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.005224245210556894]
[2024-04-20 11:57:55,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.02476593063502983]
[2024-04-20 11:57:56,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.04045683885569842]
[2024-04-20 11:57:56,364: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.028096528546450752]
[2024-04-20 11:57:56,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.018986032558680244]
[2024-04-20 11:57:56,783: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.018541970657979082]
[2024-04-20 11:57:56,994: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.046902182803247726]
[2024-04-20 11:57:57,205: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.03300114087529734]
[2024-04-20 11:57:57,416: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.03766245495989889]
[2024-04-20 11:57:57,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.020176186975596512]
[2024-04-20 11:57:57,838: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.012744043585062433]
[2024-04-20 11:57:58,050: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.009399480993281407]
[2024-04-20 11:57:58,262: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.021856161041851993]
[2024-04-20 11:57:58,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 0.030185100218128907]
[2024-04-20 11:57:58,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.03531497521836184]
[2024-04-20 11:57:58,894: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.012144089319293167]
[2024-04-20 11:57:59,106: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.041931698219171074]
[2024-04-20 11:57:59,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.007541483522002056]
[2024-04-20 11:57:59,525: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.022408873199973655]
[2024-04-20 11:57:59,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.009640384129632204]
[2024-04-20 11:57:59,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.03902274012871472]
[2024-04-20 11:58:00,153: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.021351557577030025]
[2024-04-20 11:58:00,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.029300316985501382]
[2024-04-20 11:58:00,570: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.01670220717379689]
[2024-04-20 11:58:00,780: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.01704817218964579]
[2024-04-20 11:58:00,988: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 0.008450313185733641]
[2024-04-20 11:58:01,198: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.0020997304032735007]
[2024-04-20 11:58:01,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.006867579901992629]
[2024-04-20 11:58:01,610: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.007533464788493065]
[2024-04-20 11:58:01,818: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.021483081267697605]
[2024-04-20 11:58:02,027: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.03713768709237293]
[2024-04-20 11:58:02,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.013640662583513078]
[2024-04-20 11:58:02,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.010288767957040314]
[2024-04-20 11:58:02,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.035206646836733205]
[2024-04-20 11:58:02,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.02848774702469696]
[2024-04-20 11:58:03,060: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.02017576277933889]
[2024-04-20 11:58:03,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.01190944820009993]
[2024-04-20 11:58:03,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.03395126292079647]
[2024-04-20 11:58:03,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.005936593173983911]
[2024-04-20 11:58:03,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.017607267669425594]
[2024-04-20 11:58:04,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.014264942093106412]
[2024-04-20 11:58:04,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.014023848850471999]
[2024-04-20 11:58:04,519: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.007270436673087749]
[2024-04-20 11:58:04,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.012696874282828776]
[2024-04-20 11:58:04,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.03639733894127226]
[2024-04-20 11:58:05,139: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.010363313223739892]
[2024-04-20 11:58:05,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.015897546136933283]
[2024-04-20 11:58:05,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.01351345125399348]
[2024-04-20 11:58:05,760: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.026055103198728446]
[2024-04-20 11:58:05,966: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.019747455338090743]
[2024-04-20 11:58:06,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.02901528007007743]
[2024-04-20 11:58:06,387: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.016554844634510815]
[2024-04-20 11:58:06,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.013389150448607064]
[2024-04-20 11:58:06,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.015849364938836492]
[2024-04-20 11:58:07,012: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.0021938124777402734]
[2024-04-20 11:58:07,221: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.007706373013484716]
[2024-04-20 11:58:07,429: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.017880766696909637]
[2024-04-20 11:58:07,635: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.03103026680893038]
[2024-04-20 11:58:07,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.028380076254696726]
[2024-04-20 11:58:08,050: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.008185014374323733]
[2024-04-20 11:58:08,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.011116398775943824]
[2024-04-20 11:58:08,467: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.02114481924345246]
[2024-04-20 11:58:08,674: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.0356520825316169]
[2024-04-20 11:58:08,881: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.014522002454212415]
[2024-04-20 11:58:09,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.03253537552885688]
[2024-04-20 11:58:09,293: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.018858673357306965]
[2024-04-20 11:58:09,507: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.04058713706615386]
[2024-04-20 11:58:09,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.007245270607715567]
[2024-04-20 11:58:09,928: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.022116198332841168]
[2024-04-20 11:58:10,139: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.009174186187063962]
[2024-04-20 11:58:10,351: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.015393453590393982]
[2024-04-20 11:58:10,564: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.01728728047658564]
[2024-04-20 11:58:10,779: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.026191392442916683]
[2024-04-20 11:58:10,987: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.01349268559089556]
[2024-04-20 11:58:11,193: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.018078368113517703]
[2024-04-20 11:58:11,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.00585369648663733]
[2024-04-20 11:58:11,615: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.017401907662289925]
[2024-04-20 11:58:11,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.0529517628358539]
[2024-04-20 11:58:12,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.027399667713180836]
[2024-04-20 11:58:12,252: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.0026031373270042676]
[2024-04-20 11:58:12,466: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.004066778726970306]
[2024-04-20 11:58:12,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.01122236479493903]
[2024-04-20 11:58:12,885: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.015413965471280811]
[2024-04-20 11:58:13,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.012201519035281305]
[2024-04-20 11:58:13,297: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.01906558909469678]
[2024-04-20 11:58:13,502: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.006705127175106499]
[2024-04-20 11:58:13,708: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.013921959201984612]
[2024-04-20 11:58:13,913: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.01472067667860496]
[2024-04-20 11:58:14,120: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.003903122397940427]
[2024-04-20 11:58:14,329: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.0037854333287508962]
[2024-04-20 11:58:14,538: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.010711735266746862]
[2024-04-20 11:58:14,744: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.008626409080723143]
[2024-04-20 11:58:14,951: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.01692642717158677]
[2024-04-20 11:58:15,157: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.02963316381459867]
[2024-04-20 11:58:15,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.03056706530528011]
[2024-04-20 11:58:15,569: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.01099103983349778]
[2024-04-20 11:58:15,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.005088963104181061]
[2024-04-20 11:58:15,981: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.012402371494509096]
[2024-04-20 11:58:16,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.005950779411273609]
[2024-04-20 11:58:16,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.008783930619685262]
[2024-04-20 11:58:16,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.005019509282450884]
[2024-04-20 11:58:16,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.021652030518252662]
[2024-04-20 11:58:17,006: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.016964860737470125]
[2024-04-20 11:58:17,209: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.005099645564050412]
[2024-04-20 11:58:17,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.018556641104265165]
[2024-04-20 11:58:17,623: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.005294247657778091]
[2024-04-20 11:58:17,826: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.0015700149570046704]
[2024-04-20 11:58:18,030: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.00568837556912562]
[2024-04-20 11:58:18,237: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.0020053956198887893]
[2024-04-20 11:58:18,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.018894536684279834]
[2024-04-20 11:58:18,653: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.051811940267329916]
[2024-04-20 11:58:18,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.00924409488919385]
[2024-04-20 11:58:19,061: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.015289042370038594]
[2024-04-20 11:58:19,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.027194382333829006]
[2024-04-20 11:58:19,472: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.006991271969702605]
[2024-04-20 11:58:19,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.030688359304604094]
[2024-04-20 11:58:19,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.010207436002643983]
[2024-04-20 11:58:20,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.012753019666711449]
[2024-04-20 11:58:20,294: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.003084500302300874]
[2024-04-20 11:58:20,497: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.01655272574042445]
[2024-04-20 11:58:20,705: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.0256049094137703]
[2024-04-20 11:58:20,912: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.011058324302048042]
[2024-04-20 11:58:21,117: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.008192144990936352]
[2024-04-20 11:58:21,322: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.010970398852374176]
[2024-04-20 11:58:21,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.011301831426848968]
[2024-04-20 11:58:21,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.035452066252022435]
[2024-04-20 11:58:21,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.002366898172585279]
[2024-04-20 11:58:22,139: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.011553992296186224]
[2024-04-20 11:58:22,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.02881387920821043]
[2024-04-20 11:58:22,553: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.010445563939166595]
[2024-04-20 11:58:22,766: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.016224260750003452]
[2024-04-20 11:58:22,986: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.010008374063417126]
[2024-04-20 11:58:23,192: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.0058094581227876065]
[2024-04-20 11:58:23,400: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.013761173624461389]
[2024-04-20 11:58:23,613: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.009527313604960409]
[2024-04-20 11:58:23,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.019529327038188694]
[2024-04-20 11:58:24,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.005155172223179366]
[2024-04-20 11:58:24,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.0030306535391349085]
[2024-04-20 11:58:24,456: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.02441012951039106]
[2024-04-20 11:58:24,663: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.007025480724745181]
[2024-04-20 11:58:24,874: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.0298919273647484]
[2024-04-20 11:58:25,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 0.01373808833225274]
[2024-04-20 11:58:25,301: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.016380370756777642]
[2024-04-20 11:58:25,508: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.01844710723167332]
[2024-04-20 11:58:25,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.01811480685620296]
[2024-04-20 11:58:25,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.011246208062118747]
[2024-04-20 11:58:26,123: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.053389108048092264]
[2024-04-20 11:58:26,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.016594363050888482]
[2024-04-20 11:58:26,510: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 0.004448783120761726]
[2024-04-20 11:58:48,872: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9916989067002725, 'precision': 0.7390167556619407, 'recall': 0.6877666775194065, 'f1': 0.7124712648779146}]
[2024-04-20 11:58:51,130: INFO: roberta_kFold_initial_lstm: Fold 1/3 , Epoch: 2/3]
[2024-04-20 11:58:51,865: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.004903043311332033]
[2024-04-20 11:58:52,505: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.010994128879118653]
[2024-04-20 11:58:53,138: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.017899066185273482]
[2024-04-20 11:58:53,777: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.020312672817315598]
[2024-04-20 11:58:54,413: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.006209247979251674]
[2024-04-20 11:58:55,054: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.010497621474675263]
[2024-04-20 11:58:55,697: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.00950506381325741]
[2024-04-20 11:58:56,340: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.01802378384737753]
[2024-04-20 11:58:56,986: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.0415172324074291]
[2024-04-20 11:58:57,631: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.017518705706193446]
[2024-04-20 11:58:58,276: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.0028293370962681258]
[2024-04-20 11:58:58,921: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.01685917273233602]
[2024-04-20 11:58:59,566: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.022337370249569142]
[2024-04-20 11:59:00,218: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.01024223798523897]
[2024-04-20 11:59:00,871: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.01699782342494448]
[2024-04-20 11:59:01,533: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.011638212649319914]
[2024-04-20 11:59:02,192: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.024356953187819743]
[2024-04-20 11:59:02,883: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.01003896670690164]
[2024-04-20 11:59:03,572: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.010360721187332764]
[2024-04-20 11:59:04,255: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.022697397475055548]
[2024-04-20 11:59:04,923: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.0123658617541315]
[2024-04-20 11:59:05,585: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.02459870855261622]
[2024-04-20 11:59:06,247: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.0244017530475729]
[2024-04-20 11:59:06,908: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.01373658836356564]
[2024-04-20 11:59:07,568: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.020399436603357336]
[2024-04-20 11:59:08,232: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.022459474924185676]
[2024-04-20 11:59:08,891: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.013648397618661485]
[2024-04-20 11:59:09,554: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.015206747578413251]
[2024-04-20 11:59:10,223: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.006386368495724471]
[2024-04-20 11:59:10,889: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.01169828304051928]
[2024-04-20 11:59:11,560: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.03398207310566295]
[2024-04-20 11:59:12,228: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.016473057238903806]
[2024-04-20 11:59:12,891: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.010408273605298678]
[2024-04-20 11:59:13,566: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.016061690366824286]
[2024-04-20 11:59:14,233: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.01850514394442598]
[2024-04-20 11:59:14,902: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.014462088227918762]
[2024-04-20 11:59:15,576: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.02196864935455688]
[2024-04-20 11:59:16,258: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.009829840551727068]
[2024-04-20 11:59:16,936: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.007718114558235096]
[2024-04-20 11:59:17,628: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.009369889908775167]
[2024-04-20 11:59:18,308: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.026527777297575543]
[2024-04-20 11:59:18,997: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.019639916317131922]
[2024-04-20 11:59:19,674: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.020375856730827837]
[2024-04-20 11:59:20,348: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.01371624991161713]
[2024-04-20 11:59:21,027: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.008549087587960654]
[2024-04-20 11:59:21,708: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.013255565254183433]
[2024-04-20 11:59:22,382: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.017608350559957398]
[2024-04-20 11:59:23,063: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.03264613360943911]
[2024-04-20 11:59:23,740: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.016761740749179844]
[2024-04-20 11:59:24,422: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.011997715571815143]
[2024-04-20 11:59:25,095: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.02269611315822163]
[2024-04-20 11:59:25,777: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.016636170044359234]
[2024-04-20 11:59:26,453: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.02793382847228503]
[2024-04-20 11:59:27,127: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.0158659902069725]
[2024-04-20 11:59:27,807: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.04372252589046154]
[2024-04-20 11:59:28,478: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.021337257794055202]
[2024-04-20 11:59:29,170: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.03587805213879092]
[2024-04-20 11:59:29,876: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.013303636271545863]
[2024-04-20 11:59:30,580: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.0488497763136636]
[2024-04-20 11:59:31,278: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.005456767430072167]
[2024-04-20 11:59:31,974: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.012800688259364278]
[2024-04-20 11:59:32,646: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.02144520890331367]
[2024-04-20 11:59:33,310: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.02278901371742991]
[2024-04-20 11:59:33,983: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.025039471026205195]
[2024-04-20 11:59:34,649: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.025694877966552763]
[2024-04-20 11:59:35,312: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.024307067457818982]
[2024-04-20 11:59:35,982: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.020361992731937593]
[2024-04-20 11:59:36,647: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.007071254170850571]
[2024-04-20 11:59:37,308: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.01284792554952246]
[2024-04-20 11:59:37,969: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.03884555169572949]
[2024-04-20 11:59:38,631: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.00606154045290219]
[2024-04-20 11:59:39,292: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.023460876873972105]
[2024-04-20 11:59:39,954: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.019250864912184744]
[2024-04-20 11:59:40,614: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.007410094171851557]
[2024-04-20 11:59:41,273: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.006979883466044895]
[2024-04-20 11:59:41,936: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.02871658042804276]
[2024-04-20 11:59:42,603: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.03664454215416452]
[2024-04-20 11:59:43,267: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.009833210845381123]
[2024-04-20 11:59:43,932: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.01600466080456489]
[2024-04-20 11:59:44,596: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.006489876791817029]
[2024-04-20 11:59:45,261: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.014023520178447135]
[2024-04-20 11:59:45,918: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.01594569085587831]
[2024-04-20 11:59:46,573: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.013903233531168823]
[2024-04-20 11:59:47,229: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.03613554768816357]
[2024-04-20 11:59:47,881: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.01608826467730508]
[2024-04-20 11:59:48,535: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.028085782987914525]
[2024-04-20 11:59:49,183: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.010130531353730227]
[2024-04-20 11:59:49,834: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.009364925191604602]
[2024-04-20 11:59:50,482: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.01107152034843404]
[2024-04-20 11:59:51,131: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.020695545987186963]
[2024-04-20 11:59:51,781: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.09096692164482063]
[2024-04-20 11:59:52,432: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.05197124201015686]
[2024-04-20 11:59:53,086: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.01855286514092981]
[2024-04-20 11:59:53,733: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.043022798756448474]
[2024-04-20 11:59:54,383: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.011354645352416974]
[2024-04-20 11:59:55,034: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.006128898185478401]
[2024-04-20 11:59:55,686: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.010975404526369454]
[2024-04-20 11:59:56,355: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.009771399708482516]
[2024-04-20 11:59:57,020: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.019590010089710893]
[2024-04-20 11:59:57,676: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.027133134461318802]
[2024-04-20 11:59:58,345: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.014339766647081918]
[2024-04-20 11:59:58,997: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.01034545733820772]
[2024-04-20 11:59:59,646: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.012074645393270272]
[2024-04-20 12:00:00,296: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.006585218635850488]
[2024-04-20 12:00:00,944: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.019037410226609684]
[2024-04-20 12:00:01,591: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.008762313961663805]
[2024-04-20 12:00:02,243: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.017159960473529436]
[2024-04-20 12:00:02,897: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.005913173863555545]
[2024-04-20 12:00:03,546: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.009183621960923184]
[2024-04-20 12:00:04,197: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.0067292572018145405]
[2024-04-20 12:00:04,840: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.003896731030860671]
[2024-04-20 12:00:05,488: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.009443721195582372]
[2024-04-20 12:00:06,135: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.004742242040211657]
[2024-04-20 12:00:06,784: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.017661998953613423]
[2024-04-20 12:00:07,430: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.009229340866122069]
[2024-04-20 12:00:08,083: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.044305088467172994]
[2024-04-20 12:00:08,737: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.027651114088435416]
[2024-04-20 12:00:09,391: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.008362459028765425]
[2024-04-20 12:00:10,046: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.01781639197161557]
[2024-04-20 12:00:10,697: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.06592531061934044]
[2024-04-20 12:00:11,350: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.005181555795736126]
[2024-04-20 12:00:11,999: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.01603948384836881]
[2024-04-20 12:00:12,646: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.026575417309640963]
[2024-04-20 12:00:13,294: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.019658227195374182]
[2024-04-20 12:00:13,943: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.012312832109389492]
[2024-04-20 12:00:14,590: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.007407442558675474]
[2024-04-20 12:00:15,241: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.016980548746227515]
[2024-04-20 12:00:15,890: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.006926241184015918]
[2024-04-20 12:00:16,538: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.01682507541435257]
[2024-04-20 12:00:17,185: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.005040869050709353]
[2024-04-20 12:00:17,833: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.015592387880867744]
[2024-04-20 12:00:18,478: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.042121949538588645]
[2024-04-20 12:00:19,128: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.02032127600911259]
[2024-04-20 12:00:19,777: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.004230790909908585]
[2024-04-20 12:00:20,426: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.01376630086470309]
[2024-04-20 12:00:21,072: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.01742442010424636]
[2024-04-20 12:00:21,727: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.004849480341710825]
[2024-04-20 12:00:22,383: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.07671146338858251]
[2024-04-20 12:00:23,040: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.014881295748180777]
[2024-04-20 12:00:23,697: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.009980840453293756]
[2024-04-20 12:00:24,357: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.022928105633450928]
[2024-04-20 12:00:25,014: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.003596854969283382]
[2024-04-20 12:00:25,665: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.043150464504599126]
[2024-04-20 12:00:26,314: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.008899817965223544]
[2024-04-20 12:00:26,962: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.0036741592651462567]
[2024-04-20 12:00:27,615: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.030519194126512435]
[2024-04-20 12:00:28,263: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.004271122538369273]
[2024-04-20 12:00:28,916: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.03161800229292641]
[2024-04-20 12:00:29,570: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.009047024382846281]
[2024-04-20 12:00:30,225: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.030209965340412977]
[2024-04-20 12:00:30,876: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.02800622725682689]
[2024-04-20 12:00:31,540: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.020596552164882393]
[2024-04-20 12:00:32,197: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.024491114962306177]
[2024-04-20 12:00:32,862: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.029112584730776457]
[2024-04-20 12:00:33,526: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.010580193027974225]
[2024-04-20 12:00:34,191: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.04151636714342079]
[2024-04-20 12:00:34,850: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.014537214049588092]
[2024-04-20 12:00:35,512: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.01376766551070969]
[2024-04-20 12:00:36,179: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.031154014417960306]
[2024-04-20 12:00:36,841: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.0191810153976824]
[2024-04-20 12:00:37,507: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.009752005223170336]
[2024-04-20 12:00:38,171: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.04679437158358197]
[2024-04-20 12:00:38,826: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.02972429610799081]
[2024-04-20 12:00:39,484: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.025453736908931195]
[2024-04-20 12:00:40,138: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.03004970734288695]
[2024-04-20 12:00:40,793: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.01437733220737497]
[2024-04-20 12:00:41,448: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.010689665489287146]
[2024-04-20 12:00:42,102: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.02310795649449591]
[2024-04-20 12:00:42,759: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.005707512710756781]
[2024-04-20 12:00:43,411: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.017235524457176406]
[2024-04-20 12:00:44,067: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.019771231008035968]
[2024-04-20 12:00:44,730: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.02809689853471451]
[2024-04-20 12:00:45,385: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.0244777596691528]
[2024-04-20 12:00:46,042: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.03472659269959835]
[2024-04-20 12:00:46,699: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.008516560484970207]
[2024-04-20 12:00:47,355: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.006972751068608329]
[2024-04-20 12:00:48,012: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.0161397279773812]
[2024-04-20 12:00:48,687: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.009906345979015276]
[2024-04-20 12:00:49,366: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.04733644664252757]
[2024-04-20 12:00:50,033: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.03076741437762351]
[2024-04-20 12:00:50,709: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.010921971772969215]
[2024-04-20 12:00:51,394: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.016797442159167186]
[2024-04-20 12:00:52,079: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.026950234963033518]
[2024-04-20 12:00:52,749: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.0332536120507205]
[2024-04-20 12:00:53,415: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.01522444745331381]
[2024-04-20 12:00:54,090: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.02074113128141829]
[2024-04-20 12:00:54,757: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.024875454938039002]
[2024-04-20 12:00:55,410: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.010973006855961795]
[2024-04-20 12:00:56,066: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.01176586389440168]
[2024-04-20 12:00:56,729: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.013934572496132341]
[2024-04-20 12:00:57,384: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.007053610449978765]
[2024-04-20 12:00:58,047: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.005941852253864847]
[2024-04-20 12:00:58,706: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.0054218943005209155]
[2024-04-20 12:00:59,364: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.033647911832642]
[2024-04-20 12:01:00,019: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.021005468911198477]
[2024-04-20 12:01:00,677: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.01727198013919017]
[2024-04-20 12:01:01,331: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.013636184007497689]
[2024-04-20 12:01:01,991: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.0030658729110919045]
[2024-04-20 12:01:02,644: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.010579832191447607]
[2024-04-20 12:01:03,313: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.008886551273330538]
[2024-04-20 12:01:03,981: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.015130946898553483]
[2024-04-20 12:01:04,647: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.01853667061752456]
[2024-04-20 12:01:05,327: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.018366587526607497]
[2024-04-20 12:01:05,999: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.01910770087139356]
[2024-04-20 12:01:06,654: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.019907723236882748]
[2024-04-20 12:01:07,314: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.03233025592222471]
[2024-04-20 12:01:07,966: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.005842018054154198]
[2024-04-20 12:01:08,624: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.015510630754471734]
[2024-04-20 12:01:09,279: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.015967822832521333]
[2024-04-20 12:01:09,936: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.012715258691845926]
[2024-04-20 12:01:10,598: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.05512078420571564]
[2024-04-20 12:01:11,251: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.006562812303119799]
[2024-04-20 12:01:11,907: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.03445568020487457]
[2024-04-20 12:01:12,570: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.007483163156895899]
[2024-04-20 12:01:13,228: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.014894832429419087]
[2024-04-20 12:01:13,885: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.0198236558780811]
[2024-04-20 12:01:14,539: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.013724975247158013]
[2024-04-20 12:01:15,193: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.011676995575054663]
[2024-04-20 12:01:15,849: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.03099732499198811]
[2024-04-20 12:01:16,509: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.02795159657770394]
[2024-04-20 12:01:17,174: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.02876532366524846]
[2024-04-20 12:01:17,846: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.026165137788818238]
[2024-04-20 12:01:18,515: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.006306892296634438]
[2024-04-20 12:01:19,174: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.01643085470671444]
[2024-04-20 12:01:19,831: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.015182499810391343]
[2024-04-20 12:01:20,484: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.006502324956279347]
[2024-04-20 12:01:21,137: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.015109445952589121]
[2024-04-20 12:01:21,792: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.011543652340596601]
[2024-04-20 12:01:22,447: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.02500768417781399]
[2024-04-20 12:01:23,098: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.04813893547762209]
[2024-04-20 12:01:23,749: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.0371114860206535]
[2024-04-20 12:01:24,403: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.02168474409472211]
[2024-04-20 12:01:25,056: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.015783028838124047]
[2024-04-20 12:01:25,708: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.027244430333330384]
[2024-04-20 12:01:26,357: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.00926217221937702]
[2024-04-20 12:01:27,009: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.013196856451569839]
[2024-04-20 12:01:27,662: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.014163127887734418]
[2024-04-20 12:01:28,315: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.021219553417970476]
[2024-04-20 12:01:28,966: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.016001163938677076]
[2024-04-20 12:01:29,629: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.05788814419978172]
[2024-04-20 12:01:30,294: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.010039701730152685]
[2024-04-20 12:01:30,952: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.07625351966816236]
[2024-04-20 12:01:31,608: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.014666223887711249]
[2024-04-20 12:01:32,268: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.019116160594872453]
[2024-04-20 12:01:32,919: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.032553695785237764]
[2024-04-20 12:01:33,568: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.03662459708507051]
[2024-04-20 12:01:34,222: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.01786082168206851]
[2024-04-20 12:01:34,873: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.0026995701285941003]
[2024-04-20 12:01:35,530: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.021582015561296252]
[2024-04-20 12:01:36,177: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.006743711689827405]
[2024-04-20 12:01:36,829: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.009818643258920637]
[2024-04-20 12:01:37,484: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.012812592797846837]
[2024-04-20 12:01:38,138: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.01621822233440798]
[2024-04-20 12:01:38,788: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.009742356831352515]
[2024-04-20 12:01:39,441: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.019660603662999918]
[2024-04-20 12:01:40,092: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.0214309137474588]
[2024-04-20 12:01:40,745: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.0076488147770812885]
[2024-04-20 12:01:41,396: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.025438218600243954]
[2024-04-20 12:01:42,050: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.02575952285669942]
[2024-04-20 12:01:42,706: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.01783707913895363]
[2024-04-20 12:01:43,380: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.008895730931838482]
[2024-04-20 12:01:44,053: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.032373660332606316]
[2024-04-20 12:01:44,709: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.01270762796679859]
[2024-04-20 12:01:45,373: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.009498948838280322]
[2024-04-20 12:01:46,023: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.008959272406639915]
[2024-04-20 12:01:46,684: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.006387520665537231]
[2024-04-20 12:01:47,336: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.021204120152126974]
[2024-04-20 12:01:47,990: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.01302034950216697]
[2024-04-20 12:01:48,643: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.02916359790611217]
[2024-04-20 12:01:49,295: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.015842708790857845]
[2024-04-20 12:01:49,952: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.00696289025671134]
[2024-04-20 12:01:50,605: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.04934061795998129]
[2024-04-20 12:01:51,257: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.033206921277426096]
[2024-04-20 12:01:51,908: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.00673632996829528]
[2024-04-20 12:01:52,561: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.00881648949441875]
[2024-04-20 12:01:53,210: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.015330691762892397]
[2024-04-20 12:01:53,865: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.01216318142602531]
[2024-04-20 12:01:54,515: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.01689139304587017]
[2024-04-20 12:01:55,169: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.012298134171781933]
[2024-04-20 12:01:55,832: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.011002100653932792]
[2024-04-20 12:01:56,514: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.007943672446003087]
[2024-04-20 12:01:57,181: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.0105620046864776]
[2024-04-20 12:01:57,837: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.01772718690549904]
[2024-04-20 12:01:58,507: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.002674312035930024]
[2024-04-20 12:01:59,162: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.04401789872415126]
[2024-04-20 12:01:59,811: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.015697713303700372]
[2024-04-20 12:02:00,464: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.02293485328410715]
[2024-04-20 12:02:01,130: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.010552282808188547]
[2024-04-20 12:02:01,784: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.021828913092611254]
[2024-04-20 12:02:02,433: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.03156283131846081]
[2024-04-20 12:02:03,088: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.031616999080884424]
[2024-04-20 12:02:03,744: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.012651021740734734]
[2024-04-20 12:02:04,394: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.008311984540670806]
[2024-04-20 12:02:05,047: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.009484560314180566]
[2024-04-20 12:02:05,698: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.011731290662730405]
[2024-04-20 12:02:06,351: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.0462839869666027]
[2024-04-20 12:02:07,007: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.008792268968459211]
[2024-04-20 12:02:07,663: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.011733252233646118]
[2024-04-20 12:02:08,312: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.009701014093605933]
[2024-04-20 12:02:08,970: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.02960856847420558]
[2024-04-20 12:02:09,629: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.006311228075979776]
[2024-04-20 12:02:10,291: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.023576238204176987]
[2024-04-20 12:02:10,951: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.016920901252442225]
[2024-04-20 12:02:11,614: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.010324701617565183]
[2024-04-20 12:02:12,267: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.015205890373646865]
[2024-04-20 12:02:12,918: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.014723369050620796]
[2024-04-20 12:02:13,575: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.019030480279379158]
[2024-04-20 12:02:14,231: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.02540951442506246]
[2024-04-20 12:02:14,878: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.02008054795999016]
[2024-04-20 12:02:15,533: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.011650815402130284]
[2024-04-20 12:02:16,187: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.005921816173469378]
[2024-04-20 12:02:16,844: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.0083662924551782]
[2024-04-20 12:02:17,498: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.014101672887475892]
[2024-04-20 12:02:18,152: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.012514142494743828]
[2024-04-20 12:02:18,806: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.05420532249971326]
[2024-04-20 12:02:19,459: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.024523797016995308]
[2024-04-20 12:02:20,112: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.027840719894194215]
[2024-04-20 12:02:20,767: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.016868638075398085]
[2024-04-20 12:02:21,419: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.008890862094541735]
[2024-04-20 12:02:22,084: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.005154261620963855]
[2024-04-20 12:02:22,748: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.022527331416920992]
[2024-04-20 12:02:23,416: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.012354828950717192]
[2024-04-20 12:02:24,084: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.03030865937094175]
[2024-04-20 12:02:24,744: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.031068218236528274]
[2024-04-20 12:02:25,401: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.03382987748186532]
[2024-04-20 12:02:26,057: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.029859637005757736]
[2024-04-20 12:02:26,715: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.021700627371212547]
[2024-04-20 12:02:27,369: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.013203220821866203]
[2024-04-20 12:02:28,027: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.015673950827432677]
[2024-04-20 12:02:28,678: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.00911629199707382]
[2024-04-20 12:02:29,333: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.004354819252136997]
[2024-04-20 12:02:29,985: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.05457255834951676]
[2024-04-20 12:02:30,641: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.017310553892024193]
[2024-04-20 12:02:31,297: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.01861258532795385]
[2024-04-20 12:02:31,948: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.029329516252097884]
[2024-04-20 12:02:32,603: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.024105267406589092]
[2024-04-20 12:02:33,266: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.00960724966771849]
[2024-04-20 12:02:33,919: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.013570757449181571]
[2024-04-20 12:02:34,578: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.009432841275107545]
[2024-04-20 12:02:35,253: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.01693444691473269]
[2024-04-20 12:02:35,928: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.033681561295376757]
[2024-04-20 12:02:36,589: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.03135259189909952]
[2024-04-20 12:02:37,260: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.013105472745061481]
[2024-04-20 12:02:37,927: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.011405145905896096]
[2024-04-20 12:02:38,574: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.008617412802210577]
[2024-04-20 12:02:39,232: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.026217329506595808]
[2024-04-20 12:02:39,891: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.023971208801387672]
[2024-04-20 12:02:40,551: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.009555806691184691]
[2024-04-20 12:02:41,208: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.009597713251881112]
[2024-04-20 12:02:41,867: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.011177442204784348]
[2024-04-20 12:02:42,519: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.011362084822128311]
[2024-04-20 12:02:43,184: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.01789652357872877]
[2024-04-20 12:02:43,839: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.023264839911096215]
[2024-04-20 12:02:44,494: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.03397804099621108]
[2024-04-20 12:02:45,147: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.010025650673516172]
[2024-04-20 12:02:45,805: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.01505262847374677]
[2024-04-20 12:02:46,463: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.016731001069897514]
[2024-04-20 12:02:47,121: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.040143338539634914]
[2024-04-20 12:02:47,778: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.011690829309276625]
[2024-04-20 12:02:48,439: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.020140512690156733]
[2024-04-20 12:02:49,103: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.033010849971626365]
[2024-04-20 12:02:49,773: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.017896679958952427]
[2024-04-20 12:02:50,443: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.009416545731146699]
[2024-04-20 12:02:51,108: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.009917772361215571]
[2024-04-20 12:02:51,761: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.02296356037786792]
[2024-04-20 12:02:52,416: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.018982012833541933]
[2024-04-20 12:02:53,070: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.018769506070966516]
[2024-04-20 12:02:53,727: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.023591002271060136]
[2024-04-20 12:02:54,382: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.014750707510555265]
[2024-04-20 12:02:55,036: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.02837687212267262]
[2024-04-20 12:02:55,693: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.034428309493787355]
[2024-04-20 12:02:56,349: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.024871421381110162]
[2024-04-20 12:02:57,000: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.017492031226134498]
[2024-04-20 12:02:57,658: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.020900391382986473]
[2024-04-20 12:02:58,316: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.009902102550476431]
[2024-04-20 12:02:58,970: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.009413055763873452]
[2024-04-20 12:02:59,624: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.011027017630827895]
[2024-04-20 12:03:00,279: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.008599513307047687]
[2024-04-20 12:03:00,931: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.0034748934161215306]
[2024-04-20 12:03:01,595: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.010577398575636266]
[2024-04-20 12:03:02,257: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.027112316245378073]
[2024-04-20 12:03:02,925: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.025432774212421076]
[2024-04-20 12:03:03,594: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.01086553930347389]
[2024-04-20 12:03:04,252: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.005414497275192383]
[2024-04-20 12:03:04,907: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.006413663641566176]
[2024-04-20 12:03:05,561: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.018715958799143593]
[2024-04-20 12:03:06,214: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.010923488576669207]
[2024-04-20 12:03:06,872: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.013748440737338845]
[2024-04-20 12:03:07,525: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.008415541551529798]
[2024-04-20 12:03:08,179: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.0046098606909731575]
[2024-04-20 12:03:08,835: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.022803390873230946]
[2024-04-20 12:03:09,490: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.0190895743119289]
[2024-04-20 12:03:10,141: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.007656067701122055]
[2024-04-20 12:03:10,797: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.015676117261100485]
[2024-04-20 12:03:11,454: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.029524302176010205]
[2024-04-20 12:03:12,110: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.009895602900818699]
[2024-04-20 12:03:12,767: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.04883754540543979]
[2024-04-20 12:03:13,428: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.010466375464485377]
[2024-04-20 12:03:14,090: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.012126100456105246]
[2024-04-20 12:03:14,759: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.030753212086398776]
[2024-04-20 12:03:15,426: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.017649840137264696]
[2024-04-20 12:03:16,097: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.01006905252091389]
[2024-04-20 12:03:16,763: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.019826299522679284]
[2024-04-20 12:03:17,430: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.026490540334521504]
[2024-04-20 12:03:18,084: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.007680721028471147]
[2024-04-20 12:03:18,743: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.01979045737348673]
[2024-04-20 12:03:19,396: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.010909778436264244]
[2024-04-20 12:03:20,053: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.024369316212039846]
[2024-04-20 12:03:20,710: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.01584134138288458]
[2024-04-20 12:03:21,368: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.01647039969452571]
[2024-04-20 12:03:22,023: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.006848057422538853]
[2024-04-20 12:03:22,675: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.037156737071881336]
[2024-04-20 12:03:23,332: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.018928782361778883]
[2024-04-20 12:03:23,987: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.009189826128131245]
[2024-04-20 12:03:24,638: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.014609302581957617]
[2024-04-20 12:03:25,295: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.020356685601484067]
[2024-04-20 12:03:25,951: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.013242744823812096]
[2024-04-20 12:03:26,607: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.009325346204168097]
[2024-04-20 12:03:27,266: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.007583763759309173]
[2024-04-20 12:03:27,932: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.013910816794639737]
[2024-04-20 12:03:28,603: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.013199572403252422]
[2024-04-20 12:03:29,263: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.01942899607954162]
[2024-04-20 12:03:29,922: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.0079293185826075]
[2024-04-20 12:03:30,587: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.03650396475986226]
[2024-04-20 12:03:31,239: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.023884721696542217]
[2024-04-20 12:03:31,894: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.016315327153024268]
[2024-04-20 12:03:32,549: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.08896509416079672]
[2024-04-20 12:03:33,200: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.026207337849171033]
[2024-04-20 12:03:33,861: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.004358262709038434]
[2024-04-20 12:03:34,514: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.021660353861261573]
[2024-04-20 12:03:35,177: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.041197406844211304]
[2024-04-20 12:03:35,833: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.006384834134330761]
[2024-04-20 12:03:36,488: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.021070700563609934]
[2024-04-20 12:03:37,148: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.012475277661813833]
[2024-04-20 12:03:37,807: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.011087116440117735]
[2024-04-20 12:03:38,472: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.009330720037960758]
[2024-04-20 12:03:39,135: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.024869522060118963]
[2024-04-20 12:03:39,803: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.014409937067643994]
[2024-04-20 12:03:40,455: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.007875007162833486]
[2024-04-20 12:03:41,113: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.005276679100440528]
[2024-04-20 12:03:41,784: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.010858540663123419]
[2024-04-20 12:03:42,448: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.015124676972502431]
[2024-04-20 12:03:43,111: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.012547406548463744]
[2024-04-20 12:03:43,775: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.014042269556502405]
[2024-04-20 12:03:44,433: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.019248029553891665]
[2024-04-20 12:03:45,085: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.007700959421912092]
[2024-04-20 12:03:45,741: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.02762517068036199]
[2024-04-20 12:03:46,401: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.017441436854172643]
[2024-04-20 12:03:47,056: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.01580819696173609]
[2024-04-20 12:03:47,711: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.023262126877431642]
[2024-04-20 12:03:48,364: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.00968390818101267]
[2024-04-20 12:03:49,015: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.005641831957740248]
[2024-04-20 12:03:49,669: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.010455859218777808]
[2024-04-20 12:03:50,322: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.0070659272662598254]
[2024-04-20 12:03:50,974: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.006030776839833693]
[2024-04-20 12:03:51,625: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.009768044661927617]
[2024-04-20 12:03:52,278: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.018290114602681033]
[2024-04-20 12:03:52,929: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.006455845634275573]
[2024-04-20 12:03:53,583: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.004460088587113028]
[2024-04-20 12:03:54,247: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.008048196013633567]
[2024-04-20 12:03:54,911: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.027968194653688692]
[2024-04-20 12:03:55,576: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.0026614492933148956]
[2024-04-20 12:03:56,241: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.013530004304178058]
[2024-04-20 12:03:56,928: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.01673476079833765]
[2024-04-20 12:03:57,607: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.0279845908613077]
[2024-04-20 12:03:58,269: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.015885848240591024]
[2024-04-20 12:03:58,932: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.020338864301281855]
[2024-04-20 12:03:59,599: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.05020957145594222]
[2024-04-20 12:04:00,257: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.04847172280875978]
[2024-04-20 12:04:00,908: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.013892623752709806]
[2024-04-20 12:04:01,560: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.007433813135271974]
[2024-04-20 12:04:02,219: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.01972363962934939]
[2024-04-20 12:04:02,872: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.009441012971683503]
[2024-04-20 12:04:03,522: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.01132954643527056]
[2024-04-20 12:04:04,181: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.007172457838954612]
[2024-04-20 12:04:04,833: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.0055819231128795]
[2024-04-20 12:04:05,488: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.0187282642999355]
[2024-04-20 12:04:06,137: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.03557256393123669]
[2024-04-20 12:04:06,787: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.00794024046235187]
[2024-04-20 12:04:07,440: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.012102459347174967]
[2024-04-20 12:04:08,104: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.04192623340440953]
[2024-04-20 12:04:08,774: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.013749348970412547]
[2024-04-20 12:04:09,442: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.010178286511766244]
[2024-04-20 12:04:10,105: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.012954430041546632]
[2024-04-20 12:04:10,783: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.020627413311413205]
[2024-04-20 12:04:11,443: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.0029861124512924665]
[2024-04-20 12:04:12,095: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.004419048484005453]
[2024-04-20 12:04:12,751: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.017437924916086103]
[2024-04-20 12:04:13,406: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.010073509640573412]
[2024-04-20 12:04:14,062: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.008235134783591566]
[2024-04-20 12:04:14,718: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.01254757817179176]
[2024-04-20 12:04:15,374: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.02036550427297668]
[2024-04-20 12:04:16,021: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.0074715121996877]
[2024-04-20 12:04:16,679: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.005198753890527198]
[2024-04-20 12:04:17,333: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.01841658808177367]
[2024-04-20 12:04:17,986: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.045434385388159984]
[2024-04-20 12:04:18,642: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.008904052986980833]
[2024-04-20 12:04:19,298: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.012589067728210886]
[2024-04-20 12:04:19,947: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.005357389345911813]
[2024-04-20 12:04:20,602: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.017218810023726803]
[2024-04-20 12:04:21,264: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.01789696463991039]
[2024-04-20 12:04:21,940: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.02476242233358354]
[2024-04-20 12:04:22,606: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.04449640544552357]
[2024-04-20 12:04:23,267: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.007587120705555473]
[2024-04-20 12:04:23,940: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.01511864656671122]
[2024-04-20 12:04:24,600: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.01912012304891046]
[2024-04-20 12:04:25,247: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.01021473739154098]
[2024-04-20 12:04:25,902: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.007594936323580902]
[2024-04-20 12:04:26,555: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.034782340682306644]
[2024-04-20 12:04:27,205: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.006405460810307338]
[2024-04-20 12:04:27,861: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.07704368815542426]
[2024-04-20 12:04:28,514: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.004412343790770144]
[2024-04-20 12:04:29,167: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.004977203337290313]
[2024-04-20 12:04:29,821: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.0058060171157637164]
[2024-04-20 12:04:30,473: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.016447768069782317]
[2024-04-20 12:04:31,130: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.024222074689812672]
[2024-04-20 12:04:31,785: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.0038773841747275816]
[2024-04-20 12:04:32,441: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.02673160090828204]
[2024-04-20 12:04:33,095: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.019961012390885897]
[2024-04-20 12:04:33,753: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.0032662360078830684]
[2024-04-20 12:04:34,418: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.03446791723174045]
[2024-04-20 12:04:35,078: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.00816332156880301]
[2024-04-20 12:04:35,734: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.026717475070023863]
[2024-04-20 12:04:36,392: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.011016430884514048]
[2024-04-20 12:04:37,068: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.013812027867282665]
[2024-04-20 12:04:37,731: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.035298752131618115]
[2024-04-20 12:04:38,387: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.023660612708859573]
[2024-04-20 12:04:39,045: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.009262950687427307]
[2024-04-20 12:04:39,700: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.08580563719886969]
[2024-04-20 12:04:40,358: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.018450501712575628]
[2024-04-20 12:04:41,015: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.02299643203928858]
[2024-04-20 12:04:41,674: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.031407926602817535]
[2024-04-20 12:04:42,327: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.020819808415185815]
[2024-04-20 12:04:42,984: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.01290086449651976]
[2024-04-20 12:04:43,638: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.0187920644476859]
[2024-04-20 12:04:44,295: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.007308893385917405]
[2024-04-20 12:04:44,952: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.014826725695204934]
[2024-04-20 12:04:45,605: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.010210304822974222]
[2024-04-20 12:04:46,263: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.021837632452329298]
[2024-04-20 12:04:46,921: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.038724890011943694]
[2024-04-20 12:04:47,577: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.043758661231116346]
[2024-04-20 12:04:48,235: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.03206733894880805]
[2024-04-20 12:04:48,898: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.00991046694447848]
[2024-04-20 12:04:49,560: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.012865777141538609]
[2024-04-20 12:04:50,225: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.026632742613132573]
[2024-04-20 12:04:50,892: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.007481639452469406]
[2024-04-20 12:04:51,547: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.020263767729494408]
[2024-04-20 12:04:52,202: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.005600945159749855]
[2024-04-20 12:04:52,867: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.021967670801929098]
[2024-04-20 12:04:53,525: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.014942382958485398]
[2024-04-20 12:04:54,181: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.02344270168150066]
[2024-04-20 12:04:54,833: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.004940814073984952]
[2024-04-20 12:04:55,491: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.0307362884371601]
[2024-04-20 12:04:56,148: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.0038288922983694498]
[2024-04-20 12:04:56,801: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.010678667755326325]
[2024-04-20 12:04:57,465: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.025240826714780194]
[2024-04-20 12:04:58,121: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.006296883766882098]
[2024-04-20 12:04:58,776: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.017284096835237808]
[2024-04-20 12:04:59,431: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.006876374582124713]
[2024-04-20 12:05:00,089: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.0032561236747309886]
[2024-04-20 12:05:00,752: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.03998342090042011]
[2024-04-20 12:05:01,411: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.026220624515247738]
[2024-04-20 12:05:02,076: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.020802142829769135]
[2024-04-20 12:05:02,738: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.011903796095732925]
[2024-04-20 12:05:03,401: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.012096796067682125]
[2024-04-20 12:05:04,067: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.01560322835945593]
[2024-04-20 12:05:04,722: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.01676736535627451]
[2024-04-20 12:05:05,381: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.04050314393588398]
[2024-04-20 12:05:06,038: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.015925444430180773]
[2024-04-20 12:05:06,696: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.004414073681783211]
[2024-04-20 12:05:07,348: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.012062275566907614]
[2024-04-20 12:05:08,001: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.01680795460690733]
[2024-04-20 12:05:08,656: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.004388676378783]
[2024-04-20 12:05:09,310: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.01214725573734612]
[2024-04-20 12:05:09,967: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.013581739267540926]
[2024-04-20 12:05:10,623: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.03497861079096396]
[2024-04-20 12:05:11,284: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.005712393692582939]
[2024-04-20 12:05:11,937: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.0040334173472803105]
[2024-04-20 12:05:12,595: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.0046023086245421795]
[2024-04-20 12:05:13,253: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.015779892326193513]
[2024-04-20 12:05:13,913: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.008135980490843511]
[2024-04-20 12:05:14,581: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.014274980320215548]
[2024-04-20 12:05:15,246: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.017964282738520857]
[2024-04-20 12:05:15,921: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.003999290016036821]
[2024-04-20 12:05:16,594: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.017750515071597465]
[2024-04-20 12:05:17,251: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.006315654267317451]
[2024-04-20 12:05:17,906: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.009770088151077164]
[2024-04-20 12:05:18,566: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.013517402077839451]
[2024-04-20 12:05:19,223: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.018866223928941085]
[2024-04-20 12:05:19,879: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.013794291080107542]
[2024-04-20 12:05:20,533: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.010852704073627505]
[2024-04-20 12:05:21,188: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.017666345787498965]
[2024-04-20 12:05:21,843: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.01422516921032746]
[2024-04-20 12:05:22,496: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.018681216433810148]
[2024-04-20 12:05:23,151: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.008684723951252846]
[2024-04-20 12:05:23,812: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.0024201917525700375]
[2024-04-20 12:05:24,467: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.015687130635344698]
[2024-04-20 12:05:25,126: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.025647130166589583]
[2024-04-20 12:05:25,779: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.015031697865324925]
[2024-04-20 12:05:26,432: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.015470877504108332]
[2024-04-20 12:05:27,091: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.02688597361387691]
[2024-04-20 12:05:27,766: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.012549442847065809]
[2024-04-20 12:05:28,432: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.012187148456352171]
[2024-04-20 12:05:29,093: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.028548618017799683]
[2024-04-20 12:05:29,762: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.003986225371847193]
[2024-04-20 12:05:30,420: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.002159219508021346]
[2024-04-20 12:05:31,069: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.03186291597854246]
[2024-04-20 12:05:31,729: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.01070536485042327]
[2024-04-20 12:05:32,383: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.020054965804057707]
[2024-04-20 12:05:33,038: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.006877070147681985]
[2024-04-20 12:05:33,694: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.01481767221744319]
[2024-04-20 12:05:34,351: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.03609198745153441]
[2024-04-20 12:05:35,012: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.010162750095840365]
[2024-04-20 12:05:35,665: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.014084127577039494]
[2024-04-20 12:05:36,318: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.013849330346603333]
[2024-04-20 12:05:36,972: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.001334437631097479]
[2024-04-20 12:05:37,622: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.0012065676260345913]
[2024-04-20 12:05:38,282: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.015705600217534355]
[2024-04-20 12:05:38,938: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.01544396773873474]
[2024-04-20 12:05:39,594: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.01657055228443812]
[2024-04-20 12:05:40,250: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.010378681754724589]
[2024-04-20 12:05:40,907: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.005160046106614268]
[2024-04-20 12:05:41,578: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.00620585333376278]
[2024-04-20 12:05:42,245: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.01658194601309619]
[2024-04-20 12:05:42,907: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.020687257336555145]
[2024-04-20 12:05:43,568: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.015633659140746374]
[2024-04-20 12:05:44,215: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.013419491633741664]
[2024-04-20 12:05:44,870: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.011484433865811739]
[2024-04-20 12:05:45,526: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.045926992552680304]
[2024-04-20 12:05:46,180: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.01194149210713407]
[2024-04-20 12:05:46,833: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.018371951908969897]
[2024-04-20 12:05:47,488: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.009677463559235279]
[2024-04-20 12:05:48,143: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.005786336910306192]
[2024-04-20 12:05:48,793: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.01715060838267339]
[2024-04-20 12:05:49,448: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.038957554218212176]
[2024-04-20 12:05:50,097: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.004195001487072864]
[2024-04-20 12:05:50,751: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.015536260146825132]
[2024-04-20 12:05:51,406: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.029325699779757613]
[2024-04-20 12:05:52,055: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.011176060213206024]
[2024-04-20 12:05:52,708: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.01620673521472487]
[2024-04-20 12:05:53,362: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.011835373021564915]
[2024-04-20 12:05:54,034: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.00986245937467954]
[2024-04-20 12:05:54,698: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.015313797681711748]
[2024-04-20 12:05:55,372: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.008398966544660004]
[2024-04-20 12:05:56,045: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.0046376957143148675]
[2024-04-20 12:05:56,704: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.014451161631487946]
[2024-04-20 12:05:57,358: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.024018613867713746]
[2024-04-20 12:05:58,010: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.007808609555468676]
[2024-04-20 12:05:58,661: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.02899033376731991]
[2024-04-20 12:05:59,317: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.014340409159366421]
[2024-04-20 12:05:59,974: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.00269516945067407]
[2024-04-20 12:06:00,628: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.0068421341422261785]
[2024-04-20 12:06:01,280: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.007868584097897152]
[2024-04-20 12:06:01,933: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.008415087889791242]
[2024-04-20 12:06:02,589: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.0034909423333317944]
[2024-04-20 12:06:03,242: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.02001189367001431]
[2024-04-20 12:06:03,898: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.020945745249382548]
[2024-04-20 12:06:04,553: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.02006102417905747]
[2024-04-20 12:06:05,206: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.005483199671893294]
[2024-04-20 12:06:05,865: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.02255973347067622]
[2024-04-20 12:06:06,517: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.00963870780007834]
[2024-04-20 12:06:07,195: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.015054744364937528]
[2024-04-20 12:06:07,867: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.01334690390432068]
[2024-04-20 12:06:08,521: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.00721735152976713]
[2024-04-20 12:06:09,182: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.018247897292454122]
[2024-04-20 12:06:09,841: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.015073730646066973]
[2024-04-20 12:06:10,493: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.007070064774928498]
[2024-04-20 12:06:11,145: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.01067104215647158]
[2024-04-20 12:06:11,801: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.0023580440177990315]
[2024-04-20 12:06:12,454: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.011454111804831232]
[2024-04-20 12:06:13,112: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.020821137581400546]
[2024-04-20 12:06:13,766: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.002648023075932086]
[2024-04-20 12:06:14,418: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.01137684213567165]
[2024-04-20 12:06:15,070: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.0019454910379937392]
[2024-04-20 12:06:15,725: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.006853730939744758]
[2024-04-20 12:06:16,378: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.005882007832495851]
[2024-04-20 12:06:17,032: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.05389634541230101]
[2024-04-20 12:06:17,684: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.001939640220424772]
[2024-04-20 12:06:18,338: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.01374987168274092]
[2024-04-20 12:06:18,991: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.016193959513956874]
[2024-04-20 12:06:19,643: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.00802470976167834]
[2024-04-20 12:06:20,304: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.0022677406260938034]
[2024-04-20 12:06:20,964: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.0058004673680959115]
[2024-04-20 12:06:21,634: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.02453178008165431]
[2024-04-20 12:06:22,292: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.023016923117159357]
[2024-04-20 12:06:22,949: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.015956212067749085]
[2024-04-20 12:06:23,601: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.019519473461221695]
[2024-04-20 12:06:24,253: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.03130797848833581]
[2024-04-20 12:06:24,904: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.005472307630674438]
[2024-04-20 12:06:25,559: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.007935444943994022]
[2024-04-20 12:06:26,211: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.0053189101876292095]
[2024-04-20 12:06:26,864: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.00621241881453116]
[2024-04-20 12:06:27,514: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.011183491571370276]
[2024-04-20 12:06:28,169: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.02159524423674599]
[2024-04-20 12:06:28,821: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.010338910629122004]
[2024-04-20 12:06:29,478: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.0256066634128139]
[2024-04-20 12:06:30,132: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.017850130259539326]
[2024-04-20 12:06:30,785: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.041276410927314135]
[2024-04-20 12:06:31,441: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.009315998708712327]
[2024-04-20 12:06:32,096: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.028273963900982683]
[2024-04-20 12:06:32,750: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.01572305368639363]
[2024-04-20 12:06:33,413: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.029966358643059316]
[2024-04-20 12:06:34,078: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.003484536773669781]
[2024-04-20 12:06:34,740: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.011095060952527417]
[2024-04-20 12:06:35,404: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.009318707384515115]
[2024-04-20 12:06:36,071: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.012815985343290221]
[2024-04-20 12:06:36,724: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.028415553071853502]
[2024-04-20 12:06:37,380: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.025227116534434317]
[2024-04-20 12:06:38,031: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.03184921523067886]
[2024-04-20 12:06:38,686: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.0028204950105385563]
[2024-04-20 12:06:39,340: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.0165214097080168]
[2024-04-20 12:06:39,999: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.00952699576457031]
[2024-04-20 12:06:40,654: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.03316488401497542]
[2024-04-20 12:06:41,309: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.007031470693231587]
[2024-04-20 12:06:41,971: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.01975796796729628]
[2024-04-20 12:06:42,632: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.01345146346821738]
[2024-04-20 12:06:43,290: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.03083656116966652]
[2024-04-20 12:06:43,952: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.029394806756589613]
[2024-04-20 12:06:44,631: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.008731733784561043]
[2024-04-20 12:06:45,290: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.012193714891294036]
[2024-04-20 12:06:45,943: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.020303753029650935]
[2024-04-20 12:06:46,604: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.04096877524036375]
[2024-04-20 12:06:47,266: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.028033263624246452]
[2024-04-20 12:06:47,928: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.00547004382267288]
[2024-04-20 12:06:48,604: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.026084452045668505]
[2024-04-20 12:06:49,264: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.015300152080293008]
[2024-04-20 12:06:49,919: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.041837908440757965]
[2024-04-20 12:06:50,574: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.025005774837526033]
[2024-04-20 12:06:51,234: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.028822731261469583]
[2024-04-20 12:06:51,887: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.0100109857707788]
[2024-04-20 12:06:52,543: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.01717761741860619]
[2024-04-20 12:06:53,197: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.018093141231136443]
[2024-04-20 12:06:53,852: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.013963435061200008]
[2024-04-20 12:06:54,509: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.010792172295202896]
[2024-04-20 12:06:55,161: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.011986831645798512]
[2024-04-20 12:06:55,815: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.032887975388769766]
[2024-04-20 12:06:56,467: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.04851437450488722]
[2024-04-20 12:06:57,122: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.012628383053830856]
[2024-04-20 12:06:57,775: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.0109355990237818]
[2024-04-20 12:06:58,433: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.0351681604891458]
[2024-04-20 12:06:59,085: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.030676073926714155]
[2024-04-20 12:06:59,746: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.00948264041601184]
[2024-04-20 12:07:00,414: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.01584856747177685]
[2024-04-20 12:07:01,089: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.02403920213129175]
[2024-04-20 12:07:01,759: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.03175626682362223]
[2024-04-20 12:07:02,414: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.010976153855654655]
[2024-04-20 12:07:03,084: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.012677024874892409]
[2024-04-20 12:07:03,749: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.0033891413378495127]
[2024-04-20 12:07:04,409: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.036614794185554474]
[2024-04-20 12:07:05,089: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.002955993616262326]
[2024-04-20 12:07:05,763: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.016381538024253937]
[2024-04-20 12:07:06,414: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.010496824474895035]
[2024-04-20 12:07:07,077: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.021917553835729277]
[2024-04-20 12:07:07,731: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.005827248888193776]
[2024-04-20 12:07:08,388: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.005139815215901244]
[2024-04-20 12:07:09,042: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.00528975231626211]
[2024-04-20 12:07:09,701: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.013541171140217243]
[2024-04-20 12:07:10,356: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.025874796333553787]
[2024-04-20 12:07:11,010: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.0063645375623130425]
[2024-04-20 12:07:11,664: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.008742072410246873]
[2024-04-20 12:07:12,321: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.050543019883376034]
[2024-04-20 12:07:12,981: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.021344039844847233]
[2024-04-20 12:07:13,641: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.012573366392646182]
[2024-04-20 12:07:14,304: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.01651494473568537]
[2024-04-20 12:07:14,971: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.018466469392433994]
[2024-04-20 12:07:15,638: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.005775226958367604]
[2024-04-20 12:07:16,294: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.003353205758391977]
[2024-04-20 12:07:16,948: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.016388161638759596]
[2024-04-20 12:07:17,602: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.0062978931594679785]
[2024-04-20 12:07:18,255: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.010943755522453049]
[2024-04-20 12:07:18,909: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.013932740325506517]
[2024-04-20 12:07:19,562: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.040278003450517776]
[2024-04-20 12:07:20,217: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.006753409453991406]
[2024-04-20 12:07:20,870: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.008907510735390164]
[2024-04-20 12:07:21,520: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.014754472218067784]
[2024-04-20 12:07:22,174: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.04921369494211261]
[2024-04-20 12:07:22,832: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.01633726832689655]
[2024-04-20 12:07:23,487: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.01563160732325999]
[2024-04-20 12:07:24,139: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.007314097524286583]
[2024-04-20 12:07:24,792: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.009945436545398662]
[2024-04-20 12:07:25,449: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.011736955909750412]
[2024-04-20 12:07:26,110: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.019649065085490643]
[2024-04-20 12:07:26,786: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.010964747743591616]
[2024-04-20 12:07:27,463: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.015393603567956665]
[2024-04-20 12:07:28,125: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.013405920321436088]
[2024-04-20 12:07:28,784: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.0031369462068923516]
[2024-04-20 12:07:29,440: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.0098092685135847]
[2024-04-20 12:07:30,097: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.011342983109942611]
[2024-04-20 12:07:30,755: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.010068399809613993]
[2024-04-20 12:07:31,408: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.01316426293692543]
[2024-04-20 12:07:32,063: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.014663117605114297]
[2024-04-20 12:07:32,721: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.019823578499944174]
[2024-04-20 12:07:33,379: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.007573032500231265]
[2024-04-20 12:07:34,033: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.01548917427347564]
[2024-04-20 12:07:34,691: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.015509826586934788]
[2024-04-20 12:07:35,345: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.01640088921080613]
[2024-04-20 12:07:36,003: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.037803296525782126]
[2024-04-20 12:07:36,657: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.01724369620958938]
[2024-04-20 12:07:37,312: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.008652059137774318]
[2024-04-20 12:07:37,963: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.008576661168646586]
[2024-04-20 12:07:38,619: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.009049469482297588]
[2024-04-20 12:07:39,286: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.007934598256185144]
[2024-04-20 12:07:39,953: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.021493161766391936]
[2024-04-20 12:07:40,619: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.008374250573614976]
[2024-04-20 12:07:41,285: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.005888683866120893]
[2024-04-20 12:07:41,951: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.08144079323371171]
[2024-04-20 12:07:42,607: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.008854630092224532]
[2024-04-20 12:07:43,261: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.008211967964254732]
[2024-04-20 12:07:43,913: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.004857333714941498]
[2024-04-20 12:07:44,566: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.0020021917349891368]
[2024-04-20 12:07:45,222: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.013753706006498783]
[2024-04-20 12:07:45,877: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.003667289409791829]
[2024-04-20 12:07:46,530: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.0037321071137391723]
[2024-04-20 12:07:47,180: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.015577515952730528]
[2024-04-20 12:07:47,833: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.012731936923739987]
[2024-04-20 12:07:48,488: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.0158879201197655]
[2024-04-20 12:07:49,140: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.02955536165697991]
[2024-04-20 12:07:49,794: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.04288002294021247]
[2024-04-20 12:07:50,452: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.01757346488085832]
[2024-04-20 12:07:51,109: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.022199159257612105]
[2024-04-20 12:07:51,763: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.017686420183810073]
[2024-04-20 12:07:52,433: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.01276822696598579]
[2024-04-20 12:07:53,102: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.01589619695142398]
[2024-04-20 12:07:53,763: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.015866477134119948]
[2024-04-20 12:07:54,431: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.005787870745473486]
[2024-04-20 12:07:55,097: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.041833433694535085]
[2024-04-20 12:07:55,754: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.011805864141881187]
[2024-04-20 12:07:56,414: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.0015493291705506675]
[2024-04-20 12:07:57,066: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.004059490945477691]
[2024-04-20 12:07:57,719: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.008090789547151585]
[2024-04-20 12:07:58,375: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.011741994441060225]
[2024-04-20 12:07:59,027: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.014852272875957515]
[2024-04-20 12:07:59,683: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.014738100185259513]
[2024-04-20 12:08:00,340: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.009539011240111271]
[2024-04-20 12:08:00,992: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.028258745280633244]
[2024-04-20 12:08:01,647: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.04229292848401515]
[2024-04-20 12:08:02,304: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.008868844225070584]
[2024-04-20 12:08:02,959: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.037535446661045205]
[2024-04-20 12:08:03,612: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.011649444171159687]
[2024-04-20 12:08:04,267: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.012601704903720416]
[2024-04-20 12:08:04,923: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.017464919419369354]
[2024-04-20 12:08:05,593: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.03908722268326023]
[2024-04-20 12:08:06,258: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.010099950190347623]
[2024-04-20 12:08:06,919: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.009165759507931831]
[2024-04-20 12:08:07,599: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.04356937636788727]
[2024-04-20 12:08:08,265: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.02809572451752412]
[2024-04-20 12:08:08,912: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.01194422686761197]
[2024-04-20 12:08:09,573: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.006535972332166276]
[2024-04-20 12:08:10,230: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.004575023707128584]
[2024-04-20 12:08:10,882: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.013689366647440833]
[2024-04-20 12:08:11,536: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.009458232506684703]
[2024-04-20 12:08:12,190: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.015248522707995834]
[2024-04-20 12:08:12,846: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.011019176056576077]
[2024-04-20 12:08:13,507: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.03310808698784827]
[2024-04-20 12:08:14,163: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.0021492778874571163]
[2024-04-20 12:08:14,820: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.017497123870446604]
[2024-04-20 12:08:15,475: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.009091369497476576]
[2024-04-20 12:08:16,130: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.0160303623793731]
[2024-04-20 12:08:16,785: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.02656726483694345]
[2024-04-20 12:08:17,442: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.010635840957125282]
[2024-04-20 12:08:18,101: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.01825679000201124]
[2024-04-20 12:08:18,754: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.0029066160772166076]
[2024-04-20 12:08:19,414: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.002251299423369121]
[2024-04-20 12:08:20,077: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.019523814947660045]
[2024-04-20 12:08:20,765: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.005527790031278306]
[2024-04-20 12:08:21,442: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.010217110919295247]
[2024-04-20 12:08:22,095: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.018556871844458395]
[2024-04-20 12:08:22,758: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.004634627858617806]
[2024-04-20 12:08:23,413: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.004466530700505942]
[2024-04-20 12:08:24,066: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.020910432353252215]
[2024-04-20 12:08:24,724: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.01530634616300488]
[2024-04-20 12:08:25,382: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.012034103471790786]
[2024-04-20 12:08:26,035: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.013228034350699988]
[2024-04-20 12:08:26,691: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.003714855345506394]
[2024-04-20 12:08:27,347: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.03071211442202215]
[2024-04-20 12:08:27,998: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.012895543298482609]
[2024-04-20 12:08:28,653: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.002693432566068101]
[2024-04-20 12:08:29,305: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.007863455182815718]
[2024-04-20 12:08:29,958: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.0026674563048264747]
[2024-04-20 12:08:30,617: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.011699469946483243]
[2024-04-20 12:08:31,277: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.01223789523715715]
[2024-04-20 12:08:31,935: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.0006294321002457047]
[2024-04-20 12:08:32,592: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.014031747066212961]
[2024-04-20 12:08:33,252: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.008117341662727574]
[2024-04-20 12:08:33,918: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.005525686841172869]
[2024-04-20 12:08:34,587: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.01988889745095311]
[2024-04-20 12:08:35,238: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.005451481272787836]
[2024-04-20 12:08:35,894: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.01562643505825278]
[2024-04-20 12:08:36,551: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.057290028141286205]
[2024-04-20 12:08:37,207: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.02964693893253166]
[2024-04-20 12:08:37,864: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.002756173896538114]
[2024-04-20 12:08:38,523: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.008016955372751678]
[2024-04-20 12:08:39,182: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.009275676793301393]
[2024-04-20 12:08:39,835: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.00597486948201771]
[2024-04-20 12:08:40,487: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.04456222768553315]
[2024-04-20 12:08:41,137: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.022816967265437606]
[2024-04-20 12:08:41,793: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.00827617527850297]
[2024-04-20 12:08:42,446: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.01480022479294768]
[2024-04-20 12:08:43,100: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.009384820467938535]
[2024-04-20 12:08:43,756: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.03930813520533673]
[2024-04-20 12:08:44,407: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.022110975411451458]
[2024-04-20 12:08:45,070: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.006453245729090343]
[2024-04-20 12:08:45,751: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.01064310484861733]
[2024-04-20 12:08:46,415: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.0083608958541701]
[2024-04-20 12:08:47,071: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.002624968681772922]
[2024-04-20 12:08:47,746: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.007987986557102771]
[2024-04-20 12:08:48,402: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.005922698916334693]
[2024-04-20 12:08:49,052: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.00878511247063815]
[2024-04-20 12:08:49,706: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.01433296718661772]
[2024-04-20 12:08:50,360: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.008297317481655594]
[2024-04-20 12:08:51,013: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.012730169386187932]
[2024-04-20 12:08:51,670: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.01763597220452215]
[2024-04-20 12:08:52,326: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.009298979071323281]
[2024-04-20 12:08:52,981: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.025455804116167248]
[2024-04-20 12:08:53,633: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.00872514354684869]
[2024-04-20 12:08:54,287: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.01867768362511695]
[2024-04-20 12:08:54,938: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.002734229733216192]
[2024-04-20 12:08:55,591: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.010003469840072582]
[2024-04-20 12:08:56,247: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.008424006994020133]
[2024-04-20 12:08:56,898: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.015368043318786374]
[2024-04-20 12:08:57,552: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.01030066776260902]
[2024-04-20 12:08:58,212: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.015750599580213347]
[2024-04-20 12:08:58,875: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.0020048243765184003]
[2024-04-20 12:08:59,532: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.00321896621824959]
[2024-04-20 12:09:00,209: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.01925867749252512]
[2024-04-20 12:09:00,884: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.021435018252913326]
[2024-04-20 12:09:01,535: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.021351054837489586]
[2024-04-20 12:09:02,190: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.008713307640327449]
[2024-04-20 12:09:02,844: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.0489121520215681]
[2024-04-20 12:09:03,495: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.017273937461949607]
[2024-04-20 12:09:04,148: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.005852709661455272]
[2024-04-20 12:09:04,800: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.013285734843955671]
[2024-04-20 12:09:05,453: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.012033203376454958]
[2024-04-20 12:09:06,107: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.007883319243888246]
[2024-04-20 12:09:06,758: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.026771648313876295]
[2024-04-20 12:09:07,410: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.014114388524142945]
[2024-04-20 12:09:08,065: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.019466969302556758]
[2024-04-20 12:09:08,723: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.0027340109107407127]
[2024-04-20 12:09:09,379: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.011537169275243918]
[2024-04-20 12:09:10,031: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.005539727119667316]
[2024-04-20 12:09:10,689: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.01868008853097733]
[2024-04-20 12:09:11,341: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.00759207053231005]
[2024-04-20 12:09:12,004: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.024197625534184346]
[2024-04-20 12:09:12,661: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.01190592583428905]
[2024-04-20 12:09:13,319: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.012940613888824365]
[2024-04-20 12:09:13,982: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.013063564600179068]
[2024-04-20 12:09:14,643: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.010609860618556144]
[2024-04-20 12:09:15,297: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.03225828576311751]
[2024-04-20 12:09:15,947: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.0068153089917460915]
[2024-04-20 12:09:16,605: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.02929083317094684]
[2024-04-20 12:09:17,261: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.013610364523382455]
[2024-04-20 12:09:17,918: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.014031053564688077]
[2024-04-20 12:09:18,570: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.03737935418618064]
[2024-04-20 12:09:19,225: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.09048944164108291]
[2024-04-20 12:09:19,876: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.003968805259323692]
[2024-04-20 12:09:20,527: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.013408199426249814]
[2024-04-20 12:09:21,181: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.019286836893581412]
[2024-04-20 12:09:21,832: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.006586934364792052]
[2024-04-20 12:09:22,483: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.001943365051431862]
[2024-04-20 12:09:23,132: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.006165073881092414]
[2024-04-20 12:09:23,790: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.004051975582420683]
[2024-04-20 12:09:24,448: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.015331998302809461]
[2024-04-20 12:09:25,108: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.011459663355522521]
[2024-04-20 12:09:25,773: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.026706168738059772]
[2024-04-20 12:09:26,434: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.005313528522258485]
[2024-04-20 12:09:27,092: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.016951448324980797]
[2024-04-20 12:09:27,754: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.005933367673647313]
[2024-04-20 12:09:28,409: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.006245896658457924]
[2024-04-20 12:09:29,063: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.01446099694023692]
[2024-04-20 12:09:29,717: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.0362131576624407]
[2024-04-20 12:09:30,373: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.008130718861499136]
[2024-04-20 12:09:31,024: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.036446527339220845]
[2024-04-20 12:09:31,679: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.010732926807828402]
[2024-04-20 12:09:32,330: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.012161238672415493]
[2024-04-20 12:09:32,989: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.03472081391582538]
[2024-04-20 12:09:33,645: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.0139943960852218]
[2024-04-20 12:09:34,293: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.012052145670063444]
[2024-04-20 12:09:34,952: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.004488191135422274]
[2024-04-20 12:09:35,608: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.012909376558910519]
[2024-04-20 12:09:36,262: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.01021421568719547]
[2024-04-20 12:09:36,914: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.012229703194263813]
[2024-04-20 12:09:37,567: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.011922592143532506]
[2024-04-20 12:09:38,231: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.018654062613136835]
[2024-04-20 12:09:38,898: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.009991337917021236]
[2024-04-20 12:09:39,567: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.012459984493350468]
[2024-04-20 12:09:40,232: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.008625558794725681]
[2024-04-20 12:09:40,893: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.01596900929608726]
[2024-04-20 12:09:41,549: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.011455166937501324]
[2024-04-20 12:09:42,203: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.026167483150318114]
[2024-04-20 12:09:42,858: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.009602104423422929]
[2024-04-20 12:09:43,511: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.018986884182892575]
[2024-04-20 12:09:44,165: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.017821894302755256]
[2024-04-20 12:09:44,818: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.014719581108156724]
[2024-04-20 12:09:45,473: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.017626027618567523]
[2024-04-20 12:09:46,129: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.00634690128594353]
[2024-04-20 12:09:46,785: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.021461883278928666]
[2024-04-20 12:09:47,441: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.001338273196449867]
[2024-04-20 12:09:48,099: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.008620564361512269]
[2024-04-20 12:09:48,755: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.012142936520323212]
[2024-04-20 12:09:49,416: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.10947030814258826]
[2024-04-20 12:09:50,077: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.026743675455538796]
[2024-04-20 12:09:50,736: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.009912314309587262]
[2024-04-20 12:09:51,422: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.01163898742066124]
[2024-04-20 12:09:52,096: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.03179330140931734]
[2024-04-20 12:09:52,758: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.010345853970829037]
[2024-04-20 12:09:53,426: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.012645915611455904]
[2024-04-20 12:09:54,096: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.02013432924399596]
[2024-04-20 12:09:54,760: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.003913083820694115]
[2024-04-20 12:09:55,418: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.023076064568195956]
[2024-04-20 12:09:56,070: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.0032500420714390854]
[2024-04-20 12:09:56,724: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.008071488966490131]
[2024-04-20 12:09:57,377: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.03104428525245548]
[2024-04-20 12:09:58,032: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.019078293404962376]
[2024-04-20 12:09:58,687: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.0030378357024272466]
[2024-04-20 12:09:59,342: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.022092483441992574]
[2024-04-20 12:09:59,993: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.028800659053946184]
[2024-04-20 12:10:00,650: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.012532955016094086]
[2024-04-20 12:10:01,305: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.007657869196816731]
[2024-04-20 12:10:01,963: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.013606878807041785]
[2024-04-20 12:10:02,617: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.0143861546538898]
[2024-04-20 12:10:03,271: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.04680389166381375]
[2024-04-20 12:10:03,928: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.0049889230854085025]
[2024-04-20 12:10:04,582: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.012128128300992724]
[2024-04-20 12:10:05,253: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.006268714961154679]
[2024-04-20 12:10:05,917: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.015579364878319527]
[2024-04-20 12:10:06,591: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.009388414194246141]
[2024-04-20 12:10:07,275: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.01216853431293113]
[2024-04-20 12:10:07,940: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.0025848468535978704]
[2024-04-20 12:10:08,593: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.024669680689898884]
[2024-04-20 12:10:09,249: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.0096877446864758]
[2024-04-20 12:10:09,901: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.006782747671906717]
[2024-04-20 12:10:10,580: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.020071444646579093]
[2024-04-20 12:10:11,253: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.003230326643270366]
[2024-04-20 12:10:11,914: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.00959653439918574]
[2024-04-20 12:10:12,596: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.023944622279625002]
[2024-04-20 12:10:13,263: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.0018434768418909523]
[2024-04-20 12:10:13,916: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.02559246579472202]
[2024-04-20 12:10:14,571: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.010389841181122978]
[2024-04-20 12:10:15,226: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.016494431593072786]
[2024-04-20 12:10:15,879: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.01977061247087876]
[2024-04-20 12:10:16,532: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.00591798098036179]
[2024-04-20 12:10:17,185: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.013544625957192316]
[2024-04-20 12:10:17,838: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.015323049710606577]
[2024-04-20 12:10:18,504: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.008340484219824883]
[2024-04-20 12:10:19,165: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.011216880013003786]
[2024-04-20 12:10:19,828: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.00544130825338479]
[2024-04-20 12:10:20,497: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.009312807752120615]
[2024-04-20 12:10:21,164: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.007125540021268983]
[2024-04-20 12:10:21,821: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.05198268748633021]
[2024-04-20 12:10:22,473: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.012264774684114037]
[2024-04-20 12:10:23,132: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.01025837906366928]
[2024-04-20 12:10:23,788: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.00601797949441695]
[2024-04-20 12:10:24,441: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.01675865483421358]
[2024-04-20 12:10:25,099: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.003631348973801586]
[2024-04-20 12:10:25,758: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.014730269248665778]
[2024-04-20 12:10:26,414: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.03656227112998311]
[2024-04-20 12:10:27,068: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.0032941901092475266]
[2024-04-20 12:10:27,725: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.010853909732118827]
[2024-04-20 12:10:28,380: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.055070710921960704]
[2024-04-20 12:10:29,042: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.03574253069138072]
[2024-04-20 12:10:29,697: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.004728689149741479]
[2024-04-20 12:10:30,356: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.00554381116930969]
[2024-04-20 12:10:31,011: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.02826306486674767]
[2024-04-20 12:10:31,688: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.001862828563224311]
[2024-04-20 12:10:32,354: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.024552715519962753]
[2024-04-20 12:10:33,010: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.007943736008327238]
[2024-04-20 12:10:33,681: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.02066444294544374]
[2024-04-20 12:10:34,352: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.01486272344512087]
[2024-04-20 12:10:35,005: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.013679966783724793]
[2024-04-20 12:10:35,660: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.005142007181293042]
[2024-04-20 12:10:36,313: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.008291139440601386]
[2024-04-20 12:10:36,970: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.010737813083527248]
[2024-04-20 12:10:37,626: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.009600517609632115]
[2024-04-20 12:10:38,281: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.006053363570108859]
[2024-04-20 12:10:38,935: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.019186982715389295]
[2024-04-20 12:10:39,596: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.03094837502193921]
[2024-04-20 12:10:40,250: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.015793439133222342]
[2024-04-20 12:10:40,903: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.005438214658438214]
[2024-04-20 12:10:41,558: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.008245345504908849]
[2024-04-20 12:10:42,213: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.017083528721429864]
[2024-04-20 12:10:42,870: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.026644323457132114]
[2024-04-20 12:10:43,526: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.0032069515079705254]
[2024-04-20 12:10:44,179: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.03517902611211923]
[2024-04-20 12:10:44,841: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.0031715300603304725]
[2024-04-20 12:10:45,507: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.015841094494546393]
[2024-04-20 12:10:46,169: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.06410350765860329]
[2024-04-20 12:10:46,831: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.011039196918112495]
[2024-04-20 12:10:47,492: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.013200371382974717]
[2024-04-20 12:10:48,151: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.004028444383258479]
[2024-04-20 12:10:48,806: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.031048470738197786]
[2024-04-20 12:10:49,463: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.05652361736358766]
[2024-04-20 12:10:50,119: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.004244721348004073]
[2024-04-20 12:10:50,775: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.01462931834466746]
[2024-04-20 12:10:51,431: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.04546342779221971]
[2024-04-20 12:10:52,092: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.011796601012554942]
[2024-04-20 12:10:52,749: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.005943362248653341]
[2024-04-20 12:10:53,405: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.015876491932574305]
[2024-04-20 12:10:54,062: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.018868260861620276]
[2024-04-20 12:10:54,718: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.006908022229584282]
[2024-04-20 12:10:55,372: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.01353050718356056]
[2024-04-20 12:10:56,029: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.03717843624329432]
[2024-04-20 12:10:56,682: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.008322763311091254]
[2024-04-20 12:10:57,334: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.01087580108690969]
[2024-04-20 12:10:57,992: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.03528309132062355]
[2024-04-20 12:10:58,665: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.009983805810477706]
[2024-04-20 12:10:59,334: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.018847757004575156]
[2024-04-20 12:10:59,994: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.015797334303176112]
[2024-04-20 12:11:00,655: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.015336193272700641]
[2024-04-20 12:11:01,311: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.004969405710798429]
[2024-04-20 12:11:01,967: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.012123058409510763]
[2024-04-20 12:11:02,621: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.00815545871189951]
[2024-04-20 12:11:03,274: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.08027722312356007]
[2024-04-20 12:11:03,926: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.01284045297880785]
[2024-04-20 12:11:04,586: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.01791508998308957]
[2024-04-20 12:11:05,239: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.012651210340358746]
[2024-04-20 12:11:05,897: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.0036930941407706396]
[2024-04-20 12:11:06,552: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.029002328197292742]
[2024-04-20 12:11:07,207: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.027919022731823916]
[2024-04-20 12:11:07,859: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.0021253985526528286]
[2024-04-20 12:11:08,513: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.015036472951174518]
[2024-04-20 12:11:09,165: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.018270838080442827]
[2024-04-20 12:11:09,824: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.0063230193859242605]
[2024-04-20 12:11:10,478: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.00932158862862231]
[2024-04-20 12:11:11,138: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.010343454591203166]
[2024-04-20 12:11:11,802: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.012710356999188635]
[2024-04-20 12:11:12,463: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.015142338067515936]
[2024-04-20 12:11:13,121: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.014808730733776053]
[2024-04-20 12:11:13,779: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.020816630833347505]
[2024-04-20 12:11:14,441: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.012592214627785581]
[2024-04-20 12:11:15,096: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.023680202080161767]
[2024-04-20 12:11:15,753: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.016506286097185272]
[2024-04-20 12:11:16,407: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.017057422541015863]
[2024-04-20 12:11:17,064: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.02032288352810031]
[2024-04-20 12:11:17,718: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.01624338484702336]
[2024-04-20 12:11:18,367: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.009025727982307913]
[2024-04-20 12:11:19,022: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.03677149202398662]
[2024-04-20 12:11:19,676: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.010342028708743853]
[2024-04-20 12:11:20,332: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.0013234031882823892]
[2024-04-20 12:11:20,984: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.033893474195475816]
[2024-04-20 12:11:21,640: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.024859327153810833]
[2024-04-20 12:11:22,297: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.00818227469869998]
[2024-04-20 12:11:22,953: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.019008585196087974]
[2024-04-20 12:11:23,608: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.013341333102941529]
[2024-04-20 12:11:24,259: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.02410996413189443]
[2024-04-20 12:11:24,920: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.02668246815639168]
[2024-04-20 12:11:25,593: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.019051616963550386]
[2024-04-20 12:11:26,267: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.0029390350943680143]
[2024-04-20 12:11:26,928: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.009681344170961725]
[2024-04-20 12:11:27,597: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.019479782973525893]
[2024-04-20 12:11:28,254: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.006592567970345805]
[2024-04-20 12:11:28,908: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.030781201130722156]
[2024-04-20 12:11:29,563: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.01390182337162213]
[2024-04-20 12:11:30,219: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.014867263223722098]
[2024-04-20 12:11:30,873: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.02375011815185023]
[2024-04-20 12:11:31,528: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.014475070158992206]
[2024-04-20 12:11:32,184: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.015716261578742643]
[2024-04-20 12:11:32,840: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.0047701158295297905]
[2024-04-20 12:11:33,496: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.01579044314424947]
[2024-04-20 12:11:34,143: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.015137745402025483]
[2024-04-20 12:11:34,795: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.010830962592666624]
[2024-04-20 12:11:35,449: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.020830109800446455]
[2024-04-20 12:11:36,101: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.00250367447046099]
[2024-04-20 12:11:36,756: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.014451513586556353]
[2024-04-20 12:11:37,410: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.01486917354018925]
[2024-04-20 12:11:38,079: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.017335578737656607]
[2024-04-20 12:11:38,741: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.017251813210909378]
[2024-04-20 12:11:39,419: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.016746819600762946]
[2024-04-20 12:11:40,089: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.023898719850669152]
[2024-04-20 12:11:40,741: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.007493954200487681]
[2024-04-20 12:11:41,403: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.014158718792059101]
[2024-04-20 12:11:42,059: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.0045725408483474625]
[2024-04-20 12:11:42,711: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.007084950671187438]
[2024-04-20 12:11:43,370: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.01865205359986128]
[2024-04-20 12:11:44,025: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.03886900335417166]
[2024-04-20 12:11:44,677: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.01108118002738628]
[2024-04-20 12:11:45,328: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.011276743002168755]
[2024-04-20 12:11:45,982: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.009569544662608048]
[2024-04-20 12:11:46,635: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.008991184555922434]
[2024-04-20 12:11:47,285: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.0060102643536799494]
[2024-04-20 12:11:47,940: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.012786117590910247]
[2024-04-20 12:11:48,596: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.035257002407804806]
[2024-04-20 12:11:49,249: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.009787897787733368]
[2024-04-20 12:11:49,901: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.016119356821287387]
[2024-04-20 12:11:50,556: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.009141072780585208]
[2024-04-20 12:11:51,221: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.01354728689188952]
[2024-04-20 12:11:51,880: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.033112493922324904]
[2024-04-20 12:11:52,559: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.004960227603161524]
[2024-04-20 12:11:53,226: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.0072315361390282535]
[2024-04-20 12:11:53,889: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.026168258199425354]
[2024-04-20 12:11:54,547: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.007759827529001228]
[2024-04-20 12:11:55,201: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.008058357215473643]
[2024-04-20 12:11:55,653: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.03177708716977049]
[2024-04-20 12:11:55,860: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.016487197776279074]
[2024-04-20 12:11:56,064: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.005223002378066452]
[2024-04-20 12:11:56,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.014247677550533504]
[2024-04-20 12:11:56,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.005658325588117355]
[2024-04-20 12:11:56,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.019942254626995573]
[2024-04-20 12:11:56,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.004444416277939836]
[2024-04-20 12:11:57,096: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.00970188516936462]
[2024-04-20 12:11:57,301: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.008516746084934313]
[2024-04-20 12:11:57,506: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.013967744426365204]
[2024-04-20 12:11:57,716: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.005163103565028717]
[2024-04-20 12:11:57,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.013722571396998406]
[2024-04-20 12:11:58,128: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.013422344282945073]
[2024-04-20 12:11:58,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.019943871984161587]
[2024-04-20 12:11:58,539: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.0019156516584202007]
[2024-04-20 12:11:58,744: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.011941834711670414]
[2024-04-20 12:11:58,951: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.006215882192591882]
[2024-04-20 12:11:59,157: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.008059841376179397]
[2024-04-20 12:11:59,362: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.014341172340032907]
[2024-04-20 12:11:59,567: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.010163098201242374]
[2024-04-20 12:11:59,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.02800501001450313]
[2024-04-20 12:11:59,979: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.005904202177342691]
[2024-04-20 12:12:00,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.006232333007294854]
[2024-04-20 12:12:00,395: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.012865862408777934]
[2024-04-20 12:12:00,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.01567323799013885]
[2024-04-20 12:12:00,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.0038715417249312856]
[2024-04-20 12:12:01,014: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.0021531458099724493]
[2024-04-20 12:12:01,220: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.008230613160262494]
[2024-04-20 12:12:01,426: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.011284884264379702]
[2024-04-20 12:12:01,633: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.04173394201950714]
[2024-04-20 12:12:01,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.009095613542610539]
[2024-04-20 12:12:02,041: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.016960261688439806]
[2024-04-20 12:12:02,254: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.008335004416213]
[2024-04-20 12:12:02,459: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.005274608460551665]
[2024-04-20 12:12:02,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.010995511487944936]
[2024-04-20 12:12:02,869: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.03521344150193445]
[2024-04-20 12:12:03,076: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.010307246397595546]
[2024-04-20 12:12:03,282: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.010883956666680133]
[2024-04-20 12:12:03,488: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.006965359908791666]
[2024-04-20 12:12:03,694: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.007430309099721288]
[2024-04-20 12:12:03,900: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.012432961865109478]
[2024-04-20 12:12:04,112: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.004975321045426137]
[2024-04-20 12:12:04,324: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.0055073678927500145]
[2024-04-20 12:12:04,534: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.003829715281436835]
[2024-04-20 12:12:04,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.02085933479585974]
[2024-04-20 12:12:04,960: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.011719497341639528]
[2024-04-20 12:12:05,170: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.014147967104821482]
[2024-04-20 12:12:05,378: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.008310919891018757]
[2024-04-20 12:12:05,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.03044039378172846]
[2024-04-20 12:12:05,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.011582395600014027]
[2024-04-20 12:12:06,017: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.006303906464074427]
[2024-04-20 12:12:06,225: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.002818668297020552]
[2024-04-20 12:12:06,437: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.030022700307457784]
[2024-04-20 12:12:06,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.018124770451269173]
[2024-04-20 12:12:06,862: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.009589709694711537]
[2024-04-20 12:12:07,076: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.0250103479079943]
[2024-04-20 12:12:07,286: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.015550858849772402]
[2024-04-20 12:12:07,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.007303952753798103]
[2024-04-20 12:12:07,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.011641542159818106]
[2024-04-20 12:12:07,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.008448813785898493]
[2024-04-20 12:12:08,116: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.007379909076485395]
[2024-04-20 12:12:08,322: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.0128945245277442]
[2024-04-20 12:12:08,527: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.014073638261871307]
[2024-04-20 12:12:08,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.008762594399330907]
[2024-04-20 12:12:08,937: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.010455997160575105]
[2024-04-20 12:12:09,148: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.006334689452712377]
[2024-04-20 12:12:09,352: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.023525017970071404]
[2024-04-20 12:12:09,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.0416853793743774]
[2024-04-20 12:12:09,761: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.016562631460486997]
[2024-04-20 12:12:09,965: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.005654587214645796]
[2024-04-20 12:12:10,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.004920392501710462]
[2024-04-20 12:12:10,381: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.010273274695680172]
[2024-04-20 12:12:10,589: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.007721907468180813]
[2024-04-20 12:12:10,796: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.012197830662392205]
[2024-04-20 12:12:11,002: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.04601405631232331]
[2024-04-20 12:12:11,205: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.0024080427402073936]
[2024-04-20 12:12:11,410: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.036687252403977015]
[2024-04-20 12:12:11,618: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.003265822444951758]
[2024-04-20 12:12:11,822: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.005677039654095434]
[2024-04-20 12:12:12,026: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.0054348534566752245]
[2024-04-20 12:12:12,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.02446781308511529]
[2024-04-20 12:12:12,443: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.023944768224750647]
[2024-04-20 12:12:12,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.010320527264142034]
[2024-04-20 12:12:12,854: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.010871271999091062]
[2024-04-20 12:12:13,061: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.019577689406003598]
[2024-04-20 12:12:13,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.0037109732287244025]
[2024-04-20 12:12:13,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.02076810167186275]
[2024-04-20 12:12:13,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.0028863595142849764]
[2024-04-20 12:12:13,892: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.010303379129634697]
[2024-04-20 12:12:14,100: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.0075150600997996005]
[2024-04-20 12:12:14,305: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.018903166452015712]
[2024-04-20 12:12:14,510: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.008133842848956697]
[2024-04-20 12:12:14,719: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.01671831059275757]
[2024-04-20 12:12:14,923: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.008830763751200007]
[2024-04-20 12:12:15,129: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.009370214552942046]
[2024-04-20 12:12:15,335: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.03516331031801201]
[2024-04-20 12:12:15,541: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.018066195291933825]
[2024-04-20 12:12:15,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.004108526209942525]
[2024-04-20 12:12:15,949: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.017700124308456307]
[2024-04-20 12:12:16,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.009050381488098808]
[2024-04-20 12:12:16,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.024420096909927896]
[2024-04-20 12:12:16,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.02035423023073338]
[2024-04-20 12:12:16,774: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.015260530873435227]
[2024-04-20 12:12:16,980: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.014445566574806447]
[2024-04-20 12:12:17,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.00908780924917755]
[2024-04-20 12:12:17,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.0034912484805295395]
[2024-04-20 12:12:17,606: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.015888248423674787]
[2024-04-20 12:12:17,815: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.012448888659579868]
[2024-04-20 12:12:18,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.019925816136826938]
[2024-04-20 12:12:18,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.024857447238212513]
[2024-04-20 12:12:18,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.006556804339814498]
[2024-04-20 12:12:18,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.010081354895488524]
[2024-04-20 12:12:18,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.02416978396655138]
[2024-04-20 12:12:19,086: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.039164064740592454]
[2024-04-20 12:12:19,299: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.005810383377984454]
[2024-04-20 12:12:19,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.01100243369957675]
[2024-04-20 12:12:19,733: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.02888571104818688]
[2024-04-20 12:12:19,944: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.012387677769041539]
[2024-04-20 12:12:20,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.019354083984447545]
[2024-04-20 12:12:20,370: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.025633203704619818]
[2024-04-20 12:12:20,584: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.0338678017712605]
[2024-04-20 12:12:20,799: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.05712028158158931]
[2024-04-20 12:12:21,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.017549489832247873]
[2024-04-20 12:12:21,224: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.005530406011269901]
[2024-04-20 12:12:21,432: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.030851680738060314]
[2024-04-20 12:12:21,643: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.006504728370567389]
[2024-04-20 12:12:21,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.02541787183110928]
[2024-04-20 12:12:22,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.035717825404002916]
[2024-04-20 12:12:22,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.0011122227147651908]
[2024-04-20 12:12:22,466: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.018210425603470276]
[2024-04-20 12:12:22,676: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.04201547559760041]
[2024-04-20 12:12:22,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.01208551918620005]
[2024-04-20 12:12:23,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.0073666004068029395]
[2024-04-20 12:12:23,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.05044994403290376]
[2024-04-20 12:12:23,509: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.014344407104176152]
[2024-04-20 12:12:23,718: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.0065559975162005025]
[2024-04-20 12:12:23,928: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.02255475515900642]
[2024-04-20 12:12:24,133: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.02732225578796543]
[2024-04-20 12:12:24,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.01941596388635449]
[2024-04-20 12:12:24,547: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.01682801643264453]
[2024-04-20 12:12:24,757: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.0997984719810841]
[2024-04-20 12:12:24,964: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.009228737924357485]
[2024-04-20 12:12:25,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.0014239272318015785]
[2024-04-20 12:12:25,375: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.011341905929106822]
[2024-04-20 12:12:25,582: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.03732081235874926]
[2024-04-20 12:12:25,791: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.014089235573113559]
[2024-04-20 12:12:25,999: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.012891613201756537]
[2024-04-20 12:12:26,206: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.020801594880588983]
[2024-04-20 12:12:26,415: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.013000058836314467]
[2024-04-20 12:12:26,623: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.018755660403031983]
[2024-04-20 12:12:26,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.009347659003950841]
[2024-04-20 12:12:27,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.021478819530487005]
[2024-04-20 12:12:27,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.015854465716087906]
[2024-04-20 12:12:27,449: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.012336489583549073]
[2024-04-20 12:12:27,655: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.0032916349814811436]
[2024-04-20 12:12:27,861: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.006289278099301605]
[2024-04-20 12:12:28,070: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.014998381071137061]
[2024-04-20 12:12:28,276: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.007201335985013613]
[2024-04-20 12:12:28,483: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.003358330824009672]
[2024-04-20 12:12:28,689: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.0034868674256642025]
[2024-04-20 12:12:28,894: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.008412658272316112]
[2024-04-20 12:12:29,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.017369010058766305]
[2024-04-20 12:12:29,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.03067004878275301]
[2024-04-20 12:12:29,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.008039839616254332]
[2024-04-20 12:12:29,722: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.01810093155364321]
[2024-04-20 12:12:29,928: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.019711603399554647]
[2024-04-20 12:12:30,133: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.004217530472871503]
[2024-04-20 12:12:30,340: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.00038826599592614114]
[2024-04-20 12:12:30,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.020736224364437915]
[2024-04-20 12:12:30,769: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.050367565759629224]
[2024-04-20 12:12:30,976: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.05638866278258883]
[2024-04-20 12:12:31,188: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.016174269005973015]
[2024-04-20 12:12:31,398: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.025168102931839433]
[2024-04-20 12:12:31,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.01154054535712526]
[2024-04-20 12:12:31,818: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.03654015790940299]
[2024-04-20 12:12:32,027: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.04157263708336108]
[2024-04-20 12:12:32,235: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.008669625401294857]
[2024-04-20 12:12:32,450: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.004838577306544548]
[2024-04-20 12:12:32,672: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.06999972922499735]
[2024-04-20 12:12:32,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.012275917490169168]
[2024-04-20 12:12:33,095: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.019099667335972396]
[2024-04-20 12:12:33,307: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.039712676304079625]
[2024-04-20 12:12:33,518: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.015584317477816434]
[2024-04-20 12:12:33,733: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.007384346171340256]
[2024-04-20 12:12:33,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.015965089456975234]
[2024-04-20 12:12:34,159: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.015144085584679083]
[2024-04-20 12:12:34,386: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.006984314493024613]
[2024-04-20 12:12:34,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.006916082631633658]
[2024-04-20 12:12:34,800: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.008033055260644096]
[2024-04-20 12:12:35,005: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 0.01535272087948994]
[2024-04-20 12:12:35,217: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.031627427768558335]
[2024-04-20 12:12:35,423: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.00472488732449721]
[2024-04-20 12:12:35,630: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.004564165259374053]
[2024-04-20 12:12:35,835: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.021600855846839205]
[2024-04-20 12:12:36,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.00778271402945567]
[2024-04-20 12:12:36,247: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.009784601156665346]
[2024-04-20 12:12:36,452: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.029113276222996552]
[2024-04-20 12:12:36,662: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.01726369955958183]
[2024-04-20 12:12:36,869: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.0028401682326415537]
[2024-04-20 12:12:37,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.0022643311161418146]
[2024-04-20 12:12:37,288: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.028764001609236912]
[2024-04-20 12:12:37,493: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.025816479538306063]
[2024-04-20 12:12:37,698: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.02709571445649146]
[2024-04-20 12:12:37,903: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.012876694988452593]
[2024-04-20 12:12:38,110: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.00832391662941497]
[2024-04-20 12:12:38,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.027657912109426062]
[2024-04-20 12:12:38,523: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.004448902851524208]
[2024-04-20 12:12:38,733: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.027529824468202627]
[2024-04-20 12:12:38,940: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.0297869119305026]
[2024-04-20 12:12:39,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.03538279770316584]
[2024-04-20 12:12:39,356: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.004885340128358176]
[2024-04-20 12:12:39,563: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.03485618259266989]
[2024-04-20 12:12:39,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.0029807743312578244]
[2024-04-20 12:12:39,981: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.024891728471010986]
[2024-04-20 12:12:40,193: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.0028793179928985747]
[2024-04-20 12:12:40,397: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.021000250947217775]
[2024-04-20 12:12:40,600: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.0012783262765685087]
[2024-04-20 12:12:40,806: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.017169433119383785]
[2024-04-20 12:12:41,013: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.01698783246483739]
[2024-04-20 12:12:41,218: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.020958037890691606]
[2024-04-20 12:12:41,424: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.004157335966791795]
[2024-04-20 12:12:41,624: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.0687711593696148]
[2024-04-20 12:12:41,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.013575476644245342]
[2024-04-20 12:12:42,037: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.01073966668665422]
[2024-04-20 12:12:42,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.008121844851000926]
[2024-04-20 12:12:42,451: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.0061740807719120935]
[2024-04-20 12:12:42,656: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.013870950284962007]
[2024-04-20 12:12:42,864: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.009518552964047177]
[2024-04-20 12:12:43,072: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.008116788182423127]
[2024-04-20 12:12:43,281: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.0022246001896477014]
[2024-04-20 12:12:43,489: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 0.005817520005265484]
[2024-04-20 12:12:43,699: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.006083294265134892]
[2024-04-20 12:12:43,902: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 0.00479977799209078]
[2024-04-20 12:12:44,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.014334714256782665]
[2024-04-20 12:12:44,314: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.004616083995193332]
[2024-04-20 12:12:44,521: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.007960696608319827]
[2024-04-20 12:12:44,733: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.03020677732954871]
[2024-04-20 12:12:44,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.011253712923490632]
[2024-04-20 12:12:45,161: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.004477715046657446]
[2024-04-20 12:12:45,373: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.007419020372913665]
[2024-04-20 12:12:45,586: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.0049859166399150385]
[2024-04-20 12:12:45,797: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 0.007500803908661586]
[2024-04-20 12:12:46,009: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.005459238271674332]
[2024-04-20 12:12:46,221: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.014764187654714872]
[2024-04-20 12:12:46,431: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.013167329768189849]
[2024-04-20 12:12:46,643: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.015121486425501166]
[2024-04-20 12:12:46,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.004292859749737297]
[2024-04-20 12:12:47,066: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.0023504480030220537]
[2024-04-20 12:12:47,276: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.014975363491393934]
[2024-04-20 12:12:47,489: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.013015613024175409]
[2024-04-20 12:12:47,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.002379220949454635]
[2024-04-20 12:12:47,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.015190429599999526]
[2024-04-20 12:12:48,130: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.006785813919515384]
[2024-04-20 12:12:48,336: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.01449668026162863]
[2024-04-20 12:12:48,542: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.014708229445594564]
[2024-04-20 12:12:48,752: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.010229384507232748]
[2024-04-20 12:12:48,959: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.023546495297999594]
[2024-04-20 12:12:49,167: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.008516544621623372]
[2024-04-20 12:12:49,373: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.01708643837672824]
[2024-04-20 12:12:49,578: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.023299411173288577]
[2024-04-20 12:12:49,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.014348610084690787]
[2024-04-20 12:12:49,993: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.009255738905444039]
[2024-04-20 12:12:50,198: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.009805703098097723]
[2024-04-20 12:12:50,403: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.00892479192337336]
[2024-04-20 12:12:50,609: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.003754417404863375]
[2024-04-20 12:12:50,813: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.01880855456578507]
[2024-04-20 12:12:51,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.009643272185767557]
[2024-04-20 12:12:51,235: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.03755100369041]
[2024-04-20 12:12:51,443: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.014086126845400214]
[2024-04-20 12:12:51,650: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.027026437639709848]
[2024-04-20 12:12:51,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.020303887012892523]
[2024-04-20 12:12:52,062: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.005470482612785098]
[2024-04-20 12:12:52,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.008936586179572466]
[2024-04-20 12:12:52,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.01893952428500339]
[2024-04-20 12:12:52,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.013435959496885714]
[2024-04-20 12:12:52,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.01188731331278973]
[2024-04-20 12:12:53,093: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.013412238518176458]
[2024-04-20 12:12:53,296: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.019633701672309548]
[2024-04-20 12:12:53,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.007156477942688113]
[2024-04-20 12:12:53,710: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.009717645286501335]
[2024-04-20 12:12:53,916: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 0.005088449092216786]
[2024-04-20 12:12:54,122: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.03483185878177754]
[2024-04-20 12:12:54,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.01598468759036149]
[2024-04-20 12:12:54,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.014768763064226456]
[2024-04-20 12:12:54,739: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.01560221413446623]
[2024-04-20 12:12:54,945: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.04318370504884642]
[2024-04-20 12:12:55,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.011814114841700788]
[2024-04-20 12:12:55,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.0078001380993908236]
[2024-04-20 12:12:55,562: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.04563153136602591]
[2024-04-20 12:12:55,766: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.02160250082926251]
[2024-04-20 12:12:55,974: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.009999082335528325]
[2024-04-20 12:12:56,181: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.012641273332052092]
[2024-04-20 12:12:56,388: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.0125708339785321]
[2024-04-20 12:12:56,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.011662163514725305]
[2024-04-20 12:12:56,816: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.010717069962101646]
[2024-04-20 12:12:57,029: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.029633068174216022]
[2024-04-20 12:12:57,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.03477268595647763]
[2024-04-20 12:12:57,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.027276040398796067]
[2024-04-20 12:12:57,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.030804413592930062]
[2024-04-20 12:12:57,878: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.014444740612012614]
[2024-04-20 12:12:58,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.020475371806745694]
[2024-04-20 12:12:58,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.00959117650051715]
[2024-04-20 12:12:58,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.017976507711702946]
[2024-04-20 12:12:58,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.01528199261353871]
[2024-04-20 12:12:58,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.014603463903162353]
[2024-04-20 12:12:59,160: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.01367505821393016]
[2024-04-20 12:12:59,372: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.05476139884481383]
[2024-04-20 12:12:59,584: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.012801798755592694]
[2024-04-20 12:12:59,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.026460764002207416]
[2024-04-20 12:13:00,013: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.009776352740974967]
[2024-04-20 12:13:00,222: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.009163501186149942]
[2024-04-20 12:13:00,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.051666139753642835]
[2024-04-20 12:13:00,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.01825430895205627]
[2024-04-20 12:13:00,885: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.023980228629710342]
[2024-04-20 12:13:01,100: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.016788077619150462]
[2024-04-20 12:13:01,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.026131471713567007]
[2024-04-20 12:13:01,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.028544000664442137]
[2024-04-20 12:13:01,737: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.03450905812914032]
[2024-04-20 12:13:01,951: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.0087594843157063]
[2024-04-20 12:13:02,163: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.0288649578197685]
[2024-04-20 12:13:02,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.011188047229615097]
[2024-04-20 12:13:02,586: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.018320298069765883]
[2024-04-20 12:13:02,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.010869274279837273]
[2024-04-20 12:13:03,013: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.02857509707603418]
[2024-04-20 12:13:03,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.029668785568192815]
[2024-04-20 12:13:03,431: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.01964397600742294]
[2024-04-20 12:13:03,639: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.004150715252726022]
[2024-04-20 12:13:03,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.011502348862984891]
[2024-04-20 12:13:04,055: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.031733654723859736]
[2024-04-20 12:13:04,260: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.029044569381877244]
[2024-04-20 12:13:04,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.021840572745501965]
[2024-04-20 12:13:04,672: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.016608609072974363]
[2024-04-20 12:13:04,884: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.018176657086061185]
[2024-04-20 12:13:05,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.04051176041097248]
[2024-04-20 12:13:05,297: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.01839866454740279]
[2024-04-20 12:13:05,505: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.0238424840621381]
[2024-04-20 12:13:05,713: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.03364540479027437]
[2024-04-20 12:13:05,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.034080187385270404]
[2024-04-20 12:13:06,133: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.00900377403196444]
[2024-04-20 12:13:06,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.01405271473353304]
[2024-04-20 12:13:06,544: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.032621316222121305]
[2024-04-20 12:13:06,750: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.0752368081784301]
[2024-04-20 12:13:06,952: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.0077909504437740995]
[2024-04-20 12:13:07,159: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.012698830820378924]
[2024-04-20 12:13:07,367: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.08893300920002098]
[2024-04-20 12:13:07,572: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.024285792354695433]
[2024-04-20 12:13:07,778: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.01322925957817951]
[2024-04-20 12:13:07,986: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.015821126874365612]
[2024-04-20 12:13:08,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.05699229761137059]
[2024-04-20 12:13:08,399: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.04268897486162816]
[2024-04-20 12:13:08,607: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.0948739976850571]
[2024-04-20 12:13:08,817: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.028809660886425555]
[2024-04-20 12:13:09,025: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.014455617287849701]
[2024-04-20 12:13:09,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.020213229936933346]
[2024-04-20 12:13:09,439: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.020716040481756366]
[2024-04-20 12:13:09,645: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.04898745381444373]
[2024-04-20 12:13:09,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.014250314335010096]
[2024-04-20 12:13:10,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.01517377662283693]
[2024-04-20 12:13:10,263: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.015122353805654404]
[2024-04-20 12:13:10,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.024679640105485914]
[2024-04-20 12:13:10,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.01982375301676949]
[2024-04-20 12:13:10,886: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.014570374347293039]
[2024-04-20 12:13:11,093: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.03471542261943901]
[2024-04-20 12:13:11,302: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.02430494756722337]
[2024-04-20 12:13:11,515: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.012056765277016964]
[2024-04-20 12:13:11,718: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.014154621205834703]
[2024-04-20 12:13:11,922: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.011186532762840646]
[2024-04-20 12:13:12,126: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.035889286955551165]
[2024-04-20 12:13:12,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.009746229015400776]
[2024-04-20 12:13:12,539: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.021108389743862786]
[2024-04-20 12:13:12,747: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.004396974317667857]
[2024-04-20 12:13:12,952: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.014901780720314837]
[2024-04-20 12:13:13,160: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.00789690881678781]
[2024-04-20 12:13:13,374: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.018247389310614662]
[2024-04-20 12:13:13,589: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.020546816194288164]
[2024-04-20 12:13:13,806: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.006880698140493573]
[2024-04-20 12:13:14,018: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.006062097152808854]
[2024-04-20 12:13:14,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.003565910602854314]
[2024-04-20 12:13:14,443: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.016707930585925002]
[2024-04-20 12:13:14,657: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.0069181597093864395]
[2024-04-20 12:13:14,870: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.006474210850371432]
[2024-04-20 12:13:15,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.010979461647659639]
[2024-04-20 12:13:15,294: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.024123155350415978]
[2024-04-20 12:13:15,508: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.011609707184555111]
[2024-04-20 12:13:15,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.0121662152912486]
[2024-04-20 12:13:15,937: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.02716268078779061]
[2024-04-20 12:13:16,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.01659922481444675]
[2024-04-20 12:13:16,370: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 0.008623615330398878]
[2024-04-20 12:13:16,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.032822518081123186]
[2024-04-20 12:13:16,796: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.0088590467989999]
[2024-04-20 12:13:17,002: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.046426710454917544]
[2024-04-20 12:13:17,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.01777100669899848]
[2024-04-20 12:13:17,421: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.00910153073932081]
[2024-04-20 12:13:17,630: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.04283450460762169]
[2024-04-20 12:13:17,842: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.021427821796769265]
[2024-04-20 12:13:18,049: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.00831452300525552]
[2024-04-20 12:13:18,257: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.01775603847386601]
[2024-04-20 12:13:18,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.01806963329390733]
[2024-04-20 12:13:18,676: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.004628837881563429]
[2024-04-20 12:13:18,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.031246658558705273]
[2024-04-20 12:13:19,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.018882282938902574]
[2024-04-20 12:13:19,306: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.011246469020214365]
[2024-04-20 12:13:19,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.004574308560089549]
[2024-04-20 12:13:19,728: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.011342627144053492]
[2024-04-20 12:13:19,939: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.030046027088787668]
[2024-04-20 12:13:20,153: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.020745397392834423]
[2024-04-20 12:13:20,362: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.003835925657357364]
[2024-04-20 12:13:20,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.0011846052488194436]
[2024-04-20 12:13:20,790: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.01222735963083201]
[2024-04-20 12:13:21,005: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.016434020080786076]
[2024-04-20 12:13:21,219: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.007864652838079324]
[2024-04-20 12:13:21,431: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.011161409473816792]
[2024-04-20 12:13:21,645: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.045935871102647435]
[2024-04-20 12:13:21,858: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.01359203407298999]
[2024-04-20 12:13:22,068: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.010772407482707889]
[2024-04-20 12:13:22,283: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.007237567705230288]
[2024-04-20 12:13:22,489: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.005621798700075118]
[2024-04-20 12:13:22,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.013982270622924719]
[2024-04-20 12:13:22,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.009640570038316079]
[2024-04-20 12:13:23,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.003324353046843702]
[2024-04-20 12:13:23,322: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.023283561543014582]
[2024-04-20 12:13:23,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.01283504849553346]
[2024-04-20 12:13:23,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.009134262254283909]
[2024-04-20 12:13:23,944: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.004001273646978431]
[2024-04-20 12:13:24,151: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.0324765686171347]
[2024-04-20 12:13:24,362: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.03110385920844931]
[2024-04-20 12:13:24,568: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.012400720729493196]
[2024-04-20 12:13:24,775: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.027937615513067938]
[2024-04-20 12:13:24,983: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.010846205213037384]
[2024-04-20 12:13:25,192: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.01780279418108625]
[2024-04-20 12:13:25,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.013802575041118583]
[2024-04-20 12:13:25,603: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.020468536859797364]
[2024-04-20 12:13:25,810: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.01689283188029657]
[2024-04-20 12:13:26,018: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.02449429045319763]
[2024-04-20 12:13:26,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.012188620550235155]
[2024-04-20 12:13:26,434: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.040391286844498615]
[2024-04-20 12:13:26,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.01898910427363509]
[2024-04-20 12:13:26,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.002449372227818327]
[2024-04-20 12:13:27,062: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.007057476603212383]
[2024-04-20 12:13:27,280: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.04389794056468094]
[2024-04-20 12:13:27,489: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.003939414000806943]
[2024-04-20 12:13:27,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.022438408494511945]
[2024-04-20 12:13:27,912: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.05255224612863777]
[2024-04-20 12:13:28,127: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.006573775173990468]
[2024-04-20 12:13:28,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.02517581415030748]
[2024-04-20 12:13:28,552: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.027867758221235914]
[2024-04-20 12:13:28,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.036235886470747596]
[2024-04-20 12:13:28,975: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.005508759933617382]
[2024-04-20 12:13:29,189: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.0039040251297989704]
[2024-04-20 12:13:29,397: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.02919717831496925]
[2024-04-20 12:13:29,608: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.014392557424939788]
[2024-04-20 12:13:29,819: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.01930260667107124]
[2024-04-20 12:13:30,032: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.023829638761345744]
[2024-04-20 12:13:30,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.013857738328026684]
[2024-04-20 12:13:30,451: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.018769949186456802]
[2024-04-20 12:13:30,656: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.014785569015705153]
[2024-04-20 12:13:30,866: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.034151943678091726]
[2024-04-20 12:13:31,074: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.011763633921052948]
[2024-04-20 12:13:31,282: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.010928273063770387]
[2024-04-20 12:13:31,498: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.00999730395592882]
[2024-04-20 12:13:31,712: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.014157856577037166]
[2024-04-20 12:13:31,916: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 0.017228461416836982]
[2024-04-20 12:13:32,124: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.01620641129297319]
[2024-04-20 12:13:32,328: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.0068200970619172975]
[2024-04-20 12:13:32,538: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.025835542672953418]
[2024-04-20 12:13:32,747: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.005546492286836687]
[2024-04-20 12:13:32,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.028654972351441384]
[2024-04-20 12:13:33,166: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.004387302323549833]
[2024-04-20 12:13:33,375: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.028885580383234705]
[2024-04-20 12:13:33,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.009129533047254683]
[2024-04-20 12:13:33,793: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.02835828525544641]
[2024-04-20 12:13:34,002: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.009418993203473629]
[2024-04-20 12:13:34,209: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.007922505276601141]
[2024-04-20 12:13:34,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 0.006776904638844088]
[2024-04-20 12:13:34,624: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.005532039545266038]
[2024-04-20 12:13:34,834: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.0046949832239737135]
[2024-04-20 12:13:35,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.008033985458673301]
[2024-04-20 12:13:35,247: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.011773824760850404]
[2024-04-20 12:13:35,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.031022036695091414]
[2024-04-20 12:13:35,664: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.008130311974864924]
[2024-04-20 12:13:35,871: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.004429130277766]
[2024-04-20 12:13:36,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.029182332996232716]
[2024-04-20 12:13:36,287: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.022042254092057918]
[2024-04-20 12:13:36,490: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.009559244648024408]
[2024-04-20 12:13:36,698: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.00729441285474802]
[2024-04-20 12:13:36,908: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.0226616216520651]
[2024-04-20 12:13:37,117: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.007091362219227419]
[2024-04-20 12:13:37,332: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.014848157072410299]
[2024-04-20 12:13:37,543: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.020722617526945465]
[2024-04-20 12:13:37,749: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.00504447957728367]
[2024-04-20 12:13:37,954: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.009495067809490805]
[2024-04-20 12:13:38,164: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.007993185729989935]
[2024-04-20 12:13:38,371: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.01166168795487856]
[2024-04-20 12:13:38,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.008424483774466663]
[2024-04-20 12:13:38,785: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.011333702142428908]
[2024-04-20 12:13:38,993: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.004883482481293792]
[2024-04-20 12:13:39,206: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.012635935263673587]
[2024-04-20 12:13:39,415: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.0204741951690798]
[2024-04-20 12:13:39,625: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.02804961317494752]
[2024-04-20 12:13:39,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.004200523690205075]
[2024-04-20 12:13:40,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.010874528656448286]
[2024-04-20 12:13:40,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.011633097704112949]
[2024-04-20 12:13:40,463: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.0008233959389060426]
[2024-04-20 12:13:40,678: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.008986323802442775]
[2024-04-20 12:13:40,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.016035208697938282]
[2024-04-20 12:13:41,099: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.01611267911113063]
[2024-04-20 12:13:41,313: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.018015986345302715]
[2024-04-20 12:13:41,527: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.004310247745387424]
[2024-04-20 12:13:41,746: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.0028400701912777914]
[2024-04-20 12:13:41,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.010442283295322277]
[2024-04-20 12:13:42,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.019640038673795646]
[2024-04-20 12:13:42,381: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.012420183723685065]
[2024-04-20 12:13:42,594: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.02329680202406409]
[2024-04-20 12:13:42,805: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.0067764950969783164]
[2024-04-20 12:13:43,016: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.029399093400503565]
[2024-04-20 12:13:43,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.0064018016611663295]
[2024-04-20 12:13:43,443: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.006999809971283276]
[2024-04-20 12:13:43,657: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.009284510957060194]
[2024-04-20 12:13:43,870: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.009101309526704033]
[2024-04-20 12:13:44,075: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.016634606111259137]
[2024-04-20 12:13:44,285: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.016438544155307863]
[2024-04-20 12:13:44,491: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.01176686463974726]
[2024-04-20 12:13:44,695: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.022481115573539462]
[2024-04-20 12:13:44,900: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.003342832611870617]
[2024-04-20 12:13:45,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.013955224533794282]
[2024-04-20 12:13:45,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.0421040481699523]
[2024-04-20 12:13:45,518: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.016382539858260783]
[2024-04-20 12:13:45,726: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.0022056520788484198]
[2024-04-20 12:13:45,937: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.002929698676710573]
[2024-04-20 12:13:46,146: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.010834859814107187]
[2024-04-20 12:13:46,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.0035601705982299596]
[2024-04-20 12:13:46,568: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.013943294708578214]
[2024-04-20 12:13:46,774: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.02032816656591219]
[2024-04-20 12:13:46,978: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.0092544499459026]
[2024-04-20 12:13:47,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.008633372179548885]
[2024-04-20 12:13:47,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.011066247656398921]
[2024-04-20 12:13:47,600: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.001746835389468212]
[2024-04-20 12:13:47,806: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.007013332464011245]
[2024-04-20 12:13:48,014: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.010922925824873784]
[2024-04-20 12:13:48,222: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.005338145875060184]
[2024-04-20 12:13:48,431: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.008739994311892433]
[2024-04-20 12:13:48,638: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.017895945176130024]
[2024-04-20 12:13:48,841: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.014302951154173677]
[2024-04-20 12:13:49,045: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.010411063879869288]
[2024-04-20 12:13:49,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.003836723595796756]
[2024-04-20 12:13:49,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.006146547915058219]
[2024-04-20 12:13:49,676: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.00377590298066422]
[2024-04-20 12:13:49,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.005079429821361463]
[2024-04-20 12:13:50,088: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.002667048874317801]
[2024-04-20 12:13:50,292: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.008215187365285927]
[2024-04-20 12:13:50,502: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.010834929165199427]
[2024-04-20 12:13:50,706: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.001981758290595615]
[2024-04-20 12:13:50,913: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.018943722905975843]
[2024-04-20 12:13:51,121: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.0066797919879305724]
[2024-04-20 12:13:51,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.0035778528438771186]
[2024-04-20 12:13:51,533: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.005188238654620373]
[2024-04-20 12:13:51,740: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.002719700881044338]
[2024-04-20 12:13:51,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.018882209328086742]
[2024-04-20 12:13:52,155: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.048682095703274586]
[2024-04-20 12:13:52,359: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.006609777753777907]
[2024-04-20 12:13:52,563: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.008047813585294062]
[2024-04-20 12:13:52,771: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.018839264495876924]
[2024-04-20 12:13:52,976: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.009657211984855118]
[2024-04-20 12:13:53,189: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.02117323013131454]
[2024-04-20 12:13:53,397: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.005977068297062669]
[2024-04-20 12:13:53,604: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.004521037888189312]
[2024-04-20 12:13:53,810: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.010536679005177501]
[2024-04-20 12:13:54,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.006486859557016205]
[2024-04-20 12:13:54,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.007754459613663278]
[2024-04-20 12:13:54,452: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.006333494045388758]
[2024-04-20 12:13:54,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.00915957903180994]
[2024-04-20 12:13:54,878: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.005254107180392998]
[2024-04-20 12:13:55,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.006328493284949633]
[2024-04-20 12:13:55,298: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.01590423251555827]
[2024-04-20 12:13:55,508: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.0032226364944639087]
[2024-04-20 12:13:55,721: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.011325578881288436]
[2024-04-20 12:13:55,933: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.015208364304590934]
[2024-04-20 12:13:56,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.01290252676822428]
[2024-04-20 12:13:56,353: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.01913719127432677]
[2024-04-20 12:13:56,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.006699898184947991]
[2024-04-20 12:13:56,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.007543760595013682]
[2024-04-20 12:13:56,987: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.010355234861602563]
[2024-04-20 12:13:57,205: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.00447472025630026]
[2024-04-20 12:13:57,418: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.011454597855852207]
[2024-04-20 12:13:57,623: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.004466329567887051]
[2024-04-20 12:13:57,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.003975903115347966]
[2024-04-20 12:13:58,036: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.011031350697572051]
[2024-04-20 12:13:58,242: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.004789840291639176]
[2024-04-20 12:13:58,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.010021359771345113]
[2024-04-20 12:13:58,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 0.006235237120690627]
[2024-04-20 12:13:58,862: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.006736277032375342]
[2024-04-20 12:13:59,064: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.01602270112215049]
[2024-04-20 12:13:59,274: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.014008079693402436]
[2024-04-20 12:13:59,477: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.014692840260527022]
[2024-04-20 12:13:59,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.03913145692676407]
[2024-04-20 12:13:59,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.012611698223114025]
[2024-04-20 12:14:00,065: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 0.005807095599010639]
[2024-04-20 12:14:23,937: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9920097332529062, 'precision': 0.6820185133089526, 'recall': 0.8724231883064585, 'f1': 0.7655594484459347}]
[2024-04-20 12:14:25,628: INFO: roberta_kFold_initial_lstm: Fold 1/3 , Epoch: 3/3]
[2024-04-20 12:14:26,329: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.008032446514582143]
[2024-04-20 12:14:26,964: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.022348885717972056]
[2024-04-20 12:14:27,598: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.001490457486361093]
[2024-04-20 12:14:28,238: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.03769138640187854]
[2024-04-20 12:14:28,878: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.01577510400043788]
[2024-04-20 12:14:29,517: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.02564047438307083]
[2024-04-20 12:14:30,163: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.01063839459073202]
[2024-04-20 12:14:30,804: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.005834676600813955]
[2024-04-20 12:14:31,445: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.004644730311768358]
[2024-04-20 12:14:32,091: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.019799109474718638]
[2024-04-20 12:14:32,735: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.01824279615851651]
[2024-04-20 12:14:33,382: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.0050706618807616725]
[2024-04-20 12:14:34,032: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.01427855154008089]
[2024-04-20 12:14:34,708: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.009229481754701317]
[2024-04-20 12:14:35,399: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.0038080207206604554]
[2024-04-20 12:14:36,072: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.009083026265840734]
[2024-04-20 12:14:36,737: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.017382359691699]
[2024-04-20 12:14:37,411: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.010115106379108611]
[2024-04-20 12:14:38,083: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.007733779768675244]
[2024-04-20 12:14:38,741: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.01489521099562568]
[2024-04-20 12:14:39,401: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.009670793780591384]
[2024-04-20 12:14:40,063: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.008395677230608597]
[2024-04-20 12:14:40,718: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.010321678161692846]
[2024-04-20 12:14:41,381: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.006575784108511246]
[2024-04-20 12:14:42,040: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.020034983316248978]
[2024-04-20 12:14:42,699: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.005864099951836744]
[2024-04-20 12:14:43,359: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.0261797518155547]
[2024-04-20 12:14:44,023: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.011668522432570013]
[2024-04-20 12:14:44,684: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.008089464796546762]
[2024-04-20 12:14:45,348: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.030175792325923795]
[2024-04-20 12:14:46,022: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.021696803919613053]
[2024-04-20 12:14:46,690: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.0004787728967174154]
[2024-04-20 12:14:47,357: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.0032179216056455974]
[2024-04-20 12:14:48,023: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.006391286101305948]
[2024-04-20 12:14:48,703: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.010790666449703962]
[2024-04-20 12:14:49,375: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.005237331510006816]
[2024-04-20 12:14:50,072: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.0060484768042097965]
[2024-04-20 12:14:50,770: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.016605719268391602]
[2024-04-20 12:14:51,450: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.023624324639467998]
[2024-04-20 12:14:52,120: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.0037455406555083094]
[2024-04-20 12:14:52,797: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.01568282048151338]
[2024-04-20 12:14:53,475: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.014494690647015807]
[2024-04-20 12:14:54,150: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.01386622324199754]
[2024-04-20 12:14:54,827: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.010030823533776594]
[2024-04-20 12:14:55,509: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.006354623755665505]
[2024-04-20 12:14:56,196: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.00819156403764542]
[2024-04-20 12:14:56,874: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.010439174033095943]
[2024-04-20 12:14:57,558: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.03142569604967591]
[2024-04-20 12:14:58,234: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.0005530917058996514]
[2024-04-20 12:14:58,914: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.022554463606254196]
[2024-04-20 12:14:59,595: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.010770671519940881]
[2024-04-20 12:15:00,270: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.03179371580667914]
[2024-04-20 12:15:00,954: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.02655677687355645]
[2024-04-20 12:15:01,646: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.005303210932163838]
[2024-04-20 12:15:02,336: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.00080795525089063]
[2024-04-20 12:15:03,029: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.007603355053502219]
[2024-04-20 12:15:03,712: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.009893645274934153]
[2024-04-20 12:15:04,405: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.007299860188529218]
[2024-04-20 12:15:05,087: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.004192773138219307]
[2024-04-20 12:15:05,752: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.009408630369303301]
[2024-04-20 12:15:06,425: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.002081340578984709]
[2024-04-20 12:15:07,096: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.0054471129779388484]
[2024-04-20 12:15:07,761: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.012864055977330579]
[2024-04-20 12:15:08,429: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.0029622746007546687]
[2024-04-20 12:15:09,092: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.010187936819762718]
[2024-04-20 12:15:09,757: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.008265895690910227]
[2024-04-20 12:15:10,422: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.003219391791587155]
[2024-04-20 12:15:11,089: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.019432588510678462]
[2024-04-20 12:15:11,750: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.009405903373615916]
[2024-04-20 12:15:12,414: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.011916315804988739]
[2024-04-20 12:15:13,078: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.0011085377306405044]
[2024-04-20 12:15:13,737: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.005912844168178153]
[2024-04-20 12:15:14,402: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.00134010023140066]
[2024-04-20 12:15:15,068: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.005715353106044985]
[2024-04-20 12:15:15,734: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.013549382131944709]
[2024-04-20 12:15:16,406: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.014735596305209096]
[2024-04-20 12:15:17,072: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.01175591070813717]
[2024-04-20 12:15:17,743: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.005998012561023595]
[2024-04-20 12:15:18,399: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.008146326325313303]
[2024-04-20 12:15:19,057: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.017494295721832864]
[2024-04-20 12:15:19,713: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.028802458091802815]
[2024-04-20 12:15:20,368: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.008829056074141818]
[2024-04-20 12:15:21,027: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.00834705760825813]
[2024-04-20 12:15:21,681: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.016926885126164387]
[2024-04-20 12:15:22,333: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.017235615887548725]
[2024-04-20 12:15:22,989: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.008778023191849164]
[2024-04-20 12:15:23,643: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.00906289789093069]
[2024-04-20 12:15:24,296: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.008505574717647848]
[2024-04-20 12:15:24,950: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.0023863176968582146]
[2024-04-20 12:15:25,601: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.009971038993121916]
[2024-04-20 12:15:26,257: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.012519859523181522]
[2024-04-20 12:15:26,908: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.00478877576744362]
[2024-04-20 12:15:27,560: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.0013245125374376728]
[2024-04-20 12:15:28,222: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.016453541087393476]
[2024-04-20 12:15:28,889: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.013129417748733389]
[2024-04-20 12:15:29,550: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.05171270924119863]
[2024-04-20 12:15:30,204: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.01295686077974009]
[2024-04-20 12:15:30,859: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.003478121295916196]
[2024-04-20 12:15:31,512: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.012861874633243208]
[2024-04-20 12:15:32,162: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.019203166334764394]
[2024-04-20 12:15:32,807: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.01012387512679024]
[2024-04-20 12:15:33,453: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.007180224608052199]
[2024-04-20 12:15:34,100: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.007847245728932816]
[2024-04-20 12:15:34,749: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.005511994433342679]
[2024-04-20 12:15:35,397: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.005152135379550568]
[2024-04-20 12:15:36,044: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.011165127926678276]
[2024-04-20 12:15:36,696: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.007837215761715772]
[2024-04-20 12:15:37,342: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.012698612337817628]
[2024-04-20 12:15:37,992: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.008854779433619562]
[2024-04-20 12:15:38,637: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.005966397240249545]
[2024-04-20 12:15:39,287: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.0024333245824782086]
[2024-04-20 12:15:39,939: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.009588508733724755]
[2024-04-20 12:15:40,583: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.003375878264014235]
[2024-04-20 12:15:41,232: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.004595731224980607]
[2024-04-20 12:15:41,891: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.017004829649355485]
[2024-04-20 12:15:42,550: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.02565666116005107]
[2024-04-20 12:15:43,205: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.014885923563215196]
[2024-04-20 12:15:43,863: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.011623164025757134]
[2024-04-20 12:15:44,531: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.01145663839671733]
[2024-04-20 12:15:45,182: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.007629108458474581]
[2024-04-20 12:15:45,826: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.021417484965149818]
[2024-04-20 12:15:46,480: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.003263081565324189]
[2024-04-20 12:15:47,128: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.022366477650768046]
[2024-04-20 12:15:47,775: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.037803492234800014]
[2024-04-20 12:15:48,420: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.008602168926101458]
[2024-04-20 12:15:49,066: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.00899840066639523]
[2024-04-20 12:15:49,714: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.007264118498956486]
[2024-04-20 12:15:50,364: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.010250516887824437]
[2024-04-20 12:15:51,012: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.01038154650932118]
[2024-04-20 12:15:51,661: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.014192131966610825]
[2024-04-20 12:15:52,306: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.01092587131584305]
[2024-04-20 12:15:52,955: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.003063364224159262]
[2024-04-20 12:15:53,598: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.0013513215129844099]
[2024-04-20 12:15:54,248: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.01903541579700467]
[2024-04-20 12:15:54,907: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.00378378090607704]
[2024-04-20 12:15:55,568: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.013615609552878922]
[2024-04-20 12:15:56,229: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.003871565677044483]
[2024-04-20 12:15:56,883: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.013362983412016081]
[2024-04-20 12:15:57,542: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.008502789962913272]
[2024-04-20 12:15:58,199: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.04116619896923272]
[2024-04-20 12:15:58,844: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.0006419838040692106]
[2024-04-20 12:15:59,499: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.01517010233205209]
[2024-04-20 12:16:00,153: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.00516062550420656]
[2024-04-20 12:16:00,803: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.012017582606022485]
[2024-04-20 12:16:01,454: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.015447743967410471]
[2024-04-20 12:16:02,108: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.00707281584087798]
[2024-04-20 12:16:02,763: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.013977075279015302]
[2024-04-20 12:16:03,427: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.009320656660027187]
[2024-04-20 12:16:04,091: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.00665994896883155]
[2024-04-20 12:16:04,760: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.0059242965775395074]
[2024-04-20 12:16:05,430: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.0019062325706197538]
[2024-04-20 12:16:06,084: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.005713111751157997]
[2024-04-20 12:16:06,742: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.007074349028564041]
[2024-04-20 12:16:07,397: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.012894551253301436]
[2024-04-20 12:16:08,056: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.007589159662091137]
[2024-04-20 12:16:08,716: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.013097289491036817]
[2024-04-20 12:16:09,376: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.006364113220177529]
[2024-04-20 12:16:10,037: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.008642248075530342]
[2024-04-20 12:16:10,700: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.012528081768631714]
[2024-04-20 12:16:11,361: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.002988107292802489]
[2024-04-20 12:16:12,016: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.0011865553266534926]
[2024-04-20 12:16:12,676: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.04022775543562788]
[2024-04-20 12:16:13,330: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.02553490632567847]
[2024-04-20 12:16:13,986: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.019387257435652228]
[2024-04-20 12:16:14,648: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.02041344382670645]
[2024-04-20 12:16:15,303: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.016116758728201296]
[2024-04-20 12:16:15,961: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.002021139123247051]
[2024-04-20 12:16:16,615: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.007897496623946017]
[2024-04-20 12:16:17,274: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.01304774722926708]
[2024-04-20 12:16:17,931: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.007482227179631126]
[2024-04-20 12:16:18,592: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.00827665457572893]
[2024-04-20 12:16:19,250: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.005581480470331827]
[2024-04-20 12:16:19,905: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.030284813554652935]
[2024-04-20 12:16:20,563: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.032636821481631856]
[2024-04-20 12:16:21,217: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.01625128562759782]
[2024-04-20 12:16:21,883: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.007155476136689615]
[2024-04-20 12:16:22,552: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.0033642328888444585]
[2024-04-20 12:16:23,217: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.024008227820948747]
[2024-04-20 12:16:23,889: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.008145292963254178]
[2024-04-20 12:16:24,570: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.00608851051076177]
[2024-04-20 12:16:25,245: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.009030671179623952]
[2024-04-20 12:16:25,925: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.006606280743311708]
[2024-04-20 12:16:26,607: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.01905480046827304]
[2024-04-20 12:16:27,275: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.008186686423414358]
[2024-04-20 12:16:27,933: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.010910482678420248]
[2024-04-20 12:16:28,588: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.004989269027576253]
[2024-04-20 12:16:29,244: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.011166674313362318]
[2024-04-20 12:16:29,908: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.012352919519102713]
[2024-04-20 12:16:30,563: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.0048203806491854805]
[2024-04-20 12:16:31,219: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.008326024942695224]
[2024-04-20 12:16:31,873: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.01767712389673176]
[2024-04-20 12:16:32,532: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.009436874441955059]
[2024-04-20 12:16:33,188: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.009502122681418845]
[2024-04-20 12:16:33,846: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.008235832683167608]
[2024-04-20 12:16:34,503: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.016981748260296456]
[2024-04-20 12:16:35,159: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.01299547740003976]
[2024-04-20 12:16:35,816: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.010101979957574074]
[2024-04-20 12:16:36,483: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.001972629463005772]
[2024-04-20 12:16:37,142: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.005013391649455985]
[2024-04-20 12:16:37,807: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.01531595005456542]
[2024-04-20 12:16:38,467: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.012773754820698174]
[2024-04-20 12:16:39,137: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.007672947292669631]
[2024-04-20 12:16:39,792: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.00895138867149594]
[2024-04-20 12:16:40,450: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.020339985811899816]
[2024-04-20 12:16:41,107: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.021625362691159732]
[2024-04-20 12:16:41,768: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.011797201335539464]
[2024-04-20 12:16:42,418: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.032740041257334665]
[2024-04-20 12:16:43,071: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.013876118808987172]
[2024-04-20 12:16:43,730: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.008018504130868041]
[2024-04-20 12:16:44,383: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.0009216761391089159]
[2024-04-20 12:16:45,037: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.005624760303593905]
[2024-04-20 12:16:45,689: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.014180005461722966]
[2024-04-20 12:16:46,343: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.008165281381007436]
[2024-04-20 12:16:47,001: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.01279939020249341]
[2024-04-20 12:16:47,655: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.011745033209183922]
[2024-04-20 12:16:48,310: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.019661568081592577]
[2024-04-20 12:16:48,966: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.009661859274922878]
[2024-04-20 12:16:49,630: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.008749612215255451]
[2024-04-20 12:16:50,297: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.012304982061233288]
[2024-04-20 12:16:50,964: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.007640426505267089]
[2024-04-20 12:16:51,623: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.007011126330798609]
[2024-04-20 12:16:52,286: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.011526402446558984]
[2024-04-20 12:16:52,941: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.008230898053124295]
[2024-04-20 12:16:53,607: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.025934300702997966]
[2024-04-20 12:16:54,258: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.013670690765299115]
[2024-04-20 12:16:54,912: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.0018775613719169216]
[2024-04-20 12:16:55,563: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.012003697802343696]
[2024-04-20 12:16:56,220: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.008813687319821586]
[2024-04-20 12:16:56,876: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.008980426756575398]
[2024-04-20 12:16:57,528: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.023127966325735196]
[2024-04-20 12:16:58,183: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.0014929342403980032]
[2024-04-20 12:16:58,840: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.02190500799969381]
[2024-04-20 12:16:59,496: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.005423831493494166]
[2024-04-20 12:17:00,148: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.00202652519843327]
[2024-04-20 12:17:00,804: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.008996830239228808]
[2024-04-20 12:17:01,460: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.0063851660116488775]
[2024-04-20 12:17:02,115: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.006233792696975128]
[2024-04-20 12:17:02,782: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.0057520189865639644]
[2024-04-20 12:17:03,443: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.008019418542392388]
[2024-04-20 12:17:04,104: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.035246704989980095]
[2024-04-20 12:17:04,767: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.02469820754909015]
[2024-04-20 12:17:05,444: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.014456551969019257]
[2024-04-20 12:17:06,103: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.008426796811063585]
[2024-04-20 12:17:06,750: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.004987239897954741]
[2024-04-20 12:17:07,405: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.005997099274695852]
[2024-04-20 12:17:08,060: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.0027897156304192094]
[2024-04-20 12:17:08,716: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.010555012249157815]
[2024-04-20 12:17:09,366: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.0122263144802758]
[2024-04-20 12:17:10,022: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.003145723069857741]
[2024-04-20 12:17:10,674: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.009320941491235472]
[2024-04-20 12:17:11,327: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.018647238432081107]
[2024-04-20 12:17:11,978: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.009116372700806124]
[2024-04-20 12:17:12,631: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.012765981844585146]
[2024-04-20 12:17:13,290: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.013247090078164039]
[2024-04-20 12:17:13,941: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.0040207783121654775]
[2024-04-20 12:17:14,597: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.002396475471838156]
[2024-04-20 12:17:15,252: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.0026145008638181174]
[2024-04-20 12:17:15,913: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.028022492459944127]
[2024-04-20 12:17:16,576: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.015675240533381086]
[2024-04-20 12:17:17,249: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.0036145927299506588]
[2024-04-20 12:17:17,910: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.011058447689856745]
[2024-04-20 12:17:18,584: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.014895824484967872]
[2024-04-20 12:17:19,245: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.01230874949057101]
[2024-04-20 12:17:19,901: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.007676118388616818]
[2024-04-20 12:17:20,555: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.0062176334709233925]
[2024-04-20 12:17:21,208: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.008792546500441333]
[2024-04-20 12:17:21,858: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.00859452923453521]
[2024-04-20 12:17:22,515: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.01671255928497086]
[2024-04-20 12:17:23,167: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.016834458457145936]
[2024-04-20 12:17:23,820: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.021458602947356274]
[2024-04-20 12:17:24,473: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.0035259549431015955]
[2024-04-20 12:17:25,127: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.002889881245031825]
[2024-04-20 12:17:25,781: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.033434578405385766]
[2024-04-20 12:17:26,434: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.008707661098801799]
[2024-04-20 12:17:27,087: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.003848368849101883]
[2024-04-20 12:17:27,738: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.007962285584719873]
[2024-04-20 12:17:28,394: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.017119410735623473]
[2024-04-20 12:17:29,055: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.013112056993967808]
[2024-04-20 12:17:29,718: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.003511039124466077]
[2024-04-20 12:17:30,377: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.008359718804278904]
[2024-04-20 12:17:31,033: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.007666042013747715]
[2024-04-20 12:17:31,698: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.009350681818168114]
[2024-04-20 12:17:32,357: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.015648172903332484]
[2024-04-20 12:17:33,007: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.003763965672007118]
[2024-04-20 12:17:33,661: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.007907272952887916]
[2024-04-20 12:17:34,317: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.005566146878962912]
[2024-04-20 12:17:34,972: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.013866285858809517]
[2024-04-20 12:17:35,647: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.01674312092747667]
[2024-04-20 12:17:36,307: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.04697884959932708]
[2024-04-20 12:17:36,958: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.005042938332000639]
[2024-04-20 12:17:37,616: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.023915933922588124]
[2024-04-20 12:17:38,273: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.007499244596966588]
[2024-04-20 12:17:38,924: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.006824742715317573]
[2024-04-20 12:17:39,579: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.023246808604740158]
[2024-04-20 12:17:40,231: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.01358103346850867]
[2024-04-20 12:17:40,884: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.00815386519686228]
[2024-04-20 12:17:41,540: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.018743658833825356]
[2024-04-20 12:17:42,194: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.01790496037276804]
[2024-04-20 12:17:42,878: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.013972320449504074]
[2024-04-20 12:17:43,551: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.007523568190709011]
[2024-04-20 12:17:44,213: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.021102415045039288]
[2024-04-20 12:17:44,891: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.006274621341748901]
[2024-04-20 12:17:45,553: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.009174516241941745]
[2024-04-20 12:17:46,198: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.024914890328243067]
[2024-04-20 12:17:46,856: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.01383002831577694]
[2024-04-20 12:17:47,512: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.005768474642436963]
[2024-04-20 12:17:48,164: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.003143659446464705]
[2024-04-20 12:17:48,820: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.0020750619423779426]
[2024-04-20 12:17:49,474: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.010676981329153713]
[2024-04-20 12:17:50,129: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.003783921110157746]
[2024-04-20 12:17:50,782: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.014044909228041491]
[2024-04-20 12:17:51,434: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.00867086818617941]
[2024-04-20 12:17:52,092: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.014360757315926015]
[2024-04-20 12:17:52,746: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.008537336479990125]
[2024-04-20 12:17:53,411: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.00675069657688992]
[2024-04-20 12:17:54,066: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.015312767862135437]
[2024-04-20 12:17:54,721: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.006922533551130244]
[2024-04-20 12:17:55,374: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.011952345144389217]
[2024-04-20 12:17:56,031: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.01713848093779158]
[2024-04-20 12:17:56,698: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.005045260244274275]
[2024-04-20 12:17:57,366: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.011603369987568002]
[2024-04-20 12:17:58,035: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.014425316067996598]
[2024-04-20 12:17:58,705: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.003067658995663661]
[2024-04-20 12:17:59,355: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.007216940603790106]
[2024-04-20 12:18:00,016: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.029087188429534557]
[2024-04-20 12:18:00,674: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.02703706828085201]
[2024-04-20 12:18:01,323: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.002897890144952698]
[2024-04-20 12:18:01,977: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.007030052863282406]
[2024-04-20 12:18:02,629: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.0015874317269381668]
[2024-04-20 12:18:03,284: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.004438276583782318]
[2024-04-20 12:18:03,940: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.00978118301951468]
[2024-04-20 12:18:04,596: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.01525312367945641]
[2024-04-20 12:18:05,251: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.021586569467491018]
[2024-04-20 12:18:05,907: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.005356601580880442]
[2024-04-20 12:18:06,560: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.006926341924227376]
[2024-04-20 12:18:07,215: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.009142212677923577]
[2024-04-20 12:18:07,868: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.015042499016429888]
[2024-04-20 12:18:08,522: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.005000606913489281]
[2024-04-20 12:18:09,184: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.00047357644384325845]
[2024-04-20 12:18:09,853: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.020553724560888845]
[2024-04-20 12:18:10,520: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.004027106312575205]
[2024-04-20 12:18:11,183: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.004380642109721483]
[2024-04-20 12:18:11,861: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.07451172879914712]
[2024-04-20 12:18:12,518: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.010739972742690994]
[2024-04-20 12:18:13,169: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.01994263615950698]
[2024-04-20 12:18:13,825: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.005392558052121296]
[2024-04-20 12:18:14,477: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.006500407097256069]
[2024-04-20 12:18:15,135: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.02787137216546509]
[2024-04-20 12:18:15,791: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.009764191155270692]
[2024-04-20 12:18:16,445: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.00761487130128664]
[2024-04-20 12:18:17,101: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.010681935742803418]
[2024-04-20 12:18:17,758: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.010242029877427755]
[2024-04-20 12:18:18,414: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.027433542307105766]
[2024-04-20 12:18:19,072: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.004454221767902426]
[2024-04-20 12:18:19,726: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.0035024445924814332]
[2024-04-20 12:18:20,384: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.017501426472400702]
[2024-04-20 12:18:21,036: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.010156588484856495]
[2024-04-20 12:18:21,689: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.006609656577461561]
[2024-04-20 12:18:22,349: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.0022362532995485397]
[2024-04-20 12:18:23,015: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.019674958078286436]
[2024-04-20 12:18:23,677: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.005325965378826052]
[2024-04-20 12:18:24,337: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.004167578000008333]
[2024-04-20 12:18:25,001: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.0011719849466114071]
[2024-04-20 12:18:25,659: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.010460583661272702]
[2024-04-20 12:18:26,312: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.013905573643535339]
[2024-04-20 12:18:26,963: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.05017691224782679]
[2024-04-20 12:18:27,620: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.01027831471273414]
[2024-04-20 12:18:28,274: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.003485508313038242]
[2024-04-20 12:18:28,935: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.0017426120551350625]
[2024-04-20 12:18:29,594: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.011999114290621575]
[2024-04-20 12:18:30,249: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.010925328480670753]
[2024-04-20 12:18:30,904: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.0016990931670866265]
[2024-04-20 12:18:31,562: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.00654743857712364]
[2024-04-20 12:18:32,218: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.008506043057410633]
[2024-04-20 12:18:32,880: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.009603240075603451]
[2024-04-20 12:18:33,535: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.014570087131216674]
[2024-04-20 12:18:34,187: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.007731272833571741]
[2024-04-20 12:18:34,844: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.0015236607246803672]
[2024-04-20 12:18:35,504: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.012693120164276513]
[2024-04-20 12:18:36,169: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.026634879575762313]
[2024-04-20 12:18:36,833: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.006209043678602608]
[2024-04-20 12:18:37,498: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.00463646745391577]
[2024-04-20 12:18:38,162: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.002465006440975536]
[2024-04-20 12:18:38,817: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.002578883760476193]
[2024-04-20 12:18:39,477: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.008936910512377012]
[2024-04-20 12:18:40,134: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.009497070427160503]
[2024-04-20 12:18:40,796: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.020869726962107826]
[2024-04-20 12:18:41,448: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.009567220570768094]
[2024-04-20 12:18:42,112: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.012203555923181076]
[2024-04-20 12:18:42,768: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.009982461425511444]
[2024-04-20 12:18:43,425: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.008730554497754402]
[2024-04-20 12:18:44,081: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.0050319033276792725]
[2024-04-20 12:18:44,740: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.0009414289664742768]
[2024-04-20 12:18:45,398: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.01308140181804989]
[2024-04-20 12:18:46,055: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.005241175413620387]
[2024-04-20 12:18:46,711: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.004208487097801868]
[2024-04-20 12:18:47,364: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.013070307357108056]
[2024-04-20 12:18:48,019: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.01007885848971648]
[2024-04-20 12:18:48,674: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.008589472856794534]
[2024-04-20 12:18:49,353: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.003549719973723621]
[2024-04-20 12:18:50,031: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.004347569520735474]
[2024-04-20 12:18:50,688: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.022791402300309318]
[2024-04-20 12:18:51,366: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.012798642231608065]
[2024-04-20 12:18:52,037: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.006548116607396359]
[2024-04-20 12:18:52,688: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.017138386434288014]
[2024-04-20 12:18:53,345: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.014889885145806367]
[2024-04-20 12:18:54,004: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.017126042412386598]
[2024-04-20 12:18:54,659: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.004052985838870077]
[2024-04-20 12:18:55,316: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.023171327289437868]
[2024-04-20 12:18:55,969: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.005701558513340376]
[2024-04-20 12:18:56,626: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.0017385539458755071]
[2024-04-20 12:18:57,280: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.004929724620266252]
[2024-04-20 12:18:57,936: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.01002306324035584]
[2024-04-20 12:18:58,589: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.02420200125744575]
[2024-04-20 12:18:59,244: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.010831549062085472]
[2024-04-20 12:18:59,901: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.004508033489559072]
[2024-04-20 12:19:00,558: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.011047051306436812]
[2024-04-20 12:19:01,212: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.031596211261435685]
[2024-04-20 12:19:01,866: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.010182590653850186]
[2024-04-20 12:19:02,528: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.008651520470543959]
[2024-04-20 12:19:03,198: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.0715998943771305]
[2024-04-20 12:19:03,866: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.028873881384288605]
[2024-04-20 12:19:04,526: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.014255877105738873]
[2024-04-20 12:19:05,188: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.013256282709285592]
[2024-04-20 12:19:05,840: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.015800004536780092]
[2024-04-20 12:19:06,495: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.014732353776680853]
[2024-04-20 12:19:07,146: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.011099174255531325]
[2024-04-20 12:19:07,802: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.0030775626416231516]
[2024-04-20 12:19:08,458: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.006537868142686287]
[2024-04-20 12:19:09,110: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.010465750539327003]
[2024-04-20 12:19:09,763: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.007305028905964991]
[2024-04-20 12:19:10,442: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.002825297122305895]
[2024-04-20 12:19:11,116: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.02756680157176998]
[2024-04-20 12:19:11,780: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.002010379260961643]
[2024-04-20 12:19:12,447: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.04144648365067616]
[2024-04-20 12:19:13,117: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.004274254414204381]
[2024-04-20 12:19:13,773: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.012585709885158898]
[2024-04-20 12:19:14,431: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.015248966037910268]
[2024-04-20 12:19:15,089: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.0024244467457911053]
[2024-04-20 12:19:15,748: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.011224873022340494]
[2024-04-20 12:19:16,415: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.017725816430343773]
[2024-04-20 12:19:17,075: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.009745681011959807]
[2024-04-20 12:19:17,747: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.005781767393286374]
[2024-04-20 12:19:18,418: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.043968486629623195]
[2024-04-20 12:19:19,067: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.024884793255988764]
[2024-04-20 12:19:19,718: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.012445324466776849]
[2024-04-20 12:19:20,373: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.01245720558522941]
[2024-04-20 12:19:21,025: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.012788094194620707]
[2024-04-20 12:19:21,678: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.01988401209078832]
[2024-04-20 12:19:22,335: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.009239487569952218]
[2024-04-20 12:19:22,986: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.005232696899166249]
[2024-04-20 12:19:23,638: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.008232613978373526]
[2024-04-20 12:19:24,290: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.01826494072930152]
[2024-04-20 12:19:24,941: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.014421346585207188]
[2024-04-20 12:19:25,595: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.002534011153059408]
[2024-04-20 12:19:26,253: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.007980282112550571]
[2024-04-20 12:19:26,904: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.022265142232815994]
[2024-04-20 12:19:27,556: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.00596380639857744]
[2024-04-20 12:19:28,211: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.011118080388250285]
[2024-04-20 12:19:28,871: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.00566738255915867]
[2024-04-20 12:19:29,534: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.02107941448940212]
[2024-04-20 12:19:30,202: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.01775553235158645]
[2024-04-20 12:19:30,874: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.00270955570838476]
[2024-04-20 12:19:31,552: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.006074964259246805]
[2024-04-20 12:19:32,226: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.02460442647469689]
[2024-04-20 12:19:32,890: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.004595928275746451]
[2024-04-20 12:19:33,544: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.010261009796679422]
[2024-04-20 12:19:34,206: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.016231967932605576]
[2024-04-20 12:19:34,872: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.001810486624282599]
[2024-04-20 12:19:35,529: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.02205167887847331]
[2024-04-20 12:19:36,175: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.016961159336731643]
[2024-04-20 12:19:36,832: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.007188889185303133]
[2024-04-20 12:19:37,488: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.010873872661542851]
[2024-04-20 12:19:38,140: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.01654946320906741]
[2024-04-20 12:19:38,793: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.011024601023754107]
[2024-04-20 12:19:39,446: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.017955350729365552]
[2024-04-20 12:19:40,105: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.007764810280066201]
[2024-04-20 12:19:40,761: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.006687729044861433]
[2024-04-20 12:19:41,416: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.005235049109672164]
[2024-04-20 12:19:42,071: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.013984086701320621]
[2024-04-20 12:19:42,724: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.007679025335321764]
[2024-04-20 12:19:43,388: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.007126003208813905]
[2024-04-20 12:19:44,055: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.006073623457645309]
[2024-04-20 12:19:44,720: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.005785100918583006]
[2024-04-20 12:19:45,380: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.011550497633972248]
[2024-04-20 12:19:46,045: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.013162596586503083]
[2024-04-20 12:19:46,701: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.008265405537267257]
[2024-04-20 12:19:47,355: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.006819049926202541]
[2024-04-20 12:19:48,007: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.006969286702019549]
[2024-04-20 12:19:48,658: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.0176094183239822]
[2024-04-20 12:19:49,315: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.004205899425106239]
[2024-04-20 12:19:49,971: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.037252899583037014]
[2024-04-20 12:19:50,622: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.010077490944425291]
[2024-04-20 12:19:51,274: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.0037796189335394807]
[2024-04-20 12:19:51,927: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.013424451910965494]
[2024-04-20 12:19:52,582: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.0029816331352651576]
[2024-04-20 12:19:53,232: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.007307523134583504]
[2024-04-20 12:19:53,885: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.008822070420078555]
[2024-04-20 12:19:54,538: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.030310666660402087]
[2024-04-20 12:19:55,190: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.022270595523878]
[2024-04-20 12:19:55,846: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.006162437562216525]
[2024-04-20 12:19:56,520: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.03707502938846685]
[2024-04-20 12:19:57,195: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.008202838054246136]
[2024-04-20 12:19:57,855: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.0015776563284287386]
[2024-04-20 12:19:58,525: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.001789832555790273]
[2024-04-20 12:19:59,196: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.04330961182782135]
[2024-04-20 12:19:59,851: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.008998424663576764]
[2024-04-20 12:20:00,502: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.008847951347232031]
[2024-04-20 12:20:01,159: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.005056928300406089]
[2024-04-20 12:20:01,811: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.003796648797938733]
[2024-04-20 12:20:02,465: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.013226406723731543]
[2024-04-20 12:20:03,121: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.015076453536450997]
[2024-04-20 12:20:03,774: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.015672276438613353]
[2024-04-20 12:20:04,428: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.003497976228065827]
[2024-04-20 12:20:05,085: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.0008600683640527348]
[2024-04-20 12:20:05,743: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.0044177624187138635]
[2024-04-20 12:20:06,397: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.0012466766800317936]
[2024-04-20 12:20:07,048: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.008224414533566635]
[2024-04-20 12:20:07,702: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.013114414747942752]
[2024-04-20 12:20:08,356: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.010271943426729229]
[2024-04-20 12:20:09,013: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.021834767413866644]
[2024-04-20 12:20:09,670: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.016448121341550444]
[2024-04-20 12:20:10,330: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.008176611729925462]
[2024-04-20 12:20:10,990: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.014579797455879371]
[2024-04-20 12:20:11,652: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.010394773278473326]
[2024-04-20 12:20:12,313: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.009230361570268459]
[2024-04-20 12:20:12,973: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.007379183085741501]
[2024-04-20 12:20:13,626: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.009117303933756747]
[2024-04-20 12:20:14,282: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.006604486183750562]
[2024-04-20 12:20:14,934: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.006659058605435122]
[2024-04-20 12:20:15,588: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.007457717331989079]
[2024-04-20 12:20:16,241: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.007502754577262749]
[2024-04-20 12:20:16,893: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.00754644332512643]
[2024-04-20 12:20:17,543: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.0077780589754178064]
[2024-04-20 12:20:18,194: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.004619827841196206]
[2024-04-20 12:20:18,848: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.005270221058299391]
[2024-04-20 12:20:19,502: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.001663510702008112]
[2024-04-20 12:20:20,156: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.009823370106574051]
[2024-04-20 12:20:20,810: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.004876219954442678]
[2024-04-20 12:20:21,468: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.00088334975333718]
[2024-04-20 12:20:22,121: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.004178071745477127]
[2024-04-20 12:20:22,776: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.040591078493027684]
[2024-04-20 12:20:23,434: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.010419723089014928]
[2024-04-20 12:20:24,104: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.0070104790684690395]
[2024-04-20 12:20:24,772: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.009743003146388563]
[2024-04-20 12:20:25,443: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.0033769124698671098]
[2024-04-20 12:20:26,118: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.005242570067494792]
[2024-04-20 12:20:26,779: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.0009440020645985489]
[2024-04-20 12:20:27,429: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.008699074787757239]
[2024-04-20 12:20:28,088: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.002432596124241503]
[2024-04-20 12:20:28,747: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.01298411565793603]
[2024-04-20 12:20:29,399: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.00503706624236697]
[2024-04-20 12:20:30,055: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.03853970955108256]
[2024-04-20 12:20:30,708: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.04059532537619278]
[2024-04-20 12:20:31,366: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.012821555224646826]
[2024-04-20 12:20:32,022: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.021725550323055592]
[2024-04-20 12:20:32,675: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.00810691172241971]
[2024-04-20 12:20:33,331: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.024297736196035143]
[2024-04-20 12:20:33,987: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.01028424161443222]
[2024-04-20 12:20:34,641: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.016723761477562594]
[2024-04-20 12:20:35,294: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.007214447161167098]
[2024-04-20 12:20:35,948: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.014353621343232297]
[2024-04-20 12:20:36,609: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.004069430486925821]
[2024-04-20 12:20:37,270: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.022406170364688144]
[2024-04-20 12:20:37,952: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.006902105850435742]
[2024-04-20 12:20:38,620: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.00899891453396195]
[2024-04-20 12:20:39,274: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.015027179556448472]
[2024-04-20 12:20:39,932: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.008521362369531084]
[2024-04-20 12:20:40,586: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.008471962572217181]
[2024-04-20 12:20:41,242: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.00304334755804479]
[2024-04-20 12:20:41,902: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.005964865697415993]
[2024-04-20 12:20:42,556: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.005249785196558207]
[2024-04-20 12:20:43,212: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.010546181085406815]
[2024-04-20 12:20:43,866: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.012320941165509115]
[2024-04-20 12:20:44,523: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.0012691557217936356]
[2024-04-20 12:20:45,179: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.019118952173646068]
[2024-04-20 12:20:45,832: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.042206088604937145]
[2024-04-20 12:20:46,488: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.007638105955329625]
[2024-04-20 12:20:47,140: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.009915714126312336]
[2024-04-20 12:20:47,795: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.028349656697348718]
[2024-04-20 12:20:48,451: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.008723986574349446]
[2024-04-20 12:20:49,102: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.01890425339050929]
[2024-04-20 12:20:49,759: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.017036486303373427]
[2024-04-20 12:20:50,425: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.012237569873763562]
[2024-04-20 12:20:51,107: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.008542780194079362]
[2024-04-20 12:20:51,779: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.03098740307918426]
[2024-04-20 12:20:52,446: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.003292203077475948]
[2024-04-20 12:20:53,106: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.009434739661828397]
[2024-04-20 12:20:53,767: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.010804569903417372]
[2024-04-20 12:20:54,423: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.008643959863559116]
[2024-04-20 12:20:55,080: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.003170673812243749]
[2024-04-20 12:20:55,731: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.0018987360080283957]
[2024-04-20 12:20:56,381: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.0085031337560398]
[2024-04-20 12:20:57,035: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.005799534399882019]
[2024-04-20 12:20:57,689: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.012387325426945995]
[2024-04-20 12:20:58,342: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.0030596648372331267]
[2024-04-20 12:20:58,995: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.007582726378314688]
[2024-04-20 12:20:59,651: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.0096407343837671]
[2024-04-20 12:21:00,304: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.006049048586894445]
[2024-04-20 12:21:00,961: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.006252923243392894]
[2024-04-20 12:21:01,615: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.014976569563691417]
[2024-04-20 12:21:02,271: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.012273208041283387]
[2024-04-20 12:21:02,927: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.017402605750457226]
[2024-04-20 12:21:03,588: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.016622555750902098]
[2024-04-20 12:21:04,252: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.008190499504459154]
[2024-04-20 12:21:04,920: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.013734670810128507]
[2024-04-20 12:21:05,583: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.013539268286113536]
[2024-04-20 12:21:06,256: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.009091483963317945]
[2024-04-20 12:21:06,920: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.008641069985592048]
[2024-04-20 12:21:07,573: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.033849831842851945]
[2024-04-20 12:21:08,230: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.022206600802363117]
[2024-04-20 12:21:08,884: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.015940173635256114]
[2024-04-20 12:21:09,545: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.015321155022266204]
[2024-04-20 12:21:10,201: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.012668948271090318]
[2024-04-20 12:21:10,859: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.005537337556457605]
[2024-04-20 12:21:11,511: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.00743199569767214]
[2024-04-20 12:21:12,168: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.004424451491894256]
[2024-04-20 12:21:12,827: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.003356688731455104]
[2024-04-20 12:21:13,481: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.004400127018206316]
[2024-04-20 12:21:14,138: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.005432111415434991]
[2024-04-20 12:21:14,792: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.015038864900418468]
[2024-04-20 12:21:15,447: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.006667887232761301]
[2024-04-20 12:21:16,105: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.006599965111460332]
[2024-04-20 12:21:16,773: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.02341286752528843]
[2024-04-20 12:21:17,441: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.014561943406839153]
[2024-04-20 12:21:18,097: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.009651403422789511]
[2024-04-20 12:21:18,769: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.026884199149443434]
[2024-04-20 12:21:19,441: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.0054483883185704185]
[2024-04-20 12:21:20,101: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.0028354759100882544]
[2024-04-20 12:21:20,757: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.0017116692957291505]
[2024-04-20 12:21:21,409: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.016380556224990267]
[2024-04-20 12:21:22,062: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.006202638635917071]
[2024-04-20 12:21:22,719: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.022470701778293443]
[2024-04-20 12:21:23,377: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.029322109790263614]
[2024-04-20 12:21:24,031: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.023681216715340743]
[2024-04-20 12:21:24,684: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.018734721667462293]
[2024-04-20 12:21:25,339: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.04199065810993632]
[2024-04-20 12:21:25,996: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.016366629810682428]
[2024-04-20 12:21:26,652: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.014009329942772772]
[2024-04-20 12:21:27,314: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.004803086179400403]
[2024-04-20 12:21:27,971: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.006838722258816248]
[2024-04-20 12:21:28,623: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.014558828054617737]
[2024-04-20 12:21:29,277: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.03235548351983614]
[2024-04-20 12:21:29,942: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.03504812385807983]
[2024-04-20 12:21:30,608: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.009391246676486017]
[2024-04-20 12:21:31,277: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.006528762038018949]
[2024-04-20 12:21:31,936: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.001990720291982861]
[2024-04-20 12:21:32,604: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.030406508910142228]
[2024-04-20 12:21:33,267: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.010198898700796637]
[2024-04-20 12:21:33,924: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.006915734687465859]
[2024-04-20 12:21:34,579: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.012168627947850303]
[2024-04-20 12:21:35,234: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.00863336712066201]
[2024-04-20 12:21:35,889: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.00923285350253475]
[2024-04-20 12:21:36,547: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.019148301893793754]
[2024-04-20 12:21:37,202: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.00531583749952472]
[2024-04-20 12:21:37,853: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.022675306433080387]
[2024-04-20 12:21:38,510: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.009417620806290092]
[2024-04-20 12:21:39,165: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.004798935196792474]
[2024-04-20 12:21:39,819: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.01203403161719689]
[2024-04-20 12:21:40,476: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.007151486749757549]
[2024-04-20 12:21:41,133: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.006230811264108958]
[2024-04-20 12:21:41,790: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.04882419150874702]
[2024-04-20 12:21:42,449: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.005065217381374464]
[2024-04-20 12:21:43,104: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.006855105785068486]
[2024-04-20 12:21:43,765: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.003529518725777558]
[2024-04-20 12:21:44,425: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.010484721766722977]
[2024-04-20 12:21:45,088: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.016911490557627442]
[2024-04-20 12:21:45,747: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.013334772627296423]
[2024-04-20 12:21:46,417: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.013399027280117612]
[2024-04-20 12:21:47,075: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.0051411865363538865]
[2024-04-20 12:21:47,731: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.054527964927146344]
[2024-04-20 12:21:48,386: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.00667067982840098]
[2024-04-20 12:21:49,045: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.006055721536150433]
[2024-04-20 12:21:49,701: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.011174586533204543]
[2024-04-20 12:21:50,356: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.0033772271495636115]
[2024-04-20 12:21:51,013: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.00658424712419199]
[2024-04-20 12:21:51,667: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.009451487522982005]
[2024-04-20 12:21:52,319: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.011625881480505394]
[2024-04-20 12:21:52,972: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.0031411431675478123]
[2024-04-20 12:21:53,622: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.006796453212072445]
[2024-04-20 12:21:54,277: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.02200933559237527]
[2024-04-20 12:21:54,933: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.034764933961171494]
[2024-04-20 12:21:55,591: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.007418536295207163]
[2024-04-20 12:21:56,243: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.004863141788769071]
[2024-04-20 12:21:56,922: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.00870226163034036]
[2024-04-20 12:21:57,594: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.0072882679595678845]
[2024-04-20 12:21:58,257: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.005820441047668673]
[2024-04-20 12:21:58,932: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.011394787419454187]
[2024-04-20 12:21:59,598: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.014737647809860246]
[2024-04-20 12:22:00,253: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.011891967125502159]
[2024-04-20 12:22:00,909: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.02115006714164342]
[2024-04-20 12:22:01,564: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.005115147283797066]
[2024-04-20 12:22:02,218: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.010080087990994396]
[2024-04-20 12:22:02,876: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.006560924033053791]
[2024-04-20 12:22:03,532: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.004067446258471381]
[2024-04-20 12:22:04,186: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.015776450689928646]
[2024-04-20 12:22:04,846: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.005244343683214044]
[2024-04-20 12:22:05,501: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.011374087147333664]
[2024-04-20 12:22:06,156: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.006360884690996441]
[2024-04-20 12:22:06,814: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.01247794949107429]
[2024-04-20 12:22:07,466: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.02183762680531572]
[2024-04-20 12:22:08,122: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.013483906489028995]
[2024-04-20 12:22:08,776: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.015814661945567077]
[2024-04-20 12:22:09,435: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.005043956330044722]
[2024-04-20 12:22:10,094: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.007599004827904019]
[2024-04-20 12:22:10,771: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.059621512751200055]
[2024-04-20 12:22:11,435: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.036916807506519045]
[2024-04-20 12:22:12,100: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.0017991226163031095]
[2024-04-20 12:22:12,770: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.00404420105141807]
[2024-04-20 12:22:13,425: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.0020190930888466688]
[2024-04-20 12:22:14,080: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.004846512626301342]
[2024-04-20 12:22:14,740: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.0385251629796842]
[2024-04-20 12:22:15,394: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.04371239516644894]
[2024-04-20 12:22:16,048: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.012226856862865442]
[2024-04-20 12:22:16,707: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.006370720437941933]
[2024-04-20 12:22:17,372: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.009237597179186532]
[2024-04-20 12:22:18,034: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.004828574844874568]
[2024-04-20 12:22:18,695: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.008436057586059378]
[2024-04-20 12:22:19,361: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.008708280287697651]
[2024-04-20 12:22:20,025: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.0048999937909288095]
[2024-04-20 12:22:20,678: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.018754745370740594]
[2024-04-20 12:22:21,330: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.00508518473895633]
[2024-04-20 12:22:21,987: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.008079620699507914]
[2024-04-20 12:22:22,640: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.007838435551461045]
[2024-04-20 12:22:23,298: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.021499282785795503]
[2024-04-20 12:22:23,962: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.012109986941436826]
[2024-04-20 12:22:24,625: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.0025325276827819136]
[2024-04-20 12:22:25,294: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.02151566521549119]
[2024-04-20 12:22:25,963: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.0026348309421897003]
[2024-04-20 12:22:26,632: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.011786704170415675]
[2024-04-20 12:22:27,287: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.006165342830155331]
[2024-04-20 12:22:27,944: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.009094895539018467]
[2024-04-20 12:22:28,601: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.018006170120974017]
[2024-04-20 12:22:29,258: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.0031439509255042236]
[2024-04-20 12:22:29,914: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.005722184178437261]
[2024-04-20 12:22:30,570: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.0012321181310875745]
[2024-04-20 12:22:31,228: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.0027412396428265857]
[2024-04-20 12:22:31,882: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.03735537440560407]
[2024-04-20 12:22:32,537: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.015795913972436466]
[2024-04-20 12:22:33,193: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.008086613810567649]
[2024-04-20 12:22:33,850: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.006086037221926142]
[2024-04-20 12:22:34,503: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.02233280454185536]
[2024-04-20 12:22:35,157: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.0153802076111989]
[2024-04-20 12:22:35,814: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.01974217975637036]
[2024-04-20 12:22:36,481: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.007326664596441406]
[2024-04-20 12:22:37,142: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.003359918140435082]
[2024-04-20 12:22:37,807: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.013386226144165512]
[2024-04-20 12:22:38,474: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.009448670608218853]
[2024-04-20 12:22:39,144: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.010969136615418726]
[2024-04-20 12:22:39,819: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.00786722018326027]
[2024-04-20 12:22:40,481: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.012345644057389572]
[2024-04-20 12:22:41,145: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.006046695921800473]
[2024-04-20 12:22:41,822: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.0038953900688925474]
[2024-04-20 12:22:42,491: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.03541534090548655]
[2024-04-20 12:22:43,151: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.009775115947341474]
[2024-04-20 12:22:43,809: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.02162304514487914]
[2024-04-20 12:22:44,462: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.014814279932113471]
[2024-04-20 12:22:45,127: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.010323048117915708]
[2024-04-20 12:22:45,786: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.008371811378375038]
[2024-04-20 12:22:46,439: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.005276950257405919]
[2024-04-20 12:22:47,095: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.009549511509653549]
[2024-04-20 12:22:47,750: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.009181292079327451]
[2024-04-20 12:22:48,402: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.009139860807160236]
[2024-04-20 12:22:49,052: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.014042489164561498]
[2024-04-20 12:22:49,709: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.010116836481659154]
[2024-04-20 12:22:50,362: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.005425127343075031]
[2024-04-20 12:22:51,024: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.004616984276360964]
[2024-04-20 12:22:51,688: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.01591854352780625]
[2024-04-20 12:22:52,355: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.008130347618828672]
[2024-04-20 12:22:53,024: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.011340606181140182]
[2024-04-20 12:22:53,688: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.006823181424561133]
[2024-04-20 12:22:54,352: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.026914957278564935]
[2024-04-20 12:22:55,004: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.003964245405682701]
[2024-04-20 12:22:55,659: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.005729024338663609]
[2024-04-20 12:22:56,315: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.040730012756250294]
[2024-04-20 12:22:56,975: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.0065545544208303564]
[2024-04-20 12:22:57,629: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.005158112114932206]
[2024-04-20 12:22:58,286: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.009287850827668823]
[2024-04-20 12:22:58,940: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.0017731449167938907]
[2024-04-20 12:22:59,599: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.010447205496452703]
[2024-04-20 12:23:00,254: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.013024200512599544]
[2024-04-20 12:23:00,909: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.004978337772334571]
[2024-04-20 12:23:01,564: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.009715532877661385]
[2024-04-20 12:23:02,216: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.02962098704976054]
[2024-04-20 12:23:02,877: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.004648550836765795]
[2024-04-20 12:23:03,533: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.07328393889128695]
[2024-04-20 12:23:04,189: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.005818913835214368]
[2024-04-20 12:23:04,852: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.007963626681200833]
[2024-04-20 12:23:05,517: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.006471714283346341]
[2024-04-20 12:23:06,178: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.008658330435393286]
[2024-04-20 12:23:06,840: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.009244676152930661]
[2024-04-20 12:23:07,513: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.031930993744947005]
[2024-04-20 12:23:08,169: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.006742575628640052]
[2024-04-20 12:23:08,819: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.010709805293406226]
[2024-04-20 12:23:09,472: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.022133274661143405]
[2024-04-20 12:23:10,130: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.004381736764517516]
[2024-04-20 12:23:10,785: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.025346314784032466]
[2024-04-20 12:23:11,438: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.0037186012910511474]
[2024-04-20 12:23:12,095: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.029316194545959937]
[2024-04-20 12:23:12,745: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.015170368474087252]
[2024-04-20 12:23:13,397: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.0008634944213790173]
[2024-04-20 12:23:14,052: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.001539420678226313]
[2024-04-20 12:23:14,707: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.006011951284198082]
[2024-04-20 12:23:15,361: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.0043625357027512164]
[2024-04-20 12:23:16,018: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.0071996188627909624]
[2024-04-20 12:23:16,672: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.013556869480922308]
[2024-04-20 12:23:17,331: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.01018851042301796]
[2024-04-20 12:23:17,990: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.007165907950219794]
[2024-04-20 12:23:18,648: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.015618477471122423]
[2024-04-20 12:23:19,306: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.014404771093830088]
[2024-04-20 12:23:19,964: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.0033122205492303694]
[2024-04-20 12:23:20,637: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.006304001539503142]
[2024-04-20 12:23:21,292: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.004764188828419058]
[2024-04-20 12:23:21,947: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.020324470448851537]
[2024-04-20 12:23:22,602: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.005041993883330474]
[2024-04-20 12:23:23,255: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.019649029003544295]
[2024-04-20 12:23:23,907: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.007072689580575429]
[2024-04-20 12:23:24,560: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.01277898842673449]
[2024-04-20 12:23:25,215: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.0010154820565719687]
[2024-04-20 12:23:25,871: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.03623156489109628]
[2024-04-20 12:23:26,523: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.008488321603395554]
[2024-04-20 12:23:27,178: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.006156494795220526]
[2024-04-20 12:23:27,834: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.004500740885291404]
[2024-04-20 12:23:28,490: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.005041583792353729]
[2024-04-20 12:23:29,142: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.008151541639343264]
[2024-04-20 12:23:29,797: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.004270146271415934]
[2024-04-20 12:23:30,449: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.016018491138534333]
[2024-04-20 12:23:31,104: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.0060016501700550975]
[2024-04-20 12:23:31,768: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.019976685949576304]
[2024-04-20 12:23:32,428: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.013311987249287654]
[2024-04-20 12:23:33,087: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.006329706174429522]
[2024-04-20 12:23:33,747: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.004673682053319593]
[2024-04-20 12:23:34,411: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.0007504633709831722]
[2024-04-20 12:23:35,064: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.008275193542045995]
[2024-04-20 12:23:35,715: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.007073837242317721]
[2024-04-20 12:23:36,368: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.00910902484311392]
[2024-04-20 12:23:37,022: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.009566362731237166]
[2024-04-20 12:23:37,677: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.008211101109668224]
[2024-04-20 12:23:38,328: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.012779794762158278]
[2024-04-20 12:23:38,984: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.012025128618665639]
[2024-04-20 12:23:39,635: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.011116078774814232]
[2024-04-20 12:23:40,290: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.005305577404332218]
[2024-04-20 12:23:40,944: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.012250798048077369]
[2024-04-20 12:23:41,602: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.014144495184836512]
[2024-04-20 12:23:42,256: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.007566993148796348]
[2024-04-20 12:23:42,913: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.004815436644800257]
[2024-04-20 12:23:43,567: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.005578567551288736]
[2024-04-20 12:23:44,222: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.017119966761694545]
[2024-04-20 12:23:44,882: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.013411281919076987]
[2024-04-20 12:23:45,553: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.0008017813866690387]
[2024-04-20 12:23:46,223: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.013851620898592718]
[2024-04-20 12:23:46,881: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.005865256614089674]
[2024-04-20 12:23:47,555: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.0027778192339512897]
[2024-04-20 12:23:48,214: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.022375303997152044]
[2024-04-20 12:23:48,863: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.0034351918893802515]
[2024-04-20 12:23:49,521: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.011590356994687455]
[2024-04-20 12:23:50,174: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.007587291615593408]
[2024-04-20 12:23:50,828: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.012648204540894777]
[2024-04-20 12:23:51,481: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.08170326091556385]
[2024-04-20 12:23:52,137: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.03560942696940347]
[2024-04-20 12:23:52,787: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.0060252488839813104]
[2024-04-20 12:23:53,440: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.01771568754096271]
[2024-04-20 12:23:54,092: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.01898995785890938]
[2024-04-20 12:23:54,748: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.0029693037339590237]
[2024-04-20 12:23:55,402: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.014060085236941041]
[2024-04-20 12:23:56,059: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.02258957762037314]
[2024-04-20 12:23:56,712: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.006929798558089476]
[2024-04-20 12:23:57,373: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.02421527841707371]
[2024-04-20 12:23:58,039: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.01078710861483941]
[2024-04-20 12:23:58,726: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.001410912902396831]
[2024-04-20 12:23:59,407: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.004800685050040146]
[2024-04-20 12:24:00,073: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.0043344634934308806]
[2024-04-20 12:24:00,730: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.011530905074089826]
[2024-04-20 12:24:01,389: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.012761349375082928]
[2024-04-20 12:24:02,045: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.006359038383446616]
[2024-04-20 12:24:02,695: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.032768721736951154]
[2024-04-20 12:24:03,353: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.004088526577253559]
[2024-04-20 12:24:04,009: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.016400761517676957]
[2024-04-20 12:24:04,668: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.056987257316671494]
[2024-04-20 12:24:05,325: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.009056567775438567]
[2024-04-20 12:24:05,982: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.006261092339312152]
[2024-04-20 12:24:06,632: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.007382176930345844]
[2024-04-20 12:24:07,287: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.011389975449748697]
[2024-04-20 12:24:07,940: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.013660512577740248]
[2024-04-20 12:24:08,592: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.029944561565125916]
[2024-04-20 12:24:09,245: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.022070281989871536]
[2024-04-20 12:24:09,898: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.011057365793974577]
[2024-04-20 12:24:10,553: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.01889247819063268]
[2024-04-20 12:24:11,211: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.004309021146412313]
[2024-04-20 12:24:11,873: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.010109245985193966]
[2024-04-20 12:24:12,532: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.016645092330430027]
[2024-04-20 12:24:13,192: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.01811814440454528]
[2024-04-20 12:24:13,872: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.005380754546018421]
[2024-04-20 12:24:14,540: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.008821463496272372]
[2024-04-20 12:24:15,192: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.0024205157500147003]
[2024-04-20 12:24:15,844: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.009009229623775749]
[2024-04-20 12:24:16,499: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.009313708302686977]
[2024-04-20 12:24:17,152: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.004714699658235121]
[2024-04-20 12:24:17,807: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.007780884458003864]
[2024-04-20 12:24:18,457: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.02437366385294905]
[2024-04-20 12:24:19,109: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.004129661311190054]
[2024-04-20 12:24:19,765: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.008986746057405131]
[2024-04-20 12:24:20,421: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.005099758870784055]
[2024-04-20 12:24:21,073: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.002725608271964394]
[2024-04-20 12:24:21,727: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.0027669208250328354]
[2024-04-20 12:24:22,387: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.012772483038627122]
[2024-04-20 12:24:23,037: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.007505867455048996]
[2024-04-20 12:24:23,693: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.001843661930701399]
[2024-04-20 12:24:24,346: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.05523713065855514]
[2024-04-20 12:24:25,009: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.002341054440644405]
[2024-04-20 12:24:25,680: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.0071027824792238665]
[2024-04-20 12:24:26,339: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.015667681299563904]
[2024-04-20 12:24:27,003: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.0052022374795696056]
[2024-04-20 12:24:27,670: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.010088506470159435]
[2024-04-20 12:24:28,327: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.013737832745572711]
[2024-04-20 12:24:28,979: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.013925709554110707]
[2024-04-20 12:24:29,634: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.01218515104131809]
[2024-04-20 12:24:30,290: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.007993031470341059]
[2024-04-20 12:24:30,944: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.0020352021818246316]
[2024-04-20 12:24:31,603: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.02058452716661161]
[2024-04-20 12:24:32,259: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.013011094970875948]
[2024-04-20 12:24:32,913: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.006833248785509366]
[2024-04-20 12:24:33,571: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.01584367665236668]
[2024-04-20 12:24:34,226: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.0100777424523106]
[2024-04-20 12:24:34,883: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.009972643533650603]
[2024-04-20 12:24:35,539: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.021146973163530616]
[2024-04-20 12:24:36,195: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.010349441884560917]
[2024-04-20 12:24:36,856: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.015553921306821423]
[2024-04-20 12:24:37,512: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.015222376895368742]
[2024-04-20 12:24:38,176: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.007208003395534317]
[2024-04-20 12:24:38,845: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.008139782272185802]
[2024-04-20 12:24:39,507: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.014730289015197925]
[2024-04-20 12:24:40,167: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.016387929854325883]
[2024-04-20 12:24:40,846: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.0076448632791963]
[2024-04-20 12:24:41,513: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.0034025676623306756]
[2024-04-20 12:24:42,163: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.0019968755109737125]
[2024-04-20 12:24:42,823: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.005145863780761591]
[2024-04-20 12:24:43,483: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.006817577730684525]
[2024-04-20 12:24:44,140: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.010533167971662151]
[2024-04-20 12:24:44,800: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.007460981533421576]
[2024-04-20 12:24:45,457: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.009088777415127126]
[2024-04-20 12:24:46,117: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.008737899185998488]
[2024-04-20 12:24:46,772: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.006684759243892169]
[2024-04-20 12:24:47,426: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.014810959541878718]
[2024-04-20 12:24:48,082: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.011625276684127371]
[2024-04-20 12:24:48,740: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.007294712232839605]
[2024-04-20 12:24:49,399: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.007474029213262142]
[2024-04-20 12:24:50,056: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.0006323469930974926]
[2024-04-20 12:24:50,715: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.008887740873906765]
[2024-04-20 12:24:51,384: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.007459997114629784]
[2024-04-20 12:24:52,047: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.001999127565664423]
[2024-04-20 12:24:52,716: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.013060819425317083]
[2024-04-20 12:24:53,384: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.004602921046087962]
[2024-04-20 12:24:54,055: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.007635057721963852]
[2024-04-20 12:24:54,713: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.022085360889219908]
[2024-04-20 12:24:55,371: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.0066713308030256985]
[2024-04-20 12:24:56,027: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.0032517219094266897]
[2024-04-20 12:24:56,680: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.012087544196211586]
[2024-04-20 12:24:57,334: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.016304259862041624]
[2024-04-20 12:24:57,990: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.008806091928162152]
[2024-04-20 12:24:58,650: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.011116897338310613]
[2024-04-20 12:24:59,306: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.016237219001456988]
[2024-04-20 12:24:59,964: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.006756392917167688]
[2024-04-20 12:25:00,614: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.034613231239822]
[2024-04-20 12:25:01,271: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.002193532516463008]
[2024-04-20 12:25:01,927: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.006740483948283983]
[2024-04-20 12:25:02,583: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.026494160662967257]
[2024-04-20 12:25:03,237: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.002470364541708482]
[2024-04-20 12:25:03,890: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.008306625348886088]
[2024-04-20 12:25:04,550: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.026580596344915598]
[2024-04-20 12:25:05,224: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.011248045564013084]
[2024-04-20 12:25:05,892: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.012870348652763325]
[2024-04-20 12:25:06,554: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.004531413872204437]
[2024-04-20 12:25:07,224: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.021718330095633644]
[2024-04-20 12:25:07,893: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.017904197697918813]
[2024-04-20 12:25:08,550: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.01627158097809435]
[2024-04-20 12:25:09,207: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.014113026695894764]
[2024-04-20 12:25:09,859: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.006714034709400998]
[2024-04-20 12:25:10,515: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.005238569309811716]
[2024-04-20 12:25:11,171: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.0014005820153047749]
[2024-04-20 12:25:11,830: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.00832237399558255]
[2024-04-20 12:25:12,489: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.002528875202078453]
[2024-04-20 12:25:13,143: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.011276213586389824]
[2024-04-20 12:25:13,803: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.013351424798900273]
[2024-04-20 12:25:14,455: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.0034092768959988924]
[2024-04-20 12:25:15,115: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.02600877930842347]
[2024-04-20 12:25:15,772: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.04249878459035109]
[2024-04-20 12:25:16,427: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.015377584400824307]
[2024-04-20 12:25:17,080: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.015639508732277294]
[2024-04-20 12:25:17,736: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.008152657672933794]
[2024-04-20 12:25:18,397: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.017899972550077782]
[2024-04-20 12:25:19,069: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.00944311886893052]
[2024-04-20 12:25:19,739: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.00495235999129982]
[2024-04-20 12:25:20,410: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.004917598848859834]
[2024-04-20 12:25:21,080: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.008241091816152254]
[2024-04-20 12:25:21,735: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.00790982834527834]
[2024-04-20 12:25:22,396: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.001136960305508476]
[2024-04-20 12:25:23,056: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.004811386999463379]
[2024-04-20 12:25:23,710: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.013608564682929059]
[2024-04-20 12:25:24,365: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.011803260674542378]
[2024-04-20 12:25:25,029: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.0035508376622298107]
[2024-04-20 12:25:25,708: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.015173971224674053]
[2024-04-20 12:25:26,377: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.027591921628498363]
[2024-04-20 12:25:27,037: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.01656163829786754]
[2024-04-20 12:25:27,706: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.030128178631433737]
[2024-04-20 12:25:28,359: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.008758799478593255]
[2024-04-20 12:25:29,014: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.011760352607968044]
[2024-04-20 12:25:29,674: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.011686240277261667]
[2024-04-20 12:25:30,329: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.023172958314345817]
[2024-04-20 12:25:30,987: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.025268327982771396]
[2024-04-20 12:25:31,647: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.006554975992572449]
[2024-04-20 12:25:32,315: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.014024728873332771]
[2024-04-20 12:25:32,977: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.019482517340807644]
[2024-04-20 12:25:33,647: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.004574074042568749]
[2024-04-20 12:25:34,316: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.01497461643463602]
[2024-04-20 12:25:34,970: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.002514733611813644]
[2024-04-20 12:25:35,625: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.007346760743999813]
[2024-04-20 12:25:36,282: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.004599585398793898]
[2024-04-20 12:25:36,941: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.004539562809131255]
[2024-04-20 12:25:37,600: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.013531554598728202]
[2024-04-20 12:25:38,257: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.006691446693892228]
[2024-04-20 12:25:38,915: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.008516022982113299]
[2024-04-20 12:25:39,571: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.0020491388103384034]
[2024-04-20 12:25:40,228: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.017978021353738934]
[2024-04-20 12:25:40,887: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.005222634255710115]
[2024-04-20 12:25:41,542: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.018382725650679867]
[2024-04-20 12:25:42,195: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.004406881454373708]
[2024-04-20 12:25:42,851: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.02170080442399812]
[2024-04-20 12:25:43,504: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.010056803674472632]
[2024-04-20 12:25:44,154: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.014848582022453745]
[2024-04-20 12:25:44,812: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.009884218722399606]
[2024-04-20 12:25:45,475: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.014244875305647704]
[2024-04-20 12:25:46,142: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.011812907676098229]
[2024-04-20 12:25:46,810: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.011062774102295744]
[2024-04-20 12:25:47,486: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.005701703189636017]
[2024-04-20 12:25:48,160: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.005660600154734212]
[2024-04-20 12:25:48,822: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.0011861220290535776]
[2024-04-20 12:25:49,496: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.006573038602559129]
[2024-04-20 12:25:50,159: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.004212450699044656]
[2024-04-20 12:25:50,831: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.00681562615086622]
[2024-04-20 12:25:51,496: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.00434037212834653]
[2024-04-20 12:25:52,144: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.013343233714847452]
[2024-04-20 12:25:52,806: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.020218400489212206]
[2024-04-20 12:25:53,464: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.016804511887099062]
[2024-04-20 12:25:54,116: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.0022521721290496054]
[2024-04-20 12:25:54,774: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.0045404790369013934]
[2024-04-20 12:25:55,429: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.0482124687526828]
[2024-04-20 12:25:56,084: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.010103969964743728]
[2024-04-20 12:25:56,738: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.0032976686494879917]
[2024-04-20 12:25:57,395: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.029790473368759594]
[2024-04-20 12:25:58,050: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.003871961437697921]
[2024-04-20 12:25:58,704: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.015366803657951464]
[2024-04-20 12:25:59,361: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.01259651549317415]
[2024-04-20 12:26:00,027: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.01674085781682553]
[2024-04-20 12:26:00,701: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.00823402742677514]
[2024-04-20 12:26:01,358: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.011197711467336873]
[2024-04-20 12:26:02,021: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.02851200312939471]
[2024-04-20 12:26:02,688: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.007240485336193731]
[2024-04-20 12:26:03,346: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.008988894913112411]
[2024-04-20 12:26:04,001: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.008155133325844392]
[2024-04-20 12:26:04,656: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.010172575448411318]
[2024-04-20 12:26:05,308: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.023589329369727977]
[2024-04-20 12:26:05,960: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.02005436854270351]
[2024-04-20 12:26:06,614: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.006011498737812635]
[2024-04-20 12:26:07,270: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.0038251796579934784]
[2024-04-20 12:26:07,926: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.01071699376748171]
[2024-04-20 12:26:08,581: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.007883990238164195]
[2024-04-20 12:26:09,238: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.02514255409657476]
[2024-04-20 12:26:09,896: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.01109703699510656]
[2024-04-20 12:26:10,550: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.007583467711528889]
[2024-04-20 12:26:11,209: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.014943783266025397]
[2024-04-20 12:26:11,860: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.015094345601998523]
[2024-04-20 12:26:12,514: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.009219512462684232]
[2024-04-20 12:26:13,163: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.0094662176266263]
[2024-04-20 12:26:13,821: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.013082609055532062]
[2024-04-20 12:26:14,483: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.021862956107379445]
[2024-04-20 12:26:15,155: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.023878694486828857]
[2024-04-20 12:26:15,828: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.0040284233805143975]
[2024-04-20 12:26:16,487: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.010837742772646654]
[2024-04-20 12:26:17,145: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.003877634278577268]
[2024-04-20 12:26:17,799: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.001390112757369658]
[2024-04-20 12:26:18,451: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.012558209246496872]
[2024-04-20 12:26:19,107: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.004162955564235775]
[2024-04-20 12:26:19,759: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.004921835693166335]
[2024-04-20 12:26:20,411: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.012516927137157963]
[2024-04-20 12:26:21,063: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.006165230655669137]
[2024-04-20 12:26:21,712: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.0030156003757580234]
[2024-04-20 12:26:22,369: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.003972811205971373]
[2024-04-20 12:26:23,021: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.00552232890773258]
[2024-04-20 12:26:23,679: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.004882296748179306]
[2024-04-20 12:26:24,335: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.02404746672672751]
[2024-04-20 12:26:24,988: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.014070591257787292]
[2024-04-20 12:26:25,644: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.0009729755969770891]
[2024-04-20 12:26:26,295: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.005614424971136663]
[2024-04-20 12:26:26,964: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.007992892073788295]
[2024-04-20 12:26:27,627: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.014963670147395663]
[2024-04-20 12:26:28,294: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.006588194387481428]
[2024-04-20 12:26:28,956: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.010339814736493395]
[2024-04-20 12:26:29,616: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.013400104938453825]
[2024-04-20 12:26:30,273: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.014768000078473972]
[2024-04-20 12:26:30,926: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.003953981256358456]
[2024-04-20 12:26:31,581: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.005071810136830068]
[2024-04-20 12:26:32,237: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.014613724459084744]
[2024-04-20 12:26:32,894: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.015424328988235491]
[2024-04-20 12:26:33,547: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.003491803540723558]
[2024-04-20 12:26:34,201: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.015600479285645038]
[2024-04-20 12:26:34,854: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.007120313450433323]
[2024-04-20 12:26:35,510: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.007949603592480382]
[2024-04-20 12:26:36,165: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.0063885912598928]
[2024-04-20 12:26:36,825: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.00910329719166737]
[2024-04-20 12:26:37,483: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.005035710636367835]
[2024-04-20 12:26:38,133: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.010419999448780243]
[2024-04-20 12:26:38,789: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.005355219928487226]
[2024-04-20 12:26:39,440: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.012500523139099402]
[2024-04-20 12:26:40,098: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.006176613118684914]
[2024-04-20 12:26:40,756: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.016438613492124818]
[2024-04-20 12:26:41,425: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.00413147785728137]
[2024-04-20 12:26:42,094: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.006836004648347064]
[2024-04-20 12:26:42,758: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.003154613457244486]
[2024-04-20 12:26:43,418: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.0009067708336295024]
[2024-04-20 12:26:44,076: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.010590361223068882]
[2024-04-20 12:26:44,729: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.004631395120446006]
[2024-04-20 12:26:45,385: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.016500679156724558]
[2024-04-20 12:26:46,040: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.00671439560449561]
[2024-04-20 12:26:46,695: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.006454408720740916]
[2024-04-20 12:26:47,353: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.01613479286106249]
[2024-04-20 12:26:48,008: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.0025948685146038038]
[2024-04-20 12:26:48,665: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.018007631265385654]
[2024-04-20 12:26:49,319: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.006791790456558013]
[2024-04-20 12:26:49,972: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.008706078071204154]
[2024-04-20 12:26:50,627: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.0025831560487325927]
[2024-04-20 12:26:51,280: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.03526550085295032]
[2024-04-20 12:26:51,937: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.003146943061761401]
[2024-04-20 12:26:52,590: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.006331592314572091]
[2024-04-20 12:26:53,243: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.06422416757034372]
[2024-04-20 12:26:53,916: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.00030761742373645445]
[2024-04-20 12:26:54,594: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.012236022374962156]
[2024-04-20 12:26:55,259: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.024610922251955256]
[2024-04-20 12:26:55,915: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.018545099141841864]
[2024-04-20 12:26:56,583: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.004905077627351053]
[2024-04-20 12:26:57,241: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.014202758900904144]
[2024-04-20 12:26:57,897: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.009066756019177794]
[2024-04-20 12:26:58,556: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.022404224673416018]
[2024-04-20 12:26:59,215: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.02003102619074023]
[2024-04-20 12:26:59,871: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.009041071015155956]
[2024-04-20 12:27:00,526: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.0034312602161929552]
[2024-04-20 12:27:01,180: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.011562378438287182]
[2024-04-20 12:27:01,833: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.013807665258590788]
[2024-04-20 12:27:02,488: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.008450452192074454]
[2024-04-20 12:27:03,142: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.026082898709377165]
[2024-04-20 12:27:03,795: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.004097784489669148]
[2024-04-20 12:27:04,451: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.006270565517518077]
[2024-04-20 12:27:05,108: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.007327779011452574]
[2024-04-20 12:27:05,761: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.012916316173910253]
[2024-04-20 12:27:06,415: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.0035760149123682345]
[2024-04-20 12:27:07,080: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.004240393459240165]
[2024-04-20 12:27:07,746: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.01322403102136006]
[2024-04-20 12:27:08,410: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.01566558734037919]
[2024-04-20 12:27:09,073: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.013217534109692272]
[2024-04-20 12:27:09,739: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.018590673278186483]
[2024-04-20 12:27:10,391: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.012708589358827195]
[2024-04-20 12:27:11,048: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.009522828867667284]
[2024-04-20 12:27:11,707: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.015597844799538359]
[2024-04-20 12:27:12,367: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.007427060305251631]
[2024-04-20 12:27:13,023: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.007351099588473888]
[2024-04-20 12:27:13,674: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.01142402390567786]
[2024-04-20 12:27:14,326: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.01556330607258365]
[2024-04-20 12:27:14,981: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.005987090597179543]
[2024-04-20 12:27:15,636: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.017680223825515633]
[2024-04-20 12:27:16,292: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.002044824148690391]
[2024-04-20 12:27:16,947: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.014707849622227464]
[2024-04-20 12:27:17,605: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.005238488505086534]
[2024-04-20 12:27:18,262: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.0047887184932132254]
[2024-04-20 12:27:18,918: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.005396582787412573]
[2024-04-20 12:27:19,576: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.011121791481071425]
[2024-04-20 12:27:20,243: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.007221233559926252]
[2024-04-20 12:27:20,915: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.01041434559808823]
[2024-04-20 12:27:21,585: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.012220293238416375]
[2024-04-20 12:27:22,243: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.014695092469904622]
[2024-04-20 12:27:22,916: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.00876351707797387]
[2024-04-20 12:27:23,573: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.008095157779391236]
[2024-04-20 12:27:24,226: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.0336243274233573]
[2024-04-20 12:27:24,882: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.029269372395805064]
[2024-04-20 12:27:25,539: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.006894957747792058]
[2024-04-20 12:27:26,194: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.003621452891427245]
[2024-04-20 12:27:26,851: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.004010808232109843]
[2024-04-20 12:27:27,507: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.0029127907328712075]
[2024-04-20 12:27:28,163: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.009805217719906235]
[2024-04-20 12:27:28,819: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.0036455475739008156]
[2024-04-20 12:27:29,474: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.015097400901453438]
[2024-04-20 12:27:30,132: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.011948876953690776]
[2024-04-20 12:27:30,580: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.012661675081669538]
[2024-04-20 12:27:30,787: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.01106689524126546]
[2024-04-20 12:27:30,999: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.003550928717992646]
[2024-04-20 12:27:31,205: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.01217331329345799]
[2024-04-20 12:27:31,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.004845115578054881]
[2024-04-20 12:27:31,620: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.013384614780242873]
[2024-04-20 12:27:31,828: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.0014926088991272341]
[2024-04-20 12:27:32,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.010102687732684636]
[2024-04-20 12:27:32,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.004075120539274942]
[2024-04-20 12:27:32,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.009426249719200088]
[2024-04-20 12:27:32,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.006065169409204211]
[2024-04-20 12:27:32,864: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.011938001148688147]
[2024-04-20 12:27:33,074: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.011853012019167688]
[2024-04-20 12:27:33,286: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.018525676090512762]
[2024-04-20 12:27:33,499: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.001173397714005112]
[2024-04-20 12:27:33,711: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.011730433373777693]
[2024-04-20 12:27:33,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.009510788498388214]
[2024-04-20 12:27:34,131: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.005882961117712042]
[2024-04-20 12:27:34,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.015026395404603632]
[2024-04-20 12:27:34,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.0062291251762851396]
[2024-04-20 12:27:34,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.019607814306144843]
[2024-04-20 12:27:34,976: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.003441131437044827]
[2024-04-20 12:27:35,200: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.003068418833872567]
[2024-04-20 12:27:35,414: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.010528935371770225]
[2024-04-20 12:27:35,624: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.008286813325157483]
[2024-04-20 12:27:35,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.004378176370266572]
[2024-04-20 12:27:36,048: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.000240500795502842]
[2024-04-20 12:27:36,261: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.009143955228936964]
[2024-04-20 12:27:36,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.0220336251782148]
[2024-04-20 12:27:36,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.038640478396226856]
[2024-04-20 12:27:36,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.002829008902181715]
[2024-04-20 12:27:37,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.012901350270967157]
[2024-04-20 12:27:37,302: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.005201933542811405]
[2024-04-20 12:27:37,509: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.006255626651721589]
[2024-04-20 12:27:37,715: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.009779984042956194]
[2024-04-20 12:27:37,922: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.02218790523314629]
[2024-04-20 12:27:38,128: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.003834544626944056]
[2024-04-20 12:27:38,337: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.009204211978062567]
[2024-04-20 12:27:38,544: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.005665442029428876]
[2024-04-20 12:27:38,752: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.013168311527295048]
[2024-04-20 12:27:38,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.005340880988021262]
[2024-04-20 12:27:39,165: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.0007415329787729478]
[2024-04-20 12:27:39,373: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.004317042135816379]
[2024-04-20 12:27:39,582: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.0023179125461017447]
[2024-04-20 12:27:39,788: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.01540643383425718]
[2024-04-20 12:27:39,997: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.01059199650263577]
[2024-04-20 12:27:40,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.009690855821660288]
[2024-04-20 12:27:40,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.009737771465328296]
[2024-04-20 12:27:40,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.029655538676110715]
[2024-04-20 12:27:40,819: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.00965001281899658]
[2024-04-20 12:27:41,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.0018469320907071676]
[2024-04-20 12:27:41,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.002571355305496754]
[2024-04-20 12:27:41,439: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.023830932391089722]
[2024-04-20 12:27:41,647: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.009941590169003195]
[2024-04-20 12:27:41,854: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.00927260958880827]
[2024-04-20 12:27:42,062: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.025867043038152526]
[2024-04-20 12:27:42,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.0253172935588219]
[2024-04-20 12:27:42,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.006629654071739259]
[2024-04-20 12:27:42,682: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.011869644119837194]
[2024-04-20 12:27:42,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.005182065321014671]
[2024-04-20 12:27:43,093: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.007407464958715233]
[2024-04-20 12:27:43,298: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.008622572205397422]
[2024-04-20 12:27:43,504: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.006033867004869946]
[2024-04-20 12:27:43,710: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.006047575231172031]
[2024-04-20 12:27:43,915: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.010458321867074136]
[2024-04-20 12:27:44,128: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.002091944176898547]
[2024-04-20 12:27:44,332: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.019416458074261407]
[2024-04-20 12:27:44,534: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.03020164176214421]
[2024-04-20 12:27:44,744: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.018827869038212864]
[2024-04-20 12:27:44,955: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.0049073834560568776]
[2024-04-20 12:27:45,161: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.0037171801643062813]
[2024-04-20 12:27:45,367: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.01171858975791269]
[2024-04-20 12:27:45,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.007419795131182818]
[2024-04-20 12:27:45,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.008711886780649646]
[2024-04-20 12:27:45,998: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.024178623982847175]
[2024-04-20 12:27:46,203: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.0025845334866586283]
[2024-04-20 12:27:46,407: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.021977140420967396]
[2024-04-20 12:27:46,615: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.003010668223529974]
[2024-04-20 12:27:46,828: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.005552926519610014]
[2024-04-20 12:27:47,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.006601733627762483]
[2024-04-20 12:27:47,253: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.009691956436025221]
[2024-04-20 12:27:47,464: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.011726006509521925]
[2024-04-20 12:27:47,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.012754392493709627]
[2024-04-20 12:27:47,892: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.00707877728666373]
[2024-04-20 12:27:48,102: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.01683824509136625]
[2024-04-20 12:27:48,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.0030460844408562353]
[2024-04-20 12:27:48,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.023788470300628358]
[2024-04-20 12:27:48,739: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.0015237272801414872]
[2024-04-20 12:27:48,948: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.006049825761122642]
[2024-04-20 12:27:49,162: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.0032404010018441255]
[2024-04-20 12:27:49,374: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.015315251145885292]
[2024-04-20 12:27:49,586: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.009637299793767953]
[2024-04-20 12:27:49,799: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.01872341573882286]
[2024-04-20 12:27:50,013: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.006880390838461079]
[2024-04-20 12:27:50,225: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.011432480950555091]
[2024-04-20 12:27:50,439: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.04055129739125918]
[2024-04-20 12:27:50,644: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.011732712957102386]
[2024-04-20 12:27:50,852: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.005077387266798563]
[2024-04-20 12:27:51,059: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.014455385721955379]
[2024-04-20 12:27:51,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.010563593468533935]
[2024-04-20 12:27:51,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.023341401476538043]
[2024-04-20 12:27:51,682: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.013871707766036218]
[2024-04-20 12:27:51,894: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.010619257526879191]
[2024-04-20 12:27:52,101: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.008485009031201207]
[2024-04-20 12:27:52,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.0063813307579413244]
[2024-04-20 12:27:52,518: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.005292883522018704]
[2024-04-20 12:27:52,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.010539369966259418]
[2024-04-20 12:27:52,937: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.00838454722801859]
[2024-04-20 12:27:53,143: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.01937063792950308]
[2024-04-20 12:27:53,351: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.025017705831943692]
[2024-04-20 12:27:53,561: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.004165774691297005]
[2024-04-20 12:27:53,769: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.00739213596224315]
[2024-04-20 12:27:53,975: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.028982366094607335]
[2024-04-20 12:27:54,182: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.07010431255163228]
[2024-04-20 12:27:54,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.008380783721478857]
[2024-04-20 12:27:54,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.007939062871020646]
[2024-04-20 12:27:54,806: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.014722079777003783]
[2024-04-20 12:27:55,015: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.00995149646070578]
[2024-04-20 12:27:55,222: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.016617510698604544]
[2024-04-20 12:27:55,431: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.017474540299352286]
[2024-04-20 12:27:55,640: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.021090674575350465]
[2024-04-20 12:27:55,848: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.03871955121679733]
[2024-04-20 12:27:56,058: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.01881609830803269]
[2024-04-20 12:27:56,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.0016192524948962226]
[2024-04-20 12:27:56,476: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.013870643894384442]
[2024-04-20 12:27:56,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.008453081675373226]
[2024-04-20 12:27:56,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.030528270305910637]
[2024-04-20 12:27:57,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.025154240344577188]
[2024-04-20 12:27:57,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.0012215286809129735]
[2024-04-20 12:27:57,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.015945101691408236]
[2024-04-20 12:27:57,719: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.03917110662655238]
[2024-04-20 12:27:57,926: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.00748059841152398]
[2024-04-20 12:27:58,135: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.005866932777396174]
[2024-04-20 12:27:58,343: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.041136026133110876]
[2024-04-20 12:27:58,556: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.012157381195420213]
[2024-04-20 12:27:58,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.006734842104515871]
[2024-04-20 12:27:58,968: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.012879366024186368]
[2024-04-20 12:27:59,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.02508724292429882]
[2024-04-20 12:27:59,382: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.02192300417349483]
[2024-04-20 12:27:59,589: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.014072672045302567]
[2024-04-20 12:27:59,795: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.10914612292288753]
[2024-04-20 12:28:00,002: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.008532772314854144]
[2024-04-20 12:28:00,207: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.0007997302246601313]
[2024-04-20 12:28:00,418: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.014318592609907792]
[2024-04-20 12:28:00,630: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.03264545138156989]
[2024-04-20 12:28:00,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.01117798893492169]
[2024-04-20 12:28:01,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.01055920179267706]
[2024-04-20 12:28:01,267: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.026839698325908046]
[2024-04-20 12:28:01,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.014779585690843382]
[2024-04-20 12:28:01,694: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.010941920423483147]
[2024-04-20 12:28:01,904: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.005148838905871219]
[2024-04-20 12:28:02,117: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.01977460487039271]
[2024-04-20 12:28:02,331: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.015265722444419358]
[2024-04-20 12:28:02,542: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.003786811188054084]
[2024-04-20 12:28:02,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.0023470450606324343]
[2024-04-20 12:28:02,962: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.011542935211334598]
[2024-04-20 12:28:03,173: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.017144272751383225]
[2024-04-20 12:28:03,383: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.004810629429987625]
[2024-04-20 12:28:03,598: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.0033046658528114907]
[2024-04-20 12:28:03,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.006141874928560945]
[2024-04-20 12:28:04,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.00815887108674115]
[2024-04-20 12:28:04,232: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.01901375393600434]
[2024-04-20 12:28:04,440: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.03445274650543833]
[2024-04-20 12:28:04,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.006477457179234708]
[2024-04-20 12:28:04,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.010934119270676978]
[2024-04-20 12:28:05,062: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.010524013894829275]
[2024-04-20 12:28:05,265: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.009752626521177131]
[2024-04-20 12:28:05,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.0002825525926744965]
[2024-04-20 12:28:05,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.024660776998458624]
[2024-04-20 12:28:05,890: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.032609850403575856]
[2024-04-20 12:28:06,098: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.06051441190949944]
[2024-04-20 12:28:06,304: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.011703861369892465]
[2024-04-20 12:28:06,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.02174326779940798]
[2024-04-20 12:28:06,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.016414308180285088]
[2024-04-20 12:28:06,923: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.032208517011112]
[2024-04-20 12:28:07,128: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.05538415444735879]
[2024-04-20 12:28:07,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.004983248037095357]
[2024-04-20 12:28:07,540: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.0034867714570555007]
[2024-04-20 12:28:07,750: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.06952452968159387]
[2024-04-20 12:28:07,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.004575673943062789]
[2024-04-20 12:28:08,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.012148690846915887]
[2024-04-20 12:28:08,380: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.02431202250176776]
[2024-04-20 12:28:08,587: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.016446919482425024]
[2024-04-20 12:28:08,793: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.011405951878413844]
[2024-04-20 12:28:09,004: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.014955373238444912]
[2024-04-20 12:28:09,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.00996367783633526]
[2024-04-20 12:28:09,420: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.005827119769261912]
[2024-04-20 12:28:09,628: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.007707241163875274]
[2024-04-20 12:28:09,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.0058729478995804465]
[2024-04-20 12:28:10,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 0.007892545068172963]
[2024-04-20 12:28:10,244: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.034163486619386015]
[2024-04-20 12:28:10,449: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.005435318505912594]
[2024-04-20 12:28:10,655: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.0014131133664183806]
[2024-04-20 12:28:10,861: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.014810866213096047]
[2024-04-20 12:28:11,068: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.0077305756160874995]
[2024-04-20 12:28:11,279: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.001481492118033055]
[2024-04-20 12:28:11,483: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.02448178630656195]
[2024-04-20 12:28:11,691: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.015431513928282438]
[2024-04-20 12:28:11,899: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.0021446122591291324]
[2024-04-20 12:28:12,108: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.00039461516899122164]
[2024-04-20 12:28:12,314: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.018360942054497488]
[2024-04-20 12:28:12,519: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.022514184089508806]
[2024-04-20 12:28:12,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.010039091208551482]
[2024-04-20 12:28:12,931: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.005906235907257595]
[2024-04-20 12:28:13,140: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.008237425327361]
[2024-04-20 12:28:13,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.02292880151202571]
[2024-04-20 12:28:13,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.0021519532109358992]
[2024-04-20 12:28:13,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.01297287840563592]
[2024-04-20 12:28:13,970: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.03535362701739399]
[2024-04-20 12:28:14,181: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.022305786691037107]
[2024-04-20 12:28:14,392: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.002924793469544611]
[2024-04-20 12:28:14,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.03123993561186753]
[2024-04-20 12:28:14,826: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.002863793423048405]
[2024-04-20 12:28:15,037: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.023511701474859887]
[2024-04-20 12:28:15,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.0025429356831548518]
[2024-04-20 12:28:15,458: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.017662291715602282]
[2024-04-20 12:28:15,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.0010680608547930124]
[2024-04-20 12:28:15,879: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.0043173773598801654]
[2024-04-20 12:28:16,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.014105395310241912]
[2024-04-20 12:28:16,307: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.012907351784698744]
[2024-04-20 12:28:16,520: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.0009675589934310981]
[2024-04-20 12:28:16,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.07063207658448985]
[2024-04-20 12:28:16,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.0021018754189681163]
[2024-04-20 12:28:17,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.006527776637157283]
[2024-04-20 12:28:17,364: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.006709084258861766]
[2024-04-20 12:28:17,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.008238706089480033]
[2024-04-20 12:28:17,788: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.011455470073473093]
[2024-04-20 12:28:17,999: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.018374061476742577]
[2024-04-20 12:28:18,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.005625545191876285]
[2024-04-20 12:28:18,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.0009635990684575763]
[2024-04-20 12:28:18,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 0.0018172053666027077]
[2024-04-20 12:28:18,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.0014509248490962036]
[2024-04-20 12:28:19,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 0.003427404835490118]
[2024-04-20 12:28:19,245: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.007966157843990703]
[2024-04-20 12:28:19,450: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.003328257550816446]
[2024-04-20 12:28:19,656: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.006216799932926797]
[2024-04-20 12:28:19,862: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.0324452919339301]
[2024-04-20 12:28:20,072: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.011246293214372685]
[2024-04-20 12:28:20,280: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.0038044881420738128]
[2024-04-20 12:28:20,487: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.002835674699588346]
[2024-04-20 12:28:20,695: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.0040521755235481795]
[2024-04-20 12:28:20,900: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 0.004305544836207419]
[2024-04-20 12:28:21,112: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.007468805486846525]
[2024-04-20 12:28:21,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.013028461060307242]
[2024-04-20 12:28:21,524: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.012004015675370764]
[2024-04-20 12:28:21,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.006508768898190806]
[2024-04-20 12:28:21,938: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.0018107854764686882]
[2024-04-20 12:28:22,147: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.001114926984575872]
[2024-04-20 12:28:22,356: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.014251933852119989]
[2024-04-20 12:28:22,563: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.005860218179545095]
[2024-04-20 12:28:22,770: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.0015457666337040012]
[2024-04-20 12:28:22,979: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.008413487830362885]
[2024-04-20 12:28:23,187: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.00202996730648059]
[2024-04-20 12:28:23,397: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.005260802442645558]
[2024-04-20 12:28:23,603: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.00973118988380757]
[2024-04-20 12:28:23,810: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.0065076260402038375]
[2024-04-20 12:28:24,015: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.01622824460411088]
[2024-04-20 12:28:24,227: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.006513449648665021]
[2024-04-20 12:28:24,433: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.014216581458045423]
[2024-04-20 12:28:24,639: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.01937030809913106]
[2024-04-20 12:28:24,844: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.0067180349615512495]
[2024-04-20 12:28:25,049: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.006880026649305943]
[2024-04-20 12:28:25,253: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.008347425620972746]
[2024-04-20 12:28:25,461: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.0020769385780949677]
[2024-04-20 12:28:25,666: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.0031502223119126427]
[2024-04-20 12:28:25,874: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.012290656231667715]
[2024-04-20 12:28:26,079: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.01450867091009346]
[2024-04-20 12:28:26,284: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.032807481242853605]
[2024-04-20 12:28:26,490: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.00962579837378711]
[2024-04-20 12:28:26,700: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.02488088847038105]
[2024-04-20 12:28:26,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.019418932046782706]
[2024-04-20 12:28:27,110: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.008468802502590939]
[2024-04-20 12:28:27,313: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.005349756091401959]
[2024-04-20 12:28:27,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.014705551704062103]
[2024-04-20 12:28:27,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.007579148774429836]
[2024-04-20 12:28:27,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.01176045906616494]
[2024-04-20 12:28:28,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.012491820214474978]
[2024-04-20 12:28:28,360: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.008781622569496043]
[2024-04-20 12:28:28,573: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.0045824272472735315]
[2024-04-20 12:28:28,785: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.0070240996679318156]
[2024-04-20 12:28:28,994: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 0.000464057247752478]
[2024-04-20 12:28:29,203: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.042434846726820005]
[2024-04-20 12:28:29,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.010870725969949542]
[2024-04-20 12:28:29,628: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.009588623767767515]
[2024-04-20 12:28:29,840: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.00974565124138957]
[2024-04-20 12:28:30,053: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.04464711330162384]
[2024-04-20 12:28:30,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.008843008051304821]
[2024-04-20 12:28:30,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.004255926868719619]
[2024-04-20 12:28:30,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.06348006737183057]
[2024-04-20 12:28:30,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.01998074658520097]
[2024-04-20 12:28:31,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.008666968739206768]
[2024-04-20 12:28:31,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.020452236734847546]
[2024-04-20 12:28:31,532: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.009421718164489046]
[2024-04-20 12:28:31,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.005902165629255312]
[2024-04-20 12:28:31,960: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.009566004273851418]
[2024-04-20 12:28:32,168: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.032887405645183346]
[2024-04-20 12:28:32,379: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.04089987423603806]
[2024-04-20 12:28:32,588: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.025966952122965844]
[2024-04-20 12:28:32,800: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.0347796018625228]
[2024-04-20 12:28:33,015: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.0091466747274511]
[2024-04-20 12:28:33,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.014826635020071324]
[2024-04-20 12:28:33,437: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.009160666404517234]
[2024-04-20 12:28:33,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.01806096413953306]
[2024-04-20 12:28:33,867: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.00901567805575948]
[2024-04-20 12:28:34,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.01613587755100442]
[2024-04-20 12:28:34,291: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.010845385504481442]
[2024-04-20 12:28:34,502: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.03932080472098963]
[2024-04-20 12:28:34,715: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.023140581790191052]
[2024-04-20 12:28:34,934: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.02156641381066848]
[2024-04-20 12:28:35,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.005675847714605128]
[2024-04-20 12:28:35,355: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.011698996030968955]
[2024-04-20 12:28:35,571: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.0910341001836725]
[2024-04-20 12:28:35,785: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.018957864294211545]
[2024-04-20 12:28:35,997: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.022349957777717495]
[2024-04-20 12:28:36,212: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.016939814999917507]
[2024-04-20 12:28:36,420: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.02049073450330962]
[2024-04-20 12:28:36,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.031660646239796815]
[2024-04-20 12:28:36,833: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.022770525105213556]
[2024-04-20 12:28:37,047: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.009319266416124641]
[2024-04-20 12:28:37,254: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.02088535859428598]
[2024-04-20 12:28:37,460: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.008545862884317362]
[2024-04-20 12:28:37,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.02031707837895732]
[2024-04-20 12:28:37,872: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.0059075678520331115]
[2024-04-20 12:28:38,079: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.024099731519867888]
[2024-04-20 12:28:38,287: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.023096560463278813]
[2024-04-20 12:28:38,501: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.01259985289009581]
[2024-04-20 12:28:38,712: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.0019993561508034633]
[2024-04-20 12:28:38,919: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.01089291451503482]
[2024-04-20 12:28:39,124: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.02484549545486295]
[2024-04-20 12:28:39,331: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.024554521167252753]
[2024-04-20 12:28:39,540: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.024425157947870323]
[2024-04-20 12:28:39,746: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.01611214284324352]
[2024-04-20 12:28:39,952: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.014262054383661092]
[2024-04-20 12:28:40,157: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.03194958303370263]
[2024-04-20 12:28:40,365: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.014155733617072057]
[2024-04-20 12:28:40,574: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.024764556244547417]
[2024-04-20 12:28:40,781: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.03351059439128805]
[2024-04-20 12:28:40,991: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.034044155895553846]
[2024-04-20 12:28:41,208: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.006053918399006382]
[2024-04-20 12:28:41,413: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.007801641435001817]
[2024-04-20 12:28:41,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.026179003511970837]
[2024-04-20 12:28:41,824: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.061773221551044]
[2024-04-20 12:28:42,027: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.005716622890420195]
[2024-04-20 12:28:42,241: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.006898539270924435]
[2024-04-20 12:28:42,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.09690602275919438]
[2024-04-20 12:28:42,671: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.01465468872352454]
[2024-04-20 12:28:42,879: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.012474954077204952]
[2024-04-20 12:28:43,095: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.015654231650591547]
[2024-04-20 12:28:43,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.057723951387534625]
[2024-04-20 12:28:43,521: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.03976948521978958]
[2024-04-20 12:28:43,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.09020814024574675]
[2024-04-20 12:28:43,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.032009132623277016]
[2024-04-20 12:28:44,158: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.014164534543305692]
[2024-04-20 12:28:44,370: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.01828521801803904]
[2024-04-20 12:28:44,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.014361907920688451]
[2024-04-20 12:28:44,794: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.06026793953424783]
[2024-04-20 12:28:45,003: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.006454098382976672]
[2024-04-20 12:28:45,214: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.012129787357113434]
[2024-04-20 12:28:45,426: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.013171285830354776]
[2024-04-20 12:28:45,643: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.025679005720477217]
[2024-04-20 12:28:45,860: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.01779137616699749]
[2024-04-20 12:28:46,073: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.010819949816362289]
[2024-04-20 12:28:46,279: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.029095207649042686]
[2024-04-20 12:28:46,492: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.02546840690973597]
[2024-04-20 12:28:46,699: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.011310893529243311]
[2024-04-20 12:28:46,905: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.012000729386370495]
[2024-04-20 12:28:47,109: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.009999146600493532]
[2024-04-20 12:28:47,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.04647528811854755]
[2024-04-20 12:28:47,521: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.0051037959443827295]
[2024-04-20 12:28:47,732: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.01708559546958147]
[2024-04-20 12:28:47,939: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.003276410515992626]
[2024-04-20 12:28:48,146: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.019701469901640283]
[2024-04-20 12:28:48,351: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.002767726370558988]
[2024-04-20 12:28:48,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.01846556038903982]
[2024-04-20 12:28:48,762: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.01923638506263698]
[2024-04-20 12:28:48,968: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.0052112738286682345]
[2024-04-20 12:28:49,177: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.003878316931185063]
[2024-04-20 12:28:49,387: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.0020639692352380744]
[2024-04-20 12:28:49,594: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.009522109138633984]
[2024-04-20 12:28:49,802: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.00795278294857636]
[2024-04-20 12:28:50,009: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.003806588689390979]
[2024-04-20 12:28:50,216: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.011142109736225193]
[2024-04-20 12:28:50,425: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.02784589945588249]
[2024-04-20 12:28:50,633: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.007811733195852561]
[2024-04-20 12:28:50,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.010559697644529074]
[2024-04-20 12:28:51,050: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.0214112877088699]
[2024-04-20 12:28:51,256: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.019782388943720093]
[2024-04-20 12:28:51,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 0.004468874906299096]
[2024-04-20 12:28:51,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.03974339368558038]
[2024-04-20 12:28:51,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.007903121814114261]
[2024-04-20 12:28:52,090: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.03709293239098477]
[2024-04-20 12:28:52,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.017987893323303986]
[2024-04-20 12:28:52,506: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.006064118236406875]
[2024-04-20 12:28:52,713: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.05545978027850236]
[2024-04-20 12:28:52,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.01971723950096681]
[2024-04-20 12:28:53,131: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.004977449168708222]
[2024-04-20 12:28:53,340: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.01413185193928978]
[2024-04-20 12:28:53,551: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.019730150776276437]
[2024-04-20 12:28:53,757: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.002300040463040672]
[2024-04-20 12:28:53,965: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.037095492810213355]
[2024-04-20 12:28:54,173: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.009852536209775409]
[2024-04-20 12:28:54,386: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.011106567255489613]
[2024-04-20 12:28:54,600: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.005414766207738103]
[2024-04-20 12:28:54,809: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.006837667721707643]
[2024-04-20 12:28:55,031: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.025789054638381853]
[2024-04-20 12:28:55,247: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.020365772886711993]
[2024-04-20 12:28:55,461: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.0018779358191458857]
[2024-04-20 12:28:55,674: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.0004825595798479022]
[2024-04-20 12:28:55,885: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.004120522985372963]
[2024-04-20 12:28:56,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.015399771859300117]
[2024-04-20 12:28:56,314: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.004948762205017868]
[2024-04-20 12:28:56,528: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.012267795675926698]
[2024-04-20 12:28:56,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.057195443166128505]
[2024-04-20 12:28:56,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.008041328394846172]
[2024-04-20 12:28:57,173: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.008329894104300694]
[2024-04-20 12:28:57,385: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.008683175257483473]
[2024-04-20 12:28:57,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.003172526172562104]
[2024-04-20 12:28:57,806: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.01207442231635442]
[2024-04-20 12:28:58,017: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.01053531465412207]
[2024-04-20 12:28:58,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.0033742402174034214]
[2024-04-20 12:28:58,450: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.022200057758198066]
[2024-04-20 12:28:58,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.023740774368163103]
[2024-04-20 12:28:58,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.006114774724635798]
[2024-04-20 12:28:59,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.0028607296678180424]
[2024-04-20 12:28:59,320: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.035915434161602505]
[2024-04-20 12:28:59,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.024461938930973638]
[2024-04-20 12:28:59,739: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.013116996860656021]
[2024-04-20 12:28:59,951: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.02621815149779994]
[2024-04-20 12:29:00,164: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.008102183259017352]
[2024-04-20 12:29:00,374: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.015004659190858964]
[2024-04-20 12:29:00,586: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.007009898669278681]
[2024-04-20 12:29:00,795: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.023751164565586295]
[2024-04-20 12:29:01,008: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.017868454121631003]
[2024-04-20 12:29:01,222: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.021711345577275467]
[2024-04-20 12:29:01,435: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.012066961373787453]
[2024-04-20 12:29:01,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.05055212395780157]
[2024-04-20 12:29:01,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.011612627582923762]
[2024-04-20 12:29:02,062: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.0017920100502606413]
[2024-04-20 12:29:02,270: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.009211131685574659]
[2024-04-20 12:29:02,477: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.042253625355787874]
[2024-04-20 12:29:02,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.0016850569110338602]
[2024-04-20 12:29:02,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.01870949145034196]
[2024-04-20 12:29:03,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.03769006870998657]
[2024-04-20 12:29:03,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.007257285970716139]
[2024-04-20 12:29:03,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.0279050999637914]
[2024-04-20 12:29:03,724: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.028077058346051485]
[2024-04-20 12:29:03,934: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.02607692663227135]
[2024-04-20 12:29:04,141: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.00757212273163168]
[2024-04-20 12:29:04,347: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.001001736163505002]
[2024-04-20 12:29:04,553: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.02202522227732007]
[2024-04-20 12:29:04,760: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.008836100491459942]
[2024-04-20 12:29:04,967: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.02210797059241715]
[2024-04-20 12:29:05,174: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.026390277327436203]
[2024-04-20 12:29:05,379: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.016675633780803858]
[2024-04-20 12:29:05,586: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.01417740048287415]
[2024-04-20 12:29:05,791: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.007596524987867186]
[2024-04-20 12:29:05,998: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.030577101261499796]
[2024-04-20 12:29:06,206: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.010794176304144885]
[2024-04-20 12:29:06,413: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.008695958927955653]
[2024-04-20 12:29:06,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.004627098745561986]
[2024-04-20 12:29:06,833: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.011790796607228619]
[2024-04-20 12:29:07,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 0.011880022909265384]
[2024-04-20 12:29:07,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.02605236444342384]
[2024-04-20 12:29:07,450: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.004895735426779719]
[2024-04-20 12:29:07,656: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.03957226167845243]
[2024-04-20 12:29:07,866: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.004564837834231902]
[2024-04-20 12:29:08,071: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.019189097458692878]
[2024-04-20 12:29:08,278: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.003705804181638259]
[2024-04-20 12:29:08,487: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.02677077899404749]
[2024-04-20 12:29:08,696: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.008599132598474982]
[2024-04-20 12:29:08,905: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.029289848742884858]
[2024-04-20 12:29:09,112: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.008281164676624762]
[2024-04-20 12:29:09,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.006275960407229129]
[2024-04-20 12:29:09,527: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 0.002467931025060667]
[2024-04-20 12:29:09,737: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.0021817783434608684]
[2024-04-20 12:29:09,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.002318096399406172]
[2024-04-20 12:29:10,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.0038705145874627232]
[2024-04-20 12:29:10,359: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.005141209422549375]
[2024-04-20 12:29:10,569: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.025257865672807977]
[2024-04-20 12:29:10,778: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.00454615852678169]
[2024-04-20 12:29:10,984: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.0030379244550323955]
[2024-04-20 12:29:11,191: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.036898729398842416]
[2024-04-20 12:29:11,397: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.014397068084619491]
[2024-04-20 12:29:11,608: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.0069189288435887245]
[2024-04-20 12:29:11,824: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.005048691525901653]
[2024-04-20 12:29:12,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.00978205392487164]
[2024-04-20 12:29:12,250: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.006533340518705086]
[2024-04-20 12:29:12,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.006019443666824334]
[2024-04-20 12:29:12,677: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.01668340796099927]
[2024-04-20 12:29:12,890: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.003006524410123543]
[2024-04-20 12:29:13,101: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.0004928926099067399]
[2024-04-20 12:29:13,312: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.005317754619040095]
[2024-04-20 12:29:13,533: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.00903317761340584]
[2024-04-20 12:29:13,747: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.01193459897778836]
[2024-04-20 12:29:13,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.010654963108329184]
[2024-04-20 12:29:14,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.005453646920718332]
[2024-04-20 12:29:14,387: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.015517487686795126]
[2024-04-20 12:29:14,599: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.016391893127806312]
[2024-04-20 12:29:14,813: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.028985290544687334]
[2024-04-20 12:29:15,025: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.0013444699877670815]
[2024-04-20 12:29:15,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.016803592503827805]
[2024-04-20 12:29:15,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.0060224486380790416]
[2024-04-20 12:29:15,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.0005984226083483379]
[2024-04-20 12:29:15,863: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.00885623401754345]
[2024-04-20 12:29:16,069: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.011925384196323543]
[2024-04-20 12:29:16,274: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.008672210211501814]
[2024-04-20 12:29:16,481: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.010018628814558264]
[2024-04-20 12:29:16,692: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.0028992453969740083]
[2024-04-20 12:29:16,903: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.0030956619294054064]
[2024-04-20 12:29:17,108: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.009560139451993051]
[2024-04-20 12:29:17,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.012425785492271723]
[2024-04-20 12:29:17,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.012475584301639892]
[2024-04-20 12:29:17,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.03302985758138637]
[2024-04-20 12:29:17,938: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.00829139725997681]
[2024-04-20 12:29:18,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.01271377886371332]
[2024-04-20 12:29:18,350: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.002170630268956768]
[2024-04-20 12:29:18,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.00995588390671065]
[2024-04-20 12:29:18,769: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.0055792269814091645]
[2024-04-20 12:29:18,978: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.025020068552124807]
[2024-04-20 12:29:19,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.014741611801047109]
[2024-04-20 12:29:19,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.013886020633410595]
[2024-04-20 12:29:19,598: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.010252846317633355]
[2024-04-20 12:29:19,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.021471798611471592]
[2024-04-20 12:29:20,007: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.002798337283998925]
[2024-04-20 12:29:20,212: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.0105738220087257]
[2024-04-20 12:29:20,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.04208669225876716]
[2024-04-20 12:29:20,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.023053923992464878]
[2024-04-20 12:29:20,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.0008853493031702064]
[2024-04-20 12:29:21,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.0009901444018841576]
[2024-04-20 12:29:21,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.00514748272093728]
[2024-04-20 12:29:21,459: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.0012209650823206892]
[2024-04-20 12:29:21,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.009499634568693025]
[2024-04-20 12:29:21,872: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.017126383340503235]
[2024-04-20 12:29:22,081: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.009257943207699347]
[2024-04-20 12:29:22,288: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.0046680814104654465]
[2024-04-20 12:29:22,492: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.02239573855829998]
[2024-04-20 12:29:22,699: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.0011366425805715633]
[2024-04-20 12:29:22,908: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.002795747953011111]
[2024-04-20 12:29:23,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.005909883459029938]
[2024-04-20 12:29:23,320: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.002834838404136167]
[2024-04-20 12:29:23,528: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.003915174461553009]
[2024-04-20 12:29:23,733: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.012843149645642775]
[2024-04-20 12:29:23,938: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.013637227281690957]
[2024-04-20 12:29:24,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.007053373142329065]
[2024-04-20 12:29:24,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.002726165459143999]
[2024-04-20 12:29:24,552: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.00501382158625316]
[2024-04-20 12:29:24,756: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.002942987968018174]
[2024-04-20 12:29:24,966: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.0035299994362792083]
[2024-04-20 12:29:25,172: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.002386379198784938]
[2024-04-20 12:29:25,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.008739966461063245]
[2024-04-20 12:29:25,600: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.006688349555541479]
[2024-04-20 12:29:25,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.0016735824650792497]
[2024-04-20 12:29:26,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.024832335091445286]
[2024-04-20 12:29:26,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.006966745388929904]
[2024-04-20 12:29:26,440: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.002712428189722897]
[2024-04-20 12:29:26,653: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.0037208390873646378]
[2024-04-20 12:29:26,862: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.0006451588772967751]
[2024-04-20 12:29:27,073: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.009544606627981506]
[2024-04-20 12:29:27,283: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.04420577667635552]
[2024-04-20 12:29:27,497: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.0038095833303810707]
[2024-04-20 12:29:27,705: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.0038189941186681183]
[2024-04-20 12:29:27,916: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.014654738082666386]
[2024-04-20 12:29:28,129: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.0038754228782150874]
[2024-04-20 12:29:28,340: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.02033925897331301]
[2024-04-20 12:29:28,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.004195393428487676]
[2024-04-20 12:29:28,767: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.003459763971840119]
[2024-04-20 12:29:28,973: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.008243856697776003]
[2024-04-20 12:29:29,179: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.004121942022318861]
[2024-04-20 12:29:29,387: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.008506161798396146]
[2024-04-20 12:29:29,594: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.001259721829220146]
[2024-04-20 12:29:29,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.0036374337593329214]
[2024-04-20 12:29:30,012: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.006806242972952668]
[2024-04-20 12:29:30,220: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.005771272115257711]
[2024-04-20 12:29:30,424: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.01582595437366302]
[2024-04-20 12:29:30,629: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.0009452670700070286]
[2024-04-20 12:29:30,839: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.006281729220768322]
[2024-04-20 12:29:31,047: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.0176419458908579]
[2024-04-20 12:29:31,251: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.009261253158368444]
[2024-04-20 12:29:31,456: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.015231439411424429]
[2024-04-20 12:29:31,664: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.0062073700904629004]
[2024-04-20 12:29:31,867: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.0071741171757418115]
[2024-04-20 12:29:32,072: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.007054475819855021]
[2024-04-20 12:29:32,285: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.0053134668032558995]
[2024-04-20 12:29:32,493: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.007453908828808846]
[2024-04-20 12:29:32,700: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.0017727180957999712]
[2024-04-20 12:29:32,904: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.0018165929020951723]
[2024-04-20 12:29:33,110: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.006846964448737964]
[2024-04-20 12:29:33,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.0026639035610172795]
[2024-04-20 12:29:33,525: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.013047677826082191]
[2024-04-20 12:29:33,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 0.006506498166341433]
[2024-04-20 12:29:33,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.0033952676039382275]
[2024-04-20 12:29:34,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.014135680687205523]
[2024-04-20 12:29:34,356: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.014542256927475414]
[2024-04-20 12:29:34,563: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.002342287329003909]
[2024-04-20 12:29:34,767: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.044100021702373246]
[2024-04-20 12:29:34,971: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.011386656745138127]
[2024-04-20 12:29:35,154: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 0.00405386403054403]
[2024-04-20 12:29:58,748: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9932945513360929, 'precision': 0.7357097874957894, 'recall': 0.8608221807152526, 'f1': 0.7933637612722879}]
[2024-04-20 12:30:05,606: INFO: roberta_kFold_initial_lstm: Fold 2/3]
[2024-04-20 12:30:05,613: INFO: roberta_kFold_initial_lstm: Fold 2/3 , Epoch: 1/3]
[2024-04-20 12:30:06,347: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.0109705286617528]
[2024-04-20 12:30:07,003: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.011796520983349762]
[2024-04-20 12:30:07,647: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.008894056500606451]
[2024-04-20 12:30:08,302: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.006730767264560712]
[2024-04-20 12:30:08,944: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.001742870336449796]
[2024-04-20 12:30:09,587: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.025627973879854007]
[2024-04-20 12:30:10,229: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.009965820434500994]
[2024-04-20 12:30:10,880: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.002045240753189998]
[2024-04-20 12:30:11,525: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.00861307224821183]
[2024-04-20 12:30:12,174: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.014607864108797037]
[2024-04-20 12:30:12,821: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.009540445134290346]
[2024-04-20 12:30:13,472: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.010615468763869667]
[2024-04-20 12:30:14,122: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.0033074845425587166]
[2024-04-20 12:30:14,780: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.005855381812458932]
[2024-04-20 12:30:15,433: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.027388474016116257]
[2024-04-20 12:30:16,088: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.010930925455105356]
[2024-04-20 12:30:16,749: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.01193900320482971]
[2024-04-20 12:30:17,406: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.015492970882692391]
[2024-04-20 12:30:18,061: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.012076449950196615]
[2024-04-20 12:30:18,712: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.006487301761962857]
[2024-04-20 12:30:19,369: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.004893152271435826]
[2024-04-20 12:30:20,036: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.002927970896467869]
[2024-04-20 12:30:20,697: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.003959544389941075]
[2024-04-20 12:30:21,372: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.012255800399610118]
[2024-04-20 12:30:22,053: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.009863572691802592]
[2024-04-20 12:30:22,721: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.010169267054660262]
[2024-04-20 12:30:23,380: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.026595434202578202]
[2024-04-20 12:30:24,046: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.005323884391481683]
[2024-04-20 12:30:24,710: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.01049249297805824]
[2024-04-20 12:30:25,372: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.013583287695263424]
[2024-04-20 12:30:26,039: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.01477128661835973]
[2024-04-20 12:30:26,718: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.004045282691053094]
[2024-04-20 12:30:27,381: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.0018919620304856852]
[2024-04-20 12:30:28,059: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.007732296956746107]
[2024-04-20 12:30:28,729: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.014737824001189934]
[2024-04-20 12:30:29,394: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.013953567193071824]
[2024-04-20 12:30:30,074: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.010093343818150084]
[2024-04-20 12:30:30,739: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.014413392751813166]
[2024-04-20 12:30:31,415: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.01899423440698795]
[2024-04-20 12:30:32,095: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.009154130531120687]
[2024-04-20 12:30:32,800: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.005803345624000781]
[2024-04-20 12:30:33,499: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.010540309799983124]
[2024-04-20 12:30:34,182: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.01223177965506722]
[2024-04-20 12:30:34,869: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.012659215094352423]
[2024-04-20 12:30:35,566: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.008506003290627496]
[2024-04-20 12:30:36,248: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.014157608116843749]
[2024-04-20 12:30:36,935: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.012249555476343656]
[2024-04-20 12:30:37,617: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.002817845637575338]
[2024-04-20 12:30:38,294: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.017948975912180015]
[2024-04-20 12:30:38,981: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.017669445632137307]
[2024-04-20 12:30:39,663: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.009909184942977134]
[2024-04-20 12:30:40,335: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.016943928137657133]
[2024-04-20 12:30:41,023: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.010459305275995852]
[2024-04-20 12:30:41,699: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.005770837788549748]
[2024-04-20 12:30:42,378: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.03002318534162526]
[2024-04-20 12:30:43,055: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.012713947012422367]
[2024-04-20 12:30:43,730: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.010147914746522144]
[2024-04-20 12:30:44,403: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.016924089050229272]
[2024-04-20 12:30:45,073: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.005323406954066425]
[2024-04-20 12:30:45,761: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.008608457619346225]
[2024-04-20 12:30:46,456: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.021400124201971137]
[2024-04-20 12:30:47,135: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.005297116825375692]
[2024-04-20 12:30:47,819: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.012290254612709278]
[2024-04-20 12:30:48,494: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.0029710427195870533]
[2024-04-20 12:30:49,174: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.002899625539306486]
[2024-04-20 12:30:49,837: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.007411931236374113]
[2024-04-20 12:30:50,509: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.006179494040216306]
[2024-04-20 12:30:51,168: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.013507499880473835]
[2024-04-20 12:30:51,839: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.009274017109420486]
[2024-04-20 12:30:52,502: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.008808866633613074]
[2024-04-20 12:30:53,167: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.005966527382307306]
[2024-04-20 12:30:53,832: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.008725084307145864]
[2024-04-20 12:30:54,498: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.01738735146800335]
[2024-04-20 12:30:55,159: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.018777272787467037]
[2024-04-20 12:30:55,821: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.018086813172906953]
[2024-04-20 12:30:56,479: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.018399928296942224]
[2024-04-20 12:30:57,132: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.007039120323742362]
[2024-04-20 12:30:57,799: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.01338005577205545]
[2024-04-20 12:30:58,456: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.004291417560429759]
[2024-04-20 12:30:59,117: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.007213720616484276]
[2024-04-20 12:30:59,779: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.010881798412503824]
[2024-04-20 12:31:00,451: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.029485143533403185]
[2024-04-20 12:31:01,113: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.038651236471688624]
[2024-04-20 12:31:01,788: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.006355958282225361]
[2024-04-20 12:31:02,450: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.006021454307967311]
[2024-04-20 12:31:03,106: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.017757569087071066]
[2024-04-20 12:31:03,763: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.011575202131001258]
[2024-04-20 12:31:04,416: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.0067554611736095425]
[2024-04-20 12:31:05,072: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.005749691927009571]
[2024-04-20 12:31:05,726: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.028399441552539047]
[2024-04-20 12:31:06,379: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.019988297597052167]
[2024-04-20 12:31:07,030: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.007776586575582425]
[2024-04-20 12:31:07,681: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.009378773332385704]
[2024-04-20 12:31:08,331: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.01975395867499973]
[2024-04-20 12:31:08,981: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.01331372956817507]
[2024-04-20 12:31:09,633: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.006466999283400235]
[2024-04-20 12:31:10,281: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.016050285328447537]
[2024-04-20 12:31:10,929: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.013708514166786735]
[2024-04-20 12:31:11,575: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.04618961886778013]
[2024-04-20 12:31:12,224: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.009542964115296163]
[2024-04-20 12:31:12,883: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.01905710599220083]
[2024-04-20 12:31:13,555: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.009108721547929488]
[2024-04-20 12:31:14,212: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.014126618220366899]
[2024-04-20 12:31:14,868: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.015211374535821895]
[2024-04-20 12:31:15,531: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.008453597908477389]
[2024-04-20 12:31:16,182: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.0029011769259272647]
[2024-04-20 12:31:16,837: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.009459697359430499]
[2024-04-20 12:31:17,485: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.016081482918933163]
[2024-04-20 12:31:18,129: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.017944025018237164]
[2024-04-20 12:31:18,776: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.005050801723032063]
[2024-04-20 12:31:19,422: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.005254808140609701]
[2024-04-20 12:31:20,072: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.026210172796298826]
[2024-04-20 12:31:20,720: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.021453010749917605]
[2024-04-20 12:31:21,368: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.02161152472322587]
[2024-04-20 12:31:22,013: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.012934239437980683]
[2024-04-20 12:31:22,658: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.009533524397050885]
[2024-04-20 12:31:23,305: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.006775805482188157]
[2024-04-20 12:31:23,952: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.005726462952620097]
[2024-04-20 12:31:24,601: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.008149786854613535]
[2024-04-20 12:31:25,248: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.01937622942681366]
[2024-04-20 12:31:25,898: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.01609188279132507]
[2024-04-20 12:31:26,550: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.00597547150291364]
[2024-04-20 12:31:27,202: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.011386977670199491]
[2024-04-20 12:31:27,855: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.058830530991671626]
[2024-04-20 12:31:28,518: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.003249226504989934]
[2024-04-20 12:31:29,177: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.009594730991754301]
[2024-04-20 12:31:29,825: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.008562465008410654]
[2024-04-20 12:31:30,477: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.00749607640794797]
[2024-04-20 12:31:31,125: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.012975158199723424]
[2024-04-20 12:31:31,772: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.004117043810494128]
[2024-04-20 12:31:32,419: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.0055029404511540555]
[2024-04-20 12:31:33,065: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.012401622324455136]
[2024-04-20 12:31:33,716: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.016195108730567873]
[2024-04-20 12:31:34,364: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.01485828702438303]
[2024-04-20 12:31:35,015: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.01412185036568183]
[2024-04-20 12:31:35,664: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.004090684071790196]
[2024-04-20 12:31:36,313: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.0075097798447895416]
[2024-04-20 12:31:36,965: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.017218764123193477]
[2024-04-20 12:31:37,615: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.006622396417420216]
[2024-04-20 12:31:38,267: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.030241691552885953]
[2024-04-20 12:31:38,919: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.0044332558505325815]
[2024-04-20 12:31:39,578: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.004057353229752769]
[2024-04-20 12:31:40,262: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.008249318121214702]
[2024-04-20 12:31:40,933: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.003922703897854018]
[2024-04-20 12:31:41,596: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.006230135193427117]
[2024-04-20 12:31:42,257: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.0008439426604937901]
[2024-04-20 12:31:42,924: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.011605097432385168]
[2024-04-20 12:31:43,602: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.008064430735802597]
[2024-04-20 12:31:44,297: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.013409645238459902]
[2024-04-20 12:31:44,972: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.020336023020376022]
[2024-04-20 12:31:45,627: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.02168550173790509]
[2024-04-20 12:31:46,286: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.011154677480909266]
[2024-04-20 12:31:46,942: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.015131763178481259]
[2024-04-20 12:31:47,595: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.039048556682026885]
[2024-04-20 12:31:48,247: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.0018667411916263499]
[2024-04-20 12:31:48,901: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.012335148611244441]
[2024-04-20 12:31:49,554: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.021947582330947374]
[2024-04-20 12:31:50,210: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.004637746281002906]
[2024-04-20 12:31:50,862: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.014754048958270833]
[2024-04-20 12:31:51,520: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.0048978740413043]
[2024-04-20 12:31:52,176: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.00484483650088599]
[2024-04-20 12:31:52,830: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.007259389875467567]
[2024-04-20 12:31:53,488: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.009250266891057861]
[2024-04-20 12:31:54,141: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.04632414123553447]
[2024-04-20 12:31:54,801: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.0034007823920033844]
[2024-04-20 12:31:55,464: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.004571442107579183]
[2024-04-20 12:31:56,132: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.012632277120976396]
[2024-04-20 12:31:56,794: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.0024069163535913717]
[2024-04-20 12:31:57,459: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.03709321096187185]
[2024-04-20 12:31:58,124: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.0074179628198377855]
[2024-04-20 12:31:58,783: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.015913357053704832]
[2024-04-20 12:31:59,440: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.006124561383806465]
[2024-04-20 12:32:00,101: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.008747464209437754]
[2024-04-20 12:32:00,765: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.027890433471533665]
[2024-04-20 12:32:01,425: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.006915379505719939]
[2024-04-20 12:32:02,086: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.006984626666724269]
[2024-04-20 12:32:02,740: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.018049412563773397]
[2024-04-20 12:32:03,403: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.014031610379142004]
[2024-04-20 12:32:04,078: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.0075814739252968106]
[2024-04-20 12:32:04,757: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.02843739355448854]
[2024-04-20 12:32:05,418: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.010141649567255577]
[2024-04-20 12:32:06,087: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.004821278480295961]
[2024-04-20 12:32:06,758: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.005525628880246971]
[2024-04-20 12:32:07,419: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.010578139893544917]
[2024-04-20 12:32:08,076: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.004022630664629908]
[2024-04-20 12:32:08,740: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.0011270361851144863]
[2024-04-20 12:32:09,405: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.016537405906731546]
[2024-04-20 12:32:10,093: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.007627991719455049]
[2024-04-20 12:32:10,763: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.027500670907751625]
[2024-04-20 12:32:11,431: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.005718835938199872]
[2024-04-20 12:32:12,091: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.02265806885972754]
[2024-04-20 12:32:12,746: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.004670551485203605]
[2024-04-20 12:32:13,400: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.008376102566070746]
[2024-04-20 12:32:14,062: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.019240453377409254]
[2024-04-20 12:32:14,719: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.002785203563310447]
[2024-04-20 12:32:15,377: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.005760003783055183]
[2024-04-20 12:32:16,035: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.005735157428120255]
[2024-04-20 12:32:16,694: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.010918877442954203]
[2024-04-20 12:32:17,354: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.026336524106470433]
[2024-04-20 12:32:18,014: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.011074687236480496]
[2024-04-20 12:32:18,669: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.01782826039412424]
[2024-04-20 12:32:19,327: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.01252962897007944]
[2024-04-20 12:32:19,981: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.010285832157812577]
[2024-04-20 12:32:20,635: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.000672930267408593]
[2024-04-20 12:32:21,292: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.0018539310317073898]
[2024-04-20 12:32:21,961: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.012312755402048322]
[2024-04-20 12:32:22,629: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.0016228038315261202]
[2024-04-20 12:32:23,294: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.02595509171417146]
[2024-04-20 12:32:23,962: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.0071515555242867394]
[2024-04-20 12:32:24,627: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.014297617737636596]
[2024-04-20 12:32:25,283: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.01495049860646816]
[2024-04-20 12:32:25,938: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.0013385213182187184]
[2024-04-20 12:32:26,589: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.009415050857245554]
[2024-04-20 12:32:27,245: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.013361802600057333]
[2024-04-20 12:32:27,902: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.008505541786954568]
[2024-04-20 12:32:28,558: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.009391840580784358]
[2024-04-20 12:32:29,209: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.021635445778358287]
[2024-04-20 12:32:29,864: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.0061276433116245555]
[2024-04-20 12:32:30,521: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.007847783544452916]
[2024-04-20 12:32:31,177: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.006692515274662988]
[2024-04-20 12:32:31,835: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.006023399104839703]
[2024-04-20 12:32:32,492: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.005114661026007685]
[2024-04-20 12:32:33,153: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.006389304826517217]
[2024-04-20 12:32:33,809: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.012583073994864448]
[2024-04-20 12:32:34,462: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.01455711160531187]
[2024-04-20 12:32:35,124: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.008464686990602238]
[2024-04-20 12:32:35,782: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.018801677284925728]
[2024-04-20 12:32:36,448: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.02157371169298859]
[2024-04-20 12:32:37,119: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.017282967527183786]
[2024-04-20 12:32:37,790: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.003430937339674155]
[2024-04-20 12:32:38,437: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.00897893170834942]
[2024-04-20 12:32:39,102: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.017431241610711218]
[2024-04-20 12:32:39,753: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.0045930987161408934]
[2024-04-20 12:32:40,407: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.010903200799922923]
[2024-04-20 12:32:41,058: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.015257302815203771]
[2024-04-20 12:32:41,715: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.003588181992896241]
[2024-04-20 12:32:42,372: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.009573064054462411]
[2024-04-20 12:32:43,024: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.009155527265779702]
[2024-04-20 12:32:43,681: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.017892510863507106]
[2024-04-20 12:32:44,338: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.0030028040344805777]
[2024-04-20 12:32:44,992: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.04722680948837857]
[2024-04-20 12:32:45,649: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.019790255772340767]
[2024-04-20 12:32:46,303: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.024869362833988565]
[2024-04-20 12:32:46,960: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.019030367300593154]
[2024-04-20 12:32:47,611: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.0031331936405109674]
[2024-04-20 12:32:48,265: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.005652812020499265]
[2024-04-20 12:32:48,924: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.0057776436115625695]
[2024-04-20 12:32:49,585: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.03586565661966797]
[2024-04-20 12:32:50,245: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.003796541958348933]
[2024-04-20 12:32:50,901: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.005622813862268532]
[2024-04-20 12:32:51,570: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.007512296507542079]
[2024-04-20 12:32:52,222: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.00654390861016207]
[2024-04-20 12:32:52,877: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.007141305494118098]
[2024-04-20 12:32:53,526: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.0169486396586036]
[2024-04-20 12:32:54,177: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.018569975720071956]
[2024-04-20 12:32:54,832: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.012859027437071329]
[2024-04-20 12:32:55,487: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.005755688793566517]
[2024-04-20 12:32:56,140: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.0003144808604784443]
[2024-04-20 12:32:56,794: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.06519848143527453]
[2024-04-20 12:32:57,451: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.013038974304407501]
[2024-04-20 12:32:58,108: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.016891156017474644]
[2024-04-20 12:32:58,760: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.03002946004215087]
[2024-04-20 12:32:59,415: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.0030679077427943945]
[2024-04-20 12:33:00,068: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.001941241763292959]
[2024-04-20 12:33:00,721: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.025333640727114554]
[2024-04-20 12:33:01,373: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.01906883384619015]
[2024-04-20 12:33:02,031: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.004344937596902383]
[2024-04-20 12:33:02,688: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.004761822207677835]
[2024-04-20 12:33:03,347: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.0045255019105535635]
[2024-04-20 12:33:04,010: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.01510471494038136]
[2024-04-20 12:33:04,671: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.02543509194930517]
[2024-04-20 12:33:05,327: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.00523162358783843]
[2024-04-20 12:33:05,976: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.021613183709411076]
[2024-04-20 12:33:06,624: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.011129724717727113]
[2024-04-20 12:33:07,272: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.006639864047847701]
[2024-04-20 12:33:07,923: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.006658164361907832]
[2024-04-20 12:33:08,575: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.010837671353864244]
[2024-04-20 12:33:09,230: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.00923817501853015]
[2024-04-20 12:33:09,886: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.005142310319837989]
[2024-04-20 12:33:10,537: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.023963026317727596]
[2024-04-20 12:33:11,186: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.002033810121937706]
[2024-04-20 12:33:11,833: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.017498829998791186]
[2024-04-20 12:33:12,479: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.007433779874347595]
[2024-04-20 12:33:13,133: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.013883220157722299]
[2024-04-20 12:33:13,782: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.009589717520631006]
[2024-04-20 12:33:14,436: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.00686466493058299]
[2024-04-20 12:33:15,092: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.015071003598750448]
[2024-04-20 12:33:15,756: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.01560107902458097]
[2024-04-20 12:33:16,415: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.028440071384590628]
[2024-04-20 12:33:17,075: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.009403525515239349]
[2024-04-20 12:33:17,731: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.006025047461674744]
[2024-04-20 12:33:18,390: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.04210774547361209]
[2024-04-20 12:33:19,042: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.0024072214668424585]
[2024-04-20 12:33:19,694: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.0011341086971247182]
[2024-04-20 12:33:20,352: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.002707107843033974]
[2024-04-20 12:33:21,009: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.0016395497127756928]
[2024-04-20 12:33:21,659: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.020887685263539218]
[2024-04-20 12:33:22,311: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.0032030571017547375]
[2024-04-20 12:33:22,967: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.006265244998370362]
[2024-04-20 12:33:23,622: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.001866249821423713]
[2024-04-20 12:33:24,274: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.0046330465666642754]
[2024-04-20 12:33:24,927: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.011345964120814454]
[2024-04-20 12:33:25,581: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.004805695694494873]
[2024-04-20 12:33:26,234: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.012826213132917581]
[2024-04-20 12:33:26,884: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.012890557940022732]
[2024-04-20 12:33:27,533: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.008971065386945828]
[2024-04-20 12:33:28,188: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.008059186664006018]
[2024-04-20 12:33:28,845: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.023277910154786908]
[2024-04-20 12:33:29,504: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.005015148602690386]
[2024-04-20 12:33:30,164: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.01068610520648963]
[2024-04-20 12:33:30,827: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.02995020552800321]
[2024-04-20 12:33:31,487: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.02074342994255897]
[2024-04-20 12:33:32,144: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.011632470227721674]
[2024-04-20 12:33:32,794: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.0022188158978867153]
[2024-04-20 12:33:33,447: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.03278126957926585]
[2024-04-20 12:33:34,101: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.008221607399710599]
[2024-04-20 12:33:34,752: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.00266830414342303]
[2024-04-20 12:33:35,413: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.0027844938173431843]
[2024-04-20 12:33:36,071: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.01164752686497056]
[2024-04-20 12:33:36,724: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.012618432725341305]
[2024-04-20 12:33:37,378: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.002162278334201082]
[2024-04-20 12:33:38,030: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.015066137228420566]
[2024-04-20 12:33:38,683: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.011687148493622651]
[2024-04-20 12:33:39,335: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.013069709718415128]
[2024-04-20 12:33:39,988: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.00836428575052634]
[2024-04-20 12:33:40,641: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.0072044902415260076]
[2024-04-20 12:33:41,292: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.020227317415278185]
[2024-04-20 12:33:41,943: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.003130386312916688]
[2024-04-20 12:33:42,607: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.0030419417899229697]
[2024-04-20 12:33:43,268: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.02948492923273639]
[2024-04-20 12:33:43,944: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.004160836826485786]
[2024-04-20 12:33:44,605: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.012167177198439067]
[2024-04-20 12:33:45,262: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.008585009369239473]
[2024-04-20 12:33:45,918: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.00370330695654289]
[2024-04-20 12:33:46,570: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.00712829312337242]
[2024-04-20 12:33:47,224: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.018837449799773743]
[2024-04-20 12:33:47,878: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.012003477214284297]
[2024-04-20 12:33:48,542: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.015528573371512751]
[2024-04-20 12:33:49,197: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.0018718025938568995]
[2024-04-20 12:33:49,855: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.007420440506809371]
[2024-04-20 12:33:50,513: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.01308321791178442]
[2024-04-20 12:33:51,169: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.00828377717150793]
[2024-04-20 12:33:51,825: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.006246780595543697]
[2024-04-20 12:33:52,479: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.003457493851169239]
[2024-04-20 12:33:53,136: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.018613750761619433]
[2024-04-20 12:33:53,794: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.014612809191299501]
[2024-04-20 12:33:54,448: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.005856260487564241]
[2024-04-20 12:33:55,106: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.015075273584531045]
[2024-04-20 12:33:55,784: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.00912967818784255]
[2024-04-20 12:33:56,460: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.0052327283516337775]
[2024-04-20 12:33:57,120: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.001900249273414329]
[2024-04-20 12:33:57,789: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.0024052329784125925]
[2024-04-20 12:33:58,455: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.014539270051277964]
[2024-04-20 12:33:59,106: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.0057794671316667495]
[2024-04-20 12:33:59,759: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.015031764931375634]
[2024-04-20 12:34:00,415: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.02001795098889083]
[2024-04-20 12:34:01,069: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.0029121619843183594]
[2024-04-20 12:34:01,725: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.027344967464080494]
[2024-04-20 12:34:02,379: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.026594834414658982]
[2024-04-20 12:34:03,032: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.009540626433972877]
[2024-04-20 12:34:03,687: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.013440430988307165]
[2024-04-20 12:34:04,342: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.0016497179739463806]
[2024-04-20 12:34:04,995: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.009691633060327196]
[2024-04-20 12:34:05,650: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.021000773407939426]
[2024-04-20 12:34:06,309: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.005200620500742331]
[2024-04-20 12:34:06,963: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.0020547079199574225]
[2024-04-20 12:34:07,618: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.0091297848658925]
[2024-04-20 12:34:08,280: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.00483001850886391]
[2024-04-20 12:34:08,940: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.01949041084448817]
[2024-04-20 12:34:09,614: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.006589141274810348]
[2024-04-20 12:34:10,277: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.009867089441933012]
[2024-04-20 12:34:10,944: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.007774119606336267]
[2024-04-20 12:34:11,618: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.017810092724588427]
[2024-04-20 12:34:12,281: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.003620207478359343]
[2024-04-20 12:34:12,939: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.003900069646287539]
[2024-04-20 12:34:13,596: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.019953254208986863]
[2024-04-20 12:34:14,253: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.022346489518059308]
[2024-04-20 12:34:14,910: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.024023563913368094]
[2024-04-20 12:34:15,571: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.0084997605133196]
[2024-04-20 12:34:16,225: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.00603861937328933]
[2024-04-20 12:34:16,883: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.003016849709770798]
[2024-04-20 12:34:17,536: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.014060865197939193]
[2024-04-20 12:34:18,194: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.031662830828036656]
[2024-04-20 12:34:18,846: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.021467056198247878]
[2024-04-20 12:34:19,507: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.01030293471900453]
[2024-04-20 12:34:20,167: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.006545819165436772]
[2024-04-20 12:34:20,823: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.028246554997531346]
[2024-04-20 12:34:21,479: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.0008536566920359387]
[2024-04-20 12:34:22,139: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.018082307099364363]
[2024-04-20 12:34:22,799: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.008078648074716489]
[2024-04-20 12:34:23,473: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.012501876170234412]
[2024-04-20 12:34:24,141: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.004597918878232348]
[2024-04-20 12:34:24,810: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.013093671909601834]
[2024-04-20 12:34:25,484: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.013988653659741961]
[2024-04-20 12:34:26,137: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.009576137905839605]
[2024-04-20 12:34:26,795: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.0016496155957626201]
[2024-04-20 12:34:27,452: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.00970488281233584]
[2024-04-20 12:34:28,108: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.01241325732716157]
[2024-04-20 12:34:28,762: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.00745636612796443]
[2024-04-20 12:34:29,418: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.007995200817763044]
[2024-04-20 12:34:30,070: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.024279818387582773]
[2024-04-20 12:34:30,727: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.005531543222647269]
[2024-04-20 12:34:31,383: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.00641871855907469]
[2024-04-20 12:34:32,039: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.008081545794812229]
[2024-04-20 12:34:32,706: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.0026665879722493563]
[2024-04-20 12:34:33,361: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.014111564849632746]
[2024-04-20 12:34:34,022: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.03428186207074335]
[2024-04-20 12:34:34,675: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.004990655137308233]
[2024-04-20 12:34:35,341: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.0004755216620420793]
[2024-04-20 12:34:36,006: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.007397708046748651]
[2024-04-20 12:34:36,673: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.026196698563567586]
[2024-04-20 12:34:37,342: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.00223243747623062]
[2024-04-20 12:34:38,013: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.005298085251295998]
[2024-04-20 12:34:38,680: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.008547750218121113]
[2024-04-20 12:34:39,333: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.018049647346063177]
[2024-04-20 12:34:39,988: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.0077728836837069335]
[2024-04-20 12:34:40,644: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.013325775449033033]
[2024-04-20 12:34:41,300: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.03283424082861977]
[2024-04-20 12:34:41,958: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.009235005769640212]
[2024-04-20 12:34:42,610: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.0077198505393063005]
[2024-04-20 12:34:43,269: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.004942980844167699]
[2024-04-20 12:34:43,921: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.005504276764221683]
[2024-04-20 12:34:44,578: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.013081322588669437]
[2024-04-20 12:34:45,233: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.015802671356219437]
[2024-04-20 12:34:45,889: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.011921561980134837]
[2024-04-20 12:34:46,542: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.014846038405758055]
[2024-04-20 12:34:47,198: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.006457312724085431]
[2024-04-20 12:34:47,853: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.012522956934476083]
[2024-04-20 12:34:48,511: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.002204944237530539]
[2024-04-20 12:34:49,178: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.007707527069607418]
[2024-04-20 12:34:49,845: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.015388136596852463]
[2024-04-20 12:34:50,507: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.00896066738276747]
[2024-04-20 12:34:51,188: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.002291895247456932]
[2024-04-20 12:34:51,865: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.007043412878956671]
[2024-04-20 12:34:52,546: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.017702086560839]
[2024-04-20 12:34:53,226: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.0025564698183177443]
[2024-04-20 12:34:53,908: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.013831898835705769]
[2024-04-20 12:34:54,575: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.005289594697975082]
[2024-04-20 12:34:55,229: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.014518443531420977]
[2024-04-20 12:34:55,892: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.004872263843239571]
[2024-04-20 12:34:56,552: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.005742688459140738]
[2024-04-20 12:34:57,207: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.006699020452909943]
[2024-04-20 12:34:57,862: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.007455187326208645]
[2024-04-20 12:34:58,520: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.012704490440680062]
[2024-04-20 12:34:59,175: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.0066983437642786315]
[2024-04-20 12:34:59,836: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.026250471956351818]
[2024-04-20 12:35:00,491: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.04338643038522505]
[2024-04-20 12:35:01,146: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.005450480600179099]
[2024-04-20 12:35:01,806: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.015080788786241849]
[2024-04-20 12:35:02,461: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.004029079067775231]
[2024-04-20 12:35:03,114: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.10741248284431171]
[2024-04-20 12:35:03,773: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.009176881797734895]
[2024-04-20 12:35:04,425: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.011874554353124412]
[2024-04-20 12:35:05,093: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.015242106231214138]
[2024-04-20 12:35:05,758: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.016432572143822745]
[2024-04-20 12:35:06,423: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.006644210101366731]
[2024-04-20 12:35:07,090: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.026620556587484873]
[2024-04-20 12:35:07,755: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.014329332432598966]
[2024-04-20 12:35:08,412: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.00706909436691331]
[2024-04-20 12:35:09,069: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.005212436056933044]
[2024-04-20 12:35:09,725: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.016319744872652996]
[2024-04-20 12:35:10,379: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.009128234683379054]
[2024-04-20 12:35:11,034: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.00918515523138129]
[2024-04-20 12:35:11,691: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.027666617844111077]
[2024-04-20 12:35:12,347: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.0033399427763057712]
[2024-04-20 12:35:13,005: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.00729869916784778]
[2024-04-20 12:35:13,672: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.007553919115628732]
[2024-04-20 12:35:14,334: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.003988385915134513]
[2024-04-20 12:35:14,999: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.00917820820338121]
[2024-04-20 12:35:15,664: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.006516938628373116]
[2024-04-20 12:35:16,338: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.005264893033254952]
[2024-04-20 12:35:16,997: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.0016928571417310961]
[2024-04-20 12:35:17,645: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.018686333385234913]
[2024-04-20 12:35:18,318: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.0060988833113041815]
[2024-04-20 12:35:18,984: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.005100385880646535]
[2024-04-20 12:35:19,637: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.011119694132097572]
[2024-04-20 12:35:20,296: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.0013676601345166644]
[2024-04-20 12:35:20,961: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.03543795128683522]
[2024-04-20 12:35:21,613: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.01347598142430177]
[2024-04-20 12:35:22,265: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.0020974615411245953]
[2024-04-20 12:35:22,920: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.002365450972953663]
[2024-04-20 12:35:23,575: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.01793439032767315]
[2024-04-20 12:35:24,230: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.014314137532958094]
[2024-04-20 12:35:24,886: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.04075774116786446]
[2024-04-20 12:35:25,541: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.013095132509583446]
[2024-04-20 12:35:26,197: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.0031142817857790143]
[2024-04-20 12:35:26,847: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.01096074120123545]
[2024-04-20 12:35:27,497: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.018741792178826367]
[2024-04-20 12:35:28,149: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.015741488390703332]
[2024-04-20 12:35:28,802: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.0005315022482845568]
[2024-04-20 12:35:29,454: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.003981319033108101]
[2024-04-20 12:35:30,108: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.005172023505156062]
[2024-04-20 12:35:30,763: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.010355745489817991]
[2024-04-20 12:35:31,429: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.0025460160666685703]
[2024-04-20 12:35:32,098: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.0006207052935301423]
[2024-04-20 12:35:32,764: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.022119835817113763]
[2024-04-20 12:35:33,424: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.013083786098093115]
[2024-04-20 12:35:34,092: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.015132039217270393]
[2024-04-20 12:35:34,753: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.005270810482621998]
[2024-04-20 12:35:35,405: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.011019106118423628]
[2024-04-20 12:35:36,059: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.0009859309811038263]
[2024-04-20 12:35:36,713: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.052500733911674854]
[2024-04-20 12:35:37,365: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.03533978417925854]
[2024-04-20 12:35:38,017: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.00534609832843924]
[2024-04-20 12:35:38,672: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.012565352376691048]
[2024-04-20 12:35:39,327: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.03266161692221994]
[2024-04-20 12:35:39,983: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.014900793198985181]
[2024-04-20 12:35:40,636: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.02795519146893762]
[2024-04-20 12:35:41,290: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.010762219206045488]
[2024-04-20 12:35:41,941: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.024080754692911814]
[2024-04-20 12:35:42,593: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.008679493698272985]
[2024-04-20 12:35:43,248: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.003355026945868808]
[2024-04-20 12:35:43,904: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.005647032561237438]
[2024-04-20 12:35:44,555: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.007890738467293048]
[2024-04-20 12:35:45,213: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.00756465837987941]
[2024-04-20 12:35:45,874: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.0019864440658675275]
[2024-04-20 12:35:46,538: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.007968178201208017]
[2024-04-20 12:35:47,199: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.007967846200207174]
[2024-04-20 12:35:47,863: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.01659298865447733]
[2024-04-20 12:35:48,514: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.0396128537745095]
[2024-04-20 12:35:49,165: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.012581005235344417]
[2024-04-20 12:35:49,820: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.0030171905592485332]
[2024-04-20 12:35:50,474: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.008727376901437671]
[2024-04-20 12:35:51,126: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.0021684414005071224]
[2024-04-20 12:35:51,776: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.012948211833215893]
[2024-04-20 12:35:52,427: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.01972166659548737]
[2024-04-20 12:35:53,079: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.0075337603804660975]
[2024-04-20 12:35:53,732: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.015427379558717317]
[2024-04-20 12:35:54,382: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.002812635532238985]
[2024-04-20 12:35:55,034: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.009544227520751118]
[2024-04-20 12:35:55,685: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.0061071077613319945]
[2024-04-20 12:35:56,337: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.002092585153382553]
[2024-04-20 12:35:56,984: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.025253300815209715]
[2024-04-20 12:35:57,636: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.006690564094813466]
[2024-04-20 12:35:58,301: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.01945907056649575]
[2024-04-20 12:35:58,969: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.006028521962131169]
[2024-04-20 12:35:59,626: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.005173350116708216]
[2024-04-20 12:36:00,283: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.006370246036164313]
[2024-04-20 12:36:00,940: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.006297367438054945]
[2024-04-20 12:36:01,596: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.004588190741833073]
[2024-04-20 12:36:02,249: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.007508914334760808]
[2024-04-20 12:36:02,902: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.015597966157445426]
[2024-04-20 12:36:03,556: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.0011114517990145874]
[2024-04-20 12:36:04,207: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.002808947736614674]
[2024-04-20 12:36:04,861: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.03676595586511726]
[2024-04-20 12:36:05,513: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.00799131245791805]
[2024-04-20 12:36:06,167: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.022671964448858918]
[2024-04-20 12:36:06,814: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.0043346965410934885]
[2024-04-20 12:36:07,466: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.03276940757200658]
[2024-04-20 12:36:08,121: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.00997273225042212]
[2024-04-20 12:36:08,776: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.0029216128924664385]
[2024-04-20 12:36:09,425: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.009832077495384775]
[2024-04-20 12:36:10,078: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.003968408450752887]
[2024-04-20 12:36:10,729: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.0036476042544862203]
[2024-04-20 12:36:11,386: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.008706941133031573]
[2024-04-20 12:36:12,047: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.006984764233346974]
[2024-04-20 12:36:12,709: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.008447522683864653]
[2024-04-20 12:36:13,389: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.006408577066145944]
[2024-04-20 12:36:14,060: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.0004227595236489383]
[2024-04-20 12:36:14,720: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.002732155516395173]
[2024-04-20 12:36:15,374: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.015461917542669443]
[2024-04-20 12:36:16,027: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.006297175088368215]
[2024-04-20 12:36:16,682: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.00042255537800685674]
[2024-04-20 12:36:17,336: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.018210779189840688]
[2024-04-20 12:36:17,988: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.022061616221894554]
[2024-04-20 12:36:18,643: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.00787559206235955]
[2024-04-20 12:36:19,299: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.007090439100468768]
[2024-04-20 12:36:19,952: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.007194367796123086]
[2024-04-20 12:36:20,607: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.0397392857631322]
[2024-04-20 12:36:21,263: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.014658795713306711]
[2024-04-20 12:36:21,916: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.017774923501661877]
[2024-04-20 12:36:22,572: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.0074991921609914676]
[2024-04-20 12:36:23,227: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.02465682506548858]
[2024-04-20 12:36:23,879: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.0039991940554395125]
[2024-04-20 12:36:24,535: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.010644172238212206]
[2024-04-20 12:36:25,200: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.020441468827434035]
[2024-04-20 12:36:25,866: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.026541813620878946]
[2024-04-20 12:36:26,531: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.011299210944580064]
[2024-04-20 12:36:27,195: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.008367087664801773]
[2024-04-20 12:36:27,857: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.028933920140856686]
[2024-04-20 12:36:28,510: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.00535910907489205]
[2024-04-20 12:36:29,159: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.032784962812295544]
[2024-04-20 12:36:29,814: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.013639194306303462]
[2024-04-20 12:36:30,469: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.018130349627512657]
[2024-04-20 12:36:31,126: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.01096637723426673]
[2024-04-20 12:36:31,783: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.014646315827477935]
[2024-04-20 12:36:32,437: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.04350468498052187]
[2024-04-20 12:36:33,097: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.02020709184483697]
[2024-04-20 12:36:33,753: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.007297732270821209]
[2024-04-20 12:36:34,406: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.011331853975524896]
[2024-04-20 12:36:35,064: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.011750570338603553]
[2024-04-20 12:36:35,722: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.011398227519976363]
[2024-04-20 12:36:36,379: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.0024461748276747427]
[2024-04-20 12:36:37,034: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.0067455661400773175]
[2024-04-20 12:36:37,687: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.009639603221545402]
[2024-04-20 12:36:38,351: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.012648743228743669]
[2024-04-20 12:36:39,018: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.017746014480891394]
[2024-04-20 12:36:39,694: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.01288418297257842]
[2024-04-20 12:36:40,362: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.012473649388984041]
[2024-04-20 12:36:41,026: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.007308297968622251]
[2024-04-20 12:36:41,684: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.03845055339252405]
[2024-04-20 12:36:42,340: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.011093680847290932]
[2024-04-20 12:36:42,992: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.004923003623246827]
[2024-04-20 12:36:43,650: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.0036110232129539614]
[2024-04-20 12:36:44,305: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.011442027006978009]
[2024-04-20 12:36:44,964: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.010640489687265515]
[2024-04-20 12:36:45,616: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.009694246528144233]
[2024-04-20 12:36:46,274: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.0036985425185749]
[2024-04-20 12:36:46,925: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.0063395823037066135]
[2024-04-20 12:36:47,582: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.009885274241639253]
[2024-04-20 12:36:48,234: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.00439932125711674]
[2024-04-20 12:36:48,889: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.008090023552256399]
[2024-04-20 12:36:49,548: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.005670877153181017]
[2024-04-20 12:36:50,202: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.002348699899318723]
[2024-04-20 12:36:50,856: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.03662036043683542]
[2024-04-20 12:36:51,517: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.002914707625932506]
[2024-04-20 12:36:52,186: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.010320957025799002]
[2024-04-20 12:36:52,857: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.00708793379420334]
[2024-04-20 12:36:53,530: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.006251601421275296]
[2024-04-20 12:36:54,193: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.010713743354487697]
[2024-04-20 12:36:54,861: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.006831093005226009]
[2024-04-20 12:36:55,514: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.00885211309383692]
[2024-04-20 12:36:56,170: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.00931913998988301]
[2024-04-20 12:36:56,832: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.006709865297834823]
[2024-04-20 12:36:57,487: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.0034790028946168026]
[2024-04-20 12:36:58,143: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.005747620447559415]
[2024-04-20 12:36:58,799: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.002069744326528634]
[2024-04-20 12:36:59,459: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.006518379603098478]
[2024-04-20 12:37:00,116: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.011420947627732915]
[2024-04-20 12:37:00,774: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.01018701699123652]
[2024-04-20 12:37:01,430: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.01163845320877031]
[2024-04-20 12:37:02,087: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.010072331529614948]
[2024-04-20 12:37:02,744: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.0028126138059752065]
[2024-04-20 12:37:03,403: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.012480493306463922]
[2024-04-20 12:37:04,058: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.024348306037608642]
[2024-04-20 12:37:04,721: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.013152600319475955]
[2024-04-20 12:37:05,397: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.003906572331935658]
[2024-04-20 12:37:06,070: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.027231658239477437]
[2024-04-20 12:37:06,730: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.006128442693046161]
[2024-04-20 12:37:07,391: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.016125690050462948]
[2024-04-20 12:37:08,060: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.01245121882794271]
[2024-04-20 12:37:08,717: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.001452558655816866]
[2024-04-20 12:37:09,370: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.003042023063747794]
[2024-04-20 12:37:10,024: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.003053086480944301]
[2024-04-20 12:37:10,682: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.01460653369235466]
[2024-04-20 12:37:11,338: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.01859292329489109]
[2024-04-20 12:37:11,995: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.003821749115536894]
[2024-04-20 12:37:12,650: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.022816699690703345]
[2024-04-20 12:37:13,307: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.003167460254691307]
[2024-04-20 12:37:13,963: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.01337388657969511]
[2024-04-20 12:37:14,620: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.012263260132755232]
[2024-04-20 12:37:15,276: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.017574538026241517]
[2024-04-20 12:37:15,930: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.018583079494357887]
[2024-04-20 12:37:16,585: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.013228913969535478]
[2024-04-20 12:37:17,244: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.009493947312537944]
[2024-04-20 12:37:17,900: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.005261175743559795]
[2024-04-20 12:37:18,564: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.01471598689797827]
[2024-04-20 12:37:19,235: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.011033083571085999]
[2024-04-20 12:37:19,900: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.01496337325513961]
[2024-04-20 12:37:20,569: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.023773592693383798]
[2024-04-20 12:37:21,236: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.012641829138294137]
[2024-04-20 12:37:21,897: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.0065901638201481825]
[2024-04-20 12:37:22,553: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.007778036730064416]
[2024-04-20 12:37:23,206: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.006324300635816458]
[2024-04-20 12:37:23,865: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.022104454536827953]
[2024-04-20 12:37:24,518: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.01250801604501964]
[2024-04-20 12:37:25,177: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.005498351870783687]
[2024-04-20 12:37:25,838: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.013529747473904567]
[2024-04-20 12:37:26,496: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.00836591773910499]
[2024-04-20 12:37:27,151: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.008520907763467325]
[2024-04-20 12:37:27,806: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.01859813019663608]
[2024-04-20 12:37:28,466: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.008980563609177466]
[2024-04-20 12:37:29,123: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.014524096802123986]
[2024-04-20 12:37:29,780: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.0037294610891236324]
[2024-04-20 12:37:30,438: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.018116915571157594]
[2024-04-20 12:37:31,098: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.002110802832482731]
[2024-04-20 12:37:31,768: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.01651256166030107]
[2024-04-20 12:37:32,431: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.005583358098036602]
[2024-04-20 12:37:33,101: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.0027484453314455337]
[2024-04-20 12:37:33,775: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.002713978813334193]
[2024-04-20 12:37:34,438: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.0024706542058703295]
[2024-04-20 12:37:35,103: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.00723318356600499]
[2024-04-20 12:37:35,763: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.0197910231547006]
[2024-04-20 12:37:36,416: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.0037000724371684603]
[2024-04-20 12:37:37,074: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.0036377974411639763]
[2024-04-20 12:37:37,731: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.011021520170035153]
[2024-04-20 12:37:38,392: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.0068066360700154895]
[2024-04-20 12:37:39,050: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.001668377917995461]
[2024-04-20 12:37:39,703: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.017442386335426895]
[2024-04-20 12:37:40,360: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.004219590813962902]
[2024-04-20 12:37:41,019: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.008123849981574345]
[2024-04-20 12:37:41,678: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.007262828414394275]
[2024-04-20 12:37:42,331: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.03004870127507811]
[2024-04-20 12:37:42,991: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.02219546862406859]
[2024-04-20 12:37:43,646: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.004947130965585427]
[2024-04-20 12:37:44,305: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.002344665278053988]
[2024-04-20 12:37:44,960: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.0021408675842180926]
[2024-04-20 12:37:45,620: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.000501468396136577]
[2024-04-20 12:37:46,286: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.006180553510196703]
[2024-04-20 12:37:46,950: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.0407394134961712]
[2024-04-20 12:37:47,622: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.006281296604252394]
[2024-04-20 12:37:48,292: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.006913648093115841]
[2024-04-20 12:37:48,951: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.04400233962288166]
[2024-04-20 12:37:49,601: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.01923579498747726]
[2024-04-20 12:37:50,254: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.0064435055962391175]
[2024-04-20 12:37:50,906: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.007487201409786772]
[2024-04-20 12:37:51,561: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.009696294040321471]
[2024-04-20 12:37:52,216: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.047393379628650555]
[2024-04-20 12:37:52,870: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.006178147707580068]
[2024-04-20 12:37:53,526: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.007419118024840084]
[2024-04-20 12:37:54,183: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.02242414063054198]
[2024-04-20 12:37:54,840: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.015817595298336512]
[2024-04-20 12:37:55,495: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.007114413945410006]
[2024-04-20 12:37:56,153: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.001714246597761494]
[2024-04-20 12:37:56,805: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.023683516882463042]
[2024-04-20 12:37:57,463: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.0036150459639302675]
[2024-04-20 12:37:58,117: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.013995974636552975]
[2024-04-20 12:37:58,793: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.01048803324081333]
[2024-04-20 12:37:59,486: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.010646574351640771]
[2024-04-20 12:38:00,166: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.006030017288902564]
[2024-04-20 12:38:00,831: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.009370208142934683]
[2024-04-20 12:38:01,508: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.02111926276999769]
[2024-04-20 12:38:02,197: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.014470991983463645]
[2024-04-20 12:38:02,869: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.012109709164187955]
[2024-04-20 12:38:03,544: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.003114321907422249]
[2024-04-20 12:38:04,209: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.00691205860584705]
[2024-04-20 12:38:04,864: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.0012410755616258028]
[2024-04-20 12:38:05,521: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.05076454252250086]
[2024-04-20 12:38:06,176: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.0019431563264250959]
[2024-04-20 12:38:06,831: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.011313617066584595]
[2024-04-20 12:38:07,487: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.010269664688919164]
[2024-04-20 12:38:08,142: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.012868620699907001]
[2024-04-20 12:38:08,800: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.008887471885449142]
[2024-04-20 12:38:09,451: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.00884374427882183]
[2024-04-20 12:38:10,103: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.009279788845291187]
[2024-04-20 12:38:10,758: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.003524448361263213]
[2024-04-20 12:38:11,413: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.018704653378228842]
[2024-04-20 12:38:12,070: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.0323935116134189]
[2024-04-20 12:38:12,727: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.016100468124163755]
[2024-04-20 12:38:13,381: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.006193571769841489]
[2024-04-20 12:38:14,035: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.015402777338589276]
[2024-04-20 12:38:14,692: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.006794992920780647]
[2024-04-20 12:38:15,354: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.01831279920072072]
[2024-04-20 12:38:16,021: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.0023392338826273393]
[2024-04-20 12:38:16,683: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.0022951900855714726]
[2024-04-20 12:38:17,343: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.009326725053104707]
[2024-04-20 12:38:18,001: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.023264019685599064]
[2024-04-20 12:38:18,653: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.010716442650337419]
[2024-04-20 12:38:19,306: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.011842295690240869]
[2024-04-20 12:38:19,964: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.0014831483586237016]
[2024-04-20 12:38:20,624: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.010972024013199732]
[2024-04-20 12:38:21,277: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.010501486232514871]
[2024-04-20 12:38:21,935: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.04060952324432696]
[2024-04-20 12:38:22,599: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.02039761005610747]
[2024-04-20 12:38:23,259: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.011016847574535232]
[2024-04-20 12:38:23,920: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.010017374191893275]
[2024-04-20 12:38:24,578: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.0007081118178923001]
[2024-04-20 12:38:25,235: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.004377965694985602]
[2024-04-20 12:38:25,889: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.005287076197096959]
[2024-04-20 12:38:26,545: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.0177826229823621]
[2024-04-20 12:38:27,199: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.007260993859272708]
[2024-04-20 12:38:27,864: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.01110217548375014]
[2024-04-20 12:38:28,529: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.017979604844595622]
[2024-04-20 12:38:29,190: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.01760282510870054]
[2024-04-20 12:38:29,855: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.006815228659307722]
[2024-04-20 12:38:30,519: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.015573314260272919]
[2024-04-20 12:38:31,189: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.01725396055712613]
[2024-04-20 12:38:31,849: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.006466475191276792]
[2024-04-20 12:38:32,502: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.017432530743895565]
[2024-04-20 12:38:33,154: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.030656164917361756]
[2024-04-20 12:38:33,810: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.09670892373599485]
[2024-04-20 12:38:34,462: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.017409999936471264]
[2024-04-20 12:38:35,115: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.004768956009871278]
[2024-04-20 12:38:35,768: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.010651822905956438]
[2024-04-20 12:38:36,421: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.0060367873452987116]
[2024-04-20 12:38:37,079: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.004499762977113185]
[2024-04-20 12:38:37,734: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.02511596835827905]
[2024-04-20 12:38:38,394: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.022648554721883315]
[2024-04-20 12:38:39,047: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.005971448882896517]
[2024-04-20 12:38:39,704: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.007534478746785666]
[2024-04-20 12:38:40,358: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.0038311909591223726]
[2024-04-20 12:38:41,021: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.006843079066312969]
[2024-04-20 12:38:41,689: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.030392367358139674]
[2024-04-20 12:38:42,353: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.009213370253953232]
[2024-04-20 12:38:43,015: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.008210864875283509]
[2024-04-20 12:38:43,675: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.0034449259577981383]
[2024-04-20 12:38:44,341: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.013357889983915804]
[2024-04-20 12:38:44,990: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.0066885054972558025]
[2024-04-20 12:38:45,641: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.006186848925727859]
[2024-04-20 12:38:46,300: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.030274211344483524]
[2024-04-20 12:38:46,951: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.005903585999012199]
[2024-04-20 12:38:47,606: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.020847450667841463]
[2024-04-20 12:38:48,255: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.012119513067823367]
[2024-04-20 12:38:48,912: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.007260668230848034]
[2024-04-20 12:38:49,568: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.008334137619472924]
[2024-04-20 12:38:50,227: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.0036071728664280787]
[2024-04-20 12:38:50,879: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.0042076633500353535]
[2024-04-20 12:38:51,536: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.006548855446332026]
[2024-04-20 12:38:52,195: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.00815912914343547]
[2024-04-20 12:38:52,852: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.008266551058668139]
[2024-04-20 12:38:53,511: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.025082954274094963]
[2024-04-20 12:38:54,165: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.019625423931793638]
[2024-04-20 12:38:54,819: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.02853004807892423]
[2024-04-20 12:38:55,480: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.007178507070487614]
[2024-04-20 12:38:56,146: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.015709817301497824]
[2024-04-20 12:38:56,810: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.010633497771472931]
[2024-04-20 12:38:57,474: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.00933661995646807]
[2024-04-20 12:38:58,150: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.015363235343928167]
[2024-04-20 12:38:58,806: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.0101937519890132]
[2024-04-20 12:38:59,465: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.012085684897464885]
[2024-04-20 12:39:00,119: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.0029506998709307266]
[2024-04-20 12:39:00,776: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.012558083019782194]
[2024-04-20 12:39:01,432: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.014043464024682158]
[2024-04-20 12:39:02,091: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.007552106008900104]
[2024-04-20 12:39:02,747: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.002556460024984739]
[2024-04-20 12:39:03,401: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.010796967805034932]
[2024-04-20 12:39:04,056: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.004485481080230241]
[2024-04-20 12:39:04,712: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.008763301136287777]
[2024-04-20 12:39:05,368: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.039539779096816885]
[2024-04-20 12:39:06,025: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.010257210660035808]
[2024-04-20 12:39:06,680: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.047427051722658695]
[2024-04-20 12:39:07,336: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.039623856032323636]
[2024-04-20 12:39:08,002: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.018052744059629897]
[2024-04-20 12:39:08,667: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.006979125606177216]
[2024-04-20 12:39:09,326: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.010507124530413125]
[2024-04-20 12:39:09,995: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.007688824948322732]
[2024-04-20 12:39:10,656: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.008819588828968968]
[2024-04-20 12:39:11,318: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.029761806467102588]
[2024-04-20 12:39:11,977: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.009733389120719896]
[2024-04-20 12:39:12,640: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.017993137718650496]
[2024-04-20 12:39:13,295: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.012569466295671145]
[2024-04-20 12:39:13,952: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.0016921621833795536]
[2024-04-20 12:39:14,608: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.02053414915742614]
[2024-04-20 12:39:15,263: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.005709027263664135]
[2024-04-20 12:39:15,918: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.0064197912880906835]
[2024-04-20 12:39:16,574: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.004207914869962491]
[2024-04-20 12:39:17,233: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.010561819814953686]
[2024-04-20 12:39:17,886: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.01154891751071093]
[2024-04-20 12:39:18,554: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.005117385899629891]
[2024-04-20 12:39:19,216: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.00857592352328042]
[2024-04-20 12:39:19,866: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.019262007291147822]
[2024-04-20 12:39:20,523: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.010173146047851436]
[2024-04-20 12:39:21,175: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.0017338959148671005]
[2024-04-20 12:39:21,846: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.007606746855689509]
[2024-04-20 12:39:22,515: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.003288943304744301]
[2024-04-20 12:39:23,174: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.009302852274561173]
[2024-04-20 12:39:23,846: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.005893013608278747]
[2024-04-20 12:39:24,520: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.020109362775523554]
[2024-04-20 12:39:25,176: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.011226480275791397]
[2024-04-20 12:39:25,835: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.0018127101069400837]
[2024-04-20 12:39:26,491: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.01399250342666121]
[2024-04-20 12:39:27,143: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.02591624151786436]
[2024-04-20 12:39:27,800: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.003663524452264807]
[2024-04-20 12:39:28,451: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.02113799811136617]
[2024-04-20 12:39:29,108: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.004553649283056235]
[2024-04-20 12:39:29,764: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.010038528668420574]
[2024-04-20 12:39:30,421: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.0019770366906857696]
[2024-04-20 12:39:31,078: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.02575614091739131]
[2024-04-20 12:39:31,734: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.01073343502082259]
[2024-04-20 12:39:32,390: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.005674748593290759]
[2024-04-20 12:39:33,045: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.0039829787106723065]
[2024-04-20 12:39:33,701: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.009337125332512807]
[2024-04-20 12:39:34,355: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.007003649698322983]
[2024-04-20 12:39:35,035: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.03180168631158446]
[2024-04-20 12:39:35,714: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.00801682925084969]
[2024-04-20 12:39:36,375: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.006356963070182175]
[2024-04-20 12:39:37,034: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.0041197238727266865]
[2024-04-20 12:39:37,700: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.016253330508130246]
[2024-04-20 12:39:38,350: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.0019853600352750965]
[2024-04-20 12:39:39,008: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.00802562485979206]
[2024-04-20 12:39:39,666: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.013080166533712554]
[2024-04-20 12:39:40,318: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.0019549133191569426]
[2024-04-20 12:39:40,975: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.0025868332241244804]
[2024-04-20 12:39:41,627: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.006882739787830626]
[2024-04-20 12:39:42,283: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.00817644053231468]
[2024-04-20 12:39:42,942: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.010618965677699538]
[2024-04-20 12:39:43,597: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.006389130517269434]
[2024-04-20 12:39:44,254: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.008660970649432881]
[2024-04-20 12:39:44,909: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.017763479659760648]
[2024-04-20 12:39:45,561: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.015316563293968419]
[2024-04-20 12:39:46,215: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.005448719943673269]
[2024-04-20 12:39:46,870: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.01691203863100917]
[2024-04-20 12:39:47,527: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.0031725866999052447]
[2024-04-20 12:39:48,186: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.006567362109260105]
[2024-04-20 12:39:48,843: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.013039606381832087]
[2024-04-20 12:39:49,504: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.003786233851844944]
[2024-04-20 12:39:50,176: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.013540323473836]
[2024-04-20 12:39:50,847: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.0030257575264149594]
[2024-04-20 12:39:51,504: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.003995219150948435]
[2024-04-20 12:39:52,163: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.024667308313647048]
[2024-04-20 12:39:52,816: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.0027184921888662905]
[2024-04-20 12:39:53,470: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.001389966600317589]
[2024-04-20 12:39:54,123: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.001072623946313977]
[2024-04-20 12:39:54,779: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.014548340401852692]
[2024-04-20 12:39:55,430: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.0007971413326756206]
[2024-04-20 12:39:56,084: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.02046236115507269]
[2024-04-20 12:39:56,738: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.008226499316201789]
[2024-04-20 12:39:57,390: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.0036444373879958585]
[2024-04-20 12:39:58,044: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.01812029408664269]
[2024-04-20 12:39:58,699: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.007704083415572051]
[2024-04-20 12:39:59,353: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.015217055768201903]
[2024-04-20 12:40:00,004: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.003460012576056701]
[2024-04-20 12:40:00,655: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.009462816222309786]
[2024-04-20 12:40:01,311: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.010360917629406477]
[2024-04-20 12:40:01,974: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.019623810217288876]
[2024-04-20 12:40:02,636: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.01223900930280984]
[2024-04-20 12:40:03,307: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.006651166643359647]
[2024-04-20 12:40:03,974: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.013431126436157195]
[2024-04-20 12:40:04,634: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.006105896477251437]
[2024-04-20 12:40:05,288: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.01563000740391943]
[2024-04-20 12:40:05,941: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.011884710495825764]
[2024-04-20 12:40:06,594: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.019189686106674066]
[2024-04-20 12:40:07,250: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.011659036819105828]
[2024-04-20 12:40:07,901: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.0018069998407758113]
[2024-04-20 12:40:08,554: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.004365647983609051]
[2024-04-20 12:40:09,206: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.0017175809146514557]
[2024-04-20 12:40:09,861: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.01253651282385002]
[2024-04-20 12:40:10,516: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.0038696569228641583]
[2024-04-20 12:40:11,169: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.011285196465983558]
[2024-04-20 12:40:11,826: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.004096090616906564]
[2024-04-20 12:40:12,486: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.010255337024404164]
[2024-04-20 12:40:13,141: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.002301770599040866]
[2024-04-20 12:40:13,793: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.0026553619014107193]
[2024-04-20 12:40:14,446: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.00822402306366943]
[2024-04-20 12:40:15,110: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.02199672279483356]
[2024-04-20 12:40:15,775: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.009122860541537011]
[2024-04-20 12:40:16,435: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.025733414043398007]
[2024-04-20 12:40:17,098: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.01056760463735739]
[2024-04-20 12:40:17,773: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.016145543527006864]
[2024-04-20 12:40:18,439: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.00941605051895534]
[2024-04-20 12:40:19,090: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.010730887280387803]
[2024-04-20 12:40:19,752: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.007470348307849027]
[2024-04-20 12:40:20,409: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.016222651737882784]
[2024-04-20 12:40:21,060: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.010845811839529242]
[2024-04-20 12:40:21,716: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.021568041259255166]
[2024-04-20 12:40:22,369: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.007789370947566689]
[2024-04-20 12:40:23,024: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.0034959631076954714]
[2024-04-20 12:40:23,680: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.006344035381985308]
[2024-04-20 12:40:24,334: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.04097499233679239]
[2024-04-20 12:40:24,989: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.006407000098657486]
[2024-04-20 12:40:25,642: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.0037852952306745118]
[2024-04-20 12:40:26,295: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.028862516125129148]
[2024-04-20 12:40:26,950: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.015008855609328397]
[2024-04-20 12:40:27,606: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.010295983403174568]
[2024-04-20 12:40:28,266: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.0038794887304212204]
[2024-04-20 12:40:28,929: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.005991918754251272]
[2024-04-20 12:40:29,587: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.08895859470435455]
[2024-04-20 12:40:30,246: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.007638818553259476]
[2024-04-20 12:40:30,913: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.020194806907591754]
[2024-04-20 12:40:31,577: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.004096737786046743]
[2024-04-20 12:40:32,229: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.012225374470216582]
[2024-04-20 12:40:32,884: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.011486941607425012]
[2024-04-20 12:40:33,540: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.0030785426727628373]
[2024-04-20 12:40:34,192: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.021099595980117437]
[2024-04-20 12:40:34,849: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.012448315034233635]
[2024-04-20 12:40:35,505: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.01330293559047812]
[2024-04-20 12:40:36,159: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.005857070843038335]
[2024-04-20 12:40:36,813: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.006221965476266421]
[2024-04-20 12:40:37,470: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.0262200894632349]
[2024-04-20 12:40:38,131: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.00467878388149012]
[2024-04-20 12:40:38,790: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.006133931810365309]
[2024-04-20 12:40:39,442: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.0014252361202774669]
[2024-04-20 12:40:40,099: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.004278058354993135]
[2024-04-20 12:40:40,758: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.016432194286847966]
[2024-04-20 12:40:41,415: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.00322714577233545]
[2024-04-20 12:40:42,079: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.006802111972480153]
[2024-04-20 12:40:42,740: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.01158021604418299]
[2024-04-20 12:40:43,403: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.008378309194048196]
[2024-04-20 12:40:44,063: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.017712160804156458]
[2024-04-20 12:40:44,726: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.006227232243643281]
[2024-04-20 12:40:45,381: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.010507416603702666]
[2024-04-20 12:40:46,031: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.013006790855593028]
[2024-04-20 12:40:46,689: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.012317078708546474]
[2024-04-20 12:40:47,341: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.0051931030252572894]
[2024-04-20 12:40:47,999: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.0064248853623218236]
[2024-04-20 12:40:48,655: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.002570388948701752]
[2024-04-20 12:40:49,312: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.0010772989593083957]
[2024-04-20 12:40:49,966: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.008336016591070415]
[2024-04-20 12:40:50,624: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.02444571512154945]
[2024-04-20 12:40:51,280: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.0011179147322895391]
[2024-04-20 12:40:51,934: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.013803667083108363]
[2024-04-20 12:40:52,589: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.012355649226250646]
[2024-04-20 12:40:53,242: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.0040588969695783015]
[2024-04-20 12:40:53,899: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.006396729466094717]
[2024-04-20 12:40:54,551: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.03666110510040919]
[2024-04-20 12:40:55,217: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.017921742596233785]
[2024-04-20 12:40:55,898: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.018119958658155477]
[2024-04-20 12:40:56,572: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.0239589408211832]
[2024-04-20 12:40:57,234: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.013126318979136893]
[2024-04-20 12:40:57,898: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.008362580786931223]
[2024-04-20 12:40:58,556: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.017568966451320174]
[2024-04-20 12:40:59,207: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.004246236655309957]
[2024-04-20 12:40:59,862: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.025924140055698663]
[2024-04-20 12:41:00,518: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.001745230542364274]
[2024-04-20 12:41:01,172: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.021781832898569137]
[2024-04-20 12:41:01,828: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.0108477884335858]
[2024-04-20 12:41:02,483: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.005623094188207675]
[2024-04-20 12:41:03,140: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.006361491913435724]
[2024-04-20 12:41:03,795: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.02081665832442912]
[2024-04-20 12:41:04,447: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.0034080303869825712]
[2024-04-20 12:41:05,101: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.00913845709920324]
[2024-04-20 12:41:05,755: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.028203081939505416]
[2024-04-20 12:41:06,411: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.018208998646892415]
[2024-04-20 12:41:07,068: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.0075945376718784515]
[2024-04-20 12:41:07,735: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.013926007564825949]
[2024-04-20 12:41:08,401: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.026557803742750807]
[2024-04-20 12:41:09,060: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.005416750992956868]
[2024-04-20 12:41:09,723: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.0006656124927615669]
[2024-04-20 12:41:10,387: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.007371553304562887]
[2024-04-20 12:41:11,060: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.02080308952711701]
[2024-04-20 12:41:11,733: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.004002220283097482]
[2024-04-20 12:41:12,404: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.006208030443041792]
[2024-04-20 12:41:13,066: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.005640439355236488]
[2024-04-20 12:41:13,731: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.004413601052004195]
[2024-04-20 12:41:14,382: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.002017401870553594]
[2024-04-20 12:41:15,037: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.0036747781392339938]
[2024-04-20 12:41:15,688: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.01175446946000836]
[2024-04-20 12:41:16,337: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.010672624202374928]
[2024-04-20 12:41:16,990: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.0032845889033639897]
[2024-04-20 12:41:17,642: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.0011971454055144908]
[2024-04-20 12:41:18,298: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.009031747689250753]
[2024-04-20 12:41:18,953: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.022843477097414657]
[2024-04-20 12:41:19,603: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.0020800881199252623]
[2024-04-20 12:41:20,259: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.012539161383013229]
[2024-04-20 12:41:20,920: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.033161648515946336]
[2024-04-20 12:41:21,575: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.010219925676583932]
[2024-04-20 12:41:22,232: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.008698315069754707]
[2024-04-20 12:41:22,885: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.012260276813834547]
[2024-04-20 12:41:23,539: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.012390739604260034]
[2024-04-20 12:41:24,213: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.006066537776771784]
[2024-04-20 12:41:24,876: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.010449939539931612]
[2024-04-20 12:41:25,529: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.01676297593131627]
[2024-04-20 12:41:26,195: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.004820893285319187]
[2024-04-20 12:41:26,858: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.01442443459349551]
[2024-04-20 12:41:27,513: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.051248096738226744]
[2024-04-20 12:41:28,168: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.021015438116615232]
[2024-04-20 12:41:28,824: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.005337961917071634]
[2024-04-20 12:41:29,482: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.01893689007466465]
[2024-04-20 12:41:30,136: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.011351989472071207]
[2024-04-20 12:41:30,796: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.010713880972274393]
[2024-04-20 12:41:31,459: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.0035947353575789304]
[2024-04-20 12:41:32,124: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.019990265855871558]
[2024-04-20 12:41:32,786: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.00776487694127981]
[2024-04-20 12:41:33,457: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.01285385204831311]
[2024-04-20 12:41:34,130: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.012516323069684986]
[2024-04-20 12:41:34,780: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.0032279853481446915]
[2024-04-20 12:41:35,437: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.006270575295677411]
[2024-04-20 12:41:36,093: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.006146458909226033]
[2024-04-20 12:41:36,750: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.023171417809990394]
[2024-04-20 12:41:37,416: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.01687817148544667]
[2024-04-20 12:41:38,086: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.00864916369480266]
[2024-04-20 12:41:38,755: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.004202967878742693]
[2024-04-20 12:41:39,418: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.012153825756860628]
[2024-04-20 12:41:40,098: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.010793336506363077]
[2024-04-20 12:41:40,759: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.010689829011266081]
[2024-04-20 12:41:41,409: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.008977431908653506]
[2024-04-20 12:41:42,067: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.014567645527571893]
[2024-04-20 12:41:42,724: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.00773054873989131]
[2024-04-20 12:41:43,378: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.013749325028358872]
[2024-04-20 12:41:44,038: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.011543072419813716]
[2024-04-20 12:41:44,693: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.029219012039266256]
[2024-04-20 12:41:45,347: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.043450048637656384]
[2024-04-20 12:41:46,000: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.022834789384051632]
[2024-04-20 12:41:46,658: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.010444196481394025]
[2024-04-20 12:41:47,313: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.005643636559448364]
[2024-04-20 12:41:47,967: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.016237432395819637]
[2024-04-20 12:41:48,622: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.0180255654796355]
[2024-04-20 12:41:49,273: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.0029215107670302986]
[2024-04-20 12:41:49,927: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.0035114151552470894]
[2024-04-20 12:41:50,602: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.012777226176875532]
[2024-04-20 12:41:51,268: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.01947577216292697]
[2024-04-20 12:41:51,922: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.008534821267568172]
[2024-04-20 12:41:52,583: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.014425109662586354]
[2024-04-20 12:41:53,247: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.021214068470113957]
[2024-04-20 12:41:53,901: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.005077914874489416]
[2024-04-20 12:41:54,554: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.0022496668673939206]
[2024-04-20 12:41:55,212: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.012303680195485032]
[2024-04-20 12:41:55,867: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.018581174280258787]
[2024-04-20 12:41:56,525: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.015853393782840328]
[2024-04-20 12:41:57,179: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.009933308519868048]
[2024-04-20 12:41:57,833: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.003492003042305259]
[2024-04-20 12:41:58,487: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.005721276743369395]
[2024-04-20 12:41:59,144: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.00777731662867201]
[2024-04-20 12:41:59,802: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.00422807071052135]
[2024-04-20 12:42:00,455: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.017859503003876363]
[2024-04-20 12:42:01,112: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.008113087195822552]
[2024-04-20 12:42:01,765: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.006212370634639886]
[2024-04-20 12:42:02,420: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.013357736525599588]
[2024-04-20 12:42:03,070: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.009084173559172666]
[2024-04-20 12:42:03,728: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.010512399397320009]
[2024-04-20 12:42:04,397: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.0051358720395625465]
[2024-04-20 12:42:05,072: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.010160250927984314]
[2024-04-20 12:42:05,742: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.005068187043001526]
[2024-04-20 12:42:06,399: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.01946568448000279]
[2024-04-20 12:42:07,069: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.011947770065679333]
[2024-04-20 12:42:07,726: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.0023552854874379263]
[2024-04-20 12:42:08,386: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.0034711394262931694]
[2024-04-20 12:42:09,046: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.029899314584613673]
[2024-04-20 12:42:09,694: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.023501902859494512]
[2024-04-20 12:42:10,350: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.020643248510257672]
[2024-04-20 12:42:11,001: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.011210134586346688]
[2024-04-20 12:42:11,654: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.023778931161322247]
[2024-04-20 12:42:12,313: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.0021166697261215555]
[2024-04-20 12:42:12,969: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.00809930014812925]
[2024-04-20 12:42:13,623: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.0070504252358702686]
[2024-04-20 12:42:14,278: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.007451403934175005]
[2024-04-20 12:42:14,933: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.010426487055224322]
[2024-04-20 12:42:15,601: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.01113783825585977]
[2024-04-20 12:42:16,256: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.043562359031311705]
[2024-04-20 12:42:16,913: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.012117924256281973]
[2024-04-20 12:42:17,584: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.00796812835200214]
[2024-04-20 12:42:18,250: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.011674102679867902]
[2024-04-20 12:42:18,930: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.007751468645073954]
[2024-04-20 12:42:19,596: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.015946980927605152]
[2024-04-20 12:42:20,255: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.04671980629350365]
[2024-04-20 12:42:20,911: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.022344379823927604]
[2024-04-20 12:42:21,568: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.011617270916946299]
[2024-04-20 12:42:22,225: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.03786329446252139]
[2024-04-20 12:42:22,881: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.0025978630377828144]
[2024-04-20 12:42:23,541: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.006890118540318564]
[2024-04-20 12:42:24,193: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.00473388310829155]
[2024-04-20 12:42:24,856: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.02685865333628405]
[2024-04-20 12:42:25,512: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.03155317126973921]
[2024-04-20 12:42:26,169: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.00807654729718008]
[2024-04-20 12:42:26,828: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.014256257526474726]
[2024-04-20 12:42:27,483: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.00533284680699076]
[2024-04-20 12:42:28,137: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.0028648857419181057]
[2024-04-20 12:42:28,796: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.010232648550834835]
[2024-04-20 12:42:29,453: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.017279890385177958]
[2024-04-20 12:42:30,116: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.02789737840008936]
[2024-04-20 12:42:30,786: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.04230839698507276]
[2024-04-20 12:42:31,463: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.004911148717168449]
[2024-04-20 12:42:32,130: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.011403590052496658]
[2024-04-20 12:42:32,803: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.013978277946810419]
[2024-04-20 12:42:33,481: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.006751903845656974]
[2024-04-20 12:42:34,147: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.002550717838070461]
[2024-04-20 12:42:34,799: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.00988541028033556]
[2024-04-20 12:42:35,454: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.008975199454770889]
[2024-04-20 12:42:36,111: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.009391374551583943]
[2024-04-20 12:42:36,769: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.0069213702168872205]
[2024-04-20 12:42:37,427: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.00278280661837976]
[2024-04-20 12:42:38,085: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.005129776600554774]
[2024-04-20 12:42:38,740: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.0032871499997792412]
[2024-04-20 12:42:39,399: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.009928243188681053]
[2024-04-20 12:42:40,055: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.006378912706481174]
[2024-04-20 12:42:40,712: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.005506346465774331]
[2024-04-20 12:42:41,369: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.003098882507589982]
[2024-04-20 12:42:42,025: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.009199901796142392]
[2024-04-20 12:42:42,681: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.0038500442331864575]
[2024-04-20 12:42:43,335: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.004738705613485654]
[2024-04-20 12:42:43,999: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.00472623105320492]
[2024-04-20 12:42:44,665: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.008242114816293796]
[2024-04-20 12:42:45,342: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.020473470263473504]
[2024-04-20 12:42:46,010: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.0029215086290078477]
[2024-04-20 12:42:46,677: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.03269690712403354]
[2024-04-20 12:42:47,342: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.0031353623400181313]
[2024-04-20 12:42:47,996: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.002653399226906343]
[2024-04-20 12:42:48,655: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.015924289985896022]
[2024-04-20 12:42:49,315: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.022838512283172664]
[2024-04-20 12:42:49,969: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.0067939585931189594]
[2024-04-20 12:42:50,624: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.00037736135714900616]
[2024-04-20 12:42:51,280: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.016631931567512668]
[2024-04-20 12:42:51,936: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.007035584417953541]
[2024-04-20 12:42:52,594: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.0105427336455945]
[2024-04-20 12:42:53,252: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.00874298403152976]
[2024-04-20 12:42:53,907: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.011446120975084313]
[2024-04-20 12:42:54,561: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.006506018019762964]
[2024-04-20 12:42:55,216: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.007455681380206364]
[2024-04-20 12:42:55,873: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.008090769519139092]
[2024-04-20 12:42:56,531: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.007471377227027472]
[2024-04-20 12:42:57,186: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.008745602590408642]
[2024-04-20 12:42:57,850: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.0018098757289157364]
[2024-04-20 12:42:58,514: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.006628716944925682]
[2024-04-20 12:42:59,186: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.007257621979659434]
[2024-04-20 12:42:59,853: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.015966038585413247]
[2024-04-20 12:43:00,516: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.0017983115438146768]
[2024-04-20 12:43:01,172: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.016768340182244237]
[2024-04-20 12:43:01,829: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.018594204040234465]
[2024-04-20 12:43:02,485: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.013087168699137734]
[2024-04-20 12:43:03,138: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.03515822344735102]
[2024-04-20 12:43:03,792: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.03836461575900406]
[2024-04-20 12:43:04,451: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.006763087953631141]
[2024-04-20 12:43:05,107: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.011797781427540243]
[2024-04-20 12:43:05,763: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.0037480525675247355]
[2024-04-20 12:43:06,417: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.013082369672993728]
[2024-04-20 12:43:07,070: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.006085088927099268]
[2024-04-20 12:43:07,725: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.004364367970861691]
[2024-04-20 12:43:08,382: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.0118892881011127]
[2024-04-20 12:43:09,037: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.0020630356475663395]
[2024-04-20 12:43:09,693: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.0011925270974817448]
[2024-04-20 12:43:10,348: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.0258935129066159]
[2024-04-20 12:43:10,802: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.0038518006904932063]
[2024-04-20 12:43:11,018: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.005577984331192973]
[2024-04-20 12:43:11,228: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.0023191089692365242]
[2024-04-20 12:43:11,437: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.0022785875173854902]
[2024-04-20 12:43:11,648: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.004071396765946038]
[2024-04-20 12:43:11,858: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.0017930956551109956]
[2024-04-20 12:43:12,072: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.007060743300223417]
[2024-04-20 12:43:12,284: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.011474656079382679]
[2024-04-20 12:43:12,495: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.005776354493801508]
[2024-04-20 12:43:12,706: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.005937474256476953]
[2024-04-20 12:43:12,916: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.00827403345903562]
[2024-04-20 12:43:13,126: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.0005574707901508643]
[2024-04-20 12:43:13,338: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.008716087596237349]
[2024-04-20 12:43:13,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.0061532670629577775]
[2024-04-20 12:43:13,768: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.004987567492081946]
[2024-04-20 12:43:13,980: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.015166578161979473]
[2024-04-20 12:43:14,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.005800688052331274]
[2024-04-20 12:43:14,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.011390218635589961]
[2024-04-20 12:43:14,618: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.004258671716744214]
[2024-04-20 12:43:14,823: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.004836746185258504]
[2024-04-20 12:43:15,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.007771870433755797]
[2024-04-20 12:43:15,238: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.004920131587105437]
[2024-04-20 12:43:15,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.004824451393102594]
[2024-04-20 12:43:15,653: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.005449296550290637]
[2024-04-20 12:43:15,858: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.0011119515271329422]
[2024-04-20 12:43:16,066: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.0009820414350085601]
[2024-04-20 12:43:16,273: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.0015068885963689241]
[2024-04-20 12:43:16,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.00994904433791871]
[2024-04-20 12:43:16,688: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.007668057443236408]
[2024-04-20 12:43:16,895: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.006202470470650986]
[2024-04-20 12:43:17,106: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.0037508731308601826]
[2024-04-20 12:43:17,307: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.005472859306302705]
[2024-04-20 12:43:17,510: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.002134731881145137]
[2024-04-20 12:43:17,719: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.011074166566321592]
[2024-04-20 12:43:17,927: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.0039707037840278694]
[2024-04-20 12:43:18,139: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.006011279018782107]
[2024-04-20 12:43:18,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.0003689463176883784]
[2024-04-20 12:43:18,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.0033587198134051905]
[2024-04-20 12:43:18,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.004766768127198762]
[2024-04-20 12:43:18,968: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.0025135663975180598]
[2024-04-20 12:43:19,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.005010016981055779]
[2024-04-20 12:43:19,382: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.0003749169263112514]
[2024-04-20 12:43:19,588: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.0045734088285083975]
[2024-04-20 12:43:19,796: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.005977431855670788]
[2024-04-20 12:43:20,003: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.00680407625522867]
[2024-04-20 12:43:20,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.002407065076440023]
[2024-04-20 12:43:20,419: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.003235096989046512]
[2024-04-20 12:43:20,629: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.007185701789818913]
[2024-04-20 12:43:20,835: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.0045560683791455335]
[2024-04-20 12:43:21,041: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.0022466413313542255]
[2024-04-20 12:43:21,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.001884668215110392]
[2024-04-20 12:43:21,452: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.010394439835296025]
[2024-04-20 12:43:21,658: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.014785176650746537]
[2024-04-20 12:43:21,863: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.003678399052728972]
[2024-04-20 12:43:22,070: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.0035826750550194265]
[2024-04-20 12:43:22,279: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.014612839305387799]
[2024-04-20 12:43:22,484: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.006547429726113716]
[2024-04-20 12:43:22,688: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.0005025140249732901]
[2024-04-20 12:43:22,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.0026178767606170063]
[2024-04-20 12:43:23,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.004329715162384673]
[2024-04-20 12:43:23,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.013260926723109362]
[2024-04-20 12:43:23,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.005388099243975289]
[2024-04-20 12:43:23,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.008216183374182938]
[2024-04-20 12:43:23,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.020449794291941683]
[2024-04-20 12:43:24,135: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.0043185779065423755]
[2024-04-20 12:43:24,348: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.0033448783688309583]
[2024-04-20 12:43:24,564: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.005313088768476659]
[2024-04-20 12:43:24,772: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.005896476798849661]
[2024-04-20 12:43:24,981: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.008254414006222408]
[2024-04-20 12:43:25,203: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.0009957233309446814]
[2024-04-20 12:43:25,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.0034732589728552247]
[2024-04-20 12:43:25,623: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.024338925595156227]
[2024-04-20 12:43:25,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.018541516589682103]
[2024-04-20 12:43:26,047: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.003673411637413872]
[2024-04-20 12:43:26,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.006114041462617481]
[2024-04-20 12:43:26,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.012822518328397628]
[2024-04-20 12:43:26,685: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.009596848033718585]
[2024-04-20 12:43:26,893: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.02377375736483942]
[2024-04-20 12:43:27,106: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.008134928171614831]
[2024-04-20 12:43:27,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.0012247425535168975]
[2024-04-20 12:43:27,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.00920277587167648]
[2024-04-20 12:43:27,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.0012736452966139893]
[2024-04-20 12:43:27,949: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.001973892256141576]
[2024-04-20 12:43:28,155: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.011085442744450552]
[2024-04-20 12:43:28,367: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.013208646595600587]
[2024-04-20 12:43:28,573: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.003673647052943203]
[2024-04-20 12:43:28,780: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.004110807283300852]
[2024-04-20 12:43:28,991: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.0021135782125714865]
[2024-04-20 12:43:29,198: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.00851272023766336]
[2024-04-20 12:43:29,406: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.0003068748280254676]
[2024-04-20 12:43:29,614: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.005656523509292799]
[2024-04-20 12:43:29,825: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.007367267112091042]
[2024-04-20 12:43:30,029: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.001988387272765901]
[2024-04-20 12:43:30,235: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.004181367674702214]
[2024-04-20 12:43:30,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.006291922121937902]
[2024-04-20 12:43:30,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.003406868106731742]
[2024-04-20 12:43:30,850: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.0009220038157679681]
[2024-04-20 12:43:31,059: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.00764951945212122]
[2024-04-20 12:43:31,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.0031783403274543575]
[2024-04-20 12:43:31,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.0020798938580739042]
[2024-04-20 12:43:31,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.0004651771471440164]
[2024-04-20 12:43:31,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.00990795046239248]
[2024-04-20 12:43:32,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.0117263104203076]
[2024-04-20 12:43:32,305: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.010937827623164057]
[2024-04-20 12:43:32,512: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.0044190579114963624]
[2024-04-20 12:43:32,718: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.005668597826656878]
[2024-04-20 12:43:32,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.007373069561355534]
[2024-04-20 12:43:33,138: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.013172616955662285]
[2024-04-20 12:43:33,344: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.014607814594335845]
[2024-04-20 12:43:33,552: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.0017070442779352714]
[2024-04-20 12:43:33,756: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.0001922010642944193]
[2024-04-20 12:43:33,964: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.0058758924362782095]
[2024-04-20 12:43:34,170: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.004206179576389096]
[2024-04-20 12:43:34,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.005687035486239361]
[2024-04-20 12:43:34,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.010898856195156416]
[2024-04-20 12:43:34,789: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.0008719637302542542]
[2024-04-20 12:43:34,995: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.006620027912072245]
[2024-04-20 12:43:35,205: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.009788151063123819]
[2024-04-20 12:43:35,423: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.008825569489854638]
[2024-04-20 12:43:35,631: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.0032439066319887968]
[2024-04-20 12:43:35,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.005070081187872307]
[2024-04-20 12:43:36,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.004821627376983124]
[2024-04-20 12:43:36,251: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.004097931794287782]
[2024-04-20 12:43:36,459: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.015128626112998058]
[2024-04-20 12:43:36,666: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.02924960878197411]
[2024-04-20 12:43:36,872: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.005796460377701629]
[2024-04-20 12:43:37,080: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.005485544567924354]
[2024-04-20 12:43:37,288: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.007265707723329667]
[2024-04-20 12:43:37,496: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.006919736253430479]
[2024-04-20 12:43:37,702: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.01418259179543133]
[2024-04-20 12:43:37,910: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.006060095894445908]
[2024-04-20 12:43:38,134: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.007453588448079758]
[2024-04-20 12:43:38,348: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.0033472423281346556]
[2024-04-20 12:43:38,561: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.010463859013652736]
[2024-04-20 12:43:38,772: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.0037162152641200073]
[2024-04-20 12:43:38,984: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.005160020406746804]
[2024-04-20 12:43:39,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.004881683137464657]
[2024-04-20 12:43:39,416: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.004078554143676295]
[2024-04-20 12:43:39,632: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.004554543974755106]
[2024-04-20 12:43:39,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.012142161338104224]
[2024-04-20 12:43:40,053: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.00891074948537127]
[2024-04-20 12:43:40,264: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.020141923969480773]
[2024-04-20 12:43:40,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.0035260431786934407]
[2024-04-20 12:43:40,691: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.02041779948676101]
[2024-04-20 12:43:40,899: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.019042276752053066]
[2024-04-20 12:43:41,110: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.012544333104787465]
[2024-04-20 12:43:41,321: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.0003205705025279524]
[2024-04-20 12:43:41,532: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.0034977095981706965]
[2024-04-20 12:43:41,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.028712242351297195]
[2024-04-20 12:43:41,940: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.0016317293043521075]
[2024-04-20 12:43:42,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.013951050899453985]
[2024-04-20 12:43:42,351: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.01299978273542892]
[2024-04-20 12:43:42,561: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.008349137236608418]
[2024-04-20 12:43:42,766: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.00400531450033676]
[2024-04-20 12:43:42,975: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.0046158974148082085]
[2024-04-20 12:43:43,186: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.003907608380824964]
[2024-04-20 12:43:43,393: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.009650243224232434]
[2024-04-20 12:43:43,599: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.01854991739101949]
[2024-04-20 12:43:43,805: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.0010711499421280273]
[2024-04-20 12:43:44,012: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.0012368832003892003]
[2024-04-20 12:43:44,219: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.004399776884352164]
[2024-04-20 12:43:44,428: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.013961892901568693]
[2024-04-20 12:43:44,636: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.0036690781858672705]
[2024-04-20 12:43:44,845: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.015130255208342169]
[2024-04-20 12:43:45,051: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.00042240269289956785]
[2024-04-20 12:43:45,255: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.0007890128776007377]
[2024-04-20 12:43:45,461: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.003336313536748218]
[2024-04-20 12:43:45,669: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.002169721528963981]
[2024-04-20 12:43:45,875: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.0028673317702891526]
[2024-04-20 12:43:46,080: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.006623209817943144]
[2024-04-20 12:43:46,285: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.0033233167517988022]
[2024-04-20 12:43:46,488: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.0019213605500782473]
[2024-04-20 12:43:46,696: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.009351891318737428]
[2024-04-20 12:43:46,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.002721174567561994]
[2024-04-20 12:43:47,115: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.014077665710023472]
[2024-04-20 12:43:47,323: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.0014755538669978965]
[2024-04-20 12:43:47,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.004500233244775392]
[2024-04-20 12:43:47,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.0023136544676637914]
[2024-04-20 12:43:47,943: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.0021213969850054186]
[2024-04-20 12:43:48,154: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.007600917577311223]
[2024-04-20 12:43:48,359: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.0006738127971495303]
[2024-04-20 12:43:48,565: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.0017182687664517875]
[2024-04-20 12:43:48,770: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.00224470880793117]
[2024-04-20 12:43:48,976: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.00579124765489985]
[2024-04-20 12:43:49,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.0006171797530138321]
[2024-04-20 12:43:49,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.010721471921732721]
[2024-04-20 12:43:49,597: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.004869858145571765]
[2024-04-20 12:43:49,805: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.005464667689952811]
[2024-04-20 12:43:50,012: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.003017571809895412]
[2024-04-20 12:43:50,218: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 0.012061914779881552]
[2024-04-20 12:43:50,426: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.007695232386024087]
[2024-04-20 12:43:50,632: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.0074820976912325565]
[2024-04-20 12:43:50,835: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.018587555329752904]
[2024-04-20 12:43:51,041: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.0012253142278844413]
[2024-04-20 12:43:51,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.0056277593673649965]
[2024-04-20 12:43:51,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.0003828145014070188]
[2024-04-20 12:43:51,663: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.003555216083740051]
[2024-04-20 12:43:51,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.004646470866907033]
[2024-04-20 12:43:52,090: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.004325358179262177]
[2024-04-20 12:43:52,303: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.007068395198618583]
[2024-04-20 12:43:52,515: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.0030579782357352575]
[2024-04-20 12:43:52,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.00688943038312514]
[2024-04-20 12:43:52,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.0033878052808953545]
[2024-04-20 12:43:53,142: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.017588554725100777]
[2024-04-20 12:43:53,358: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.004372677089990477]
[2024-04-20 12:43:53,565: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.0043758018094826505]
[2024-04-20 12:43:53,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.003963863349201341]
[2024-04-20 12:43:53,985: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.008214409817350624]
[2024-04-20 12:43:54,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.006881992147743339]
[2024-04-20 12:43:54,399: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.0017706795980367168]
[2024-04-20 12:43:54,612: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.010676426473867694]
[2024-04-20 12:43:54,820: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.0016678858754256194]
[2024-04-20 12:43:55,037: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.003133356241495817]
[2024-04-20 12:43:55,244: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.0048432681339445754]
[2024-04-20 12:43:55,449: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.002992099262006985]
[2024-04-20 12:43:55,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.003744452353761837]
[2024-04-20 12:43:55,867: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.0030207446043834384]
[2024-04-20 12:43:56,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.0023122119211380315]
[2024-04-20 12:43:56,283: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.00756109279185309]
[2024-04-20 12:43:56,489: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.0063554875300801976]
[2024-04-20 12:43:56,695: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.005524585370921092]
[2024-04-20 12:43:56,899: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.008767598280347129]
[2024-04-20 12:43:57,111: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.011967202147844767]
[2024-04-20 12:43:57,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.004630091319477412]
[2024-04-20 12:43:57,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.009368299142434056]
[2024-04-20 12:43:57,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.020072860956988302]
[2024-04-20 12:43:57,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.008257965017136278]
[2024-04-20 12:43:58,138: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.0043738859286129575]
[2024-04-20 12:43:58,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.0010484819236010708]
[2024-04-20 12:43:58,551: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.006726790812750324]
[2024-04-20 12:43:58,757: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 0.0020247872514294885]
[2024-04-20 12:43:58,963: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.004433511174514859]
[2024-04-20 12:43:59,168: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 0.004500197548893011]
[2024-04-20 12:43:59,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.0021427303219850613]
[2024-04-20 12:43:59,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.02120927189680831]
[2024-04-20 12:43:59,786: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.00838193755764648]
[2024-04-20 12:43:59,993: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.0017784839750182163]
[2024-04-20 12:44:00,197: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.008752849392990486]
[2024-04-20 12:44:00,405: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.001250033612743379]
[2024-04-20 12:44:00,615: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.0016853863562452482]
[2024-04-20 12:44:00,827: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.007803180594088339]
[2024-04-20 12:44:01,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 0.004811543987063395]
[2024-04-20 12:44:01,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.0025715256454542225]
[2024-04-20 12:44:01,444: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.0033557986500378214]
[2024-04-20 12:44:01,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.003563591270569607]
[2024-04-20 12:44:01,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.008962900197712764]
[2024-04-20 12:44:02,065: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.016322052554678404]
[2024-04-20 12:44:02,271: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.00941068103705683]
[2024-04-20 12:44:02,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.01065647698295944]
[2024-04-20 12:44:02,678: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.0012105503986012554]
[2024-04-20 12:44:02,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.0049177084832920815]
[2024-04-20 12:44:03,090: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.006200009989279294]
[2024-04-20 12:44:03,298: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.0064414401850735265]
[2024-04-20 12:44:03,504: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.012483769132541057]
[2024-04-20 12:44:03,711: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.003241134368855116]
[2024-04-20 12:44:03,918: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.0018631920695952986]
[2024-04-20 12:44:04,122: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.0013713033505314577]
[2024-04-20 12:44:04,333: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.005523067985569878]
[2024-04-20 12:44:04,537: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.005719435691624063]
[2024-04-20 12:44:04,744: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.015642224911841425]
[2024-04-20 12:44:04,954: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.008429274062942624]
[2024-04-20 12:44:05,160: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.004628504086407044]
[2024-04-20 12:44:05,365: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.010786595571844736]
[2024-04-20 12:44:05,576: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.008424231303731974]
[2024-04-20 12:44:05,788: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.002236739185632468]
[2024-04-20 12:44:06,000: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.0037887829440035187]
[2024-04-20 12:44:06,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.012185174457423033]
[2024-04-20 12:44:06,420: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.0010688556322392712]
[2024-04-20 12:44:06,629: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.0009519660467765822]
[2024-04-20 12:44:06,841: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.0018134485489106889]
[2024-04-20 12:44:07,052: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.011450151186982891]
[2024-04-20 12:44:07,263: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.019547201641677597]
[2024-04-20 12:44:07,471: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.003977979988496479]
[2024-04-20 12:44:07,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.01269180208939715]
[2024-04-20 12:44:07,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.006225114171365421]
[2024-04-20 12:44:08,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.008978294241211065]
[2024-04-20 12:44:08,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.009081295987026302]
[2024-04-20 12:44:08,527: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.0023480644148161957]
[2024-04-20 12:44:08,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.004331878715686408]
[2024-04-20 12:44:08,950: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.005785394477078824]
[2024-04-20 12:44:09,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 0.015028179143431854]
[2024-04-20 12:44:09,364: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.012909864486605454]
[2024-04-20 12:44:09,569: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.004600643813790203]
[2024-04-20 12:44:09,778: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.001542623019059601]
[2024-04-20 12:44:09,981: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.000916521092716681]
[2024-04-20 12:44:10,186: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.019482870642475194]
[2024-04-20 12:44:10,395: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.007069656213709756]
[2024-04-20 12:44:10,602: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.01013197195908333]
[2024-04-20 12:44:10,809: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.014377571058299617]
[2024-04-20 12:44:11,017: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.026381711331516393]
[2024-04-20 12:44:11,223: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.00148704690612466]
[2024-04-20 12:44:11,427: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.01116285172473456]
[2024-04-20 12:44:11,634: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.0074858897997783285]
[2024-04-20 12:44:11,841: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.005346397326617115]
[2024-04-20 12:44:12,048: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.010069063055164373]
[2024-04-20 12:44:12,256: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.006201783278346097]
[2024-04-20 12:44:12,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.016379556808236675]
[2024-04-20 12:44:12,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.008980638531852232]
[2024-04-20 12:44:12,886: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.01663430896600843]
[2024-04-20 12:44:13,092: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.006614049459154678]
[2024-04-20 12:44:13,298: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.0047028143423158905]
[2024-04-20 12:44:13,508: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.0633367412929689]
[2024-04-20 12:44:13,715: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.012801288080525835]
[2024-04-20 12:44:13,920: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.00982648147101513]
[2024-04-20 12:44:14,127: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.003117561552917312]
[2024-04-20 12:44:14,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.020825635057730326]
[2024-04-20 12:44:14,540: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.004956658362341115]
[2024-04-20 12:44:14,746: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.009358306460761218]
[2024-04-20 12:44:14,953: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.002028088825626281]
[2024-04-20 12:44:15,159: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.005762551257366911]
[2024-04-20 12:44:15,364: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.010719515299562065]
[2024-04-20 12:44:15,570: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.009570154020591106]
[2024-04-20 12:44:15,777: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.013249754718032069]
[2024-04-20 12:44:15,992: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.04038294747654796]
[2024-04-20 12:44:16,196: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.006988487240521614]
[2024-04-20 12:44:16,401: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.003489803404707228]
[2024-04-20 12:44:16,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.0030224620368811926]
[2024-04-20 12:44:16,828: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.040312219050329334]
[2024-04-20 12:44:17,045: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.004114970786303696]
[2024-04-20 12:44:17,257: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.0030088590313086853]
[2024-04-20 12:44:17,466: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.002191199388157052]
[2024-04-20 12:44:17,676: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.012147050821320815]
[2024-04-20 12:44:17,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.016970565617217936]
[2024-04-20 12:44:18,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.01457396449092631]
[2024-04-20 12:44:18,313: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.011110555882234653]
[2024-04-20 12:44:18,525: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.0024121208487748002]
[2024-04-20 12:44:18,734: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.018596670298659274]
[2024-04-20 12:44:18,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.018517596195795946]
[2024-04-20 12:44:19,159: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.0015346352107735585]
[2024-04-20 12:44:19,375: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.011629889632589582]
[2024-04-20 12:44:19,590: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.005263598311778304]
[2024-04-20 12:44:19,809: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.02035289209984344]
[2024-04-20 12:44:20,025: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.011719597983371714]
[2024-04-20 12:44:20,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.00873570954521718]
[2024-04-20 12:44:20,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.01383896601493142]
[2024-04-20 12:44:20,666: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.015076207283901315]
[2024-04-20 12:44:20,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.014104818174561202]
[2024-04-20 12:44:21,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.001520210286767137]
[2024-04-20 12:44:21,302: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.01978401453242306]
[2024-04-20 12:44:21,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.010917695981159603]
[2024-04-20 12:44:21,730: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.016637143343277556]
[2024-04-20 12:44:21,939: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.0036933674797939987]
[2024-04-20 12:44:22,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.016826796395406587]
[2024-04-20 12:44:22,361: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.00585310372152233]
[2024-04-20 12:44:22,576: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.018167902473224144]
[2024-04-20 12:44:22,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.013691339977984218]
[2024-04-20 12:44:22,994: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.01885317362797186]
[2024-04-20 12:44:23,206: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.010139819853827078]
[2024-04-20 12:44:23,425: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.007167607306291661]
[2024-04-20 12:44:23,639: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.014733967370830702]
[2024-04-20 12:44:23,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.01103562140453995]
[2024-04-20 12:44:24,055: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.01736000438211568]
[2024-04-20 12:44:24,257: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.01082018165513497]
[2024-04-20 12:44:24,463: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.006505918547687413]
[2024-04-20 12:44:24,672: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.002870320729064434]
[2024-04-20 12:44:24,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.002584470309329845]
[2024-04-20 12:44:25,086: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.014983594331319593]
[2024-04-20 12:44:25,292: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.027365807230194928]
[2024-04-20 12:44:25,498: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.00809135883126357]
[2024-04-20 12:44:25,705: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.005662083298511953]
[2024-04-20 12:44:25,912: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.005349635830500476]
[2024-04-20 12:44:26,117: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.007409022735878913]
[2024-04-20 12:44:26,325: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.003508107144313827]
[2024-04-20 12:44:26,533: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.0060132347459647675]
[2024-04-20 12:44:26,737: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.005768863801287669]
[2024-04-20 12:44:26,945: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.016855626987355463]
[2024-04-20 12:44:27,151: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.008640268913261893]
[2024-04-20 12:44:27,359: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.005141710636733908]
[2024-04-20 12:44:27,568: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.0034063802735957035]
[2024-04-20 12:44:27,774: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.005850741099431935]
[2024-04-20 12:44:27,979: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.001043165301891343]
[2024-04-20 12:44:28,187: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.002487377186621233]
[2024-04-20 12:44:28,397: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.010039733880713607]
[2024-04-20 12:44:28,603: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.009679713118136223]
[2024-04-20 12:44:28,812: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.00482423758025693]
[2024-04-20 12:44:29,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.0014725840523859683]
[2024-04-20 12:44:29,224: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.0045868376154966]
[2024-04-20 12:44:29,430: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.003431632547793753]
[2024-04-20 12:44:29,639: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.006429907040990751]
[2024-04-20 12:44:29,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.001729239391270545]
[2024-04-20 12:44:30,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.020780071811651965]
[2024-04-20 12:44:30,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.008502170249546826]
[2024-04-20 12:44:30,470: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.009945534185830123]
[2024-04-20 12:44:30,677: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.009152444107734022]
[2024-04-20 12:44:30,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.005939394077116614]
[2024-04-20 12:44:31,089: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.020131510510792962]
[2024-04-20 12:44:31,297: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.01698361093668611]
[2024-04-20 12:44:31,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 0.00878260778554413]
[2024-04-20 12:44:31,708: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.00983708165135398]
[2024-04-20 12:44:31,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.02703045974530845]
[2024-04-20 12:44:32,120: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.004941915758282333]
[2024-04-20 12:44:32,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.008027356092563049]
[2024-04-20 12:44:32,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.0036178137961153517]
[2024-04-20 12:44:32,742: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.008424861434663889]
[2024-04-20 12:44:32,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.003152662098759344]
[2024-04-20 12:44:33,157: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.005423016842987616]
[2024-04-20 12:44:33,365: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.0062609533732784165]
[2024-04-20 12:44:33,573: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.010883989963512615]
[2024-04-20 12:44:33,779: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.0012824055267632872]
[2024-04-20 12:44:33,993: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.0009475760010350309]
[2024-04-20 12:44:34,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.0026955176337281335]
[2024-04-20 12:44:34,413: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.0064419145495427]
[2024-04-20 12:44:34,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.0009305967036545261]
[2024-04-20 12:44:34,833: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.0016621136132769572]
[2024-04-20 12:44:35,043: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.00969569893678218]
[2024-04-20 12:44:35,253: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.00021458716993337696]
[2024-04-20 12:44:35,471: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.019248020275308954]
[2024-04-20 12:44:35,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.0054980958312976945]
[2024-04-20 12:44:35,890: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.007118380077458652]
[2024-04-20 12:44:36,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.005882022795855991]
[2024-04-20 12:44:36,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.009660078616107827]
[2024-04-20 12:44:36,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.004159695641522388]
[2024-04-20 12:44:36,741: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.005955362859761329]
[2024-04-20 12:44:36,954: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.00972893335141122]
[2024-04-20 12:44:37,168: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.0067414251430577875]
[2024-04-20 12:44:37,389: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.007928781239715929]
[2024-04-20 12:44:37,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.012888661765268343]
[2024-04-20 12:44:37,816: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.004737473991328744]
[2024-04-20 12:44:38,024: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.013643938624472484]
[2024-04-20 12:44:38,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.010785700439174366]
[2024-04-20 12:44:38,444: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.014793589434789825]
[2024-04-20 12:44:38,648: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.001116170029225335]
[2024-04-20 12:44:38,854: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.009555175158237944]
[2024-04-20 12:44:39,059: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.003167410697410071]
[2024-04-20 12:44:39,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.004886760559926279]
[2024-04-20 12:44:39,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.004984329595406813]
[2024-04-20 12:44:39,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.009223067792974146]
[2024-04-20 12:44:39,894: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.0003682077366286553]
[2024-04-20 12:44:40,100: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.004808251917418314]
[2024-04-20 12:44:40,304: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.006161507576587162]
[2024-04-20 12:44:40,520: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.003179827850003246]
[2024-04-20 12:44:40,730: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.005490377956134737]
[2024-04-20 12:44:40,940: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.010031576806976545]
[2024-04-20 12:44:41,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.006174701111258825]
[2024-04-20 12:44:41,366: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.003333038432299662]
[2024-04-20 12:44:41,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.0029512375652246325]
[2024-04-20 12:44:41,789: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.009123774629228042]
[2024-04-20 12:44:42,001: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.008267689417769938]
[2024-04-20 12:44:42,215: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.000424578101984635]
[2024-04-20 12:44:42,428: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.010128188488522951]
[2024-04-20 12:44:42,637: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.028594236043396136]
[2024-04-20 12:44:42,854: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.007890099984867893]
[2024-04-20 12:44:43,065: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.0062298164415300235]
[2024-04-20 12:44:43,274: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.0033253347892350576]
[2024-04-20 12:44:43,481: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.004905065089156201]
[2024-04-20 12:44:43,695: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.0004013471657489853]
[2024-04-20 12:44:43,907: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.015295414488077587]
[2024-04-20 12:44:44,122: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.013137970053962071]
[2024-04-20 12:44:44,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.005129857219100355]
[2024-04-20 12:44:44,540: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.02998931155800586]
[2024-04-20 12:44:44,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.00521876664996624]
[2024-04-20 12:44:44,955: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.005288178981932459]
[2024-04-20 12:44:45,165: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.0026301212565066102]
[2024-04-20 12:44:45,370: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.0014717540748479337]
[2024-04-20 12:44:45,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.016491994693676564]
[2024-04-20 12:44:45,780: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.0012588902600829685]
[2024-04-20 12:44:45,986: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.004116152334712943]
[2024-04-20 12:44:46,197: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.020042828830931555]
[2024-04-20 12:44:46,405: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.003227258742878181]
[2024-04-20 12:44:46,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.002812769116739727]
[2024-04-20 12:44:46,828: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.0007582129376492597]
[2024-04-20 12:44:47,042: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 0.004502485158001014]
[2024-04-20 12:44:47,245: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.015095488027678494]
[2024-04-20 12:44:47,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.025005083305603682]
[2024-04-20 12:44:47,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.0008024434030866219]
[2024-04-20 12:44:47,879: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.003314645491656573]
[2024-04-20 12:44:48,093: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.016142388420757447]
[2024-04-20 12:44:48,305: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.003294542570514209]
[2024-04-20 12:44:48,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.0018606507026438168]
[2024-04-20 12:44:48,730: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.004986861326729336]
[2024-04-20 12:44:48,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.002902782241357932]
[2024-04-20 12:44:49,160: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.010191879024056846]
[2024-04-20 12:44:49,371: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.004610118590851485]
[2024-04-20 12:44:49,579: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 0.002820738167764153]
[2024-04-20 12:44:49,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.005317415064713019]
[2024-04-20 12:44:50,004: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.00344857455110782]
[2024-04-20 12:44:50,216: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.0024095905289667797]
[2024-04-20 12:44:50,429: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.0014568244589812677]
[2024-04-20 12:44:50,658: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.0047039589565657045]
[2024-04-20 12:44:50,871: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.006847198727500411]
[2024-04-20 12:44:51,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.007305949310393133]
[2024-04-20 12:44:51,296: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.0070024309052246405]
[2024-04-20 12:44:51,501: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.003982681938505711]
[2024-04-20 12:44:51,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.0035109813259965018]
[2024-04-20 12:44:51,913: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.006148848279621635]
[2024-04-20 12:44:52,125: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.01143077487084708]
[2024-04-20 12:44:52,331: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.00026681020774865706]
[2024-04-20 12:44:52,539: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.0018402775312991876]
[2024-04-20 12:44:52,748: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.0021201287137702003]
[2024-04-20 12:44:52,955: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.008625461503104122]
[2024-04-20 12:44:53,163: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.0020961051035034784]
[2024-04-20 12:44:53,369: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.0032264473504508458]
[2024-04-20 12:44:53,579: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.002477103481487478]
[2024-04-20 12:44:53,786: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.01577060059026342]
[2024-04-20 12:44:53,994: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.046312083732760814]
[2024-04-20 12:44:54,204: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.006933902255279848]
[2024-04-20 12:44:54,409: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.005778998894726853]
[2024-04-20 12:44:54,618: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.001184918141524795]
[2024-04-20 12:44:54,827: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.0016636331313208855]
[2024-04-20 12:44:55,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.01690441436377443]
[2024-04-20 12:44:55,244: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.0038020065605087255]
[2024-04-20 12:44:55,452: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.00604806972811619]
[2024-04-20 12:44:55,660: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.006015980628530793]
[2024-04-20 12:44:55,866: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.004566024065172043]
[2024-04-20 12:44:56,075: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.002873056263391721]
[2024-04-20 12:44:56,280: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.008445951158586188]
[2024-04-20 12:44:56,486: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.0016011158559853694]
[2024-04-20 12:44:56,693: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.024946183127319]
[2024-04-20 12:44:56,899: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.00261476927495961]
[2024-04-20 12:44:57,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.00033229675581362576]
[2024-04-20 12:44:57,311: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.003105542939001311]
[2024-04-20 12:44:57,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.005070220646012216]
[2024-04-20 12:44:57,726: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.004510080501099236]
[2024-04-20 12:44:57,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.0017254886422276153]
[2024-04-20 12:44:58,138: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.005756005399691582]
[2024-04-20 12:44:58,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.010375201436833242]
[2024-04-20 12:44:58,548: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.005439280809130214]
[2024-04-20 12:44:58,754: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.001635800492222292]
[2024-04-20 12:44:58,959: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.008256331653737582]
[2024-04-20 12:44:59,168: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.012472282712515343]
[2024-04-20 12:44:59,378: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.0011002224434487982]
[2024-04-20 12:44:59,585: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.004219816305292218]
[2024-04-20 12:44:59,794: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.01348427278576518]
[2024-04-20 12:45:00,005: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.006115668201220519]
[2024-04-20 12:45:00,214: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.0030872446068448646]
[2024-04-20 12:45:00,419: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.002854276519247713]
[2024-04-20 12:45:00,623: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.0005691281433022577]
[2024-04-20 12:45:00,830: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.003385230584801941]
[2024-04-20 12:45:01,036: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.0005710172224956966]
[2024-04-20 12:45:01,244: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.0007636294369953018]
[2024-04-20 12:45:01,458: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.004891194313061314]
[2024-04-20 12:45:01,668: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.0030035660486366677]
[2024-04-20 12:45:01,885: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.004220778274437514]
[2024-04-20 12:45:02,098: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.00293460917084017]
[2024-04-20 12:45:02,304: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.0001539887152328593]
[2024-04-20 12:45:02,514: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.0040691124072176794]
[2024-04-20 12:45:02,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.01221864380339978]
[2024-04-20 12:45:02,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.012353430390306203]
[2024-04-20 12:45:03,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.0009172870554517292]
[2024-04-20 12:45:03,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.004236866650485356]
[2024-04-20 12:45:03,556: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.0032750026877520115]
[2024-04-20 12:45:03,770: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.0031640307615301397]
[2024-04-20 12:45:03,979: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.0010965837269515202]
[2024-04-20 12:45:04,186: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.015398644854546315]
[2024-04-20 12:45:04,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.002912926913080557]
[2024-04-20 12:45:04,618: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.007735149239782059]
[2024-04-20 12:45:04,833: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.01691956000401328]
[2024-04-20 12:45:05,046: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.014637440838029913]
[2024-04-20 12:45:05,253: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.0077165455671831034]
[2024-04-20 12:45:05,460: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.011859678490070427]
[2024-04-20 12:45:05,666: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.0023820425245144375]
[2024-04-20 12:45:05,876: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.003519064687840211]
[2024-04-20 12:45:06,081: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.0122912330725258]
[2024-04-20 12:45:06,283: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.000469590039006796]
[2024-04-20 12:45:06,486: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.0056897959178977145]
[2024-04-20 12:45:06,692: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.0019122959400031377]
[2024-04-20 12:45:06,900: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.0013591684490361533]
[2024-04-20 12:45:07,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.001219665474505196]
[2024-04-20 12:45:07,320: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.00457500561109045]
[2024-04-20 12:45:07,525: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.005377498444669923]
[2024-04-20 12:45:07,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.0037904134188305825]
[2024-04-20 12:45:07,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.00796439372186203]
[2024-04-20 12:45:08,147: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.011301039850968258]
[2024-04-20 12:45:08,352: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.0038801401526739367]
[2024-04-20 12:45:08,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.0008749582593608712]
[2024-04-20 12:45:08,766: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.0010910457811034568]
[2024-04-20 12:45:08,971: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.0031565516836145257]
[2024-04-20 12:45:09,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.0002515753581204207]
[2024-04-20 12:45:09,377: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.0068007710746103844]
[2024-04-20 12:45:09,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.0013170379059263488]
[2024-04-20 12:45:09,793: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.009510177674916865]
[2024-04-20 12:45:10,002: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.002758529937906236]
[2024-04-20 12:45:10,210: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.01037363532652279]
[2024-04-20 12:45:10,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.006282725465245726]
[2024-04-20 12:45:10,627: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.0021902843671051204]
[2024-04-20 12:45:10,831: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.0011236199704862692]
[2024-04-20 12:45:11,037: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.005011918632211299]
[2024-04-20 12:45:11,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.003950391594280391]
[2024-04-20 12:45:11,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.0011810489497492609]
[2024-04-20 12:45:11,660: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.005887285469669677]
[2024-04-20 12:45:11,865: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.002661023502061145]
[2024-04-20 12:45:12,069: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.001613017507812666]
[2024-04-20 12:45:12,270: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.0010810876168960704]
[2024-04-20 12:45:12,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.00397435200191403]
[2024-04-20 12:45:12,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.0022721100251220246]
[2024-04-20 12:45:12,889: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.0024556731510591394]
[2024-04-20 12:45:13,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.004384074403752583]
[2024-04-20 12:45:13,304: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.005020158980643467]
[2024-04-20 12:45:13,507: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.0005187060161636621]
[2024-04-20 12:45:13,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 8.765749225236369e-05]
[2024-04-20 12:45:13,913: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.0036293115968238946]
[2024-04-20 12:45:14,117: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.005223658693042922]
[2024-04-20 12:45:14,323: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.0009417551744836643]
[2024-04-20 12:45:14,532: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.00013270837817407007]
[2024-04-20 12:45:14,730: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.009931274006550478]
[2024-04-20 12:45:14,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.0025983991991534584]
[2024-04-20 12:45:15,122: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 0.0005538932176773465]
[2024-04-20 12:45:38,633: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9956776280700887, 'precision': 0.8144692468283282, 'recall': 0.906372864393452, 'f1': 0.8579669446653021}]
[2024-04-20 12:45:41,574: INFO: roberta_kFold_initial_lstm: Fold 2/3 , Epoch: 2/3]
[2024-04-20 12:45:42,319: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.005687931766360876]
[2024-04-20 12:45:42,981: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.006829097123713325]
[2024-04-20 12:45:43,632: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.00939240904596243]
[2024-04-20 12:45:44,285: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.0012299618514739674]
[2024-04-20 12:45:44,933: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.004305896071288267]
[2024-04-20 12:45:45,577: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.013109777718791342]
[2024-04-20 12:45:46,223: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.0140951525606265]
[2024-04-20 12:45:46,870: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.008756538880825204]
[2024-04-20 12:45:47,517: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.003402065179942651]
[2024-04-20 12:45:48,164: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.009839951269920872]
[2024-04-20 12:45:48,814: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.004612332177938482]
[2024-04-20 12:45:49,463: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.010561829337691913]
[2024-04-20 12:45:50,112: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.018538191852481026]
[2024-04-20 12:45:50,760: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.005438175603645241]
[2024-04-20 12:45:51,418: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.0017339139040633811]
[2024-04-20 12:45:52,074: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.005950627398439067]
[2024-04-20 12:45:52,730: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.018555825816814992]
[2024-04-20 12:45:53,390: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.017885854347377213]
[2024-04-20 12:45:54,050: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.0073808875704274085]
[2024-04-20 12:45:54,718: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.008408954285781043]
[2024-04-20 12:45:55,394: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.005228741732665378]
[2024-04-20 12:45:56,061: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.014638133997834696]
[2024-04-20 12:45:56,741: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.014118215204330294]
[2024-04-20 12:45:57,413: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.028909916370422267]
[2024-04-20 12:45:58,083: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.03138180109574052]
[2024-04-20 12:45:58,752: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.06985812372576058]
[2024-04-20 12:45:59,422: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.0022641419876069995]
[2024-04-20 12:46:00,088: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.014638867316335187]
[2024-04-20 12:46:00,756: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.010516762351651797]
[2024-04-20 12:46:01,419: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.0008818434464579485]
[2024-04-20 12:46:02,091: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.0033661396852525723]
[2024-04-20 12:46:02,760: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.009226616197533373]
[2024-04-20 12:46:03,430: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.006257674064900056]
[2024-04-20 12:46:04,098: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.015010191143797693]
[2024-04-20 12:46:04,772: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.013753375161534126]
[2024-04-20 12:46:05,445: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.03989549860266487]
[2024-04-20 12:46:06,117: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.015248614282046793]
[2024-04-20 12:46:06,792: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.0030220415594480513]
[2024-04-20 12:46:07,463: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.003760990316983876]
[2024-04-20 12:46:08,141: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.005158424103140473]
[2024-04-20 12:46:08,820: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.002987593749979977]
[2024-04-20 12:46:09,509: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.005363664909426805]
[2024-04-20 12:46:10,197: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.03879974709822041]
[2024-04-20 12:46:10,893: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.001087474584480497]
[2024-04-20 12:46:11,578: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.003885505945470458]
[2024-04-20 12:46:12,269: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.0016122901561679349]
[2024-04-20 12:46:12,951: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.02475724083927426]
[2024-04-20 12:46:13,632: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.014613713379167585]
[2024-04-20 12:46:14,309: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.0068927815411858485]
[2024-04-20 12:46:14,995: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.0070197458928413425]
[2024-04-20 12:46:15,669: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.005801813465966392]
[2024-04-20 12:46:16,346: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.006141996275569241]
[2024-04-20 12:46:17,030: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.003329646745358797]
[2024-04-20 12:46:17,705: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.007574561780176553]
[2024-04-20 12:46:18,386: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.012003373834797122]
[2024-04-20 12:46:19,063: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.009173355673764087]
[2024-04-20 12:46:19,741: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.007844876019213852]
[2024-04-20 12:46:20,416: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.0045465825732841116]
[2024-04-20 12:46:21,091: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.004371390807181803]
[2024-04-20 12:46:21,765: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.007244533161893605]
[2024-04-20 12:46:22,435: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.00826755289048605]
[2024-04-20 12:46:23,113: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.0018430441166870436]
[2024-04-20 12:46:23,792: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.01647826401626991]
[2024-04-20 12:46:24,472: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.013847856004528506]
[2024-04-20 12:46:25,159: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.009506776797633775]
[2024-04-20 12:46:25,834: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.0025677093301397177]
[2024-04-20 12:46:26,506: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.009325079732914108]
[2024-04-20 12:46:27,170: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.007913981507317286]
[2024-04-20 12:46:27,831: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.0015296689057573115]
[2024-04-20 12:46:28,497: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.00463284606576312]
[2024-04-20 12:46:29,158: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.01616482140031429]
[2024-04-20 12:46:29,819: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.015212644194887147]
[2024-04-20 12:46:30,479: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.004497090382877319]
[2024-04-20 12:46:31,138: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.012051039861606742]
[2024-04-20 12:46:31,803: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.0007036831355795527]
[2024-04-20 12:46:32,463: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.01664400464673745]
[2024-04-20 12:46:33,120: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.00124201293509976]
[2024-04-20 12:46:33,783: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.0031536941896524793]
[2024-04-20 12:46:34,437: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.014483967840255749]
[2024-04-20 12:46:35,091: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.0025702214905553343]
[2024-04-20 12:46:35,750: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.0012009476858678573]
[2024-04-20 12:46:36,423: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.003915475282200073]
[2024-04-20 12:46:37,097: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.03789207791721226]
[2024-04-20 12:46:37,773: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.0167299116557104]
[2024-04-20 12:46:38,431: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.0014548833129256616]
[2024-04-20 12:46:39,107: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.0018016333971617006]
[2024-04-20 12:46:39,762: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.01070226255314081]
[2024-04-20 12:46:40,411: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.006925082660626441]
[2024-04-20 12:46:41,060: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.009671258119163783]
[2024-04-20 12:46:41,713: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.011929129133375179]
[2024-04-20 12:46:42,361: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.0009673828197389762]
[2024-04-20 12:46:43,015: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.005094705655452106]
[2024-04-20 12:46:43,667: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.0018393536264850582]
[2024-04-20 12:46:44,315: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.030293266887923196]
[2024-04-20 12:46:44,965: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.0007753008434133522]
[2024-04-20 12:46:45,617: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.022799712424404622]
[2024-04-20 12:46:46,270: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.017738423096787696]
[2024-04-20 12:46:46,923: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.0009141304574673142]
[2024-04-20 12:46:47,573: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.0034084292205830246]
[2024-04-20 12:46:48,227: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.008334085585326242]
[2024-04-20 12:46:48,875: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.009015144889529435]
[2024-04-20 12:46:49,545: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.010361760958887837]
[2024-04-20 12:46:50,206: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.002876841017356399]
[2024-04-20 12:46:50,861: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.004112067181651047]
[2024-04-20 12:46:51,517: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.014481587539407563]
[2024-04-20 12:46:52,174: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.01191192069497158]
[2024-04-20 12:46:52,822: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.016271037566934713]
[2024-04-20 12:46:53,470: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.0020829672020439313]
[2024-04-20 12:46:54,118: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.01908904557856655]
[2024-04-20 12:46:54,762: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.005100101309681452]
[2024-04-20 12:46:55,408: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.007723595767103879]
[2024-04-20 12:46:56,058: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.0033081233334047544]
[2024-04-20 12:46:56,704: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.010474469501625058]
[2024-04-20 12:46:57,357: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.011066499047352261]
[2024-04-20 12:46:58,004: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.01841173972290838]
[2024-04-20 12:46:58,650: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.008191101591100508]
[2024-04-20 12:46:59,298: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.0017216324688066255]
[2024-04-20 12:46:59,944: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.011876138457667957]
[2024-04-20 12:47:00,590: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.0075751611224121026]
[2024-04-20 12:47:01,237: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.0057032829600687585]
[2024-04-20 12:47:01,882: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.0014070281314374922]
[2024-04-20 12:47:02,531: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.00977334218873111]
[2024-04-20 12:47:03,199: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.0035458800607585514]
[2024-04-20 12:47:03,870: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.0024836304779117255]
[2024-04-20 12:47:04,525: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.01298958726461085]
[2024-04-20 12:47:05,194: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.009726057986038716]
[2024-04-20 12:47:05,843: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.014092977074263312]
[2024-04-20 12:47:06,491: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.011633436859993341]
[2024-04-20 12:47:07,140: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.0028643265447842957]
[2024-04-20 12:47:07,785: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.017431042816558998]
[2024-04-20 12:47:08,435: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.023378142913271324]
[2024-04-20 12:47:09,081: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.010147678029118371]
[2024-04-20 12:47:09,731: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.001541609167478697]
[2024-04-20 12:47:10,376: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.005227037937774385]
[2024-04-20 12:47:11,026: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.004643004245378618]
[2024-04-20 12:47:11,675: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.008568059585216491]
[2024-04-20 12:47:12,320: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.009396325429758332]
[2024-04-20 12:47:12,969: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.023116003523188326]
[2024-04-20 12:47:13,620: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.0465528713384798]
[2024-04-20 12:47:14,271: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.015041410041015533]
[2024-04-20 12:47:14,924: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.006876254489938453]
[2024-04-20 12:47:15,576: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.002730546370696187]
[2024-04-20 12:47:16,237: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.017445885291870043]
[2024-04-20 12:47:16,904: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.00949966043772931]
[2024-04-20 12:47:17,559: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.0007456425559826425]
[2024-04-20 12:47:18,221: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.009748987508291031]
[2024-04-20 12:47:18,886: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.00461110470960284]
[2024-04-20 12:47:19,540: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.008855828622913816]
[2024-04-20 12:47:20,195: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.01423648947878418]
[2024-04-20 12:47:20,845: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.009836184900090314]
[2024-04-20 12:47:21,501: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.006629241077031289]
[2024-04-20 12:47:22,157: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.0025097489048729912]
[2024-04-20 12:47:22,811: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.013850483063634077]
[2024-04-20 12:47:23,465: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.008607912610241826]
[2024-04-20 12:47:24,123: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.01290450072361268]
[2024-04-20 12:47:24,778: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.003134424405767137]
[2024-04-20 12:47:25,432: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.007125418373278402]
[2024-04-20 12:47:26,092: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.00411428225929784]
[2024-04-20 12:47:26,747: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.0074048669683559835]
[2024-04-20 12:47:27,405: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.018490688325362225]
[2024-04-20 12:47:28,067: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.008999888171254211]
[2024-04-20 12:47:28,734: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.006827387809801808]
[2024-04-20 12:47:29,410: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.012678424567913887]
[2024-04-20 12:47:30,095: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.003058951041559208]
[2024-04-20 12:47:30,773: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.004410293675598392]
[2024-04-20 12:47:31,445: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.008480263907408862]
[2024-04-20 12:47:32,124: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.0036035832713480678]
[2024-04-20 12:47:32,796: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.0036358308857305888]
[2024-04-20 12:47:33,461: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.007978119616403446]
[2024-04-20 12:47:34,124: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.005079947157215887]
[2024-04-20 12:47:34,779: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.010212006941748779]
[2024-04-20 12:47:35,436: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.0011382248819247244]
[2024-04-20 12:47:36,096: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.013508190380854298]
[2024-04-20 12:47:36,756: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.005910571413858548]
[2024-04-20 12:47:37,412: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.01586686961990954]
[2024-04-20 12:47:38,075: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.013213916149382651]
[2024-04-20 12:47:38,733: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.0033984461861707523]
[2024-04-20 12:47:39,391: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.009048953928090298]
[2024-04-20 12:47:40,053: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.01203068563026742]
[2024-04-20 12:47:40,713: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.00291348545243031]
[2024-04-20 12:47:41,370: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.005541545489066315]
[2024-04-20 12:47:42,029: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.0034665913379369295]
[2024-04-20 12:47:42,691: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.0035974035154460087]
[2024-04-20 12:47:43,350: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.0088578538250375]
[2024-04-20 12:47:44,026: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.008411619024661674]
[2024-04-20 12:47:44,700: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.007386046844370418]
[2024-04-20 12:47:45,377: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.0015868311014627862]
[2024-04-20 12:47:46,045: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.0009180114046951093]
[2024-04-20 12:47:46,707: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.005063709825321095]
[2024-04-20 12:47:47,367: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.007582686948749802]
[2024-04-20 12:47:48,026: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.01705658205714783]
[2024-04-20 12:47:48,682: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.006720330750139481]
[2024-04-20 12:47:49,340: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.02882274680269302]
[2024-04-20 12:47:50,000: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.0023186229274334614]
[2024-04-20 12:47:50,655: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.020167387683529926]
[2024-04-20 12:47:51,315: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.004638039587936395]
[2024-04-20 12:47:51,978: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.02343391980744137]
[2024-04-20 12:47:52,647: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.0013032567009811063]
[2024-04-20 12:47:53,311: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.0032051246765738297]
[2024-04-20 12:47:53,983: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.008447529093652996]
[2024-04-20 12:47:54,650: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.013066064916881125]
[2024-04-20 12:47:55,308: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.008858439388682362]
[2024-04-20 12:47:55,971: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.007322903401500558]
[2024-04-20 12:47:56,630: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.001369948411451038]
[2024-04-20 12:47:57,302: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.004213030305138569]
[2024-04-20 12:47:57,981: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.005778848825016661]
[2024-04-20 12:47:58,641: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.011801807400543951]
[2024-04-20 12:47:59,317: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.0024900447202176926]
[2024-04-20 12:47:59,983: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.0015631616053660372]
[2024-04-20 12:48:00,634: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.010545324394273485]
[2024-04-20 12:48:01,292: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.012528096779046293]
[2024-04-20 12:48:01,949: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.007419899605319109]
[2024-04-20 12:48:02,609: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.013883079595146421]
[2024-04-20 12:48:03,266: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.004155795371283208]
[2024-04-20 12:48:03,924: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.006320119878178503]
[2024-04-20 12:48:04,575: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.0028541313441333327]
[2024-04-20 12:48:05,232: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.046535997257918814]
[2024-04-20 12:48:05,883: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.0035841912948836605]
[2024-04-20 12:48:06,537: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.0027781912263863495]
[2024-04-20 12:48:07,193: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.016855787716634128]
[2024-04-20 12:48:07,847: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.005810516935054029]
[2024-04-20 12:48:08,501: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.017951470164177107]
[2024-04-20 12:48:09,159: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.02458475945522087]
[2024-04-20 12:48:09,816: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.019707476447090578]
[2024-04-20 12:48:10,475: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.017403545560904562]
[2024-04-20 12:48:11,144: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.013858710018887251]
[2024-04-20 12:48:11,807: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.003649355027492837]
[2024-04-20 12:48:12,468: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.013933087927739373]
[2024-04-20 12:48:13,129: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.0033849565238564475]
[2024-04-20 12:48:13,781: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.011913378142506394]
[2024-04-20 12:48:14,435: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.003694734141191261]
[2024-04-20 12:48:15,090: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.005332672775748805]
[2024-04-20 12:48:15,750: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.00596410551178014]
[2024-04-20 12:48:16,402: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.016206029345975002]
[2024-04-20 12:48:17,055: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.008823852483814542]
[2024-04-20 12:48:17,712: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.005512721473376674]
[2024-04-20 12:48:18,369: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.005523268783743558]
[2024-04-20 12:48:19,024: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.013687174400610487]
[2024-04-20 12:48:19,679: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.010181544219364482]
[2024-04-20 12:48:20,340: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.004917827688939935]
[2024-04-20 12:48:20,993: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.015648497820197237]
[2024-04-20 12:48:21,648: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.011141619021166949]
[2024-04-20 12:48:22,307: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.018490999074802218]
[2024-04-20 12:48:22,959: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.013270907314993977]
[2024-04-20 12:48:23,620: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.005285419281690994]
[2024-04-20 12:48:24,287: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.013076212408044817]
[2024-04-20 12:48:24,956: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.003493134700842512]
[2024-04-20 12:48:25,621: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.0006371329688824504]
[2024-04-20 12:48:26,290: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.005171200045524785]
[2024-04-20 12:48:26,949: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.021384161617550048]
[2024-04-20 12:48:27,599: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.005245920454019733]
[2024-04-20 12:48:28,255: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.001739797100496585]
[2024-04-20 12:48:28,916: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.0012631930477942132]
[2024-04-20 12:48:29,573: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.0034373284437312817]
[2024-04-20 12:48:30,226: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.007303835396808582]
[2024-04-20 12:48:30,878: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.00883132231748952]
[2024-04-20 12:48:31,534: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.002917965386774662]
[2024-04-20 12:48:32,185: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.002951794488569205]
[2024-04-20 12:48:32,834: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.02107353060501627]
[2024-04-20 12:48:33,486: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.009362886352764443]
[2024-04-20 12:48:34,138: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.010174913706871045]
[2024-04-20 12:48:34,794: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.015219850437113273]
[2024-04-20 12:48:35,449: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.0077154579822395685]
[2024-04-20 12:48:36,100: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.003131850886857878]
[2024-04-20 12:48:36,759: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.006330430139883126]
[2024-04-20 12:48:37,424: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.0013784793293088698]
[2024-04-20 12:48:38,084: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.0057393306342199656]
[2024-04-20 12:48:38,749: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.0062238522692129325]
[2024-04-20 12:48:39,414: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.010833788808547474]
[2024-04-20 12:48:40,071: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.004093556229721058]
[2024-04-20 12:48:40,724: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.01499867404416633]
[2024-04-20 12:48:41,376: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.003738512520290239]
[2024-04-20 12:48:42,030: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.019599598739561335]
[2024-04-20 12:48:42,677: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.010355268939077714]
[2024-04-20 12:48:43,329: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.004290414521863126]
[2024-04-20 12:48:43,983: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.021455905976937424]
[2024-04-20 12:48:44,635: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.001084411045313302]
[2024-04-20 12:48:45,288: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.010588934928366052]
[2024-04-20 12:48:45,940: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.011250835166847462]
[2024-04-20 12:48:46,594: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.02099785722296321]
[2024-04-20 12:48:47,247: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.006680427608815456]
[2024-04-20 12:48:47,898: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.018187353892018053]
[2024-04-20 12:48:48,551: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.008743326350471285]
[2024-04-20 12:48:49,206: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.003090499698275223]
[2024-04-20 12:48:49,860: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.010939368348119368]
[2024-04-20 12:48:50,520: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.022644654717054454]
[2024-04-20 12:48:51,183: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.007565047466156199]
[2024-04-20 12:48:51,842: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.0077375747750439315]
[2024-04-20 12:48:52,505: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.01629883145782059]
[2024-04-20 12:48:53,172: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.004811833861583331]
[2024-04-20 12:48:53,828: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.0022842588307214304]
[2024-04-20 12:48:54,479: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.003494779147265695]
[2024-04-20 12:48:55,128: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.0026970782525431577]
[2024-04-20 12:48:55,778: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.026649312187153048]
[2024-04-20 12:48:56,428: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.013275195083843607]
[2024-04-20 12:48:57,082: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.00672443275515612]
[2024-04-20 12:48:57,735: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.007728236001527775]
[2024-04-20 12:48:58,387: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.004047042533351528]
[2024-04-20 12:48:59,040: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.01671693854262645]
[2024-04-20 12:48:59,691: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.004290326894586975]
[2024-04-20 12:49:00,339: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.005589687027531536]
[2024-04-20 12:49:00,990: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.02692168111460304]
[2024-04-20 12:49:01,647: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.0010978103406978435]
[2024-04-20 12:49:02,300: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.0010079583346831991]
[2024-04-20 12:49:02,954: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.003781169459182488]
[2024-04-20 12:49:03,620: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.008679846412863484]
[2024-04-20 12:49:04,284: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.005573189147087841]
[2024-04-20 12:49:04,939: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.013120276796427402]
[2024-04-20 12:49:05,597: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.016188544022839098]
[2024-04-20 12:49:06,259: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.011065242271592297]
[2024-04-20 12:49:06,915: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.004921396295048328]
[2024-04-20 12:49:07,567: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.027863971666828847]
[2024-04-20 12:49:08,221: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.006605224461634931]
[2024-04-20 12:49:08,875: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.02102369407257534]
[2024-04-20 12:49:09,536: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.009237169529572632]
[2024-04-20 12:49:10,192: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.0029330065803087656]
[2024-04-20 12:49:10,848: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.003523527982617119]
[2024-04-20 12:49:11,502: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.005774821264171425]
[2024-04-20 12:49:12,156: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.01760510270665313]
[2024-04-20 12:49:12,813: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.02122714984144627]
[2024-04-20 12:49:13,465: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.029222430319665697]
[2024-04-20 12:49:14,121: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.00595278247163411]
[2024-04-20 12:49:14,777: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.006079587662187097]
[2024-04-20 12:49:15,428: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.019994737490346186]
[2024-04-20 12:49:16,082: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.00325520074266133]
[2024-04-20 12:49:16,747: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.006408752035894036]
[2024-04-20 12:49:17,408: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.020350190764444193]
[2024-04-20 12:49:18,067: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.004358046675243501]
[2024-04-20 12:49:18,729: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.013317726238365368]
[2024-04-20 12:49:19,411: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.009682371183939225]
[2024-04-20 12:49:20,080: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.008103426644312947]
[2024-04-20 12:49:20,733: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.004606271839497312]
[2024-04-20 12:49:21,387: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.0033514032639409995]
[2024-04-20 12:49:22,043: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.02098201712364541]
[2024-04-20 12:49:22,696: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.00424773117858092]
[2024-04-20 12:49:23,353: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.003184928895008629]
[2024-04-20 12:49:24,012: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.0033632191323748686]
[2024-04-20 12:49:24,667: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.003121739257026478]
[2024-04-20 12:49:25,322: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.022953774399050966]
[2024-04-20 12:49:25,973: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.012937772429234582]
[2024-04-20 12:49:26,628: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.001102736755269755]
[2024-04-20 12:49:27,280: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.010103207116743814]
[2024-04-20 12:49:27,934: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.003794404506639395]
[2024-04-20 12:49:28,590: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.00782580863250988]
[2024-04-20 12:49:29,242: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.0008546841779159817]
[2024-04-20 12:49:29,897: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.01560230851127766]
[2024-04-20 12:49:30,555: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.006333833051070922]
[2024-04-20 12:49:31,219: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.005426930590305706]
[2024-04-20 12:49:31,883: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.003666640773590932]
[2024-04-20 12:49:32,549: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.0020626904530734454]
[2024-04-20 12:49:33,215: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.005850332633072604]
[2024-04-20 12:49:33,873: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.009992341702748457]
[2024-04-20 12:49:34,528: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.006569047239601662]
[2024-04-20 12:49:35,184: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.020764151616665314]
[2024-04-20 12:49:35,838: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.0018631595667674033]
[2024-04-20 12:49:36,495: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.002726974006963769]
[2024-04-20 12:49:37,149: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.013865183320023263]
[2024-04-20 12:49:37,806: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.004441055118912993]
[2024-04-20 12:49:38,464: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.004384295729112497]
[2024-04-20 12:49:39,121: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.0039205238357854]
[2024-04-20 12:49:39,774: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.006342709303402436]
[2024-04-20 12:49:40,430: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.0015055102240301218]
[2024-04-20 12:49:41,084: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.00824648705910626]
[2024-04-20 12:49:41,736: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.010369847432629422]
[2024-04-20 12:49:42,392: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.0038739658828052547]
[2024-04-20 12:49:43,047: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.003331859029369183]
[2024-04-20 12:49:43,707: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.002922563209570967]
[2024-04-20 12:49:44,366: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.006498260315595814]
[2024-04-20 12:49:45,032: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.01171034056639354]
[2024-04-20 12:49:45,689: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.0012512551105084608]
[2024-04-20 12:49:46,347: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.0057246463382368325]
[2024-04-20 12:49:47,002: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.010047016658366395]
[2024-04-20 12:49:47,661: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.02314209432193986]
[2024-04-20 12:49:48,319: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.0032690399382378907]
[2024-04-20 12:49:48,975: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.02399618863328653]
[2024-04-20 12:49:49,635: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.010066373451254893]
[2024-04-20 12:49:50,290: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.012605735022527317]
[2024-04-20 12:49:50,945: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.005775986972449456]
[2024-04-20 12:49:51,599: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.0025920819703676534]
[2024-04-20 12:49:52,255: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.01621996459443737]
[2024-04-20 12:49:52,909: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.002241236616306719]
[2024-04-20 12:49:53,562: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.006651437301147382]
[2024-04-20 12:49:54,218: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.016209056111438153]
[2024-04-20 12:49:54,870: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.008814160709035389]
[2024-04-20 12:49:55,526: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.004190503970547479]
[2024-04-20 12:49:56,183: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.006269863490194524]
[2024-04-20 12:49:56,842: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.0030490226869595728]
[2024-04-20 12:49:57,504: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.010054525631992665]
[2024-04-20 12:49:58,165: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.01629445530741184]
[2024-04-20 12:49:58,832: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.0005820540699906362]
[2024-04-20 12:49:59,489: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.009115794997615896]
[2024-04-20 12:50:00,150: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.017458931349168566]
[2024-04-20 12:50:00,803: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.0012473042016639844]
[2024-04-20 12:50:01,458: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.0062161239093307084]
[2024-04-20 12:50:02,113: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.006305027675703888]
[2024-04-20 12:50:02,765: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.011879214020190515]
[2024-04-20 12:50:03,419: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.010080593377857203]
[2024-04-20 12:50:04,073: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.018842620090705652]
[2024-04-20 12:50:04,730: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.0014938752757155077]
[2024-04-20 12:50:05,389: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.011011795080992468]
[2024-04-20 12:50:06,043: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.010698809644345591]
[2024-04-20 12:50:06,698: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.013024656761166275]
[2024-04-20 12:50:07,354: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.006414143725947564]
[2024-04-20 12:50:08,011: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.004889342109178193]
[2024-04-20 12:50:08,665: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.002030162908231286]
[2024-04-20 12:50:09,321: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.004875635758959207]
[2024-04-20 12:50:09,979: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.011288049723939805]
[2024-04-20 12:50:10,644: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.008127031928548687]
[2024-04-20 12:50:11,316: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.003264444421198347]
[2024-04-20 12:50:11,990: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.00444028358768826]
[2024-04-20 12:50:12,672: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.015424110438824253]
[2024-04-20 12:50:13,333: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.008703677598792663]
[2024-04-20 12:50:13,987: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.010175931892154365]
[2024-04-20 12:50:14,646: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.016282399115393316]
[2024-04-20 12:50:15,302: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.0025699436192210857]
[2024-04-20 12:50:15,961: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.013132873549384689]
[2024-04-20 12:50:16,612: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.0010541351599509029]
[2024-04-20 12:50:17,269: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.001712685036437542]
[2024-04-20 12:50:17,923: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.009398427011854726]
[2024-04-20 12:50:18,579: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.002746945883772137]
[2024-04-20 12:50:19,231: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.006426505307665245]
[2024-04-20 12:50:19,889: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.02260752389079276]
[2024-04-20 12:50:20,544: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.018490978860702854]
[2024-04-20 12:50:21,203: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.005175296047517307]
[2024-04-20 12:50:21,860: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.003934744943606534]
[2024-04-20 12:50:22,516: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.01566259796996238]
[2024-04-20 12:50:23,169: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.006068451642241744]
[2024-04-20 12:50:23,833: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.011615988855566658]
[2024-04-20 12:50:24,496: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.008003103298614821]
[2024-04-20 12:50:25,159: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.007653776636767634]
[2024-04-20 12:50:25,821: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.013593078510479495]
[2024-04-20 12:50:26,489: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.0054004185039203375]
[2024-04-20 12:50:27,143: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.0010930960608240231]
[2024-04-20 12:50:27,796: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.016762840911143526]
[2024-04-20 12:50:28,447: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.004637578992347831]
[2024-04-20 12:50:29,096: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.00570260411712309]
[2024-04-20 12:50:29,754: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.000628274604296509]
[2024-04-20 12:50:30,408: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.007589329482106741]
[2024-04-20 12:50:31,068: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.015107019189567264]
[2024-04-20 12:50:31,722: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.0038371147361580113]
[2024-04-20 12:50:32,379: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.008395977180802705]
[2024-04-20 12:50:33,042: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.005360401426288712]
[2024-04-20 12:50:33,701: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.02725978959668928]
[2024-04-20 12:50:34,352: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.002949030831038936]
[2024-04-20 12:50:35,006: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.0017231743182620344]
[2024-04-20 12:50:35,662: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.0031915933412284374]
[2024-04-20 12:50:36,315: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.0072063318990123575]
[2024-04-20 12:50:36,974: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.008473119923819102]
[2024-04-20 12:50:37,644: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.013009522887824452]
[2024-04-20 12:50:38,315: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.003728958021239443]
[2024-04-20 12:50:38,982: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.0022100364915485665]
[2024-04-20 12:50:39,644: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.00813764971704125]
[2024-04-20 12:50:40,317: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.007829516972330605]
[2024-04-20 12:50:41,003: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.009776669086262593]
[2024-04-20 12:50:41,676: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.0017029647985667491]
[2024-04-20 12:50:42,333: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.011586546378610089]
[2024-04-20 12:50:43,006: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.013481683880872572]
[2024-04-20 12:50:43,670: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.0034016735991878586]
[2024-04-20 12:50:44,325: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.008290952907938173]
[2024-04-20 12:50:44,978: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.02186646481724257]
[2024-04-20 12:50:45,636: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.010020112371618276]
[2024-04-20 12:50:46,287: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.0016170340167768324]
[2024-04-20 12:50:46,944: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.0010593216519481881]
[2024-04-20 12:50:47,598: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.010751320829171147]
[2024-04-20 12:50:48,251: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.001092028405881846]
[2024-04-20 12:50:48,907: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.01167997885302718]
[2024-04-20 12:50:49,559: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.0042932130815806924]
[2024-04-20 12:50:50,212: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.008148093405874258]
[2024-04-20 12:50:50,867: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.018556573962214926]
[2024-04-20 12:50:51,523: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.010330336285166228]
[2024-04-20 12:50:52,189: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.010599440622923145]
[2024-04-20 12:50:52,858: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.014513470938621377]
[2024-04-20 12:50:53,521: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.005707934889339888]
[2024-04-20 12:50:54,181: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.010376053969278983]
[2024-04-20 12:50:54,843: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.023795729242588316]
[2024-04-20 12:50:55,498: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.007555262089559119]
[2024-04-20 12:50:56,152: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.007841415093204596]
[2024-04-20 12:50:56,804: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.005133111601084646]
[2024-04-20 12:50:57,459: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.009995895281480066]
[2024-04-20 12:50:58,117: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.0008210906704642873]
[2024-04-20 12:50:58,771: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.010415901725154738]
[2024-04-20 12:50:59,432: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.014990874810408639]
[2024-04-20 12:51:00,091: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.002370648239366164]
[2024-04-20 12:51:00,746: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.006159448501087051]
[2024-04-20 12:51:01,399: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.009538048696790119]
[2024-04-20 12:51:02,049: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.008040953457701268]
[2024-04-20 12:51:02,704: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.005060913878397527]
[2024-04-20 12:51:03,360: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.010436135325443999]
[2024-04-20 12:51:04,022: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.003074359149172017]
[2024-04-20 12:51:04,689: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.013353580304533126]
[2024-04-20 12:51:05,364: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.010267953834372045]
[2024-04-20 12:51:06,040: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.004154414675210025]
[2024-04-20 12:51:06,714: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.009779631111329396]
[2024-04-20 12:51:07,381: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.0042377665513401944]
[2024-04-20 12:51:08,053: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.008204398381532738]
[2024-04-20 12:51:08,722: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.00400516952548198]
[2024-04-20 12:51:09,384: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.004590307494925656]
[2024-04-20 12:51:10,060: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.012342155552642484]
[2024-04-20 12:51:10,711: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.0008245291360359484]
[2024-04-20 12:51:11,369: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.001394349265761234]
[2024-04-20 12:51:12,025: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.017853519468008165]
[2024-04-20 12:51:12,680: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.000401009678967849]
[2024-04-20 12:51:13,340: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.004551909539798257]
[2024-04-20 12:51:13,998: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.008034383996886354]
[2024-04-20 12:51:14,654: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.024189549699552195]
[2024-04-20 12:51:15,310: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.001397629255130466]
[2024-04-20 12:51:15,963: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.015318212814255277]
[2024-04-20 12:51:16,619: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.010287574486825593]
[2024-04-20 12:51:17,275: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.002490583056561385]
[2024-04-20 12:51:17,930: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.003236429843753111]
[2024-04-20 12:51:18,583: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.00072301211617492]
[2024-04-20 12:51:19,236: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.022557430261362192]
[2024-04-20 12:51:19,892: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.008045329025384837]
[2024-04-20 12:51:20,549: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.0018951963253179744]
[2024-04-20 12:51:21,223: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.006222030550343526]
[2024-04-20 12:51:21,890: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.005299189673324672]
[2024-04-20 12:51:22,555: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.007753345177197288]
[2024-04-20 12:51:23,226: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.004127489591944024]
[2024-04-20 12:51:23,878: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.006812626965453266]
[2024-04-20 12:51:24,534: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.010918269941169543]
[2024-04-20 12:51:25,191: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.0017064425560974839]
[2024-04-20 12:51:25,847: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.01092506661327292]
[2024-04-20 12:51:26,503: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.006430841215737367]
[2024-04-20 12:51:27,155: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.001055568759145965]
[2024-04-20 12:51:27,812: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.004106561780719952]
[2024-04-20 12:51:28,465: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.03012181584915616]
[2024-04-20 12:51:29,118: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.00799954445328209]
[2024-04-20 12:51:29,772: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.0010585916016865495]
[2024-04-20 12:51:30,426: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.008975334824118506]
[2024-04-20 12:51:31,080: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.003958616285068299]
[2024-04-20 12:51:31,733: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.008647820213810975]
[2024-04-20 12:51:32,388: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.027626446643398857]
[2024-04-20 12:51:33,043: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.012418925723304913]
[2024-04-20 12:51:33,701: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.008772355360785277]
[2024-04-20 12:51:34,364: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.01694929072792752]
[2024-04-20 12:51:35,020: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.003825909422147016]
[2024-04-20 12:51:35,693: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.027091851431178378]
[2024-04-20 12:51:36,375: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.0065221160295467805]
[2024-04-20 12:51:37,031: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.0017544569894732513]
[2024-04-20 12:51:37,682: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.004958463120609806]
[2024-04-20 12:51:38,335: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.008236842050124288]
[2024-04-20 12:51:38,991: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.0006521082116468736]
[2024-04-20 12:51:39,646: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.009661112118667605]
[2024-04-20 12:51:40,300: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.006357349412301555]
[2024-04-20 12:51:40,951: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.011643439836566719]
[2024-04-20 12:51:41,608: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.004347483592160747]
[2024-04-20 12:51:42,262: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.002283102397985611]
[2024-04-20 12:51:42,920: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.0041385971860341784]
[2024-04-20 12:51:43,572: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.01083567683718827]
[2024-04-20 12:51:44,227: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.013005995291004711]
[2024-04-20 12:51:44,883: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.010522455966170383]
[2024-04-20 12:51:45,536: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.0010549591827449087]
[2024-04-20 12:51:46,195: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.011401188664687178]
[2024-04-20 12:51:46,859: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.01646197588315462]
[2024-04-20 12:51:47,522: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.02016827088686718]
[2024-04-20 12:51:48,182: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.018258022703428533]
[2024-04-20 12:51:48,846: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.006201070309464696]
[2024-04-20 12:51:49,509: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.013852244048232602]
[2024-04-20 12:51:50,162: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.005155746797790187]
[2024-04-20 12:51:50,817: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.009406087114486811]
[2024-04-20 12:51:51,472: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.009010664852896814]
[2024-04-20 12:51:52,128: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.006785080154543505]
[2024-04-20 12:51:52,779: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.007667340986807904]
[2024-04-20 12:51:53,437: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.010254901510704057]
[2024-04-20 12:51:54,087: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.008117402384420146]
[2024-04-20 12:51:54,742: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.011621765363969841]
[2024-04-20 12:51:55,399: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.0054899958593662]
[2024-04-20 12:51:56,058: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.003116524133935836]
[2024-04-20 12:51:56,719: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.0030965191720515035]
[2024-04-20 12:51:57,373: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.005974037103077131]
[2024-04-20 12:51:58,029: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.015091966956532551]
[2024-04-20 12:51:58,682: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.004526063852606967]
[2024-04-20 12:51:59,336: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.0018358636009188419]
[2024-04-20 12:51:59,993: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.014920205414128963]
[2024-04-20 12:52:00,654: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.002196317485788262]
[2024-04-20 12:52:01,312: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.01623957182764935]
[2024-04-20 12:52:01,979: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.02136673950710476]
[2024-04-20 12:52:02,644: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.00910448560864305]
[2024-04-20 12:52:03,305: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.008606321615433973]
[2024-04-20 12:52:03,960: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.012120763765023074]
[2024-04-20 12:52:04,609: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.007077755635781091]
[2024-04-20 12:52:05,264: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.013696066231320797]
[2024-04-20 12:52:05,915: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.0009616243508640978]
[2024-04-20 12:52:06,567: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.002992268327964392]
[2024-04-20 12:52:07,224: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.005381196592110008]
[2024-04-20 12:52:07,876: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.005344465019053488]
[2024-04-20 12:52:08,530: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.015990764208164594]
[2024-04-20 12:52:09,185: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.010891429666217567]
[2024-04-20 12:52:09,843: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.008483612954284315]
[2024-04-20 12:52:10,500: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.010089417006849101]
[2024-04-20 12:52:11,158: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.0064137210252592]
[2024-04-20 12:52:11,821: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.01961722460089305]
[2024-04-20 12:52:12,475: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.0018261408393344324]
[2024-04-20 12:52:13,128: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.015816215174322006]
[2024-04-20 12:52:13,791: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.07037763259345722]
[2024-04-20 12:52:14,456: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.013121957540812565]
[2024-04-20 12:52:15,116: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.013900266556205566]
[2024-04-20 12:52:15,778: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.008444373178052333]
[2024-04-20 12:52:16,444: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.045638706661653546]
[2024-04-20 12:52:17,097: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.015040450485726624]
[2024-04-20 12:52:17,754: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.0030037873015472043]
[2024-04-20 12:52:18,409: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.008120366456532187]
[2024-04-20 12:52:19,062: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.005958387601302355]
[2024-04-20 12:52:19,717: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.03144363896872811]
[2024-04-20 12:52:20,372: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.020502435927276012]
[2024-04-20 12:52:21,025: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.011001801462364517]
[2024-04-20 12:52:21,681: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.002821670198187679]
[2024-04-20 12:52:22,335: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.00494529535727713]
[2024-04-20 12:52:22,992: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.00553529330024786]
[2024-04-20 12:52:23,647: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.02005068529522037]
[2024-04-20 12:52:24,297: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.026156683262181853]
[2024-04-20 12:52:24,954: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.0038486987142723993]
[2024-04-20 12:52:25,609: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.005334177828654333]
[2024-04-20 12:52:26,269: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.018269110560750642]
[2024-04-20 12:52:26,929: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.017324811501229994]
[2024-04-20 12:52:27,598: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.01410579852347354]
[2024-04-20 12:52:28,265: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.005240228864951766]
[2024-04-20 12:52:28,926: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.011286695251117907]
[2024-04-20 12:52:29,593: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.0036459007436440934]
[2024-04-20 12:52:30,255: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.011838682558041266]
[2024-04-20 12:52:30,910: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.009732019115268224]
[2024-04-20 12:52:31,566: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.0038392229957032666]
[2024-04-20 12:52:32,221: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.010328151716629461]
[2024-04-20 12:52:32,874: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.007020368411183871]
[2024-04-20 12:52:33,529: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.0128762839854528]
[2024-04-20 12:52:34,181: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.0037876193342521068]
[2024-04-20 12:52:34,836: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.004924889456920078]
[2024-04-20 12:52:35,492: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.004947094894971854]
[2024-04-20 12:52:36,145: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.004694789585248795]
[2024-04-20 12:52:36,800: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.004932282328155832]
[2024-04-20 12:52:37,456: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.010326097440077191]
[2024-04-20 12:52:38,113: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.00987055799893676]
[2024-04-20 12:52:38,767: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.012608940497014873]
[2024-04-20 12:52:39,428: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.008062953381664533]
[2024-04-20 12:52:40,096: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.009297461466744435]
[2024-04-20 12:52:40,758: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.0010618253129515548]
[2024-04-20 12:52:41,438: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.0028563459506830134]
[2024-04-20 12:52:42,107: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.00572953958337489]
[2024-04-20 12:52:42,769: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.006202065388705823]
[2024-04-20 12:52:43,429: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.0035101784335368233]
[2024-04-20 12:52:44,083: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.004596565035839824]
[2024-04-20 12:52:44,740: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.0017261801099572797]
[2024-04-20 12:52:45,397: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.007619593485340215]
[2024-04-20 12:52:46,053: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.01891492305805626]
[2024-04-20 12:52:46,710: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.004047289757350477]
[2024-04-20 12:52:47,361: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.0012668913406571856]
[2024-04-20 12:52:48,016: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.009571298946896671]
[2024-04-20 12:52:48,674: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.0032027854417587664]
[2024-04-20 12:52:49,331: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.002405425759113222]
[2024-04-20 12:52:49,993: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.0029299263448234404]
[2024-04-20 12:52:50,646: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.0014926333956983224]
[2024-04-20 12:52:51,304: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.002968749622945341]
[2024-04-20 12:52:51,959: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.008852398424058251]
[2024-04-20 12:52:52,616: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.014747043635167836]
[2024-04-20 12:52:53,274: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.01815574115327545]
[2024-04-20 12:52:53,936: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.0031453851653889552]
[2024-04-20 12:52:54,602: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.006551336109205976]
[2024-04-20 12:52:55,270: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.005367765200121511]
[2024-04-20 12:52:55,941: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.00043095015342255015]
[2024-04-20 12:52:56,603: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.001794575503691239]
[2024-04-20 12:52:57,261: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.005494802531285565]
[2024-04-20 12:52:57,920: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.0010715895256112973]
[2024-04-20 12:52:58,575: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.00436491292617943]
[2024-04-20 12:52:59,237: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.02546163854256573]
[2024-04-20 12:52:59,889: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.008696620450385882]
[2024-04-20 12:53:00,545: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.001979344541170264]
[2024-04-20 12:53:01,200: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.0069633284303119965]
[2024-04-20 12:53:01,856: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.008771747623546383]
[2024-04-20 12:53:02,516: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.005973017843415758]
[2024-04-20 12:53:03,177: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.005858741351789258]
[2024-04-20 12:53:03,837: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.008887096351975711]
[2024-04-20 12:53:04,492: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.002323032421560913]
[2024-04-20 12:53:05,146: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.016725955346629195]
[2024-04-20 12:53:05,805: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.001214670963919018]
[2024-04-20 12:53:06,464: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.004438398697855248]
[2024-04-20 12:53:07,127: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.007105025968130264]
[2024-04-20 12:53:07,795: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.005026412679951594]
[2024-04-20 12:53:08,470: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.007783808611642832]
[2024-04-20 12:53:09,143: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.008825914196689204]
[2024-04-20 12:53:09,819: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.006773351346105967]
[2024-04-20 12:53:10,481: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.0014337031543923803]
[2024-04-20 12:53:11,133: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.00402676204106092]
[2024-04-20 12:53:11,796: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.013102930487207164]
[2024-04-20 12:53:12,451: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.00499690900066748]
[2024-04-20 12:53:13,107: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.02073024744025376]
[2024-04-20 12:53:13,761: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.00030323301632827464]
[2024-04-20 12:53:14,421: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.004473999453372345]
[2024-04-20 12:53:15,075: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.005884091485842054]
[2024-04-20 12:53:15,737: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.004793325555196486]
[2024-04-20 12:53:16,393: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.0010531213477256607]
[2024-04-20 12:53:17,051: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.0034065737672684952]
[2024-04-20 12:53:17,705: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.01292042008192467]
[2024-04-20 12:53:18,364: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.021464750206529926]
[2024-04-20 12:53:19,021: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.04170214444312655]
[2024-04-20 12:53:19,674: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.0027619575098722436]
[2024-04-20 12:53:20,337: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.010232097670083162]
[2024-04-20 12:53:21,002: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.0016048832817404666]
[2024-04-20 12:53:21,670: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.011353171310387022]
[2024-04-20 12:53:22,336: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.007843532234489914]
[2024-04-20 12:53:22,995: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.008480962146383001]
[2024-04-20 12:53:23,653: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.0036014172213370693]
[2024-04-20 12:53:24,308: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.00982599757385561]
[2024-04-20 12:53:24,969: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.007932685800219972]
[2024-04-20 12:53:25,626: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.001088951643837519]
[2024-04-20 12:53:26,286: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.005317913502643471]
[2024-04-20 12:53:26,946: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.011072818063608872]
[2024-04-20 12:53:27,601: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.00571959009689004]
[2024-04-20 12:53:28,252: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.00402834909919527]
[2024-04-20 12:53:28,906: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.0022698097446833816]
[2024-04-20 12:53:29,564: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.0037022698267506603]
[2024-04-20 12:53:30,217: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.003959194363502637]
[2024-04-20 12:53:30,871: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.0028024134502977033]
[2024-04-20 12:53:31,523: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.052385316501909106]
[2024-04-20 12:53:32,177: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.005390327232372775]
[2024-04-20 12:53:32,832: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.00996080917754322]
[2024-04-20 12:53:33,492: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.013974146867820812]
[2024-04-20 12:53:34,155: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.016937886826818484]
[2024-04-20 12:53:34,831: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.015225459671858675]
[2024-04-20 12:53:35,501: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.005394121190549431]
[2024-04-20 12:53:36,161: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.0018714711468163015]
[2024-04-20 12:53:36,824: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.0035214250336560817]
[2024-04-20 12:53:37,486: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.02422783882860072]
[2024-04-20 12:53:38,148: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.004755144781560826]
[2024-04-20 12:53:38,802: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.004084030907964145]
[2024-04-20 12:53:39,457: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.021936684523293323]
[2024-04-20 12:53:40,110: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.005927919409297797]
[2024-04-20 12:53:40,766: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.013177781905923633]
[2024-04-20 12:53:41,417: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.0036693252237789318]
[2024-04-20 12:53:42,072: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.0091160907110706]
[2024-04-20 12:53:42,725: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.005295964048368272]
[2024-04-20 12:53:43,381: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.011032289486573572]
[2024-04-20 12:53:44,040: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.008091357378061588]
[2024-04-20 12:53:44,696: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.005286787190104849]
[2024-04-20 12:53:45,351: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.018874214239920754]
[2024-04-20 12:53:46,002: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.0024855953244047736]
[2024-04-20 12:53:46,658: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.011351422053207954]
[2024-04-20 12:53:47,319: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.012274990356360411]
[2024-04-20 12:53:47,980: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.0024516769667801727]
[2024-04-20 12:53:48,644: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.023681165603918097]
[2024-04-20 12:53:49,311: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.009574901881093273]
[2024-04-20 12:53:49,986: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.005534579778747068]
[2024-04-20 12:53:50,657: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.008189533015117965]
[2024-04-20 12:53:51,314: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.01212201874626354]
[2024-04-20 12:53:51,979: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.015182002459515894]
[2024-04-20 12:53:52,640: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.004937630255204656]
[2024-04-20 12:53:53,297: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.003243947906448215]
[2024-04-20 12:53:53,963: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.004328033806897079]
[2024-04-20 12:53:54,621: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.0038359742134015068]
[2024-04-20 12:53:55,271: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.0030930800599683972]
[2024-04-20 12:53:55,928: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.004010382578168919]
[2024-04-20 12:53:56,586: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.0008376814459812263]
[2024-04-20 12:53:57,239: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.004700301990460958]
[2024-04-20 12:53:57,893: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.022573147633561785]
[2024-04-20 12:53:58,550: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.005881882808627481]
[2024-04-20 12:53:59,207: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.007611911599458957]
[2024-04-20 12:53:59,867: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.009957351284518709]
[2024-04-20 12:54:00,526: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.0341785756904365]
[2024-04-20 12:54:01,185: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.005116797837824264]
[2024-04-20 12:54:01,846: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.012894589646732693]
[2024-04-20 12:54:02,509: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.02751943247946986]
[2024-04-20 12:54:03,180: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.007371713573611112]
[2024-04-20 12:54:03,836: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.0069088695338358425]
[2024-04-20 12:54:04,488: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.008551339011314074]
[2024-04-20 12:54:05,138: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.006336287654566024]
[2024-04-20 12:54:05,794: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.00853213992713338]
[2024-04-20 12:54:06,447: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.011989520980561903]
[2024-04-20 12:54:07,100: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.00224273105831438]
[2024-04-20 12:54:07,750: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.013613035980936052]
[2024-04-20 12:54:08,405: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.0038830417533206657]
[2024-04-20 12:54:09,062: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.004589237215514828]
[2024-04-20 12:54:09,716: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.010870468959936]
[2024-04-20 12:54:10,370: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.0038271689083736907]
[2024-04-20 12:54:11,024: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.005319205160490777]
[2024-04-20 12:54:11,677: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.005122433906793693]
[2024-04-20 12:54:12,334: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.0359312758647281]
[2024-04-20 12:54:12,996: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.015790562467540736]
[2024-04-20 12:54:13,663: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.003907555336419678]
[2024-04-20 12:54:14,340: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.011982555064237487]
[2024-04-20 12:54:15,002: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.0018275208580453308]
[2024-04-20 12:54:15,668: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.009080136014259887]
[2024-04-20 12:54:16,330: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.0040779858709611904]
[2024-04-20 12:54:16,990: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.014748756993546762]
[2024-04-20 12:54:17,674: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.003402043253657541]
[2024-04-20 12:54:18,364: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.010815320648655974]
[2024-04-20 12:54:19,024: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.0160207850419418]
[2024-04-20 12:54:19,690: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.0076215111520520455]
[2024-04-20 12:54:20,347: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.0037167770363793493]
[2024-04-20 12:54:21,006: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.006253851463382274]
[2024-04-20 12:54:21,658: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.00299186352571382]
[2024-04-20 12:54:22,311: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.01160832975083321]
[2024-04-20 12:54:22,962: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.0011674387695524608]
[2024-04-20 12:54:23,615: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.009230117559651979]
[2024-04-20 12:54:24,271: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.013728552526026148]
[2024-04-20 12:54:24,927: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.004524003930805236]
[2024-04-20 12:54:25,582: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.0038370523975209524]
[2024-04-20 12:54:26,239: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.022129493829831745]
[2024-04-20 12:54:26,901: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.011653590752681176]
[2024-04-20 12:54:27,555: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.013920512092994677]
[2024-04-20 12:54:28,211: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.006207574698172208]
[2024-04-20 12:54:28,872: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.021337413352223968]
[2024-04-20 12:54:29,533: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.014229216121899072]
[2024-04-20 12:54:30,214: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.006426031702745304]
[2024-04-20 12:54:30,881: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.0020429525132348615]
[2024-04-20 12:54:31,543: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.005418124179159094]
[2024-04-20 12:54:32,201: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.0015353681713181008]
[2024-04-20 12:54:32,856: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.01399383690693538]
[2024-04-20 12:54:33,512: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.003485903631195972]
[2024-04-20 12:54:34,169: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.00905184333206607]
[2024-04-20 12:54:34,823: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.01827935535868556]
[2024-04-20 12:54:35,479: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.024620088533476598]
[2024-04-20 12:54:36,138: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.023123584410719825]
[2024-04-20 12:54:36,796: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.004981480772383843]
[2024-04-20 12:54:37,452: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.009603770972056197]
[2024-04-20 12:54:38,107: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.011205863507500592]
[2024-04-20 12:54:38,762: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.016875013790472418]
[2024-04-20 12:54:39,417: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.048349562359362865]
[2024-04-20 12:54:40,069: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.011914816537727182]
[2024-04-20 12:54:40,720: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.008414129342532663]
[2024-04-20 12:54:41,373: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.0069318031710967655]
[2024-04-20 12:54:42,042: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.00996367351597431]
[2024-04-20 12:54:42,705: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.006051340689021997]
[2024-04-20 12:54:43,371: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.01888260347667105]
[2024-04-20 12:54:44,033: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.01863951509456004]
[2024-04-20 12:54:44,694: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.007651207139216944]
[2024-04-20 12:54:45,345: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.007728985184835871]
[2024-04-20 12:54:46,000: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.0031347041949133262]
[2024-04-20 12:54:46,653: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.006168428518079793]
[2024-04-20 12:54:47,306: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.005829559951432722]
[2024-04-20 12:54:47,963: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.004498930167502896]
[2024-04-20 12:54:48,620: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.004924224934620925]
[2024-04-20 12:54:49,273: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.0036323110961061747]
[2024-04-20 12:54:49,931: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.011743500523454999]
[2024-04-20 12:54:50,586: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.0021567930653900768]
[2024-04-20 12:54:51,239: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.01614320199331334]
[2024-04-20 12:54:51,894: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.004483206971719518]
[2024-04-20 12:54:52,551: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.010098895976519657]
[2024-04-20 12:54:53,210: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.010331823642681365]
[2024-04-20 12:54:53,869: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.0059518720280201925]
[2024-04-20 12:54:54,521: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.02345797313604706]
[2024-04-20 12:54:55,187: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.010836469329720457]
[2024-04-20 12:54:55,850: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.012978963517717542]
[2024-04-20 12:54:56,524: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.003613416010259691]
[2024-04-20 12:54:57,189: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.005168461792483059]
[2024-04-20 12:54:57,850: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.017911117796402455]
[2024-04-20 12:54:58,518: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.001196381651681803]
[2024-04-20 12:54:59,171: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.004570261701288367]
[2024-04-20 12:54:59,827: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.005382147426292775]
[2024-04-20 12:55:00,480: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.005432538212121201]
[2024-04-20 12:55:01,133: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.003379368736297661]
[2024-04-20 12:55:01,788: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.011603794301384644]
[2024-04-20 12:55:02,439: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.011311534330717524]
[2024-04-20 12:55:03,095: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.004821503829400656]
[2024-04-20 12:55:03,753: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.015529174325207342]
[2024-04-20 12:55:04,409: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.003627340062363142]
[2024-04-20 12:55:05,064: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.013806632359103916]
[2024-04-20 12:55:05,719: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.02373771081433583]
[2024-04-20 12:55:06,373: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.010737861420734006]
[2024-04-20 12:55:07,028: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.001146240438685713]
[2024-04-20 12:55:07,680: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.0035949248696193446]
[2024-04-20 12:55:08,335: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.008273467324593513]
[2024-04-20 12:55:08,996: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.0012742034043774055]
[2024-04-20 12:55:09,660: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.013326077596270584]
[2024-04-20 12:55:10,321: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.0030558612219060066]
[2024-04-20 12:55:10,997: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.026812927629634387]
[2024-04-20 12:55:11,661: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.008117984747377507]
[2024-04-20 12:55:12,315: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.012399549281423226]
[2024-04-20 12:55:12,969: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.009558309943814595]
[2024-04-20 12:55:13,623: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.007248126134037563]
[2024-04-20 12:55:14,278: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.00443479796192049]
[2024-04-20 12:55:14,935: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.005294382007893703]
[2024-04-20 12:55:15,590: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.007424439095011253]
[2024-04-20 12:55:16,244: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.007449266278024202]
[2024-04-20 12:55:16,897: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.0007984644139127981]
[2024-04-20 12:55:17,549: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.0074956688963457845]
[2024-04-20 12:55:18,204: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.015334459889723904]
[2024-04-20 12:55:18,860: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.0008605775801415002]
[2024-04-20 12:55:19,516: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.010985664150895596]
[2024-04-20 12:55:20,171: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.0018273230333408382]
[2024-04-20 12:55:20,827: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.007325719841087125]
[2024-04-20 12:55:21,479: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.00843236683898811]
[2024-04-20 12:55:22,155: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.008081531045153014]
[2024-04-20 12:55:22,839: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.011873987208513032]
[2024-04-20 12:55:23,500: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.0016320332565719956]
[2024-04-20 12:55:24,156: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.0005798101873513407]
[2024-04-20 12:55:24,824: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.007032427716833869]
[2024-04-20 12:55:25,481: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.0069227185124225215]
[2024-04-20 12:55:26,138: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.005866533161732119]
[2024-04-20 12:55:26,791: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.0004462965304950663]
[2024-04-20 12:55:27,445: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.004425476786262018]
[2024-04-20 12:55:28,097: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.025776743054439152]
[2024-04-20 12:55:28,750: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.006564211847111144]
[2024-04-20 12:55:29,401: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.0049379351548807056]
[2024-04-20 12:55:30,057: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.0063396759028946205]
[2024-04-20 12:55:30,710: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.0025744281809203413]
[2024-04-20 12:55:31,363: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.02151404924387494]
[2024-04-20 12:55:32,019: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.01770877319969593]
[2024-04-20 12:55:32,678: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.016798662776992154]
[2024-04-20 12:55:33,333: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.009695692960634548]
[2024-04-20 12:55:33,990: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.023599886396878014]
[2024-04-20 12:55:34,641: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.008078089831607231]
[2024-04-20 12:55:35,306: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.005314661243539673]
[2024-04-20 12:55:35,971: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.005590634200415584]
[2024-04-20 12:55:36,634: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.01158827304126944]
[2024-04-20 12:55:37,314: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.010705011629382574]
[2024-04-20 12:55:37,987: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.006761976515756138]
[2024-04-20 12:55:38,646: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.004831784136843817]
[2024-04-20 12:55:39,300: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.021608841270774833]
[2024-04-20 12:55:39,954: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.02711904632327789]
[2024-04-20 12:55:40,606: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.011408276800128087]
[2024-04-20 12:55:41,264: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.007722457139325144]
[2024-04-20 12:55:41,917: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.0025324732264673084]
[2024-04-20 12:55:42,571: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.007773646006201139]
[2024-04-20 12:55:43,229: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.009116697206638089]
[2024-04-20 12:55:43,885: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.008498601531346852]
[2024-04-20 12:55:44,539: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.0024220126847291487]
[2024-04-20 12:55:45,193: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.002710006062252502]
[2024-04-20 12:55:45,844: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.006743883297531801]
[2024-04-20 12:55:46,499: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.005843204132455933]
[2024-04-20 12:55:47,153: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.0043327193643875545]
[2024-04-20 12:55:47,805: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.00726417445310618]
[2024-04-20 12:55:48,458: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.004041128959441807]
[2024-04-20 12:55:49,121: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.0005460857562560369]
[2024-04-20 12:55:49,783: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.002168907460194563]
[2024-04-20 12:55:50,442: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.002144150172694054]
[2024-04-20 12:55:51,109: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.0024122661280006146]
[2024-04-20 12:55:51,779: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.014397635272796397]
[2024-04-20 12:55:52,438: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.024421697703867838]
[2024-04-20 12:55:53,093: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.0019758153703692467]
[2024-04-20 12:55:53,750: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.006897512736212126]
[2024-04-20 12:55:54,410: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.012719525973693005]
[2024-04-20 12:55:55,068: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.0037261125258795176]
[2024-04-20 12:55:55,722: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.014371003966233193]
[2024-04-20 12:55:56,377: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.002393099848145777]
[2024-04-20 12:55:57,030: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.013175497599240542]
[2024-04-20 12:55:57,687: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.009069119627709819]
[2024-04-20 12:55:58,339: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.010643610507034933]
[2024-04-20 12:55:58,992: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.009418885561288424]
[2024-04-20 12:55:59,650: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.012199816121112471]
[2024-04-20 12:56:00,305: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.008924532289552096]
[2024-04-20 12:56:00,959: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.002702534181782099]
[2024-04-20 12:56:01,614: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.0029288914561046635]
[2024-04-20 12:56:02,279: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.0005542417619834734]
[2024-04-20 12:56:02,940: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.006450950349930247]
[2024-04-20 12:56:03,601: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.003701318911175035]
[2024-04-20 12:56:04,264: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.010391609837502916]
[2024-04-20 12:56:04,928: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.004873643062522699]
[2024-04-20 12:56:05,585: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.007726782301376264]
[2024-04-20 12:56:06,242: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.01152527294628317]
[2024-04-20 12:56:06,899: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.013306256779562693]
[2024-04-20 12:56:07,554: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.008582979015121674]
[2024-04-20 12:56:08,208: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.017218700989704117]
[2024-04-20 12:56:08,863: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.009056118494063254]
[2024-04-20 12:56:09,519: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.014302947027114857]
[2024-04-20 12:56:10,175: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.010170564788039124]
[2024-04-20 12:56:10,829: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.002260454059700929]
[2024-04-20 12:56:11,485: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.004193464002864431]
[2024-04-20 12:56:12,141: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.005910461077708674]
[2024-04-20 12:56:12,799: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.006681036917205535]
[2024-04-20 12:56:13,454: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.005334618295133914]
[2024-04-20 12:56:14,111: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.002400738899456306]
[2024-04-20 12:56:14,763: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.005007012797565]
[2024-04-20 12:56:15,423: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.015427149334768594]
[2024-04-20 12:56:16,087: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.005873687484983906]
[2024-04-20 12:56:16,760: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.010112731623453039]
[2024-04-20 12:56:17,431: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.0036676555398792348]
[2024-04-20 12:56:18,090: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.0018725475600372434]
[2024-04-20 12:56:18,754: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.0017434011770144009]
[2024-04-20 12:56:19,408: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.005489677415874977]
[2024-04-20 12:56:20,063: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.01652828490594309]
[2024-04-20 12:56:20,717: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.012481605132639535]
[2024-04-20 12:56:21,371: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.004892142844141403]
[2024-04-20 12:56:22,027: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.01494897307095925]
[2024-04-20 12:56:22,683: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.0047905254959372725]
[2024-04-20 12:56:23,339: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.01354526611389777]
[2024-04-20 12:56:23,991: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.0035881929285608923]
[2024-04-20 12:56:24,643: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.013383716867832005]
[2024-04-20 12:56:25,294: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.009429129329560517]
[2024-04-20 12:56:25,948: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.005460025757264979]
[2024-04-20 12:56:26,605: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.010098103713554057]
[2024-04-20 12:56:27,258: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.006129967547632497]
[2024-04-20 12:56:27,914: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.0010265264247033385]
[2024-04-20 12:56:28,569: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.002797592283177972]
[2024-04-20 12:56:29,228: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.01617621892076104]
[2024-04-20 12:56:29,891: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.005722400981791996]
[2024-04-20 12:56:30,557: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.0015840950072774388]
[2024-04-20 12:56:31,223: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.0030237097435022527]
[2024-04-20 12:56:31,893: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.0028492183514139823]
[2024-04-20 12:56:32,547: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.0026982587239498374]
[2024-04-20 12:56:33,203: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.01463950537516919]
[2024-04-20 12:56:33,856: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.007983734469808755]
[2024-04-20 12:56:34,509: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.018080783990982143]
[2024-04-20 12:56:35,165: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.004924576455138521]
[2024-04-20 12:56:35,822: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.004107153749922913]
[2024-04-20 12:56:36,479: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.003446056565148583]
[2024-04-20 12:56:37,133: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.01967733881484751]
[2024-04-20 12:56:37,787: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.004902047710563894]
[2024-04-20 12:56:38,445: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.00483832449386563]
[2024-04-20 12:56:39,095: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.019340967594699044]
[2024-04-20 12:56:39,752: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.010289118777948499]
[2024-04-20 12:56:40,406: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.005501686070728883]
[2024-04-20 12:56:41,059: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.006031506516305347]
[2024-04-20 12:56:41,716: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.009623685640084735]
[2024-04-20 12:56:42,374: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.0035198432323995874]
[2024-04-20 12:56:43,059: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.012042663387175606]
[2024-04-20 12:56:43,727: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.008450426795703226]
[2024-04-20 12:56:44,387: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.006193106776556831]
[2024-04-20 12:56:45,060: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.0068316174846955735]
[2024-04-20 12:56:45,720: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.01035813494509581]
[2024-04-20 12:56:46,374: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.0038354249057820145]
[2024-04-20 12:56:47,030: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.006700029456336623]
[2024-04-20 12:56:47,689: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.005145423735748903]
[2024-04-20 12:56:48,340: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.0020440761618468954]
[2024-04-20 12:56:48,995: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.005558799396442402]
[2024-04-20 12:56:49,652: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.005484092840272356]
[2024-04-20 12:56:50,308: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.004953227361133021]
[2024-04-20 12:56:50,964: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.007878168728037493]
[2024-04-20 12:56:51,617: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.025147159433625884]
[2024-04-20 12:56:52,276: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.005574462891096329]
[2024-04-20 12:56:52,932: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.005444603733913168]
[2024-04-20 12:56:53,588: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.0036834290667689443]
[2024-04-20 12:56:54,244: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.007031681291825293]
[2024-04-20 12:56:54,899: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.00554128773940903]
[2024-04-20 12:56:55,558: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.0015705914348981293]
[2024-04-20 12:56:56,234: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.010194009389746532]
[2024-04-20 12:56:56,903: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.0013373848075498888]
[2024-04-20 12:56:57,563: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.009373371035820253]
[2024-04-20 12:56:58,230: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.013150725051840182]
[2024-04-20 12:56:58,900: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.02147564597956186]
[2024-04-20 12:56:59,557: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.007449186403856038]
[2024-04-20 12:57:00,213: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.005071965849563499]
[2024-04-20 12:57:00,867: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.0038658043600116225]
[2024-04-20 12:57:01,524: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.004500667188494423]
[2024-04-20 12:57:02,177: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.0052162932522618125]
[2024-04-20 12:57:02,831: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.005901881947535497]
[2024-04-20 12:57:03,497: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.007286035845041811]
[2024-04-20 12:57:04,155: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.008890832933661547]
[2024-04-20 12:57:04,819: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.009426905652677913]
[2024-04-20 12:57:05,482: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.004226929255181651]
[2024-04-20 12:57:06,158: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.0008225883932403571]
[2024-04-20 12:57:06,822: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.0014740912277574388]
[2024-04-20 12:57:07,470: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.007005059432535706]
[2024-04-20 12:57:08,123: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.003954153440505562]
[2024-04-20 12:57:08,779: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.03248607798261335]
[2024-04-20 12:57:09,442: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.02146873307041763]
[2024-04-20 12:57:10,111: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.006301060635474464]
[2024-04-20 12:57:10,785: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.02956813061287826]
[2024-04-20 12:57:11,452: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.005656856419264956]
[2024-04-20 12:57:12,113: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.011898460522457811]
[2024-04-20 12:57:12,765: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.015416778690636197]
[2024-04-20 12:57:13,422: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.01128412200185669]
[2024-04-20 12:57:14,071: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.005257784796269915]
[2024-04-20 12:57:14,732: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.009102201402738867]
[2024-04-20 12:57:15,384: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.003787058667515716]
[2024-04-20 12:57:16,039: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.025883715436124884]
[2024-04-20 12:57:16,692: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.009700126011818563]
[2024-04-20 12:57:17,348: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.007887240178665886]
[2024-04-20 12:57:17,999: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.009684556812456523]
[2024-04-20 12:57:18,655: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.008456519547061732]
[2024-04-20 12:57:19,314: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.005330030181263846]
[2024-04-20 12:57:19,967: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.0074627803759174955]
[2024-04-20 12:57:20,624: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.005220225791502978]
[2024-04-20 12:57:21,278: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.005123317903991087]
[2024-04-20 12:57:21,932: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.014525176162656637]
[2024-04-20 12:57:22,611: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.002809521235031685]
[2024-04-20 12:57:23,277: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.005374576312434207]
[2024-04-20 12:57:23,934: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.018242408281279102]
[2024-04-20 12:57:24,603: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.004132611763542749]
[2024-04-20 12:57:25,271: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.014117519019106217]
[2024-04-20 12:57:25,928: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.008113169487891942]
[2024-04-20 12:57:26,591: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.0033283878676240415]
[2024-04-20 12:57:27,249: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.013543454529349583]
[2024-04-20 12:57:27,916: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.011730118043748388]
[2024-04-20 12:57:28,588: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.011415626620460152]
[2024-04-20 12:57:29,259: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.007130342048526813]
[2024-04-20 12:57:29,919: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.011593526461845175]
[2024-04-20 12:57:30,572: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.01897940813932887]
[2024-04-20 12:57:31,226: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.015565352845482628]
[2024-04-20 12:57:31,881: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.006351644874811974]
[2024-04-20 12:57:32,539: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.00877254373069789]
[2024-04-20 12:57:33,196: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.004471736985916115]
[2024-04-20 12:57:33,850: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.006806029988050801]
[2024-04-20 12:57:34,505: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.011954299561805933]
[2024-04-20 12:57:35,162: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.006009275964851351]
[2024-04-20 12:57:35,824: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.005441074096680068]
[2024-04-20 12:57:36,482: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.019496469966699036]
[2024-04-20 12:57:37,146: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.011724678703143367]
[2024-04-20 12:57:37,806: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.004976236038959515]
[2024-04-20 12:57:38,473: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.009242906613069167]
[2024-04-20 12:57:39,134: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.0034461778310607804]
[2024-04-20 12:57:39,794: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.005661877034623189]
[2024-04-20 12:57:40,451: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.027285367660903156]
[2024-04-20 12:57:41,109: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.00862807000690922]
[2024-04-20 12:57:41,762: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.014244011509955778]
[2024-04-20 12:57:42,416: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.006225372511214556]
[2024-04-20 12:57:43,072: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.03268721850962899]
[2024-04-20 12:57:43,730: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.0011410612102494653]
[2024-04-20 12:57:44,388: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.0023462254987042944]
[2024-04-20 12:57:45,044: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.02206638906339018]
[2024-04-20 12:57:45,702: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.015496495106955372]
[2024-04-20 12:57:46,358: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.0076587443482068335]
[2024-04-20 12:57:47,014: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.0033652639891615086]
[2024-04-20 12:57:47,668: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.014145647016760108]
[2024-04-20 12:57:48,324: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.007356969014326853]
[2024-04-20 12:57:48,981: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.007945078816702277]
[2024-04-20 12:57:49,646: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.0037718164523121954]
[2024-04-20 12:57:50,324: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.007077502024720853]
[2024-04-20 12:57:50,993: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.016681024033529838]
[2024-04-20 12:57:51,653: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.014073562730448422]
[2024-04-20 12:57:52,321: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.007241517373442356]
[2024-04-20 12:57:52,979: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.017590701998271913]
[2024-04-20 12:57:53,634: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.0013112500862373126]
[2024-04-20 12:57:54,291: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.017403688452102925]
[2024-04-20 12:57:54,949: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.004804361744337225]
[2024-04-20 12:57:55,603: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.004602521862881711]
[2024-04-20 12:57:56,258: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.002043857048080761]
[2024-04-20 12:57:56,919: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.007248889126815482]
[2024-04-20 12:57:57,574: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.009241860091053574]
[2024-04-20 12:57:58,234: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.00031016273802457163]
[2024-04-20 12:57:58,888: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.0035279981039652883]
[2024-04-20 12:57:59,544: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.006453865446885861]
[2024-04-20 12:58:00,202: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.006905859381094696]
[2024-04-20 12:58:00,865: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.01512890149754364]
[2024-04-20 12:58:01,521: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.0010763501806075385]
[2024-04-20 12:58:02,179: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.0029145713662661614]
[2024-04-20 12:58:02,843: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.008461213414542059]
[2024-04-20 12:58:03,508: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.008876024016747232]
[2024-04-20 12:58:04,183: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.0033175840543626183]
[2024-04-20 12:58:04,856: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.006785464738620022]
[2024-04-20 12:58:05,522: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.003319948341145725]
[2024-04-20 12:58:06,175: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.016918678464981757]
[2024-04-20 12:58:06,834: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.003959926986068885]
[2024-04-20 12:58:07,494: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.01286369317430479]
[2024-04-20 12:58:08,149: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.009612118245782678]
[2024-04-20 12:58:08,807: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.009886235192341816]
[2024-04-20 12:58:09,464: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.004322831600496932]
[2024-04-20 12:58:10,120: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.0064317088558770155]
[2024-04-20 12:58:10,776: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.005580743313818553]
[2024-04-20 12:58:11,432: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.0031784338417852665]
[2024-04-20 12:58:12,086: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.011424686890093903]
[2024-04-20 12:58:12,741: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.0033783972129486036]
[2024-04-20 12:58:13,400: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.001616574565503348]
[2024-04-20 12:58:14,057: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.026980696399458447]
[2024-04-20 12:58:14,713: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.022031654780751416]
[2024-04-20 12:58:15,369: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.0043563092890165495]
[2024-04-20 12:58:16,046: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.011769685423292294]
[2024-04-20 12:58:16,722: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.001092542871340486]
[2024-04-20 12:58:17,388: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.002286590805557342]
[2024-04-20 12:58:18,051: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.004871152633413741]
[2024-04-20 12:58:18,723: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.00645287203719499]
[2024-04-20 12:58:19,377: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.00037413495633284113]
[2024-04-20 12:58:20,032: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.017378986495162653]
[2024-04-20 12:58:20,692: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.0022325514151960496]
[2024-04-20 12:58:21,347: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.010166182598230622]
[2024-04-20 12:58:22,002: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.04646832424042378]
[2024-04-20 12:58:22,656: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.008442944810747833]
[2024-04-20 12:58:23,311: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.018044641163845472]
[2024-04-20 12:58:23,969: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.0008107709047337566]
[2024-04-20 12:58:24,626: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.0060359146309970965]
[2024-04-20 12:58:25,283: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.004481446001727762]
[2024-04-20 12:58:25,941: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.003591556021845512]
[2024-04-20 12:58:26,595: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.0012512367994688518]
[2024-04-20 12:58:27,254: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.02394837898001661]
[2024-04-20 12:58:27,910: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.0040534682090667806]
[2024-04-20 12:58:28,568: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.0024758724223318375]
[2024-04-20 12:58:29,234: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.006696242241649798]
[2024-04-20 12:58:29,900: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.0021418814603258725]
[2024-04-20 12:58:30,566: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.023269243217908898]
[2024-04-20 12:58:31,230: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.005653362215932597]
[2024-04-20 12:58:31,893: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.0039650386811404745]
[2024-04-20 12:58:32,556: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.002755974709511914]
[2024-04-20 12:58:33,211: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.013450823122086203]
[2024-04-20 12:58:33,873: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.010778253906526813]
[2024-04-20 12:58:34,533: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.0042111987530916465]
[2024-04-20 12:58:35,188: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.00654848898969819]
[2024-04-20 12:58:35,845: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.011798243221389606]
[2024-04-20 12:58:36,498: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.008249880870140369]
[2024-04-20 12:58:37,151: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.009287956639227714]
[2024-04-20 12:58:37,812: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.003495755643270979]
[2024-04-20 12:58:38,465: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.011867303950646547]
[2024-04-20 12:58:39,122: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.021321851458817587]
[2024-04-20 12:58:39,779: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.009304497632762391]
[2024-04-20 12:58:40,435: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.012198290984181117]
[2024-04-20 12:58:41,095: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.009376635697093638]
[2024-04-20 12:58:41,752: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.00971343314645703]
[2024-04-20 12:58:42,411: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.014843112400982357]
[2024-04-20 12:58:43,077: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.0388173468794647]
[2024-04-20 12:58:43,742: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.010867966850420145]
[2024-04-20 12:58:44,404: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.004921210922760242]
[2024-04-20 12:58:45,078: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.014160077759696472]
[2024-04-20 12:58:45,742: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.009535501644546822]
[2024-04-20 12:58:46,400: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.006333517072169]
[2024-04-20 12:58:46,847: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.0018401166431704988]
[2024-04-20 12:58:47,053: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.007838691969692247]
[2024-04-20 12:58:47,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.004126771605184205]
[2024-04-20 12:58:47,464: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.003170575714146719]
[2024-04-20 12:58:47,669: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.005971345453536645]
[2024-04-20 12:58:47,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.0033717960396171384]
[2024-04-20 12:58:48,093: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.013560369761986185]
[2024-04-20 12:58:48,298: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.011842424945770463]
[2024-04-20 12:58:48,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.005337019872657097]
[2024-04-20 12:58:48,710: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.0050548252261932896]
[2024-04-20 12:58:48,925: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.0075341201810693766]
[2024-04-20 12:58:49,129: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.0006182545190418146]
[2024-04-20 12:58:49,333: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.005453623875239868]
[2024-04-20 12:58:49,539: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.005471178696391531]
[2024-04-20 12:58:49,746: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.004165755760633998]
[2024-04-20 12:58:49,951: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.028046357650103194]
[2024-04-20 12:58:50,160: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.004010246944490876]
[2024-04-20 12:58:50,367: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.008247805380351917]
[2024-04-20 12:58:50,573: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.009446666181983823]
[2024-04-20 12:58:50,777: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.004685943987123615]
[2024-04-20 12:58:50,982: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.008076376746824349]
[2024-04-20 12:58:51,190: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.0053936500189881095]
[2024-04-20 12:58:51,400: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.00399912858834623]
[2024-04-20 12:58:51,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.008893902040496738]
[2024-04-20 12:58:51,811: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.0015138793230980744]
[2024-04-20 12:58:52,020: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.0010450734762786893]
[2024-04-20 12:58:52,227: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.0007919885133991106]
[2024-04-20 12:58:52,434: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.009291249057717518]
[2024-04-20 12:58:52,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.006352908662006291]
[2024-04-20 12:58:52,847: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.006020187956336846]
[2024-04-20 12:58:53,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.004881536627639515]
[2024-04-20 12:58:53,257: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.007453551935050782]
[2024-04-20 12:58:53,459: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.003159691859513698]
[2024-04-20 12:58:53,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.008524479616698956]
[2024-04-20 12:58:53,873: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.009355346888734406]
[2024-04-20 12:58:54,079: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.010522889079303972]
[2024-04-20 12:58:54,285: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.0005218229559033613]
[2024-04-20 12:58:54,491: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.0029582909543851843]
[2024-04-20 12:58:54,700: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.003810570652409612]
[2024-04-20 12:58:54,907: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.0020212559263154905]
[2024-04-20 12:58:55,112: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.0046880820339741495]
[2024-04-20 12:58:55,323: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.0008232167546095584]
[2024-04-20 12:58:55,528: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.001486105567832923]
[2024-04-20 12:58:55,740: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.005413332411536935]
[2024-04-20 12:58:55,967: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.010925312243944744]
[2024-04-20 12:58:56,186: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.003063364405035655]
[2024-04-20 12:58:56,393: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.0018896894152153508]
[2024-04-20 12:58:56,603: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.006832889267014229]
[2024-04-20 12:58:56,818: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.0034213219816325354]
[2024-04-20 12:58:57,034: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.002987986589931505]
[2024-04-20 12:58:57,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.004169498884147925]
[2024-04-20 12:58:57,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.01001368674242615]
[2024-04-20 12:58:57,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.003957929249102816]
[2024-04-20 12:58:57,874: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.0030944409964028187]
[2024-04-20 12:58:58,086: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.003130012359576101]
[2024-04-20 12:58:58,294: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.015075729175436878]
[2024-04-20 12:58:58,509: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.010228970827804646]
[2024-04-20 12:58:58,718: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.0006564387262062482]
[2024-04-20 12:58:58,928: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.00287237608836327]
[2024-04-20 12:58:59,147: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.003786641805609913]
[2024-04-20 12:58:59,362: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.014951683671801719]
[2024-04-20 12:58:59,568: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.004764707048023065]
[2024-04-20 12:58:59,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.010435081488283994]
[2024-04-20 12:58:59,983: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.021926754798462452]
[2024-04-20 12:59:00,191: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.00505475658201746]
[2024-04-20 12:59:00,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.0015986464365116547]
[2024-04-20 12:59:00,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.0038066860207821335]
[2024-04-20 12:59:00,806: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.00885255807460286]
[2024-04-20 12:59:01,010: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.011306035622443188]
[2024-04-20 12:59:01,217: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.0026081101273566745]
[2024-04-20 12:59:01,428: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.0038831354030501447]
[2024-04-20 12:59:01,635: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.030563223188722292]
[2024-04-20 12:59:01,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.020312630747599918]
[2024-04-20 12:59:02,053: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.005495163496941294]
[2024-04-20 12:59:02,258: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.008088709680422237]
[2024-04-20 12:59:02,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.01672696310692488]
[2024-04-20 12:59:02,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.005647009780631399]
[2024-04-20 12:59:02,881: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.02396281074251186]
[2024-04-20 12:59:03,086: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.006900744497572719]
[2024-04-20 12:59:03,291: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.001289828875922423]
[2024-04-20 12:59:03,497: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.00837952774136016]
[2024-04-20 12:59:03,703: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.001316936708963216]
[2024-04-20 12:59:03,910: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.002414923762353227]
[2024-04-20 12:59:04,118: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.01432250721802193]
[2024-04-20 12:59:04,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.03154666128256828]
[2024-04-20 12:59:04,534: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.0037198881860729368]
[2024-04-20 12:59:04,739: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.0038800858004676936]
[2024-04-20 12:59:04,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.0019160036716031794]
[2024-04-20 12:59:05,157: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.010685235658117645]
[2024-04-20 12:59:05,371: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.00024075210711107522]
[2024-04-20 12:59:05,579: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.00408923089129222]
[2024-04-20 12:59:05,783: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.008747641455968702]
[2024-04-20 12:59:05,988: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.0022750743602136547]
[2024-04-20 12:59:06,197: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.005546827622476779]
[2024-04-20 12:59:06,402: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.004683622573203265]
[2024-04-20 12:59:06,610: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.0026688253132564617]
[2024-04-20 12:59:06,816: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.0006080341170566646]
[2024-04-20 12:59:07,022: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.006297643698708864]
[2024-04-20 12:59:07,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.005753510252937528]
[2024-04-20 12:59:07,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.0010133901720077848]
[2024-04-20 12:59:07,647: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.0002700468238343172]
[2024-04-20 12:59:07,853: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.005589511823548621]
[2024-04-20 12:59:08,060: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.01241785612313384]
[2024-04-20 12:59:08,267: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.010969781793548938]
[2024-04-20 12:59:08,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.004262139432950144]
[2024-04-20 12:59:08,689: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.00775335084118726]
[2024-04-20 12:59:08,898: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.0031577956180408504]
[2024-04-20 12:59:09,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.014090408102352826]
[2024-04-20 12:59:09,314: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.015003786877290587]
[2024-04-20 12:59:09,528: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.0015644745056157838]
[2024-04-20 12:59:09,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.00047598939216601083]
[2024-04-20 12:59:09,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.004458467995504607]
[2024-04-20 12:59:10,154: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.0026066403004214016]
[2024-04-20 12:59:10,366: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.007641374230021254]
[2024-04-20 12:59:10,581: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.007951505021845003]
[2024-04-20 12:59:10,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.0012069613452199471]
[2024-04-20 12:59:11,006: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.006060377366177949]
[2024-04-20 12:59:11,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.008074810180776406]
[2024-04-20 12:59:11,437: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.008060107109888375]
[2024-04-20 12:59:11,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.00291235502241434]
[2024-04-20 12:59:11,869: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.004360689667739694]
[2024-04-20 12:59:12,081: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.005610367245431502]
[2024-04-20 12:59:12,303: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.005605696837742227]
[2024-04-20 12:59:12,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.01474383382111455]
[2024-04-20 12:59:12,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.036868815867726605]
[2024-04-20 12:59:12,938: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.006892326088562049]
[2024-04-20 12:59:13,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.004025694907456895]
[2024-04-20 12:59:13,364: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.006344090830007426]
[2024-04-20 12:59:13,571: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.009264731532573253]
[2024-04-20 12:59:13,779: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.015456612276784087]
[2024-04-20 12:59:13,987: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.013125817643630215]
[2024-04-20 12:59:14,199: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.006870041555601757]
[2024-04-20 12:59:14,405: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.002749061979586678]
[2024-04-20 12:59:14,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.015712368097546114]
[2024-04-20 12:59:14,816: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.005645952557951242]
[2024-04-20 12:59:15,024: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.005530531160201207]
[2024-04-20 12:59:15,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.0018272715289292432]
[2024-04-20 12:59:15,437: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.003166791050319831]
[2024-04-20 12:59:15,646: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.004560904229083174]
[2024-04-20 12:59:15,855: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.009445582301971199]
[2024-04-20 12:59:16,062: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.01444321710549891]
[2024-04-20 12:59:16,267: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.01371528969447007]
[2024-04-20 12:59:16,477: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.0033343306787123167]
[2024-04-20 12:59:16,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.01958312053437904]
[2024-04-20 12:59:16,889: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.020360059845361336]
[2024-04-20 12:59:17,095: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.01260680348380728]
[2024-04-20 12:59:17,303: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.0007771300498574656]
[2024-04-20 12:59:17,513: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.0070905002785393535]
[2024-04-20 12:59:17,720: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.02447583008889389]
[2024-04-20 12:59:17,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.0017497803622974787]
[2024-04-20 12:59:18,126: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.013350499847270275]
[2024-04-20 12:59:18,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.00820203846039141]
[2024-04-20 12:59:18,542: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.008719159662767893]
[2024-04-20 12:59:18,751: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.0025475964396770414]
[2024-04-20 12:59:18,959: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.004321323637441735]
[2024-04-20 12:59:19,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.003852664230807513]
[2024-04-20 12:59:19,379: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.014549378105790768]
[2024-04-20 12:59:19,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.015747866688842267]
[2024-04-20 12:59:19,787: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.003324389459908783]
[2024-04-20 12:59:19,993: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.001014587035046227]
[2024-04-20 12:59:20,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.007449512372303966]
[2024-04-20 12:59:20,408: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.010133512675794059]
[2024-04-20 12:59:20,619: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.005167886365151382]
[2024-04-20 12:59:20,826: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.016747785025602417]
[2024-04-20 12:59:21,032: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.0005598389669984072]
[2024-04-20 12:59:21,238: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.0008219499624569185]
[2024-04-20 12:59:21,445: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.0026043039267470555]
[2024-04-20 12:59:21,650: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.001998466215752762]
[2024-04-20 12:59:21,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.0030681771181553835]
[2024-04-20 12:59:22,061: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.0073788718219442995]
[2024-04-20 12:59:22,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.005593375095238101]
[2024-04-20 12:59:22,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.0018345210262635334]
[2024-04-20 12:59:22,682: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.007377960466034456]
[2024-04-20 12:59:22,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.0032523631372440155]
[2024-04-20 12:59:23,095: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.02014989288019913]
[2024-04-20 12:59:23,309: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.0023181072209532533]
[2024-04-20 12:59:23,525: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.002989589155650395]
[2024-04-20 12:59:23,739: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.0018184829141631692]
[2024-04-20 12:59:23,950: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.001858060319475084]
[2024-04-20 12:59:24,160: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.008574163815236643]
[2024-04-20 12:59:24,371: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.0010762976422398142]
[2024-04-20 12:59:24,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.0015145326374459405]
[2024-04-20 12:59:24,795: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.001344700284626837]
[2024-04-20 12:59:25,005: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.005952692631063963]
[2024-04-20 12:59:25,215: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.0006280466822229758]
[2024-04-20 12:59:25,423: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.008253715231173447]
[2024-04-20 12:59:25,636: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.006006064270263583]
[2024-04-20 12:59:25,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.004376181713003992]
[2024-04-20 12:59:26,062: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.0021036758224394353]
[2024-04-20 12:59:26,275: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 0.007858388950775902]
[2024-04-20 12:59:26,491: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.008406065544305669]
[2024-04-20 12:59:26,700: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.004042761447751214]
[2024-04-20 12:59:26,910: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.014849561446763977]
[2024-04-20 12:59:27,116: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.0008214279409700151]
[2024-04-20 12:59:27,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.005978981701686063]
[2024-04-20 12:59:27,534: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.0005122351753664003]
[2024-04-20 12:59:27,744: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.0020545884163653202]
[2024-04-20 12:59:27,952: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.004906725830042941]
[2024-04-20 12:59:28,164: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.0039473155725081215]
[2024-04-20 12:59:28,375: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.005747111074852283]
[2024-04-20 12:59:28,584: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.004484318857913296]
[2024-04-20 12:59:28,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.0043600951831062815]
[2024-04-20 12:59:29,001: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.00161773489161219]
[2024-04-20 12:59:29,204: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.017400479009073738]
[2024-04-20 12:59:29,410: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.007287807212019311]
[2024-04-20 12:59:29,613: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.0031821245715139375]
[2024-04-20 12:59:29,815: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.0038187745630819995]
[2024-04-20 12:59:30,022: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.004809754394850557]
[2024-04-20 12:59:30,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.007243261792132404]
[2024-04-20 12:59:30,427: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.0016796998306059232]
[2024-04-20 12:59:30,636: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.010105989387163634]
[2024-04-20 12:59:30,841: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.0038885750660699334]
[2024-04-20 12:59:31,047: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.003710797153151145]
[2024-04-20 12:59:31,251: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.004310090225019462]
[2024-04-20 12:59:31,457: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.002942113086054892]
[2024-04-20 12:59:31,666: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.009313497303199046]
[2024-04-20 12:59:31,876: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.0020061839496964776]
[2024-04-20 12:59:32,083: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.0023904233360505195]
[2024-04-20 12:59:32,290: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.009561076077037623]
[2024-04-20 12:59:32,497: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.0056751931989572225]
[2024-04-20 12:59:32,702: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.0035013090981133787]
[2024-04-20 12:59:32,907: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.009241265917814935]
[2024-04-20 12:59:33,111: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.0065716790770902755]
[2024-04-20 12:59:33,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.0038675514998804793]
[2024-04-20 12:59:33,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.00781375616118191]
[2024-04-20 12:59:33,727: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.0054917464949173185]
[2024-04-20 12:59:33,936: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.008014307309753754]
[2024-04-20 12:59:34,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.004408738272161372]
[2024-04-20 12:59:34,350: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.0007042588774743324]
[2024-04-20 12:59:34,553: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.004333179750743403]
[2024-04-20 12:59:34,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 0.00498687222508102]
[2024-04-20 12:59:34,966: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.0036425484102956523]
[2024-04-20 12:59:35,173: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 0.0023697891419488123]
[2024-04-20 12:59:35,379: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.0015441926040952751]
[2024-04-20 12:59:35,589: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.003199309710284279]
[2024-04-20 12:59:35,794: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.00899353162795818]
[2024-04-20 12:59:36,002: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.0019743177075938214]
[2024-04-20 12:59:36,210: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.007956952884281282]
[2024-04-20 12:59:36,421: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.0010186966493472554]
[2024-04-20 12:59:36,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.0012096691862198941]
[2024-04-20 12:59:36,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.0058725276601926096]
[2024-04-20 12:59:37,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 0.005798770592495617]
[2024-04-20 12:59:37,253: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.007515329570506099]
[2024-04-20 12:59:37,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.00399352234593571]
[2024-04-20 12:59:37,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.0032785791355063225]
[2024-04-20 12:59:37,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.01009774210878913]
[2024-04-20 12:59:38,100: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.015040844115107716]
[2024-04-20 12:59:38,309: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.009457020986875578]
[2024-04-20 12:59:38,521: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.014632950652719206]
[2024-04-20 12:59:38,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.0007642553851945919]
[2024-04-20 12:59:38,950: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.006416381325836299]
[2024-04-20 12:59:39,162: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.010832698493384425]
[2024-04-20 12:59:39,372: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.0021440950294850775]
[2024-04-20 12:59:39,586: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.00691524470746806]
[2024-04-20 12:59:39,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.003315141142483783]
[2024-04-20 12:59:40,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.0015745671994561578]
[2024-04-20 12:59:40,229: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.0025638334631110605]
[2024-04-20 12:59:40,440: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.005015651231132116]
[2024-04-20 12:59:40,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.005899034583688331]
[2024-04-20 12:59:40,865: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.015276097968614255]
[2024-04-20 12:59:41,073: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.01470360578725232]
[2024-04-20 12:59:41,277: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.0029307423184713436]
[2024-04-20 12:59:41,485: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.008451377814423367]
[2024-04-20 12:59:41,691: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.01724118780629432]
[2024-04-20 12:59:41,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.005294853074142944]
[2024-04-20 12:59:42,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.004859304512329317]
[2024-04-20 12:59:42,312: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.016025966104715676]
[2024-04-20 12:59:42,523: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.0006702433375409605]
[2024-04-20 12:59:42,729: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.00038995903786207757]
[2024-04-20 12:59:42,934: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.0025772534295388145]
[2024-04-20 12:59:43,142: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.01450397854389893]
[2024-04-20 12:59:43,350: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.020533256078421158]
[2024-04-20 12:59:43,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.006955161243564537]
[2024-04-20 12:59:43,761: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.01323771772987338]
[2024-04-20 12:59:43,967: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.016807337644780738]
[2024-04-20 12:59:44,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.011876287666567722]
[2024-04-20 12:59:44,377: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.004983919102852859]
[2024-04-20 12:59:44,584: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.003997918765349552]
[2024-04-20 12:59:44,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.0047519187203713805]
[2024-04-20 12:59:44,997: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.0041678847617841715]
[2024-04-20 12:59:45,202: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 0.009514213314718871]
[2024-04-20 12:59:45,408: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.016077980387448853]
[2024-04-20 12:59:45,615: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.003942195811322794]
[2024-04-20 12:59:45,823: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.0018100497619948067]
[2024-04-20 12:59:46,030: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.002116975946137245]
[2024-04-20 12:59:46,235: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.01660918811765594]
[2024-04-20 12:59:46,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.007823145342192764]
[2024-04-20 12:59:46,650: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.010290268958645864]
[2024-04-20 12:59:46,860: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.008730578153327307]
[2024-04-20 12:59:47,068: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.02671964575440524]
[2024-04-20 12:59:47,273: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.0010928478113623407]
[2024-04-20 12:59:47,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.007472780075742146]
[2024-04-20 12:59:47,685: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.007569332503430541]
[2024-04-20 12:59:47,893: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.0064511658640227275]
[2024-04-20 12:59:48,100: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.016520790561251095]
[2024-04-20 12:59:48,308: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.007222120590483946]
[2024-04-20 12:59:48,515: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.01724777088816179]
[2024-04-20 12:59:48,720: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.013584460799476377]
[2024-04-20 12:59:48,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.016400533289530356]
[2024-04-20 12:59:49,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.0034679225398874703]
[2024-04-20 12:59:49,347: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.00786748749046772]
[2024-04-20 12:59:49,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.06636897879620576]
[2024-04-20 12:59:49,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.017592242172554926]
[2024-04-20 12:59:49,968: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.01056120965390998]
[2024-04-20 12:59:50,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.003162912169218886]
[2024-04-20 12:59:50,379: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.03188834701456978]
[2024-04-20 12:59:50,587: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.008133056920613306]
[2024-04-20 12:59:50,793: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.013575766860602941]
[2024-04-20 12:59:51,004: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.0019955205160788643]
[2024-04-20 12:59:51,213: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.007079853791691885]
[2024-04-20 12:59:51,422: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.01024884476572021]
[2024-04-20 12:59:51,635: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.008198272969678493]
[2024-04-20 12:59:51,848: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.012426342744346239]
[2024-04-20 12:59:52,060: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.042628227195534336]
[2024-04-20 12:59:52,272: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.00988533978580765]
[2024-04-20 12:59:52,483: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.0034554710397852895]
[2024-04-20 12:59:52,695: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.003462707253125923]
[2024-04-20 12:59:52,907: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.03561850870601057]
[2024-04-20 12:59:53,116: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.004925325299669554]
[2024-04-20 12:59:53,328: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.00293508900568053]
[2024-04-20 12:59:53,539: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.0030773657796420743]
[2024-04-20 12:59:53,750: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.02997920769505822]
[2024-04-20 12:59:53,964: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.014423925465616612]
[2024-04-20 12:59:54,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.017682379032230612]
[2024-04-20 12:59:54,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.017885293266918796]
[2024-04-20 12:59:54,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.0020794232952889512]
[2024-04-20 12:59:54,809: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.014649748347454295]
[2024-04-20 12:59:55,016: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.015473803047480405]
[2024-04-20 12:59:55,223: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.0020428158538370986]
[2024-04-20 12:59:55,434: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.01195828627925224]
[2024-04-20 12:59:55,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.007450419731388263]
[2024-04-20 12:59:55,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.042527676796315105]
[2024-04-20 12:59:56,056: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.009951528469288205]
[2024-04-20 12:59:56,261: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.013088131904256211]
[2024-04-20 12:59:56,468: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.009456328229991035]
[2024-04-20 12:59:56,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.02401398874124449]
[2024-04-20 12:59:56,882: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.01338622530250368]
[2024-04-20 12:59:57,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.0021607389758971944]
[2024-04-20 12:59:57,292: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.03405241436970275]
[2024-04-20 12:59:57,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.01262944304594331]
[2024-04-20 12:59:57,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.013762118421643935]
[2024-04-20 12:59:57,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.005598207154680271]
[2024-04-20 12:59:58,120: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.008839069042572253]
[2024-04-20 12:59:58,329: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.007140266122993628]
[2024-04-20 12:59:58,537: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.021277366467209125]
[2024-04-20 12:59:58,741: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.013739457912093687]
[2024-04-20 12:59:58,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.015288470792453879]
[2024-04-20 12:59:59,154: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.009520237729703285]
[2024-04-20 12:59:59,362: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.005620559295501963]
[2024-04-20 12:59:59,569: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.016421539217195757]
[2024-04-20 12:59:59,777: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.010945230647791073]
[2024-04-20 12:59:59,983: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.008688596133787418]
[2024-04-20 13:00:00,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.010529630550401724]
[2024-04-20 13:00:00,389: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.005639080423506804]
[2024-04-20 13:00:00,595: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.0042131984937509945]
[2024-04-20 13:00:00,802: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.00416515772172697]
[2024-04-20 13:00:01,010: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.010057519674499624]
[2024-04-20 13:00:01,217: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.027324282908191787]
[2024-04-20 13:00:01,422: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.004065162213158548]
[2024-04-20 13:00:01,629: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.005342001302809672]
[2024-04-20 13:00:01,833: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.004664698047234928]
[2024-04-20 13:00:02,043: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.0054774287611047846]
[2024-04-20 13:00:02,251: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.004262954350659327]
[2024-04-20 13:00:02,459: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.00624018332290212]
[2024-04-20 13:00:02,666: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.007029965259972038]
[2024-04-20 13:00:02,873: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.0143606850597181]
[2024-04-20 13:00:03,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.00957021794400837]
[2024-04-20 13:00:03,285: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.006795683231558363]
[2024-04-20 13:00:03,495: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.004563697348551727]
[2024-04-20 13:00:03,702: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.007913690465356287]
[2024-04-20 13:00:03,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.0012342227607310416]
[2024-04-20 13:00:04,115: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.0036653864568122257]
[2024-04-20 13:00:04,324: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.005560072942577761]
[2024-04-20 13:00:04,532: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.005024002364616186]
[2024-04-20 13:00:04,748: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.004597114467402416]
[2024-04-20 13:00:04,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.002279633472734497]
[2024-04-20 13:00:05,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.005167637087189425]
[2024-04-20 13:00:05,379: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.0031306188816665474]
[2024-04-20 13:00:05,595: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.007381361512059048]
[2024-04-20 13:00:05,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.001310793017993948]
[2024-04-20 13:00:06,022: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.028863848225109318]
[2024-04-20 13:00:06,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.0085591587982299]
[2024-04-20 13:00:06,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.005816949573799197]
[2024-04-20 13:00:06,657: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.00740476847211112]
[2024-04-20 13:00:06,867: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.005898989761260804]
[2024-04-20 13:00:07,077: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.012538335175480971]
[2024-04-20 13:00:07,288: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.01895631181893991]
[2024-04-20 13:00:07,500: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 0.00847931888635527]
[2024-04-20 13:00:07,708: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.009128190346348753]
[2024-04-20 13:00:07,920: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.017068931035881762]
[2024-04-20 13:00:08,132: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.0050007221497323975]
[2024-04-20 13:00:08,353: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.009359350544736574]
[2024-04-20 13:00:08,571: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.0062034157917280446]
[2024-04-20 13:00:08,776: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.007590062516744115]
[2024-04-20 13:00:08,983: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.0027261307472844615]
[2024-04-20 13:00:09,191: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.012292271914899207]
[2024-04-20 13:00:09,403: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.005518888615450395]
[2024-04-20 13:00:09,608: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.0076652617458321]
[2024-04-20 13:00:09,816: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.0014838884920362993]
[2024-04-20 13:00:10,023: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.0006516853424615911]
[2024-04-20 13:00:10,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.0035782566126838504]
[2024-04-20 13:00:10,440: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.006155556458489578]
[2024-04-20 13:00:10,645: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.003259968323075603]
[2024-04-20 13:00:10,850: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.000897635581887042]
[2024-04-20 13:00:11,058: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.00781353629183718]
[2024-04-20 13:00:11,265: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.0002586895392889114]
[2024-04-20 13:00:11,470: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.016194228762057065]
[2024-04-20 13:00:11,677: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.004954429793728023]
[2024-04-20 13:00:11,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.009603686388617503]
[2024-04-20 13:00:12,093: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.005984798534958515]
[2024-04-20 13:00:12,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.008832069705603927]
[2024-04-20 13:00:12,508: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.006635194480495307]
[2024-04-20 13:00:12,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.004076792772375515]
[2024-04-20 13:00:12,927: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.009300331927783602]
[2024-04-20 13:00:13,136: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.009268706494199443]
[2024-04-20 13:00:13,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.008618137503835433]
[2024-04-20 13:00:13,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.013767721199938215]
[2024-04-20 13:00:13,761: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.0036436386675921476]
[2024-04-20 13:00:13,968: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.014532491887365785]
[2024-04-20 13:00:14,174: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.00778593747819586]
[2024-04-20 13:00:14,380: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.014799010606416122]
[2024-04-20 13:00:14,585: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.003577791111322973]
[2024-04-20 13:00:14,791: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.016972844754203763]
[2024-04-20 13:00:14,995: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.002281596789189717]
[2024-04-20 13:00:15,209: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.007444810525501194]
[2024-04-20 13:00:15,419: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.0280919300065647]
[2024-04-20 13:00:15,636: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.009339920257510572]
[2024-04-20 13:00:15,848: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.00034973660502356864]
[2024-04-20 13:00:16,077: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.006911810007736056]
[2024-04-20 13:00:16,287: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.00699753759621294]
[2024-04-20 13:00:16,499: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.0025448310967519858]
[2024-04-20 13:00:16,710: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.006516764346999229]
[2024-04-20 13:00:16,920: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.017995043992903845]
[2024-04-20 13:00:17,132: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.0056270218146826706]
[2024-04-20 13:00:17,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.004406530170015256]
[2024-04-20 13:00:17,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.016808472547803235]
[2024-04-20 13:00:17,762: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.00908494667503316]
[2024-04-20 13:00:17,973: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.01348138468768426]
[2024-04-20 13:00:18,183: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.0003932597336953771]
[2024-04-20 13:00:18,398: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.007578737469322065]
[2024-04-20 13:00:18,619: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.03230446086528196]
[2024-04-20 13:00:18,834: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.010947806510163029]
[2024-04-20 13:00:19,045: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.004476145811352426]
[2024-04-20 13:00:19,261: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.0028746283767917095]
[2024-04-20 13:00:19,471: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.005291448165985631]
[2024-04-20 13:00:19,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.0007211740698508345]
[2024-04-20 13:00:19,893: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.03930525660679439]
[2024-04-20 13:00:20,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.011669439775400064]
[2024-04-20 13:00:20,321: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.0070595668239552874]
[2024-04-20 13:00:20,534: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.02933427627187814]
[2024-04-20 13:00:20,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.004338642820391028]
[2024-04-20 13:00:20,961: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.001484816205124941]
[2024-04-20 13:00:21,173: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.0040949390634324075]
[2024-04-20 13:00:21,384: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.0011318341280069982]
[2024-04-20 13:00:21,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.012642148518624843]
[2024-04-20 13:00:21,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.0011813929915527922]
[2024-04-20 13:00:22,024: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.006018782709850872]
[2024-04-20 13:00:22,236: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.020245959969237826]
[2024-04-20 13:00:22,455: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.006479196536338561]
[2024-04-20 13:00:22,668: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.003988454062941409]
[2024-04-20 13:00:22,879: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.0013183049814865697]
[2024-04-20 13:00:23,085: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 0.0038261157540069334]
[2024-04-20 13:00:23,289: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.02257629650662278]
[2024-04-20 13:00:23,498: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.0182137263670046]
[2024-04-20 13:00:23,703: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.00281315109058783]
[2024-04-20 13:00:23,910: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.0012246916004050293]
[2024-04-20 13:00:24,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.006865831757852179]
[2024-04-20 13:00:24,323: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.0021047839796135633]
[2024-04-20 13:00:24,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.0017876991857585468]
[2024-04-20 13:00:24,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.007140566739115675]
[2024-04-20 13:00:24,945: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.004006498320406716]
[2024-04-20 13:00:25,153: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.023944955820569113]
[2024-04-20 13:00:25,362: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.0045969720828472685]
[2024-04-20 13:00:25,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 0.0018487639596143338]
[2024-04-20 13:00:25,775: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.005392261312354272]
[2024-04-20 13:00:25,986: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.003889816020929316]
[2024-04-20 13:00:26,199: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.0024466252744194854]
[2024-04-20 13:00:26,405: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.001477244290627648]
[2024-04-20 13:00:26,613: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.004595506562268374]
[2024-04-20 13:00:26,821: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.011133877396540261]
[2024-04-20 13:00:27,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.004311044678345232]
[2024-04-20 13:00:27,236: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.005822437013226756]
[2024-04-20 13:00:27,444: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.004774684145951025]
[2024-04-20 13:00:27,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.0007213086084279298]
[2024-04-20 13:00:27,859: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.006206074867546667]
[2024-04-20 13:00:28,067: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.010030023603345043]
[2024-04-20 13:00:28,274: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.0016246666597876864]
[2024-04-20 13:00:28,481: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.0012444899935652358]
[2024-04-20 13:00:28,688: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.001294549877435813]
[2024-04-20 13:00:28,900: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.006231582574635406]
[2024-04-20 13:00:29,109: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.0023654340921008482]
[2024-04-20 13:00:29,317: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.0029088350892251037]
[2024-04-20 13:00:29,524: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.0022226515044661763]
[2024-04-20 13:00:29,732: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.01478937396662454]
[2024-04-20 13:00:29,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.06181127191680031]
[2024-04-20 13:00:30,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.0058313138931969264]
[2024-04-20 13:00:30,356: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.00922093605210647]
[2024-04-20 13:00:30,563: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.0014346589433376035]
[2024-04-20 13:00:30,770: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.00023222315473376992]
[2024-04-20 13:00:30,983: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.014678824402375324]
[2024-04-20 13:00:31,191: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.0033923967595658956]
[2024-04-20 13:00:31,395: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.008621984837433936]
[2024-04-20 13:00:31,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.004769367169348294]
[2024-04-20 13:00:31,811: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.005124054920071125]
[2024-04-20 13:00:32,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.002038501561053764]
[2024-04-20 13:00:32,225: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.008913114874032917]
[2024-04-20 13:00:32,433: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.0009946112802108691]
[2024-04-20 13:00:32,640: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.015259449742889003]
[2024-04-20 13:00:32,853: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.001848979349230232]
[2024-04-20 13:00:33,064: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.00033900244669075164]
[2024-04-20 13:00:33,285: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.0026722404608234026]
[2024-04-20 13:00:33,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.008050562172670694]
[2024-04-20 13:00:33,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.005425345040020774]
[2024-04-20 13:00:33,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.0022265724592689345]
[2024-04-20 13:00:34,134: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.005444433126003107]
[2024-04-20 13:00:34,340: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.012008775699803343]
[2024-04-20 13:00:34,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.005786811216743502]
[2024-04-20 13:00:34,764: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.0024642368823369594]
[2024-04-20 13:00:34,972: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.01005581162051783]
[2024-04-20 13:00:35,192: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.012805292019187418]
[2024-04-20 13:00:35,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.00041509026563082047]
[2024-04-20 13:00:35,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.0019643642039886226]
[2024-04-20 13:00:35,845: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.013187557408788186]
[2024-04-20 13:00:36,058: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.005908648249235999]
[2024-04-20 13:00:36,270: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.0033014510500329972]
[2024-04-20 13:00:36,486: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.001532779468381804]
[2024-04-20 13:00:36,691: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.0010500009589321964]
[2024-04-20 13:00:36,895: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.001810730568183415]
[2024-04-20 13:00:37,098: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.0007247297258892839]
[2024-04-20 13:00:37,307: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.0007990807130524729]
[2024-04-20 13:00:37,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.0021282012090724054]
[2024-04-20 13:00:37,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.002525472156228786]
[2024-04-20 13:00:37,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.0039242782968843554]
[2024-04-20 13:00:38,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.003668304793374047]
[2024-04-20 13:00:38,364: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.0001846326595752854]
[2024-04-20 13:00:38,580: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.0025503040844354822]
[2024-04-20 13:00:38,790: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.015139166680558057]
[2024-04-20 13:00:38,996: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.018224814793399043]
[2024-04-20 13:00:39,200: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.001290332484687644]
[2024-04-20 13:00:39,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.002869471106541084]
[2024-04-20 13:00:39,632: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.004079165495725215]
[2024-04-20 13:00:39,853: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.0046501946846167755]
[2024-04-20 13:00:40,061: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.0010515751594672097]
[2024-04-20 13:00:40,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.01165533426387574]
[2024-04-20 13:00:40,491: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.0028087705108881863]
[2024-04-20 13:00:40,713: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.008274559935652813]
[2024-04-20 13:00:40,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.012977816766670197]
[2024-04-20 13:00:41,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.017864183789693917]
[2024-04-20 13:00:41,369: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.0017111634434262815]
[2024-04-20 13:00:41,590: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.012711248946488314]
[2024-04-20 13:00:41,803: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.0017243894232764373]
[2024-04-20 13:00:42,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.0026273680277713075]
[2024-04-20 13:00:42,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.011721855748549139]
[2024-04-20 13:00:42,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.000573598133310456]
[2024-04-20 13:00:42,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.0042895453192784]
[2024-04-20 13:00:42,855: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.0009893458757152466]
[2024-04-20 13:00:43,065: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.002809350683793459]
[2024-04-20 13:00:43,270: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.0010626735061290324]
[2024-04-20 13:00:43,481: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.0032585532370778838]
[2024-04-20 13:00:43,690: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.007545656793465769]
[2024-04-20 13:00:43,902: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.0028633795324647846]
[2024-04-20 13:00:44,111: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.004937220348311967]
[2024-04-20 13:00:44,329: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.012074442372531087]
[2024-04-20 13:00:44,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.0033845745837740786]
[2024-04-20 13:00:44,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.0007216612480854246]
[2024-04-20 13:00:44,962: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.0010239429263455234]
[2024-04-20 13:00:45,166: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.004399126158185105]
[2024-04-20 13:00:45,370: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.0002310475668993526]
[2024-04-20 13:00:45,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.007186513270697469]
[2024-04-20 13:00:45,787: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.001416879970953293]
[2024-04-20 13:00:45,997: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.011565522101586189]
[2024-04-20 13:00:46,203: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.005551192854496777]
[2024-04-20 13:00:46,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.012004152294629611]
[2024-04-20 13:00:46,631: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.002584973318401824]
[2024-04-20 13:00:46,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.004530442228207078]
[2024-04-20 13:00:47,056: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.0008912235682912615]
[2024-04-20 13:00:47,272: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.004638412067971567]
[2024-04-20 13:00:47,484: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.003756101465351182]
[2024-04-20 13:00:47,695: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.002002215825138916]
[2024-04-20 13:00:47,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.0038553114934185735]
[2024-04-20 13:00:48,123: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.006909011126568958]
[2024-04-20 13:00:48,331: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.0019131813147292623]
[2024-04-20 13:00:48,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.0013990013510707781]
[2024-04-20 13:00:48,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.0035026276821461663]
[2024-04-20 13:00:48,960: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.0014392151171789688]
[2024-04-20 13:00:49,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.0019052112253075536]
[2024-04-20 13:00:49,386: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.007201236081583087]
[2024-04-20 13:00:49,600: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.004637797587837023]
[2024-04-20 13:00:49,811: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.0007347894834613341]
[2024-04-20 13:00:50,018: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 9.133598524969749e-05]
[2024-04-20 13:00:50,227: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.004241041790385719]
[2024-04-20 13:00:50,437: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.004702121062860172]
[2024-04-20 13:00:50,648: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.00040512113901179295]
[2024-04-20 13:00:50,854: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.0001481621415275047]
[2024-04-20 13:00:51,052: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.005789472113766164]
[2024-04-20 13:00:51,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.0031357828280787533]
[2024-04-20 13:00:51,446: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 0.0008790240942368409]
[2024-04-20 13:01:16,006: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9955695172905173, 'precision': 0.8079613379117385, 'recall': 0.9082850811351776, 'f1': 0.855190980986034}]
[2024-04-20 13:01:16,016: INFO: roberta_kFold_initial_lstm: Fold 2/3 , Epoch: 3/3]
[2024-04-20 13:01:16,724: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.0031279231575811976]
[2024-04-20 13:01:17,370: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.0018740642919171612]
[2024-04-20 13:01:18,021: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.005572381947461323]
[2024-04-20 13:01:18,678: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.004612375985446155]
[2024-04-20 13:01:19,314: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.012876212369661324]
[2024-04-20 13:01:19,960: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.014524114643574403]
[2024-04-20 13:01:20,604: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.00787857603253627]
[2024-04-20 13:01:21,246: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.0007506340272438794]
[2024-04-20 13:01:21,890: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.012066598503379562]
[2024-04-20 13:01:22,533: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.010613509647173697]
[2024-04-20 13:01:23,183: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.005966048240935937]
[2024-04-20 13:01:23,841: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.011060192669922564]
[2024-04-20 13:01:24,489: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.004275466143739063]
[2024-04-20 13:01:25,140: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.002926835303722156]
[2024-04-20 13:01:25,790: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.00065364187811085]
[2024-04-20 13:01:26,441: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.015089705224520212]
[2024-04-20 13:01:27,096: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.0005839943230324366]
[2024-04-20 13:01:27,750: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.009020717613316168]
[2024-04-20 13:01:28,408: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.003910314971429194]
[2024-04-20 13:01:29,070: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.004338368794508152]
[2024-04-20 13:01:29,739: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.010013304852059634]
[2024-04-20 13:01:30,400: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.008949841611583253]
[2024-04-20 13:01:31,061: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.0007534489080487151]
[2024-04-20 13:01:31,735: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.00912673176634702]
[2024-04-20 13:01:32,401: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.017372671550691728]
[2024-04-20 13:01:33,061: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.024734104338121385]
[2024-04-20 13:01:33,731: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.022355355936755347]
[2024-04-20 13:01:34,400: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.001767100346984385]
[2024-04-20 13:01:35,075: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.0027673625778063763]
[2024-04-20 13:01:35,741: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.0048437326462455015]
[2024-04-20 13:01:36,422: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.008310079145846033]
[2024-04-20 13:01:37,082: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.00919726106690823]
[2024-04-20 13:01:37,749: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.007479105338644404]
[2024-04-20 13:01:38,431: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.003582066322994532]
[2024-04-20 13:01:39,105: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.003677476554615802]
[2024-04-20 13:01:39,780: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.00607357762361091]
[2024-04-20 13:01:40,453: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.0046617619759596884]
[2024-04-20 13:01:41,126: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.024467009392053513]
[2024-04-20 13:01:41,799: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.004934926239463669]
[2024-04-20 13:01:42,487: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.035789039455948454]
[2024-04-20 13:01:43,176: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.009780819583304913]
[2024-04-20 13:01:43,870: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.004202156008683699]
[2024-04-20 13:01:44,561: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.008154579373289643]
[2024-04-20 13:01:45,253: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.020810574785172176]
[2024-04-20 13:01:45,948: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.004135415482752462]
[2024-04-20 13:01:46,630: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.007432793919812168]
[2024-04-20 13:01:47,313: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.00430017537927701]
[2024-04-20 13:01:47,987: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.0018959401551334803]
[2024-04-20 13:01:48,669: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.0033565677729009208]
[2024-04-20 13:01:49,346: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.007383154551798862]
[2024-04-20 13:01:50,028: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.014065754242718395]
[2024-04-20 13:01:50,710: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.002981174286125052]
[2024-04-20 13:01:51,388: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.00762178607356176]
[2024-04-20 13:01:52,063: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.008600226227983045]
[2024-04-20 13:01:52,739: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.014039381793701046]
[2024-04-20 13:01:53,421: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.0033283166965281984]
[2024-04-20 13:01:54,100: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.002348082912748966]
[2024-04-20 13:01:54,775: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.007731962941255879]
[2024-04-20 13:01:55,450: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.0014079303385356103]
[2024-04-20 13:01:56,124: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.006186285700555529]
[2024-04-20 13:01:56,804: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.021375484183371644]
[2024-04-20 13:01:57,475: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.007173810204568674]
[2024-04-20 13:01:58,150: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.0026001007520101765]
[2024-04-20 13:01:58,845: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.007702845813152087]
[2024-04-20 13:01:59,524: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.0026190066034769556]
[2024-04-20 13:02:00,190: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.003721235135506435]
[2024-04-20 13:02:00,853: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.0022246964334154133]
[2024-04-20 13:02:01,519: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.010409404490954394]
[2024-04-20 13:02:02,182: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.01481136290104879]
[2024-04-20 13:02:02,846: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.024471209806552634]
[2024-04-20 13:02:03,507: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.0007858193228612376]
[2024-04-20 13:02:04,169: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.0011522824569058258]
[2024-04-20 13:02:04,832: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.01950293166144671]
[2024-04-20 13:02:05,492: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.0027202765609130194]
[2024-04-20 13:02:06,151: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.005548798929807288]
[2024-04-20 13:02:06,810: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.0011889602827245365]
[2024-04-20 13:02:07,468: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.007724508553404874]
[2024-04-20 13:02:08,126: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.004859115163841585]
[2024-04-20 13:02:08,781: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.005663457033001286]
[2024-04-20 13:02:09,441: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.002460011078714044]
[2024-04-20 13:02:10,103: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.007310178223982393]
[2024-04-20 13:02:10,761: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.00207091578505668]
[2024-04-20 13:02:11,427: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.006852017178543817]
[2024-04-20 13:02:12,095: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.01842123911337082]
[2024-04-20 13:02:12,769: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.004091019499966567]
[2024-04-20 13:02:13,425: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.004484976313597753]
[2024-04-20 13:02:14,078: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.0014013139705378668]
[2024-04-20 13:02:14,733: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.010610973109452342]
[2024-04-20 13:02:15,385: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.016370566391059306]
[2024-04-20 13:02:16,035: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.007625132444363381]
[2024-04-20 13:02:16,686: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.006711003973639166]
[2024-04-20 13:02:17,334: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.006591936629372843]
[2024-04-20 13:02:17,985: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.020687777323261557]
[2024-04-20 13:02:18,636: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.002771931997992686]
[2024-04-20 13:02:19,287: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.004726039299501387]
[2024-04-20 13:02:19,937: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.004837840785916841]
[2024-04-20 13:02:20,590: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.003178272452712891]
[2024-04-20 13:02:21,235: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.006549156540557103]
[2024-04-20 13:02:21,885: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.0031007270963650966]
[2024-04-20 13:02:22,538: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.004731663157998622]
[2024-04-20 13:02:23,196: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.0007596220207252086]
[2024-04-20 13:02:23,868: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.0038127260735111054]
[2024-04-20 13:02:24,525: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.008792860394051855]
[2024-04-20 13:02:25,187: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.009100522710862756]
[2024-04-20 13:02:25,845: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.0028647836860361234]
[2024-04-20 13:02:26,511: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.00038052573926977695]
[2024-04-20 13:02:27,164: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.021471411920603402]
[2024-04-20 13:02:27,814: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.0017098781265008957]
[2024-04-20 13:02:28,467: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.005240834561130542]
[2024-04-20 13:02:29,113: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.01000547523034466]
[2024-04-20 13:02:29,757: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.00994765608764042]
[2024-04-20 13:02:30,400: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.02414458309410362]
[2024-04-20 13:02:31,050: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.010961585922308384]
[2024-04-20 13:02:31,694: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.0011703747184340614]
[2024-04-20 13:02:32,342: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.005538494954975851]
[2024-04-20 13:02:32,989: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.010023620614270925]
[2024-04-20 13:02:33,639: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.006025254693327502]
[2024-04-20 13:02:34,289: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.0037285605579974283]
[2024-04-20 13:02:34,937: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.009504472984514116]
[2024-04-20 13:02:35,589: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.0022435915931476647]
[2024-04-20 13:02:36,237: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.009608902677976481]
[2024-04-20 13:02:36,883: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.006954013802337128]
[2024-04-20 13:02:37,540: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.005294331564399007]
[2024-04-20 13:02:38,196: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.003287125357460939]
[2024-04-20 13:02:38,855: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.00575219648555958]
[2024-04-20 13:02:39,519: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.007390484460198561]
[2024-04-20 13:02:40,180: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.012016039867931799]
[2024-04-20 13:02:40,832: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.01875917523316334]
[2024-04-20 13:02:41,482: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.0030181363119047514]
[2024-04-20 13:02:42,127: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.008182882667983163]
[2024-04-20 13:02:42,777: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.0004181408909882563]
[2024-04-20 13:02:43,430: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.009860211154517082]
[2024-04-20 13:02:44,084: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.0016274654159288014]
[2024-04-20 13:02:44,733: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.004408404345754226]
[2024-04-20 13:02:45,390: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.021811785053336204]
[2024-04-20 13:02:46,038: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.007836773950865673]
[2024-04-20 13:02:46,689: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.0013153107948012089]
[2024-04-20 13:02:47,338: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.00958070336756618]
[2024-04-20 13:02:47,991: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.009739568933467039]
[2024-04-20 13:02:48,641: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.008688368755962902]
[2024-04-20 13:02:49,293: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.0042702288970298125]
[2024-04-20 13:02:49,942: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.00229867423033655]
[2024-04-20 13:02:50,600: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.006350177716994222]
[2024-04-20 13:02:51,265: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.004992905173062549]
[2024-04-20 13:02:51,927: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.0050411864954845575]
[2024-04-20 13:02:52,587: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.005623796554628573]
[2024-04-20 13:02:53,249: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.007608500710530198]
[2024-04-20 13:02:53,917: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.0076756444128937866]
[2024-04-20 13:02:54,573: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.011564392001137732]
[2024-04-20 13:02:55,228: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.009399122723331358]
[2024-04-20 13:02:55,879: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.004027561716696562]
[2024-04-20 13:02:56,538: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.002701579364025691]
[2024-04-20 13:02:57,192: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.0030129535183270367]
[2024-04-20 13:02:57,850: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.012311775549160105]
[2024-04-20 13:02:58,505: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.0034014660444588968]
[2024-04-20 13:02:59,166: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.006823272991706904]
[2024-04-20 13:02:59,826: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.0006708917646805735]
[2024-04-20 13:03:00,484: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.008631239389620952]
[2024-04-20 13:03:01,146: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.012470916428247237]
[2024-04-20 13:03:01,804: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.003253542866311894]
[2024-04-20 13:03:02,459: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.006421828449308748]
[2024-04-20 13:03:03,113: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.007527753311461343]
[2024-04-20 13:03:03,774: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.001693281506844498]
[2024-04-20 13:03:04,439: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.0018307274929484035]
[2024-04-20 13:03:05,115: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.00023459736773752106]
[2024-04-20 13:03:05,792: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.0058920719133625865]
[2024-04-20 13:03:06,463: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.0037582237915823008]
[2024-04-20 13:03:07,130: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.0013819254260433022]
[2024-04-20 13:03:07,793: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.0016799569553372269]
[2024-04-20 13:03:08,457: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.011123041936968461]
[2024-04-20 13:03:09,117: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.0024641348392090943]
[2024-04-20 13:03:09,773: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.005400686752523722]
[2024-04-20 13:03:10,434: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.009702298228712023]
[2024-04-20 13:03:11,093: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.003379099071247216]
[2024-04-20 13:03:11,757: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.001699870605762363]
[2024-04-20 13:03:12,422: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.005695730426616521]
[2024-04-20 13:03:13,087: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.0035271751737543356]
[2024-04-20 13:03:13,749: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.0016011359349835084]
[2024-04-20 13:03:14,412: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.009619259710550917]
[2024-04-20 13:03:15,075: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.0011783837050300886]
[2024-04-20 13:03:15,735: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.01045301311767452]
[2024-04-20 13:03:16,399: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.01393652735026373]
[2024-04-20 13:03:17,057: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.01641439692038232]
[2024-04-20 13:03:17,726: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.0049448751606343275]
[2024-04-20 13:03:18,392: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.016079714703607546]
[2024-04-20 13:03:19,064: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.00525723739338279]
[2024-04-20 13:03:19,729: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.008669975788606534]
[2024-04-20 13:03:20,394: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.001451420181747145]
[2024-04-20 13:03:21,072: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.014067380388319046]
[2024-04-20 13:03:21,740: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.0006369326153441182]
[2024-04-20 13:03:22,399: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.008110192040995706]
[2024-04-20 13:03:23,061: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.0022278517915464923]
[2024-04-20 13:03:23,717: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.005148657409199895]
[2024-04-20 13:03:24,377: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.006992013002270923]
[2024-04-20 13:03:25,038: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.01878996589117392]
[2024-04-20 13:03:25,698: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.006807991228417403]
[2024-04-20 13:03:26,363: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.0023352741212443805]
[2024-04-20 13:03:27,024: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.003885246128955279]
[2024-04-20 13:03:27,692: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.011149198196724046]
[2024-04-20 13:03:28,353: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.007583261213992306]
[2024-04-20 13:03:29,012: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.0034155907787659784]
[2024-04-20 13:03:29,674: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.007978105752597494]
[2024-04-20 13:03:30,340: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.004383389221819256]
[2024-04-20 13:03:31,002: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.012870491798618478]
[2024-04-20 13:03:31,683: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.020603004396929258]
[2024-04-20 13:03:32,355: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.007517165003372448]
[2024-04-20 13:03:33,022: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.006054127825964381]
[2024-04-20 13:03:33,690: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.0003888745270883413]
[2024-04-20 13:03:34,354: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.0004794707275749289]
[2024-04-20 13:03:35,022: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.0035731754018501777]
[2024-04-20 13:03:35,688: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.0021920695654912997]
[2024-04-20 13:03:36,352: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.006707974623216791]
[2024-04-20 13:03:37,007: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.019082120781093184]
[2024-04-20 13:03:37,668: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.015246243215458335]
[2024-04-20 13:03:38,323: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.0054753831521843375]
[2024-04-20 13:03:38,978: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.003505894270173821]
[2024-04-20 13:03:39,634: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.014013586071953618]
[2024-04-20 13:03:40,292: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.005227221148364683]
[2024-04-20 13:03:40,950: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.01692614151505626]
[2024-04-20 13:03:41,608: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.0041961544864852545]
[2024-04-20 13:03:42,263: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.0057522629071146076]
[2024-04-20 13:03:42,917: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.008795398701965364]
[2024-04-20 13:03:43,572: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.004063637811789579]
[2024-04-20 13:03:44,231: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.0016175153229518137]
[2024-04-20 13:03:44,885: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.010100869943311767]
[2024-04-20 13:03:45,551: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.004064192101332152]
[2024-04-20 13:03:46,221: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.0028679153811102804]
[2024-04-20 13:03:46,882: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.0010320096873372006]
[2024-04-20 13:03:47,545: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.005323112021374364]
[2024-04-20 13:03:48,206: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.0019059973067990657]
[2024-04-20 13:03:48,864: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.0003507526261799677]
[2024-04-20 13:03:49,520: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.0022012524944925106]
[2024-04-20 13:03:50,181: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.0023727798195132353]
[2024-04-20 13:03:50,854: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.01714725799196768]
[2024-04-20 13:03:51,522: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.010409290712812474]
[2024-04-20 13:03:52,195: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.0032164496680560633]
[2024-04-20 13:03:52,869: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.0008873553982758244]
[2024-04-20 13:03:53,530: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.011355357826649235]
[2024-04-20 13:03:54,181: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.0029250520861743394]
[2024-04-20 13:03:54,836: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.007775120204738504]
[2024-04-20 13:03:55,491: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.004455813479914055]
[2024-04-20 13:03:56,144: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.008661261951289528]
[2024-04-20 13:03:56,800: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.0012254145236356949]
[2024-04-20 13:03:57,454: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.005281408743277363]
[2024-04-20 13:03:58,107: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.00035073534170763866]
[2024-04-20 13:03:58,762: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.005638808108531605]
[2024-04-20 13:03:59,422: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.01350671026913117]
[2024-04-20 13:04:00,085: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.011221164774609878]
[2024-04-20 13:04:00,745: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.019488796689868006]
[2024-04-20 13:04:01,403: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.012073664977605059]
[2024-04-20 13:04:02,063: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.006641279764972973]
[2024-04-20 13:04:02,715: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.0017450842205872347]
[2024-04-20 13:04:03,369: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.006150939239310481]
[2024-04-20 13:04:04,022: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.00669175578224986]
[2024-04-20 13:04:04,672: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.008263494209891923]
[2024-04-20 13:04:05,323: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.008832950053642374]
[2024-04-20 13:04:05,976: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.0073618197877088655]
[2024-04-20 13:04:06,630: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.0021472091543127425]
[2024-04-20 13:04:07,284: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.0016246178003496228]
[2024-04-20 13:04:07,939: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.010545249418795309]
[2024-04-20 13:04:08,591: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.006421243668478033]
[2024-04-20 13:04:09,244: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.01525080248499885]
[2024-04-20 13:04:09,902: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.0017333793530568936]
[2024-04-20 13:04:10,553: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.001205533448102892]
[2024-04-20 13:04:11,204: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.005176716776407639]
[2024-04-20 13:04:11,853: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.014419469165323547]
[2024-04-20 13:04:12,510: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.0019395297166923057]
[2024-04-20 13:04:13,180: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.004886782789639931]
[2024-04-20 13:04:13,849: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.010842020354171159]
[2024-04-20 13:04:14,510: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.008334052726526965]
[2024-04-20 13:04:15,176: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.0033881628486343743]
[2024-04-20 13:04:15,836: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.0023049995578738637]
[2024-04-20 13:04:16,488: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.004121936855164795]
[2024-04-20 13:04:17,138: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.03166978753467852]
[2024-04-20 13:04:17,789: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.002065183525950431]
[2024-04-20 13:04:18,436: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.004704320690754353]
[2024-04-20 13:04:19,088: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.001322548034261963]
[2024-04-20 13:04:19,740: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.00857133355686577]
[2024-04-20 13:04:20,393: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.0005491680953198654]
[2024-04-20 13:04:21,042: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.005131035599370546]
[2024-04-20 13:04:21,696: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.011683912502388356]
[2024-04-20 13:04:22,348: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.015895803567711513]
[2024-04-20 13:04:22,998: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.003675878119022221]
[2024-04-20 13:04:23,652: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.005298350851262918]
[2024-04-20 13:04:24,305: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.004223472478579757]
[2024-04-20 13:04:24,959: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.008058451556733282]
[2024-04-20 13:04:25,612: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.0004446733556079471]
[2024-04-20 13:04:26,273: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.0038002453649904765]
[2024-04-20 13:04:26,931: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.0048772595318674825]
[2024-04-20 13:04:27,595: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.006438635580687243]
[2024-04-20 13:04:28,253: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.008624823620377677]
[2024-04-20 13:04:28,910: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.0028280928355352494]
[2024-04-20 13:04:29,574: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.008463422494223542]
[2024-04-20 13:04:30,226: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.004976170592535945]
[2024-04-20 13:04:30,882: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.004745519792218255]
[2024-04-20 13:04:31,534: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.008226088617579737]
[2024-04-20 13:04:32,188: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.003838746376794188]
[2024-04-20 13:04:32,843: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.0051482075278938685]
[2024-04-20 13:04:33,499: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.002020032803043994]
[2024-04-20 13:04:34,150: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.0022910367278682225]
[2024-04-20 13:04:34,807: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.01026308551482662]
[2024-04-20 13:04:35,462: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.004738001668309972]
[2024-04-20 13:04:36,117: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.0038445565702887215]
[2024-04-20 13:04:36,774: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.009878822708611245]
[2024-04-20 13:04:37,428: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.005190140423557115]
[2024-04-20 13:04:38,079: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.0016005500779369736]
[2024-04-20 13:04:38,734: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.0017087168730981397]
[2024-04-20 13:04:39,392: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.009372814090600102]
[2024-04-20 13:04:40,052: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.014549470057155619]
[2024-04-20 13:04:40,714: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.010112021511292759]
[2024-04-20 13:04:41,372: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.0001410859516435496]
[2024-04-20 13:04:42,039: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.0212697062403071]
[2024-04-20 13:04:42,702: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.004167331866420587]
[2024-04-20 13:04:43,353: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.015383327321924831]
[2024-04-20 13:04:44,017: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.0013735644980486586]
[2024-04-20 13:04:44,675: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.0027371969889931195]
[2024-04-20 13:04:45,330: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.004479306759353191]
[2024-04-20 13:04:45,979: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.003295464309898619]
[2024-04-20 13:04:46,630: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.0192277243403847]
[2024-04-20 13:04:47,281: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.0175910216346698]
[2024-04-20 13:04:47,937: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.0005735702352300816]
[2024-04-20 13:04:48,593: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.003224743278091468]
[2024-04-20 13:04:49,247: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.001815069287283148]
[2024-04-20 13:04:49,902: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.0041300669368440615]
[2024-04-20 13:04:50,561: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.006278171277136671]
[2024-04-20 13:04:51,216: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.006236401895905196]
[2024-04-20 13:04:51,870: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.007559464032469014]
[2024-04-20 13:04:52,527: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.0011994617764981964]
[2024-04-20 13:04:53,203: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.009207540330920297]
[2024-04-20 13:04:53,875: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.0028731338525552603]
[2024-04-20 13:04:54,534: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.011038159804216545]
[2024-04-20 13:04:55,204: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.0036502418845488615]
[2024-04-20 13:04:55,876: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.007558019714755376]
[2024-04-20 13:04:56,534: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.006841046365133127]
[2024-04-20 13:04:57,190: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.012536992434431531]
[2024-04-20 13:04:57,846: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.00337020135144121]
[2024-04-20 13:04:58,500: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.003874243337324916]
[2024-04-20 13:04:59,154: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.006217172235082872]
[2024-04-20 13:04:59,810: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.0023145424877205425]
[2024-04-20 13:05:00,460: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.013918152444953712]
[2024-04-20 13:05:01,115: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.001093456142773489]
[2024-04-20 13:05:01,773: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.009395441043885048]
[2024-04-20 13:05:02,427: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.0005477587062231759]
[2024-04-20 13:05:03,083: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.00863637169744008]
[2024-04-20 13:05:03,742: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.00343216590732837]
[2024-04-20 13:05:04,395: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.022868220750196663]
[2024-04-20 13:05:05,050: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.0034873608787924244]
[2024-04-20 13:05:05,707: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.00018191718336059713]
[2024-04-20 13:05:06,369: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.006954750495695466]
[2024-04-20 13:05:07,039: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.0031589970277336923]
[2024-04-20 13:05:07,701: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.0024383303170226575]
[2024-04-20 13:05:08,364: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.0022307278200802577]
[2024-04-20 13:05:09,032: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.0052733309638960104]
[2024-04-20 13:05:09,691: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.004548370815719286]
[2024-04-20 13:05:10,348: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.0036875548696661776]
[2024-04-20 13:05:11,000: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.005417216176159649]
[2024-04-20 13:05:11,658: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.00687285727670738]
[2024-04-20 13:05:12,313: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.02488758770815786]
[2024-04-20 13:05:12,974: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.0021564817188162453]
[2024-04-20 13:05:13,627: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.002085927140421378]
[2024-04-20 13:05:14,285: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.010386518201503409]
[2024-04-20 13:05:14,943: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.006040974773854872]
[2024-04-20 13:05:15,600: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.010200557802542878]
[2024-04-20 13:05:16,255: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.0004746840637583538]
[2024-04-20 13:05:16,908: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.002093316963265921]
[2024-04-20 13:05:17,567: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.00012633375957322733]
[2024-04-20 13:05:18,224: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.002651139100138095]
[2024-04-20 13:05:18,896: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.003337550837279379]
[2024-04-20 13:05:19,557: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.003093499578831545]
[2024-04-20 13:05:20,211: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.01619178243757538]
[2024-04-20 13:05:20,880: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.008554787948301992]
[2024-04-20 13:05:21,544: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.0006766215015932295]
[2024-04-20 13:05:22,206: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.002881641130304243]
[2024-04-20 13:05:22,880: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.005642262143109493]
[2024-04-20 13:05:23,538: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.0035331535782639374]
[2024-04-20 13:05:24,194: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.004341852881408179]
[2024-04-20 13:05:24,851: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.007493822411146536]
[2024-04-20 13:05:25,509: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.02690936698550335]
[2024-04-20 13:05:26,164: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.014527538738613482]
[2024-04-20 13:05:26,822: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.0046553423349781475]
[2024-04-20 13:05:27,482: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.00025047108925344317]
[2024-04-20 13:05:28,136: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.0032979719589248074]
[2024-04-20 13:05:28,794: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.004119170963282804]
[2024-04-20 13:05:29,448: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.00023762799393749423]
[2024-04-20 13:05:30,101: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.000934269893630602]
[2024-04-20 13:05:30,759: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.004926356239236425]
[2024-04-20 13:05:31,418: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.0002822322920855767]
[2024-04-20 13:05:32,076: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.0035973916509693324]
[2024-04-20 13:05:32,730: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.010168265510018346]
[2024-04-20 13:05:33,399: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.0019603778506044624]
[2024-04-20 13:05:34,065: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.0014430757785390907]
[2024-04-20 13:05:34,743: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.007901217041864833]
[2024-04-20 13:05:35,416: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.014029250189481533]
[2024-04-20 13:05:36,079: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.008794600237709957]
[2024-04-20 13:05:36,739: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.009291401300581231]
[2024-04-20 13:05:37,393: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.015468526416527132]
[2024-04-20 13:05:38,050: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.02827974927447114]
[2024-04-20 13:05:38,705: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.006378901695979199]
[2024-04-20 13:05:39,368: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.001757119802341772]
[2024-04-20 13:05:40,022: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.0031873182721376776]
[2024-04-20 13:05:40,676: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.0041211068306337756]
[2024-04-20 13:05:41,332: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.014726584496913959]
[2024-04-20 13:05:41,985: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.0008354505271832354]
[2024-04-20 13:05:42,643: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.0068675453965869665]
[2024-04-20 13:05:43,298: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.005508507490769246]
[2024-04-20 13:05:43,954: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.006616398795516355]
[2024-04-20 13:05:44,612: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.004597373484590297]
[2024-04-20 13:05:45,268: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.013633532748543382]
[2024-04-20 13:05:45,925: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.0023268509087959782]
[2024-04-20 13:05:46,598: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.004949527913559248]
[2024-04-20 13:05:47,262: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.003086257518116535]
[2024-04-20 13:05:47,925: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.006110860259064249]
[2024-04-20 13:05:48,590: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.0010424614265758594]
[2024-04-20 13:05:49,262: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.026144409878747218]
[2024-04-20 13:05:49,923: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.005702566792190038]
[2024-04-20 13:05:50,581: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.003643787753803264]
[2024-04-20 13:05:51,238: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.006625405269672371]
[2024-04-20 13:05:51,895: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.003417387035189518]
[2024-04-20 13:05:52,552: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.006401839624382821]
[2024-04-20 13:05:53,207: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.0058476530442947445]
[2024-04-20 13:05:53,861: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.00041286241853821115]
[2024-04-20 13:05:54,516: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.007653467180167041]
[2024-04-20 13:05:55,170: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.0008876422569789378]
[2024-04-20 13:05:55,826: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.00038308490614998985]
[2024-04-20 13:05:56,484: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.012362914756562626]
[2024-04-20 13:05:57,141: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.005543440553089662]
[2024-04-20 13:05:57,793: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.005406361460823159]
[2024-04-20 13:05:58,450: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.006178727047844457]
[2024-04-20 13:05:59,107: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.009202441842897207]
[2024-04-20 13:05:59,764: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.0005319092268249489]
[2024-04-20 13:06:00,425: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.008070123672910278]
[2024-04-20 13:06:01,087: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.0118262426536917]
[2024-04-20 13:06:01,758: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.0017939899565552885]
[2024-04-20 13:06:02,425: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.007433558152226683]
[2024-04-20 13:06:03,096: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.005849281446201597]
[2024-04-20 13:06:03,755: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.01025683877674542]
[2024-04-20 13:06:04,411: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.007664249812938144]
[2024-04-20 13:06:05,068: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.01869640860744277]
[2024-04-20 13:06:05,726: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.0019293360070491148]
[2024-04-20 13:06:06,381: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.006725645751486968]
[2024-04-20 13:06:07,040: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.011438982034367839]
[2024-04-20 13:06:07,692: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.005153030824803213]
[2024-04-20 13:06:08,349: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.006002954750084163]
[2024-04-20 13:06:09,005: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.009364820414165786]
[2024-04-20 13:06:09,661: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.00412398986021597]
[2024-04-20 13:06:10,318: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.004058063978608622]
[2024-04-20 13:06:10,974: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.0065040091357171335]
[2024-04-20 13:06:11,629: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.0006028686850842323]
[2024-04-20 13:06:12,284: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.003975948406358232]
[2024-04-20 13:06:12,939: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.00704632477450775]
[2024-04-20 13:06:13,597: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.006199821078636827]
[2024-04-20 13:06:14,259: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.003368717842779801]
[2024-04-20 13:06:14,932: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.022782826693998285]
[2024-04-20 13:06:15,603: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.008990758910422064]
[2024-04-20 13:06:16,267: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.001028155549185122]
[2024-04-20 13:06:16,923: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.006032202852787114]
[2024-04-20 13:06:17,576: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.011003466171913369]
[2024-04-20 13:06:18,231: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.0032116240927401365]
[2024-04-20 13:06:18,890: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.005371147948442236]
[2024-04-20 13:06:19,547: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.015737852368146597]
[2024-04-20 13:06:20,204: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.018148547757443362]
[2024-04-20 13:06:20,860: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.009148688469899052]
[2024-04-20 13:06:21,520: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.02968980155681517]
[2024-04-20 13:06:22,179: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.0030758733308514177]
[2024-04-20 13:06:22,831: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.005905708220494434]
[2024-04-20 13:06:23,488: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.005298193821460886]
[2024-04-20 13:06:24,144: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.003433288351173258]
[2024-04-20 13:06:24,798: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.016554296935460545]
[2024-04-20 13:06:25,452: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.007826086047196026]
[2024-04-20 13:06:26,106: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.005219402061223984]
[2024-04-20 13:06:26,763: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.0010793804194483723]
[2024-04-20 13:06:27,427: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.0048206211043109745]
[2024-04-20 13:06:28,091: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.003161236002472702]
[2024-04-20 13:06:28,772: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.0012199909157595392]
[2024-04-20 13:06:29,443: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.003913097075919608]
[2024-04-20 13:06:30,106: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.005785001466712872]
[2024-04-20 13:06:30,762: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.002471127910006104]
[2024-04-20 13:06:31,417: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.02514083298563796]
[2024-04-20 13:06:32,070: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.0015211040086778262]
[2024-04-20 13:06:32,726: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.0032930737626548825]
[2024-04-20 13:06:33,385: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.004816486715678695]
[2024-04-20 13:06:34,038: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.01247179532375123]
[2024-04-20 13:06:34,693: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.006545673311511285]
[2024-04-20 13:06:35,347: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.0025399231432939803]
[2024-04-20 13:06:36,002: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.01624609717156309]
[2024-04-20 13:06:36,659: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.015841730146948882]
[2024-04-20 13:06:37,315: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.029893610046936935]
[2024-04-20 13:06:37,965: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.006004347389081667]
[2024-04-20 13:06:38,622: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.0032385390245532365]
[2024-04-20 13:06:39,279: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.012907860715937006]
[2024-04-20 13:06:39,937: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.0011165671531935641]
[2024-04-20 13:06:40,603: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.013463302635153019]
[2024-04-20 13:06:41,265: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.020109507794520313]
[2024-04-20 13:06:41,931: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.002291527805375506]
[2024-04-20 13:06:42,602: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.010348311664294178]
[2024-04-20 13:06:43,277: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.01637604282692976]
[2024-04-20 13:06:43,956: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.008137457792790076]
[2024-04-20 13:06:44,631: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.003087294444601457]
[2024-04-20 13:06:45,298: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.002830560904766091]
[2024-04-20 13:06:45,964: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.01114730167981752]
[2024-04-20 13:06:46,642: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.004167568756697519]
[2024-04-20 13:06:47,307: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.008636837559699458]
[2024-04-20 13:06:47,954: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.005989609434781904]
[2024-04-20 13:06:48,613: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.0025342668843447084]
[2024-04-20 13:06:49,272: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.006639968747330311]
[2024-04-20 13:06:49,927: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.004490509276652153]
[2024-04-20 13:06:50,584: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.007731244985370099]
[2024-04-20 13:06:51,238: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.009236611316643344]
[2024-04-20 13:06:51,891: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.0067924789003232745]
[2024-04-20 13:06:52,551: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.0027369609186868615]
[2024-04-20 13:06:53,205: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.007593846728696077]
[2024-04-20 13:06:53,856: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.01323462564021289]
[2024-04-20 13:06:54,511: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.01104167560977074]
[2024-04-20 13:06:55,169: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.01009299939685719]
[2024-04-20 13:06:55,829: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.0016033406961034565]
[2024-04-20 13:06:56,493: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.005533545914225882]
[2024-04-20 13:06:57,163: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.010536887908693157]
[2024-04-20 13:06:57,835: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.00487174199150115]
[2024-04-20 13:06:58,491: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.0018676203077994575]
[2024-04-20 13:06:59,146: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.004943778811590253]
[2024-04-20 13:06:59,806: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.006672617655906419]
[2024-04-20 13:07:00,465: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.0035759791401792826]
[2024-04-20 13:07:01,123: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.009532741851496725]
[2024-04-20 13:07:01,776: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.019284329448902748]
[2024-04-20 13:07:02,430: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.0015459589308268135]
[2024-04-20 13:07:03,087: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.013375317837515742]
[2024-04-20 13:07:03,766: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.009140745170525514]
[2024-04-20 13:07:04,437: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.011153679755939854]
[2024-04-20 13:07:05,096: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.010637335653978274]
[2024-04-20 13:07:05,766: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.004237298267577936]
[2024-04-20 13:07:06,427: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.0012738190140138112]
[2024-04-20 13:07:07,083: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.003825786300322431]
[2024-04-20 13:07:07,740: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.0005071058439820099]
[2024-04-20 13:07:08,397: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.012718284590997959]
[2024-04-20 13:07:09,064: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.002182329420733795]
[2024-04-20 13:07:09,730: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.005072156103959273]
[2024-04-20 13:07:10,401: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.01533363779507548]
[2024-04-20 13:07:11,063: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.005910084164763763]
[2024-04-20 13:07:11,719: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.014727674303448927]
[2024-04-20 13:07:12,378: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.0022074447995382982]
[2024-04-20 13:07:13,031: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.009480768171717703]
[2024-04-20 13:07:13,687: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.013961942200589524]
[2024-04-20 13:07:14,341: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.0043847475082973405]
[2024-04-20 13:07:14,994: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.023639128215597428]
[2024-04-20 13:07:15,646: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.006061214546833648]
[2024-04-20 13:07:16,299: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.007851780541118578]
[2024-04-20 13:07:16,951: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.0156895568198712]
[2024-04-20 13:07:17,609: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.0002516002695206223]
[2024-04-20 13:07:18,259: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.011161421066941693]
[2024-04-20 13:07:18,915: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.0012338535763098638]
[2024-04-20 13:07:19,568: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.0031800740907817057]
[2024-04-20 13:07:20,222: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.0029273951889929777]
[2024-04-20 13:07:20,874: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.003491554549417671]
[2024-04-20 13:07:21,536: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.001135150980734969]
[2024-04-20 13:07:22,198: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.001017216911778767]
[2024-04-20 13:07:22,871: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.0036519947346265384]
[2024-04-20 13:07:23,550: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.011457155385899951]
[2024-04-20 13:07:24,210: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.0031980607635739714]
[2024-04-20 13:07:24,873: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.015083004964514576]
[2024-04-20 13:07:25,527: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.00600101350367725]
[2024-04-20 13:07:26,181: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.0036965394819157256]
[2024-04-20 13:07:26,838: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.001821600118535777]
[2024-04-20 13:07:27,495: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.0023166679901623767]
[2024-04-20 13:07:28,152: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.008001672729645533]
[2024-04-20 13:07:28,804: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.015230164267205453]
[2024-04-20 13:07:29,460: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.009355955233281093]
[2024-04-20 13:07:30,114: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.004809683846995684]
[2024-04-20 13:07:30,772: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.0057587077883392915]
[2024-04-20 13:07:31,425: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.00870676270072294]
[2024-04-20 13:07:32,081: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.010581599546290761]
[2024-04-20 13:07:32,731: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.007645240378683559]
[2024-04-20 13:07:33,392: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.003571971446272547]
[2024-04-20 13:07:34,052: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.0032453882399404816]
[2024-04-20 13:07:34,706: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.012012077855179801]
[2024-04-20 13:07:35,375: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.01013427205777699]
[2024-04-20 13:07:36,039: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.006211494155997406]
[2024-04-20 13:07:36,712: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.002643025575375311]
[2024-04-20 13:07:37,385: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.028083081401506033]
[2024-04-20 13:07:38,047: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.009742225236290016]
[2024-04-20 13:07:38,700: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.014574890505235218]
[2024-04-20 13:07:39,355: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.005370518253936501]
[2024-04-20 13:07:40,012: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.0039382048473484525]
[2024-04-20 13:07:40,669: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.004757781459283795]
[2024-04-20 13:07:41,323: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.009756626380830873]
[2024-04-20 13:07:41,977: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.00814026893688104]
[2024-04-20 13:07:42,633: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.0006343011829447929]
[2024-04-20 13:07:43,287: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.00350480782312813]
[2024-04-20 13:07:43,941: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.005708144076527827]
[2024-04-20 13:07:44,596: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.00821020208428967]
[2024-04-20 13:07:45,254: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.009878561043157834]
[2024-04-20 13:07:45,905: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.00337722921513383]
[2024-04-20 13:07:46,559: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.016821284587300735]
[2024-04-20 13:07:47,210: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.006909902492423239]
[2024-04-20 13:07:47,864: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.006191890804547052]
[2024-04-20 13:07:48,542: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.0008029981167660262]
[2024-04-20 13:07:49,217: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.015924796724873302]
[2024-04-20 13:07:49,874: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.009434025374166365]
[2024-04-20 13:07:50,539: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.005283458054137007]
[2024-04-20 13:07:51,201: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.01893114105857194]
[2024-04-20 13:07:51,858: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.0005967953029869413]
[2024-04-20 13:07:52,510: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.0014590497991043097]
[2024-04-20 13:07:53,164: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.01146649156367019]
[2024-04-20 13:07:53,816: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.009928261298802015]
[2024-04-20 13:07:54,469: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.007696958125119238]
[2024-04-20 13:07:55,125: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.0020626237210465467]
[2024-04-20 13:07:55,778: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.032224718104832]
[2024-04-20 13:07:56,428: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.009981239098485408]
[2024-04-20 13:07:57,078: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.005056686216376126]
[2024-04-20 13:07:57,727: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.02285604317943567]
[2024-04-20 13:07:58,378: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.011621910635379408]
[2024-04-20 13:07:59,033: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.002181589579451308]
[2024-04-20 13:07:59,691: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.00037001443046868045]
[2024-04-20 13:08:00,343: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.005584999576718075]
[2024-04-20 13:08:00,995: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.005531978737071559]
[2024-04-20 13:08:01,652: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.003492689241117432]
[2024-04-20 13:08:02,310: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.010595586551786973]
[2024-04-20 13:08:02,975: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.010010297726167464]
[2024-04-20 13:08:03,637: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.0016498925616238256]
[2024-04-20 13:08:04,314: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.013759968056985065]
[2024-04-20 13:08:04,978: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.007344825117817227]
[2024-04-20 13:08:05,627: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.005336294998055049]
[2024-04-20 13:08:06,283: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.0071296930057906435]
[2024-04-20 13:08:06,937: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.002504726136040413]
[2024-04-20 13:08:07,591: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.007481336396888883]
[2024-04-20 13:08:08,250: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.007794060292094456]
[2024-04-20 13:08:08,906: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.005773232082748306]
[2024-04-20 13:08:09,562: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.011233847584258704]
[2024-04-20 13:08:10,218: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.0053243809005746046]
[2024-04-20 13:08:10,872: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.006549092205494751]
[2024-04-20 13:08:11,529: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.001099256012254414]
[2024-04-20 13:08:12,185: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.009995989614586528]
[2024-04-20 13:08:12,839: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.0036577633066457705]
[2024-04-20 13:08:13,496: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.004949026849720573]
[2024-04-20 13:08:14,147: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.009043617306174753]
[2024-04-20 13:08:14,801: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.014618066225654409]
[2024-04-20 13:08:15,462: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.002146444935911443]
[2024-04-20 13:08:16,121: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.0054752366879341225]
[2024-04-20 13:08:16,785: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.00016183068489448595]
[2024-04-20 13:08:17,445: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.006681418813190154]
[2024-04-20 13:08:18,104: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.0017002486713226723]
[2024-04-20 13:08:18,758: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.0020453288550282413]
[2024-04-20 13:08:19,408: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.0008171436582409911]
[2024-04-20 13:08:20,069: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.0018413309916462802]
[2024-04-20 13:08:20,722: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.0049931219114015294]
[2024-04-20 13:08:21,373: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.004719356841750572]
[2024-04-20 13:08:22,025: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.003749410147764571]
[2024-04-20 13:08:22,681: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.0035281867682882056]
[2024-04-20 13:08:23,333: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.008885488827795596]
[2024-04-20 13:08:23,985: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.006775217872808787]
[2024-04-20 13:08:24,639: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.01121067578488935]
[2024-04-20 13:08:25,296: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.003211924912176142]
[2024-04-20 13:08:25,950: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.005870041441016995]
[2024-04-20 13:08:26,602: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.024818807597218606]
[2024-04-20 13:08:27,256: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.00446364816212581]
[2024-04-20 13:08:27,910: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.0030282571206898252]
[2024-04-20 13:08:28,567: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.004277659151113948]
[2024-04-20 13:08:29,227: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.0011929867932378478]
[2024-04-20 13:08:29,908: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.006601048790586499]
[2024-04-20 13:08:30,573: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.00996761443249442]
[2024-04-20 13:08:31,226: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.0019381002837850871]
[2024-04-20 13:08:31,879: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.007013086812001251]
[2024-04-20 13:08:32,534: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.004158143923602232]
[2024-04-20 13:08:33,191: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.003039308976400756]
[2024-04-20 13:08:33,848: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.012136823828323607]
[2024-04-20 13:08:34,505: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.09891999250448631]
[2024-04-20 13:08:35,159: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.002622501995317348]
[2024-04-20 13:08:35,812: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.00045895023567353496]
[2024-04-20 13:08:36,472: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.002604057574577553]
[2024-04-20 13:08:37,127: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.004136741844972823]
[2024-04-20 13:08:37,783: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.007572260527082654]
[2024-04-20 13:08:38,436: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.008442832593794369]
[2024-04-20 13:08:39,090: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.004572059593677028]
[2024-04-20 13:08:39,749: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.0001997364820343361]
[2024-04-20 13:08:40,405: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.003542428260736422]
[2024-04-20 13:08:41,056: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.008566021069135165]
[2024-04-20 13:08:41,714: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.0006861013956051406]
[2024-04-20 13:08:42,375: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.00789813119160843]
[2024-04-20 13:08:43,038: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.0014990329465135112]
[2024-04-20 13:08:43,698: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.00492786196573151]
[2024-04-20 13:08:44,367: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.0034978889134686204]
[2024-04-20 13:08:45,037: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.01954929708823148]
[2024-04-20 13:08:45,691: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.003436681184882398]
[2024-04-20 13:08:46,349: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.0016360069228805612]
[2024-04-20 13:08:47,007: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.0024534120663854387]
[2024-04-20 13:08:47,660: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.009355253038930667]
[2024-04-20 13:08:48,314: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.0013114189607748394]
[2024-04-20 13:08:48,970: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.007841971784855833]
[2024-04-20 13:08:49,626: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.0009383894734199997]
[2024-04-20 13:08:50,283: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.005736736401974306]
[2024-04-20 13:08:50,936: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.0004083750863422693]
[2024-04-20 13:08:51,589: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.048856283171335]
[2024-04-20 13:08:52,245: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.012378772384358559]
[2024-04-20 13:08:52,902: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.00935330116982625]
[2024-04-20 13:08:53,560: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.00971638184983032]
[2024-04-20 13:08:54,216: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.007636405534393144]
[2024-04-20 13:08:54,872: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.0032257542985533686]
[2024-04-20 13:08:55,535: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.02031193091243621]
[2024-04-20 13:08:56,201: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.004181194240503456]
[2024-04-20 13:08:56,861: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.0003992966588966987]
[2024-04-20 13:08:57,537: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.009068792752229993]
[2024-04-20 13:08:58,213: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.00171190611961856]
[2024-04-20 13:08:58,874: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.01937116539834721]
[2024-04-20 13:08:59,529: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.011015713204565191]
[2024-04-20 13:09:00,183: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.0017166330789158937]
[2024-04-20 13:09:00,838: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.022663631014501376]
[2024-04-20 13:09:01,496: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.006103779188905233]
[2024-04-20 13:09:02,151: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.012039271885072565]
[2024-04-20 13:09:02,809: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.0049199465917838395]
[2024-04-20 13:09:03,462: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.002885311436191963]
[2024-04-20 13:09:04,117: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.020639188193691135]
[2024-04-20 13:09:04,770: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.007534850209386567]
[2024-04-20 13:09:05,424: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.0009272506813652471]
[2024-04-20 13:09:06,077: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.005138107591755466]
[2024-04-20 13:09:06,729: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.008487933673738212]
[2024-04-20 13:09:07,385: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.0038856378676743212]
[2024-04-20 13:09:08,041: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.0021353853909595096]
[2024-04-20 13:09:08,708: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.006076272537939637]
[2024-04-20 13:09:09,370: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.017236990643720435]
[2024-04-20 13:09:10,038: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.008793628351626576]
[2024-04-20 13:09:10,704: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.007488399022458636]
[2024-04-20 13:09:11,365: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.003938696558523546]
[2024-04-20 13:09:12,024: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.010669747957874098]
[2024-04-20 13:09:12,681: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.009347255719696825]
[2024-04-20 13:09:13,339: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.001844618995100027]
[2024-04-20 13:09:13,993: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.00016448504781203078]
[2024-04-20 13:09:14,649: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.007221346366557332]
[2024-04-20 13:09:15,305: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.0019607163169948153]
[2024-04-20 13:09:15,957: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.004314163958481587]
[2024-04-20 13:09:16,613: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.009650458736683711]
[2024-04-20 13:09:17,270: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.009315445438439823]
[2024-04-20 13:09:17,926: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.006727620903914907]
[2024-04-20 13:09:18,584: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.0026541842194340213]
[2024-04-20 13:09:19,243: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.019876281812777518]
[2024-04-20 13:09:19,898: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.0026085765600128742]
[2024-04-20 13:09:20,560: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.005654684446083052]
[2024-04-20 13:09:21,213: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.002503113706451302]
[2024-04-20 13:09:21,875: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.008163542578510458]
[2024-04-20 13:09:22,539: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.003003886713166785]
[2024-04-20 13:09:23,209: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.011388344474440492]
[2024-04-20 13:09:23,886: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.0036957404797351625]
[2024-04-20 13:09:24,547: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.012614750911555525]
[2024-04-20 13:09:25,229: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.0113825184884984]
[2024-04-20 13:09:25,894: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.014251698924339327]
[2024-04-20 13:09:26,541: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.017711946727179705]
[2024-04-20 13:09:27,201: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.01126772345214352]
[2024-04-20 13:09:27,858: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.0006553628096233968]
[2024-04-20 13:09:28,512: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.005824776066175004]
[2024-04-20 13:09:29,169: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.008731162491240337]
[2024-04-20 13:09:29,826: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.012089610345577413]
[2024-04-20 13:09:30,480: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.0026264920057101153]
[2024-04-20 13:09:31,135: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.012102061332846479]
[2024-04-20 13:09:31,789: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.0028311946263869054]
[2024-04-20 13:09:32,445: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.0018585840718406733]
[2024-04-20 13:09:33,105: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.010073068646787536]
[2024-04-20 13:09:33,761: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.004989201792101891]
[2024-04-20 13:09:34,416: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.004031882611013223]
[2024-04-20 13:09:35,076: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.008094093077286172]
[2024-04-20 13:09:35,749: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.0005029463252432148]
[2024-04-20 13:09:36,414: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.0018053227625985878]
[2024-04-20 13:09:37,078: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.009920588857521511]
[2024-04-20 13:09:37,752: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.004334930997854149]
[2024-04-20 13:09:38,417: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.001200141982413322]
[2024-04-20 13:09:39,070: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.007369049550149727]
[2024-04-20 13:09:39,726: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.022658041853722367]
[2024-04-20 13:09:40,385: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.003945500100674516]
[2024-04-20 13:09:41,040: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.004835501883389792]
[2024-04-20 13:09:41,696: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.001816429502784108]
[2024-04-20 13:09:42,357: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.02375090175265264]
[2024-04-20 13:09:43,015: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.013735683356211182]
[2024-04-20 13:09:43,671: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.006829874359857475]
[2024-04-20 13:09:44,328: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.01135374780313749]
[2024-04-20 13:09:44,983: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.004498893062269542]
[2024-04-20 13:09:45,641: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.007425080990517948]
[2024-04-20 13:09:46,301: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.0026524593934877778]
[2024-04-20 13:09:46,957: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.0034692053906133042]
[2024-04-20 13:09:47,610: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.006916003821177706]
[2024-04-20 13:09:48,265: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.0032407308493908535]
[2024-04-20 13:09:48,921: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.004610902407199744]
[2024-04-20 13:09:49,595: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.004203669504266596]
[2024-04-20 13:09:50,258: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.05993438087063493]
[2024-04-20 13:09:50,917: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.013036091421747057]
[2024-04-20 13:09:51,580: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.002182885571800265]
[2024-04-20 13:09:52,244: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.0057354599709895865]
[2024-04-20 13:09:52,901: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.011403000550819685]
[2024-04-20 13:09:53,556: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.01151045382716184]
[2024-04-20 13:09:54,211: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.009672759965144296]
[2024-04-20 13:09:54,863: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.0013340414529327694]
[2024-04-20 13:09:55,520: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.017883149072756056]
[2024-04-20 13:09:56,182: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.006813330278755466]
[2024-04-20 13:09:56,854: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.005485918743878718]
[2024-04-20 13:09:57,524: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.01374882351088471]
[2024-04-20 13:09:58,188: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.006203173773724586]
[2024-04-20 13:09:58,852: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.004846119843670008]
[2024-04-20 13:09:59,525: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.012891544722836296]
[2024-04-20 13:10:00,183: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.01242373224719767]
[2024-04-20 13:10:00,840: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.01599156473870446]
[2024-04-20 13:10:01,494: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.002569640616465415]
[2024-04-20 13:10:02,151: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.013098315801138375]
[2024-04-20 13:10:02,814: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.01504861214827731]
[2024-04-20 13:10:03,477: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.005898103451946358]
[2024-04-20 13:10:04,143: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.003308880202762487]
[2024-04-20 13:10:04,803: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.014952177937017157]
[2024-04-20 13:10:05,475: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.005424732116389752]
[2024-04-20 13:10:06,129: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.02914090643164272]
[2024-04-20 13:10:06,785: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.00441459044679027]
[2024-04-20 13:10:07,444: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.008818455505744281]
[2024-04-20 13:10:08,110: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.013387770260596692]
[2024-04-20 13:10:08,769: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.0005611911747492845]
[2024-04-20 13:10:09,425: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.0037746486923799605]
[2024-04-20 13:10:10,081: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.0035275300092040907]
[2024-04-20 13:10:10,739: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.0050955679238839525]
[2024-04-20 13:10:11,398: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.007885102713205722]
[2024-04-20 13:10:12,060: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.00795201684243667]
[2024-04-20 13:10:12,718: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.0030850575812887567]
[2024-04-20 13:10:13,375: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.010669639417136006]
[2024-04-20 13:10:14,028: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.014345601646542114]
[2024-04-20 13:10:14,679: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.00969215421105733]
[2024-04-20 13:10:15,333: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.0014745432812986567]
[2024-04-20 13:10:15,992: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.002970580791922542]
[2024-04-20 13:10:16,656: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.0010346968975601379]
[2024-04-20 13:10:17,337: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.0023977978453907085]
[2024-04-20 13:10:18,008: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.002696945615353661]
[2024-04-20 13:10:18,675: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.0015656314021288097]
[2024-04-20 13:10:19,346: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.011882395380424978]
[2024-04-20 13:10:20,013: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.005886170421009036]
[2024-04-20 13:10:20,677: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.0029562875589428453]
[2024-04-20 13:10:21,339: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.007354906671713853]
[2024-04-20 13:10:22,000: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.004443576033951004]
[2024-04-20 13:10:22,656: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.002026342914342408]
[2024-04-20 13:10:23,313: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.0029017008794378243]
[2024-04-20 13:10:23,967: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.009139013998293137]
[2024-04-20 13:10:24,624: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.000780062840196867]
[2024-04-20 13:10:25,283: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.0007808200755191523]
[2024-04-20 13:10:25,939: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.011553965450928332]
[2024-04-20 13:10:26,596: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.012777580095240123]
[2024-04-20 13:10:27,253: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.015039973973844123]
[2024-04-20 13:10:27,909: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.0022224668168258142]
[2024-04-20 13:10:28,561: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.0004623684815468394]
[2024-04-20 13:10:29,215: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.0023277482712469066]
[2024-04-20 13:10:29,876: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.011068426137076665]
[2024-04-20 13:10:30,533: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.01039514870553537]
[2024-04-20 13:10:31,205: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.0009076177856952221]
[2024-04-20 13:10:31,875: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.0033540040313504464]
[2024-04-20 13:10:32,536: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.015395294059973008]
[2024-04-20 13:10:33,204: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.010245032713048323]
[2024-04-20 13:10:33,870: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.017915746524805085]
[2024-04-20 13:10:34,528: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.0041793018866961565]
[2024-04-20 13:10:35,183: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.0019199816335750742]
[2024-04-20 13:10:35,840: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.00028676214773374004]
[2024-04-20 13:10:36,494: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.002997734406065513]
[2024-04-20 13:10:37,148: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.003180894796819073]
[2024-04-20 13:10:37,802: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.011436931928366612]
[2024-04-20 13:10:38,460: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.0005931228812607028]
[2024-04-20 13:10:39,115: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.008655658451264842]
[2024-04-20 13:10:39,770: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.008157051339871506]
[2024-04-20 13:10:40,426: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.0041272989878973244]
[2024-04-20 13:10:41,081: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.013941674510634714]
[2024-04-20 13:10:41,738: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.0032543333776674558]
[2024-04-20 13:10:42,393: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.006013567944273691]
[2024-04-20 13:10:43,045: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.0015444884024885482]
[2024-04-20 13:10:43,702: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.01541707405122613]
[2024-04-20 13:10:44,364: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.00273998943520584]
[2024-04-20 13:10:45,031: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.006180351318598066]
[2024-04-20 13:10:45,700: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.005710738700715918]
[2024-04-20 13:10:46,360: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.011733929737754676]
[2024-04-20 13:10:47,023: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.0001221080717704425]
[2024-04-20 13:10:47,679: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.0031940127030643576]
[2024-04-20 13:10:48,333: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.008741155136156163]
[2024-04-20 13:10:48,983: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.005373581202431651]
[2024-04-20 13:10:49,646: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.00027162583947057183]
[2024-04-20 13:10:50,303: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.00430286077325771]
[2024-04-20 13:10:50,960: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.010703720616441937]
[2024-04-20 13:10:51,618: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.006115879281272403]
[2024-04-20 13:10:52,276: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.003741929126695234]
[2024-04-20 13:10:52,931: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.0013941130201496148]
[2024-04-20 13:10:53,588: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.017440025452292514]
[2024-04-20 13:10:54,244: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.003925222148218817]
[2024-04-20 13:10:54,900: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.0009785778870684003]
[2024-04-20 13:10:55,553: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.012513530745391037]
[2024-04-20 13:10:56,207: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.012985431598063552]
[2024-04-20 13:10:56,858: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.0024547955261728944]
[2024-04-20 13:10:57,523: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.0010779395907113477]
[2024-04-20 13:10:58,186: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.0035255687932697526]
[2024-04-20 13:10:58,845: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.0034962210397519833]
[2024-04-20 13:10:59,507: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.0009335524278502688]
[2024-04-20 13:11:00,166: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.014023164015169539]
[2024-04-20 13:11:00,825: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.01912384517120564]
[2024-04-20 13:11:01,479: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.01844908059497706]
[2024-04-20 13:11:02,133: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.003903703863815833]
[2024-04-20 13:11:02,790: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.011209065694356965]
[2024-04-20 13:11:03,445: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.00680844832669544]
[2024-04-20 13:11:04,103: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.00842223819690392]
[2024-04-20 13:11:04,762: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.007417108362497028]
[2024-04-20 13:11:05,419: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.014551680510640043]
[2024-04-20 13:11:06,079: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.006822413382889807]
[2024-04-20 13:11:06,734: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.008108549224928083]
[2024-04-20 13:11:07,385: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.008320882546101369]
[2024-04-20 13:11:08,041: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.011889218384458352]
[2024-04-20 13:11:08,697: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.0029097910762473406]
[2024-04-20 13:11:09,352: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.009066676138311733]
[2024-04-20 13:11:10,006: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.006367827756794411]
[2024-04-20 13:11:10,663: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.005456590441001192]
[2024-04-20 13:11:11,330: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.008193189695980025]
[2024-04-20 13:11:11,990: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.010173040652338412]
[2024-04-20 13:11:12,667: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.007510193698703381]
[2024-04-20 13:11:13,337: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.002286548583790095]
[2024-04-20 13:11:13,996: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.014411151406707606]
[2024-04-20 13:11:14,654: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.00814040505093739]
[2024-04-20 13:11:15,313: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.005565327963046665]
[2024-04-20 13:11:15,967: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.021842421792553596]
[2024-04-20 13:11:16,620: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.004336968708709565]
[2024-04-20 13:11:17,275: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.0010437058636918518]
[2024-04-20 13:11:17,931: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.0018743598702658524]
[2024-04-20 13:11:18,585: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.0013626078321376522]
[2024-04-20 13:11:19,237: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.013113891739916088]
[2024-04-20 13:11:19,893: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.012531238421322673]
[2024-04-20 13:11:20,548: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.00323858854241524]
[2024-04-20 13:11:21,203: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.003219943186912601]
[2024-04-20 13:11:21,858: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.003945365210697332]
[2024-04-20 13:11:22,514: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.014095197971539245]
[2024-04-20 13:11:23,169: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.007132590456062594]
[2024-04-20 13:11:23,821: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.0051475001722516445]
[2024-04-20 13:11:24,478: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.01068497566825226]
[2024-04-20 13:11:25,138: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.008036506953608554]
[2024-04-20 13:11:25,799: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.005222711776568529]
[2024-04-20 13:11:26,468: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.03144929692690525]
[2024-04-20 13:11:27,147: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.001186547747010584]
[2024-04-20 13:11:27,805: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.0018339919498901879]
[2024-04-20 13:11:28,455: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.002747335458814005]
[2024-04-20 13:11:29,109: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.00879707075883766]
[2024-04-20 13:11:29,761: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.004809211048502373]
[2024-04-20 13:11:30,411: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.0031882659017425084]
[2024-04-20 13:11:31,067: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.006528599158057708]
[2024-04-20 13:11:31,721: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.004714280528804429]
[2024-04-20 13:11:32,379: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.003811786057243708]
[2024-04-20 13:11:33,035: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.008665608788943954]
[2024-04-20 13:11:33,691: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.007041614453112551]
[2024-04-20 13:11:34,344: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.01560643064942351]
[2024-04-20 13:11:35,000: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.027116132486844646]
[2024-04-20 13:11:35,654: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.008395841562816014]
[2024-04-20 13:11:36,307: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.009531985097462045]
[2024-04-20 13:11:36,958: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.010070572550771447]
[2024-04-20 13:11:37,625: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.008713093269670989]
[2024-04-20 13:11:38,287: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.004622176976187431]
[2024-04-20 13:11:38,948: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.008711403537420625]
[2024-04-20 13:11:39,610: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.017131997175174274]
[2024-04-20 13:11:40,281: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.00516049138326815]
[2024-04-20 13:11:40,940: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.00946995233367551]
[2024-04-20 13:11:41,591: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.0033320090246711106]
[2024-04-20 13:11:42,241: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.002966526060339038]
[2024-04-20 13:11:42,899: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.001692929117635671]
[2024-04-20 13:11:43,554: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.00704493044939497]
[2024-04-20 13:11:44,206: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.010272597726386584]
[2024-04-20 13:11:44,859: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.01295318796838889]
[2024-04-20 13:11:45,513: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.01415434361142315]
[2024-04-20 13:11:46,165: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.006752844284995975]
[2024-04-20 13:11:46,819: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.0008256463139293207]
[2024-04-20 13:11:47,472: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.006090214410485624]
[2024-04-20 13:11:48,126: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.0034434045524833336]
[2024-04-20 13:11:48,780: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.014743522652736204]
[2024-04-20 13:11:49,436: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.0052713691000027705]
[2024-04-20 13:11:50,095: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.0027937675017537644]
[2024-04-20 13:11:50,750: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.007462149808019661]
[2024-04-20 13:11:51,421: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.017035198067137585]
[2024-04-20 13:11:52,086: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.010404254139784101]
[2024-04-20 13:11:52,742: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.01580507151698537]
[2024-04-20 13:11:53,408: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.012407695379048124]
[2024-04-20 13:11:54,072: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.007752242237529701]
[2024-04-20 13:11:54,729: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.003094794204286282]
[2024-04-20 13:11:55,385: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.007332403336126876]
[2024-04-20 13:11:56,042: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.013436055255814002]
[2024-04-20 13:11:56,695: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.00426262421936145]
[2024-04-20 13:11:57,351: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.0056544593592491145]
[2024-04-20 13:11:58,009: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.0033570228427028384]
[2024-04-20 13:11:58,665: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.003958463300027671]
[2024-04-20 13:11:59,316: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.005325426516855138]
[2024-04-20 13:11:59,972: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.01148304974000094]
[2024-04-20 13:12:00,627: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.012640180612527377]
[2024-04-20 13:12:01,281: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.017079880751948474]
[2024-04-20 13:12:01,938: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.0028217398635922934]
[2024-04-20 13:12:02,592: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.0033082348799400494]
[2024-04-20 13:12:03,255: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.008267318397023445]
[2024-04-20 13:12:03,911: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.0015414615229767143]
[2024-04-20 13:12:04,593: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.0029602945208060134]
[2024-04-20 13:12:05,265: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.003976689724073857]
[2024-04-20 13:12:05,925: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.011325127442080533]
[2024-04-20 13:12:06,595: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.002482709561389915]
[2024-04-20 13:12:07,268: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.014465189109941587]
[2024-04-20 13:12:07,931: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.004794948815185713]
[2024-04-20 13:12:08,584: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.002179596721963957]
[2024-04-20 13:12:09,245: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.019468256079275926]
[2024-04-20 13:12:09,902: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.005337409307389589]
[2024-04-20 13:12:10,552: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.005633278984110799]
[2024-04-20 13:12:11,207: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.0012204433589089309]
[2024-04-20 13:12:11,863: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.013123187191068605]
[2024-04-20 13:12:12,523: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.008064867919439701]
[2024-04-20 13:12:13,184: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.005644282419565071]
[2024-04-20 13:12:13,842: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.0160622634241829]
[2024-04-20 13:12:14,499: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.008029398046293003]
[2024-04-20 13:12:15,153: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.005691323710742419]
[2024-04-20 13:12:15,810: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.017282043621904945]
[2024-04-20 13:12:16,465: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.0005231244950305569]
[2024-04-20 13:12:17,120: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.007827700161208146]
[2024-04-20 13:12:17,785: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.004813614481001697]
[2024-04-20 13:12:18,450: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.0117209047417427]
[2024-04-20 13:12:19,128: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.0011875364318433388]
[2024-04-20 13:12:19,795: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.015066352569542222]
[2024-04-20 13:12:20,460: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.00598013140281019]
[2024-04-20 13:12:21,113: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.014028700424052952]
[2024-04-20 13:12:21,771: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.0022099909796485604]
[2024-04-20 13:12:22,428: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.005334859282484104]
[2024-04-20 13:12:23,090: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.008818091454634676]
[2024-04-20 13:12:23,745: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.02317171816174714]
[2024-04-20 13:12:24,403: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.012054412590966436]
[2024-04-20 13:12:25,056: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.0019277298039271733]
[2024-04-20 13:12:25,721: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.004284443501016884]
[2024-04-20 13:12:26,382: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.016300332963227818]
[2024-04-20 13:12:27,039: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.006401996518939494]
[2024-04-20 13:12:27,699: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.010469082402884338]
[2024-04-20 13:12:28,357: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.005447359125528069]
[2024-04-20 13:12:29,015: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.0011102976902255721]
[2024-04-20 13:12:29,669: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.011349641029247156]
[2024-04-20 13:12:30,323: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.004392452754623864]
[2024-04-20 13:12:30,982: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.005428268387704031]
[2024-04-20 13:12:31,650: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.003332568374016106]
[2024-04-20 13:12:32,313: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.003550926282690313]
[2024-04-20 13:12:32,980: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.022383180406130784]
[2024-04-20 13:12:33,648: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.01730542585958888]
[2024-04-20 13:12:34,313: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.0009234050588537804]
[2024-04-20 13:12:34,968: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.010995533590335735]
[2024-04-20 13:12:35,626: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.012747701524457523]
[2024-04-20 13:12:36,283: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.02005578218976671]
[2024-04-20 13:12:36,940: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.0007973454301925394]
[2024-04-20 13:12:37,602: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.011328784786943049]
[2024-04-20 13:12:38,252: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.01951459860753239]
[2024-04-20 13:12:38,911: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.010851524391640548]
[2024-04-20 13:12:39,567: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.001724821426995929]
[2024-04-20 13:12:40,227: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.0018505672644232372]
[2024-04-20 13:12:40,884: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.010517141712787144]
[2024-04-20 13:12:41,538: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.014621163281575315]
[2024-04-20 13:12:42,193: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.004643221475781806]
[2024-04-20 13:12:42,848: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.01580424902050195]
[2024-04-20 13:12:43,506: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.004665718317113173]
[2024-04-20 13:12:44,164: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.013607230135007874]
[2024-04-20 13:12:44,838: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.012595291908008082]
[2024-04-20 13:12:45,509: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.01619084377909985]
[2024-04-20 13:12:46,168: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.005479746163052371]
[2024-04-20 13:12:46,833: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.0014289924788827794]
[2024-04-20 13:12:47,504: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.0030901547879936147]
[2024-04-20 13:12:48,161: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.006442712026148107]
[2024-04-20 13:12:48,819: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.0021186527242111454]
[2024-04-20 13:12:49,478: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.0030699712344124065]
[2024-04-20 13:12:50,136: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.001939052196551571]
[2024-04-20 13:12:50,793: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.007050695717502655]
[2024-04-20 13:12:51,445: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.008435335009394923]
[2024-04-20 13:12:52,101: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.009169263308240538]
[2024-04-20 13:12:52,756: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.004996549241597525]
[2024-04-20 13:12:53,414: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.006507403914728339]
[2024-04-20 13:12:54,070: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.002026229889262452]
[2024-04-20 13:12:54,730: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.00950156213469499]
[2024-04-20 13:12:55,385: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.0055271587749686525]
[2024-04-20 13:12:56,044: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.0006023363130621916]
[2024-04-20 13:12:56,703: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.003978153853719765]
[2024-04-20 13:12:57,360: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.005676892523441924]
[2024-04-20 13:12:58,028: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.0025581523031098915]
[2024-04-20 13:12:58,693: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.01754142873254328]
[2024-04-20 13:12:59,373: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.030197715419468647]
[2024-04-20 13:13:00,045: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.006685236106131178]
[2024-04-20 13:13:00,703: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.001119241723671728]
[2024-04-20 13:13:01,363: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.005515463620988233]
[2024-04-20 13:13:02,023: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.009506416613523376]
[2024-04-20 13:13:02,680: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.004450408091904166]
[2024-04-20 13:13:03,339: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.018276674149481233]
[2024-04-20 13:13:03,994: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.004677898737435009]
[2024-04-20 13:13:04,648: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.00925556659497614]
[2024-04-20 13:13:05,307: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.005330656030143645]
[2024-04-20 13:13:05,963: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.00589835834539218]
[2024-04-20 13:13:06,618: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.0008337174970916127]
[2024-04-20 13:13:07,273: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.009993787009734197]
[2024-04-20 13:13:07,927: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.0026212336360928656]
[2024-04-20 13:13:08,582: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.0010046054929012428]
[2024-04-20 13:13:09,237: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.004450700705671551]
[2024-04-20 13:13:09,898: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.002194192082789213]
[2024-04-20 13:13:10,555: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.008924918210338806]
[2024-04-20 13:13:11,223: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.011526514528309396]
[2024-04-20 13:13:11,894: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.0022319825763618085]
[2024-04-20 13:13:12,568: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.00973209082322204]
[2024-04-20 13:13:13,252: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.006533976568975832]
[2024-04-20 13:13:13,929: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.002677300626764364]
[2024-04-20 13:13:14,605: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.0076742689257648265]
[2024-04-20 13:13:15,277: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.007523111073944951]
[2024-04-20 13:13:15,953: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.022387550925389233]
[2024-04-20 13:13:16,640: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.009284708654429121]
[2024-04-20 13:13:17,316: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.014085002535158452]
[2024-04-20 13:13:17,967: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.0010575789768637633]
[2024-04-20 13:13:18,624: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.0016562859076282917]
[2024-04-20 13:13:19,283: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.0007904440786668941]
[2024-04-20 13:13:19,940: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.005030557836290623]
[2024-04-20 13:13:20,594: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.01938370186331782]
[2024-04-20 13:13:21,253: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.0019369223036609813]
[2024-04-20 13:13:21,913: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.016948791527148066]
[2024-04-20 13:13:22,568: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.000497574245950785]
[2024-04-20 13:13:23,219: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.002442297437583536]
[2024-04-20 13:13:23,875: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.011027258489566715]
[2024-04-20 13:13:24,531: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.014328690310691816]
[2024-04-20 13:13:25,191: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.006205394934915397]
[2024-04-20 13:13:25,846: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.003159439929590163]
[2024-04-20 13:13:26,502: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.004755046259741211]
[2024-04-20 13:13:27,169: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.0013687806958457898]
[2024-04-20 13:13:27,840: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.0005650181422475742]
[2024-04-20 13:13:28,500: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.0009428229940316699]
[2024-04-20 13:13:29,168: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.006168040556598489]
[2024-04-20 13:13:29,831: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.011773387242136299]
[2024-04-20 13:13:30,487: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.012023003978082909]
[2024-04-20 13:13:31,142: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.004255600045614217]
[2024-04-20 13:13:31,794: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.01938972223464553]
[2024-04-20 13:13:32,453: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.012764475401930028]
[2024-04-20 13:13:33,110: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.0006835569809430374]
[2024-04-20 13:13:33,768: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.006400614965199467]
[2024-04-20 13:13:34,426: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.008700949719445116]
[2024-04-20 13:13:35,082: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.0009158490005786127]
[2024-04-20 13:13:35,735: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.008878856361543997]
[2024-04-20 13:13:36,394: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.005572364440497691]
[2024-04-20 13:13:37,049: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.004441642187172542]
[2024-04-20 13:13:37,702: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.009567464247503014]
[2024-04-20 13:13:38,357: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.012556632953076822]
[2024-04-20 13:13:39,020: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.002705892002730866]
[2024-04-20 13:13:39,678: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.0017317899241216762]
[2024-04-20 13:13:40,351: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.012778889263650346]
[2024-04-20 13:13:41,014: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.004115877309067497]
[2024-04-20 13:13:41,673: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.0025984825265473834]
[2024-04-20 13:13:42,340: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.009369881171878569]
[2024-04-20 13:13:43,004: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.049017252271075215]
[2024-04-20 13:13:43,663: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.015397954770233053]
[2024-04-20 13:13:44,315: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.0050990111680915395]
[2024-04-20 13:13:44,972: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.00024872419943525366]
[2024-04-20 13:13:45,628: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.013816727440042418]
[2024-04-20 13:13:46,282: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.006372841281654473]
[2024-04-20 13:13:46,937: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.004338905406013258]
[2024-04-20 13:13:47,592: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.0015983432784583433]
[2024-04-20 13:13:48,245: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.003116202806846051]
[2024-04-20 13:13:48,902: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.01619583998213858]
[2024-04-20 13:13:49,555: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.00247189888277784]
[2024-04-20 13:13:50,210: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.0011226515402081854]
[2024-04-20 13:13:50,870: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.006547240392436473]
[2024-04-20 13:13:51,529: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.01738544872619348]
[2024-04-20 13:13:52,182: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.016756347939631714]
[2024-04-20 13:13:52,833: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.0034791295982063123]
[2024-04-20 13:13:53,488: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.004379796847808444]
[2024-04-20 13:13:54,146: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.001334088068441009]
[2024-04-20 13:13:54,804: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.0016937280370170206]
[2024-04-20 13:13:55,479: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.004072246871577599]
[2024-04-20 13:13:56,148: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.05411772982451946]
[2024-04-20 13:13:56,807: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.0026532960126125506]
[2024-04-20 13:13:57,465: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.006987544089632685]
[2024-04-20 13:13:58,121: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.0007876100408302995]
[2024-04-20 13:13:58,778: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.007356347179210561]
[2024-04-20 13:13:59,438: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.01653058834953124]
[2024-04-20 13:14:00,092: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.010546734374398702]
[2024-04-20 13:14:00,756: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.007506296435125952]
[2024-04-20 13:14:01,411: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.014944915936518683]
[2024-04-20 13:14:02,069: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.0013499688111503554]
[2024-04-20 13:14:02,721: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.010927552622551436]
[2024-04-20 13:14:03,377: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.011934228950344454]
[2024-04-20 13:14:04,033: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.000947358578140954]
[2024-04-20 13:14:04,684: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.013958841958826275]
[2024-04-20 13:14:05,339: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.011366758844182463]
[2024-04-20 13:14:05,994: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.0014589163172216485]
[2024-04-20 13:14:06,648: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.00720242063312214]
[2024-04-20 13:14:07,312: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.003995897213686028]
[2024-04-20 13:14:07,978: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.0039162100102225475]
[2024-04-20 13:14:08,658: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.00315134501001623]
[2024-04-20 13:14:09,328: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.003829041942505741]
[2024-04-20 13:14:09,987: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.001221947685252554]
[2024-04-20 13:14:10,643: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.004532026034891256]
[2024-04-20 13:14:11,300: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.0066896071011591516]
[2024-04-20 13:14:11,952: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.0037963912077596477]
[2024-04-20 13:14:12,611: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.006757879211440968]
[2024-04-20 13:14:13,265: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.0017909390152114084]
[2024-04-20 13:14:13,923: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.002901103920756219]
[2024-04-20 13:14:14,577: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.00982680499851904]
[2024-04-20 13:14:15,231: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.006265438627492405]
[2024-04-20 13:14:15,887: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.016686445966358897]
[2024-04-20 13:14:16,545: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.0022654200000947265]
[2024-04-20 13:14:17,198: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.006542767877779997]
[2024-04-20 13:14:17,858: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.0022223957067283103]
[2024-04-20 13:14:18,515: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.0019785244267307707]
[2024-04-20 13:14:19,172: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.011112975420603141]
[2024-04-20 13:14:19,824: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.0034995611267360795]
[2024-04-20 13:14:20,487: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.006831789496521658]
[2024-04-20 13:14:21,162: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.0025230309132139492]
[2024-04-20 13:14:21,615: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.008056926062294386]
[2024-04-20 13:14:21,830: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.007084779597278596]
[2024-04-20 13:14:22,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.0017787480701359193]
[2024-04-20 13:14:22,251: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.003571877582020715]
[2024-04-20 13:14:22,463: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.004512004692125028]
[2024-04-20 13:14:22,678: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.0019674708328126927]
[2024-04-20 13:14:22,889: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.00972384359810428]
[2024-04-20 13:14:23,099: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.012322802085536709]
[2024-04-20 13:14:23,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.006478634951370175]
[2024-04-20 13:14:23,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.006544633090443848]
[2024-04-20 13:14:23,727: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.008360542912011399]
[2024-04-20 13:14:23,933: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.00032190172274943667]
[2024-04-20 13:14:24,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.008851831289551276]
[2024-04-20 13:14:24,342: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.009842473243249427]
[2024-04-20 13:14:24,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.003927502324301867]
[2024-04-20 13:14:24,762: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.01505578475755218]
[2024-04-20 13:14:24,968: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.005415928444021157]
[2024-04-20 13:14:25,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.012411651904346439]
[2024-04-20 13:14:25,384: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.006625309128296888]
[2024-04-20 13:14:25,590: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.002648424122123409]
[2024-04-20 13:14:25,794: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.008482097026495742]
[2024-04-20 13:14:26,001: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.006250181083872829]
[2024-04-20 13:14:26,207: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.00550167252455297]
[2024-04-20 13:14:26,413: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.005487469217223881]
[2024-04-20 13:14:26,619: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.00113819556651845]
[2024-04-20 13:14:26,828: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.0015235349367744462]
[2024-04-20 13:14:27,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.0012783901937311062]
[2024-04-20 13:14:27,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.010129073558546984]
[2024-04-20 13:14:27,449: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.005270333357971947]
[2024-04-20 13:14:27,656: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.008818799070905797]
[2024-04-20 13:14:27,863: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.003444941568691362]
[2024-04-20 13:14:28,070: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.004072833882797527]
[2024-04-20 13:14:28,274: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.0037846030738048642]
[2024-04-20 13:14:28,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.00804870875429764]
[2024-04-20 13:14:28,688: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.006037655172915816]
[2024-04-20 13:14:28,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.0038446987639902354]
[2024-04-20 13:14:29,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.00016562204329433384]
[2024-04-20 13:14:29,309: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.004334463503283389]
[2024-04-20 13:14:29,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.002745697487028234]
[2024-04-20 13:14:29,722: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.0033323590407571897]
[2024-04-20 13:14:29,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.0035755705950156385]
[2024-04-20 13:14:30,136: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.00035318249236896684]
[2024-04-20 13:14:30,342: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.0010976841132504793]
[2024-04-20 13:14:30,549: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.006711648661689062]
[2024-04-20 13:14:30,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.00932473431956015]
[2024-04-20 13:14:30,970: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.003154996085111857]
[2024-04-20 13:14:31,180: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.003959376417047041]
[2024-04-20 13:14:31,385: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.024362183157020382]
[2024-04-20 13:14:31,593: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.002271523823478231]
[2024-04-20 13:14:31,799: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.003099832535388604]
[2024-04-20 13:14:32,005: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.0007653948930278047]
[2024-04-20 13:14:32,209: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.010801468664245025]
[2024-04-20 13:14:32,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.02023889404570413]
[2024-04-20 13:14:32,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.0029584355812509334]
[2024-04-20 13:14:32,828: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.0037049926579336835]
[2024-04-20 13:14:33,034: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.013993039768137362]
[2024-04-20 13:14:33,241: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.00820418957031574]
[2024-04-20 13:14:33,448: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.0004413008165983959]
[2024-04-20 13:14:33,659: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.001271446937270594]
[2024-04-20 13:14:33,872: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.004016373264172789]
[2024-04-20 13:14:34,092: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.016994666545474813]
[2024-04-20 13:14:34,303: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.003780516537161925]
[2024-04-20 13:14:34,513: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.01002444568098459]
[2024-04-20 13:14:34,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.025105453821553835]
[2024-04-20 13:14:34,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.005142390294777866]
[2024-04-20 13:14:35,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.0021232982254868675]
[2024-04-20 13:14:35,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.003715893872830141]
[2024-04-20 13:14:35,572: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.015077566095049521]
[2024-04-20 13:14:35,780: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.007030619151002473]
[2024-04-20 13:14:35,990: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.0018615376924527203]
[2024-04-20 13:14:36,203: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.005492690757103711]
[2024-04-20 13:14:36,415: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.031331986491234795]
[2024-04-20 13:14:36,636: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.020575145694266214]
[2024-04-20 13:14:36,848: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.005877116550057347]
[2024-04-20 13:14:37,068: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.00636397445100774]
[2024-04-20 13:14:37,280: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.024118391677990163]
[2024-04-20 13:14:37,487: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.00534503330855871]
[2024-04-20 13:14:37,691: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.023093647654029596]
[2024-04-20 13:14:37,901: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.007232512065236114]
[2024-04-20 13:14:38,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.0016400274480109164]
[2024-04-20 13:14:38,321: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.008628452098045379]
[2024-04-20 13:14:38,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.0010692708163378068]
[2024-04-20 13:14:38,733: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.003590018933955278]
[2024-04-20 13:14:38,942: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.014260626036451686]
[2024-04-20 13:14:39,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.015252003338656396]
[2024-04-20 13:14:39,358: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.006180430155146131]
[2024-04-20 13:14:39,565: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.0052710307560179595]
[2024-04-20 13:14:39,771: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.0018621415267936277]
[2024-04-20 13:14:39,981: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.012000916633759533]
[2024-04-20 13:14:40,191: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 7.24374104476163e-05]
[2024-04-20 13:14:40,398: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.014844891392754777]
[2024-04-20 13:14:40,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.008871544278303617]
[2024-04-20 13:14:40,816: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.0018034838727384959]
[2024-04-20 13:14:41,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.0041477228959698725]
[2024-04-20 13:14:41,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.004902401633642142]
[2024-04-20 13:14:41,433: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.0022044278119443964]
[2024-04-20 13:14:41,639: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.0005269103266535778]
[2024-04-20 13:14:41,845: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.008042949670418346]
[2024-04-20 13:14:42,052: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.003580403028751232]
[2024-04-20 13:14:42,260: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.0013490902692428037]
[2024-04-20 13:14:42,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.00034073293968521387]
[2024-04-20 13:14:42,672: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.004343599138752708]
[2024-04-20 13:14:42,878: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.011651238576371662]
[2024-04-20 13:14:43,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.012852493391057084]
[2024-04-20 13:14:43,297: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.004447718684320481]
[2024-04-20 13:14:43,505: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.004057052885314584]
[2024-04-20 13:14:43,716: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.0015843630637358047]
[2024-04-20 13:14:43,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.0157860455991733]
[2024-04-20 13:14:44,136: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.02767496795686271]
[2024-04-20 13:14:44,343: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.002216108370317661]
[2024-04-20 13:14:44,548: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.00037224980169597925]
[2024-04-20 13:14:44,757: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.0037141331120710483]
[2024-04-20 13:14:44,963: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.0009910733120018355]
[2024-04-20 13:14:45,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.00598338901408088]
[2024-04-20 13:14:45,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.005787397123242192]
[2024-04-20 13:14:45,581: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.0018040811385357488]
[2024-04-20 13:14:45,790: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.005607616849247517]
[2024-04-20 13:14:46,001: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.010152444124475624]
[2024-04-20 13:14:46,210: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.00778027953925068]
[2024-04-20 13:14:46,416: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.0021204597424430965]
[2024-04-20 13:14:46,625: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.003211159175253202]
[2024-04-20 13:14:46,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.004159214270796961]
[2024-04-20 13:14:47,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.008168514005587997]
[2024-04-20 13:14:47,253: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.021562282685304253]
[2024-04-20 13:14:47,467: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.043015137700892846]
[2024-04-20 13:14:47,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.007900352687138497]
[2024-04-20 13:14:47,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.003959388029126864]
[2024-04-20 13:14:48,099: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.007601944635438509]
[2024-04-20 13:14:48,309: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.011190492830451489]
[2024-04-20 13:14:48,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.013863170184072167]
[2024-04-20 13:14:48,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.01169194030473561]
[2024-04-20 13:14:48,965: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.005308243963225348]
[2024-04-20 13:14:49,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.002842834206436685]
[2024-04-20 13:14:49,389: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.014049349716194447]
[2024-04-20 13:14:49,603: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.004708494956283426]
[2024-04-20 13:14:49,812: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.008257141379348907]
[2024-04-20 13:14:50,026: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.002237983100965685]
[2024-04-20 13:14:50,241: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.0012189571209609887]
[2024-04-20 13:14:50,455: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.00565455773453294]
[2024-04-20 13:14:50,669: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.011090297916316126]
[2024-04-20 13:14:50,880: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.01405737555581111]
[2024-04-20 13:14:51,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.012680012640178926]
[2024-04-20 13:14:51,301: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.002978836793639248]
[2024-04-20 13:14:51,507: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.02307732788346436]
[2024-04-20 13:14:51,711: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.01761026320789549]
[2024-04-20 13:14:51,917: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.009467416905596783]
[2024-04-20 13:14:52,120: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.0007860286958806597]
[2024-04-20 13:14:52,324: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.007713118731999201]
[2024-04-20 13:14:52,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.02890646210930583]
[2024-04-20 13:14:52,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.0005501210583713683]
[2024-04-20 13:14:52,948: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.016242274129795724]
[2024-04-20 13:14:53,153: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.010123845738906284]
[2024-04-20 13:14:53,361: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.003208948372653524]
[2024-04-20 13:14:53,572: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.005284949988269341]
[2024-04-20 13:14:53,782: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.0034084938228705433]
[2024-04-20 13:14:53,992: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.0030810732134872497]
[2024-04-20 13:14:54,200: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.015508605719632886]
[2024-04-20 13:14:54,405: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.023997653279071676]
[2024-04-20 13:14:54,612: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.004574199472763623]
[2024-04-20 13:14:54,820: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.001770069008308406]
[2024-04-20 13:14:55,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.006898009481279412]
[2024-04-20 13:14:55,236: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.0045105395528478665]
[2024-04-20 13:14:55,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.004250657515208756]
[2024-04-20 13:14:55,652: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.011451740762912376]
[2024-04-20 13:14:55,859: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.001078041547235032]
[2024-04-20 13:14:56,064: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.004622612279060625]
[2024-04-20 13:14:56,272: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.0016542790215155346]
[2024-04-20 13:14:56,477: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.0016255838499691063]
[2024-04-20 13:14:56,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.003130107997831651]
[2024-04-20 13:14:56,890: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.00657395174628054]
[2024-04-20 13:14:57,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.0008079842508466108]
[2024-04-20 13:14:57,302: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.0013415254754364102]
[2024-04-20 13:14:57,508: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.00955339336930725]
[2024-04-20 13:14:57,713: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.001910891967883343]
[2024-04-20 13:14:57,920: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.02312322348692445]
[2024-04-20 13:14:58,132: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.001233040857920314]
[2024-04-20 13:14:58,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.0026105415518813445]
[2024-04-20 13:14:58,548: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.0007317989349031421]
[2024-04-20 13:14:58,754: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.0013320028928884902]
[2024-04-20 13:14:58,959: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.019761586364651165]
[2024-04-20 13:14:59,163: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.00026106683837080633]
[2024-04-20 13:14:59,368: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.0009030806647191521]
[2024-04-20 13:14:59,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.0006553668813644359]
[2024-04-20 13:14:59,786: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.005943459093507765]
[2024-04-20 13:14:59,998: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.00026821608714810627]
[2024-04-20 13:15:00,205: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.007091456318056191]
[2024-04-20 13:15:00,409: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.004983136355981842]
[2024-04-20 13:15:00,616: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.006375078681255395]
[2024-04-20 13:15:00,826: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.0009154696608825985]
[2024-04-20 13:15:01,036: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 0.011594876381582417]
[2024-04-20 13:15:01,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.008225173971616621]
[2024-04-20 13:15:01,452: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.0030672257780873157]
[2024-04-20 13:15:01,664: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.016746143666136814]
[2024-04-20 13:15:01,873: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.00047219170730794735]
[2024-04-20 13:15:02,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.0099879613418154]
[2024-04-20 13:15:02,320: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.000551176822198826]
[2024-04-20 13:15:02,533: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.0025117131641784513]
[2024-04-20 13:15:02,744: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.0025121499631889097]
[2024-04-20 13:15:02,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.004647565841549076]
[2024-04-20 13:15:03,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.0077395509244718875]
[2024-04-20 13:15:03,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.0061212264591621966]
[2024-04-20 13:15:03,599: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.005200570227107751]
[2024-04-20 13:15:03,809: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.002810176329806738]
[2024-04-20 13:15:04,020: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.023470864314759553]
[2024-04-20 13:15:04,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.004920846237699975]
[2024-04-20 13:15:04,444: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.005087103822193345]
[2024-04-20 13:15:04,656: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.005031241335737014]
[2024-04-20 13:15:04,866: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.006361627768258889]
[2024-04-20 13:15:05,074: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.009156806222417326]
[2024-04-20 13:15:05,275: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.001337635372198096]
[2024-04-20 13:15:05,484: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.00606502360857654]
[2024-04-20 13:15:05,690: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.00472493754994111]
[2024-04-20 13:15:05,893: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.0020878747578682603]
[2024-04-20 13:15:06,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.0040110146119292514]
[2024-04-20 13:15:06,301: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.0022177018393482327]
[2024-04-20 13:15:06,512: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.013511725537245148]
[2024-04-20 13:15:06,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.0007417175876171276]
[2024-04-20 13:15:06,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.0025586997381683574]
[2024-04-20 13:15:07,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.009590511491851703]
[2024-04-20 13:15:07,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.006607494670342095]
[2024-04-20 13:15:07,551: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.004210547729456788]
[2024-04-20 13:15:07,755: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.007099946195459857]
[2024-04-20 13:15:07,962: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.010159077440180995]
[2024-04-20 13:15:08,167: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.0034850736260062286]
[2024-04-20 13:15:08,375: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.011046069240223201]
[2024-04-20 13:15:08,581: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.016312533470841068]
[2024-04-20 13:15:08,789: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.008740507769845852]
[2024-04-20 13:15:08,997: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.004842185198957854]
[2024-04-20 13:15:09,202: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.006752620716813546]
[2024-04-20 13:15:09,407: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.005166516965308981]
[2024-04-20 13:15:09,616: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 0.0015129332411154756]
[2024-04-20 13:15:09,824: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.004295810921283813]
[2024-04-20 13:15:10,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 0.007900693562973985]
[2024-04-20 13:15:10,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.0022295948642656826]
[2024-04-20 13:15:10,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.0017240453082080231]
[2024-04-20 13:15:10,652: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.005552321989904325]
[2024-04-20 13:15:10,863: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.0018926232251693597]
[2024-04-20 13:15:11,070: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.004536606345636301]
[2024-04-20 13:15:11,278: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.0011618040716791782]
[2024-04-20 13:15:11,488: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.0004246032570137493]
[2024-04-20 13:15:11,693: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.007142947829121681]
[2024-04-20 13:15:11,897: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 0.004430363583951805]
[2024-04-20 13:15:12,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.0015759177441594027]
[2024-04-20 13:15:12,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.0008659606668878372]
[2024-04-20 13:15:12,515: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.0035648405244266684]
[2024-04-20 13:15:12,721: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.008337993140289367]
[2024-04-20 13:15:12,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.017657138765320393]
[2024-04-20 13:15:13,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.012449014621367577]
[2024-04-20 13:15:13,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.023918956678059503]
[2024-04-20 13:15:13,546: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.001387368199276782]
[2024-04-20 13:15:13,754: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.0052749659750433815]
[2024-04-20 13:15:13,963: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.0018311151905417533]
[2024-04-20 13:15:14,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.0014115773824711782]
[2024-04-20 13:15:14,377: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.007079053555774987]
[2024-04-20 13:15:14,582: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.0031180950176571062]
[2024-04-20 13:15:14,790: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.000929371772507108]
[2024-04-20 13:15:15,000: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.00226433499181852]
[2024-04-20 13:15:15,210: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.006267526786719722]
[2024-04-20 13:15:15,425: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.004739619410063787]
[2024-04-20 13:15:15,644: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.01544782930477418]
[2024-04-20 13:15:15,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.01807893918652666]
[2024-04-20 13:15:16,073: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.004555981026641924]
[2024-04-20 13:15:16,282: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.006841655116863942]
[2024-04-20 13:15:16,500: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.013644839601992914]
[2024-04-20 13:15:16,710: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.0017796507398786996]
[2024-04-20 13:15:16,923: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.0016738402938889867]
[2024-04-20 13:15:17,133: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.015167236710730657]
[2024-04-20 13:15:17,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.0004292686017217862]
[2024-04-20 13:15:17,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.00023930866547882166]
[2024-04-20 13:15:17,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.002844731398033792]
[2024-04-20 13:15:17,986: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.01594346810946518]
[2024-04-20 13:15:18,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.02350353306459882]
[2024-04-20 13:15:18,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.0017709061739143253]
[2024-04-20 13:15:18,624: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.011369318672410296]
[2024-04-20 13:15:18,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.009511866330016874]
[2024-04-20 13:15:19,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.010354874692887128]
[2024-04-20 13:15:19,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.016455319635457172]
[2024-04-20 13:15:19,455: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.001834280805081889]
[2024-04-20 13:15:19,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.003386955354920039]
[2024-04-20 13:15:19,869: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.003291521870867532]
[2024-04-20 13:15:20,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 0.008445194175314686]
[2024-04-20 13:15:20,284: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.017342948189969634]
[2024-04-20 13:15:20,488: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.00501132811989965]
[2024-04-20 13:15:20,697: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.000276999001912687]
[2024-04-20 13:15:20,905: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.0007910101430599061]
[2024-04-20 13:15:21,111: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.020385454731952562]
[2024-04-20 13:15:21,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.009914153547555331]
[2024-04-20 13:15:21,524: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.005607695590247029]
[2024-04-20 13:15:21,734: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.016167747342332027]
[2024-04-20 13:15:21,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.032358191800738824]
[2024-04-20 13:15:22,146: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.0009465268970427549]
[2024-04-20 13:15:22,349: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.009894868248330886]
[2024-04-20 13:15:22,556: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.005955535716590481]
[2024-04-20 13:15:22,768: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.00725230537164206]
[2024-04-20 13:15:22,977: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.010586714442753633]
[2024-04-20 13:15:23,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.003884925860221487]
[2024-04-20 13:15:23,392: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.03806301445090226]
[2024-04-20 13:15:23,599: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.013609140887661618]
[2024-04-20 13:15:23,809: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.018386606384238797]
[2024-04-20 13:15:24,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.004062795536396803]
[2024-04-20 13:15:24,226: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.009514155638875834]
[2024-04-20 13:15:24,433: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.06594350348057539]
[2024-04-20 13:15:24,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.015745162581830313]
[2024-04-20 13:15:24,851: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.015904669430913256]
[2024-04-20 13:15:25,057: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.0036812290505612725]
[2024-04-20 13:15:25,263: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.040248259777803067]
[2024-04-20 13:15:25,470: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.0034998259077166863]
[2024-04-20 13:15:25,677: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.011673147186197167]
[2024-04-20 13:15:25,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.0016041636491668084]
[2024-04-20 13:15:26,089: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.0048384868546382]
[2024-04-20 13:15:26,293: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.01135077588341002]
[2024-04-20 13:15:26,502: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.006716111925083303]
[2024-04-20 13:15:26,709: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.009778368427866948]
[2024-04-20 13:15:26,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.0390993943064097]
[2024-04-20 13:15:27,133: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.004289600847851156]
[2024-04-20 13:15:27,338: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.0028723409730709937]
[2024-04-20 13:15:27,544: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.0029920351334069262]
[2024-04-20 13:15:27,748: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.03242872219946567]
[2024-04-20 13:15:27,959: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.003596790378027535]
[2024-04-20 13:15:28,165: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.0022628954299919344]
[2024-04-20 13:15:28,373: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.0028953219522040567]
[2024-04-20 13:15:28,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.02379225533510033]
[2024-04-20 13:15:28,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.016795321721457677]
[2024-04-20 13:15:28,996: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.019723368322362576]
[2024-04-20 13:15:29,210: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.011507841313083977]
[2024-04-20 13:15:29,430: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.0016701948279485936]
[2024-04-20 13:15:29,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.015866806131286163]
[2024-04-20 13:15:29,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.027887021644638178]
[2024-04-20 13:15:30,066: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.0011511097712080674]
[2024-04-20 13:15:30,280: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.012688507652275591]
[2024-04-20 13:15:30,490: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.007115906770650604]
[2024-04-20 13:15:30,700: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.03742453813949163]
[2024-04-20 13:15:30,912: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.01641231686402461]
[2024-04-20 13:15:31,123: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.011874632152718114]
[2024-04-20 13:15:31,331: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.008496517883134743]
[2024-04-20 13:15:31,545: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.011826583619173301]
[2024-04-20 13:15:31,756: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.018442892565854206]
[2024-04-20 13:15:31,966: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.001239503275429031]
[2024-04-20 13:15:32,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.01784130928666869]
[2024-04-20 13:15:32,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.015456122116333133]
[2024-04-20 13:15:32,597: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.013532140597550167]
[2024-04-20 13:15:32,803: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.00844871210879455]
[2024-04-20 13:15:33,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.015547727586332674]
[2024-04-20 13:15:33,223: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.005493477002768151]
[2024-04-20 13:15:33,429: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.024400428165095304]
[2024-04-20 13:15:33,634: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.007476705069342959]
[2024-04-20 13:15:33,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.02323799044291075]
[2024-04-20 13:15:34,051: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.006884259275612988]
[2024-04-20 13:15:34,261: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.00562239668413578]
[2024-04-20 13:15:34,469: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.026313942286768137]
[2024-04-20 13:15:34,676: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.010275853773893305]
[2024-04-20 13:15:34,881: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.006412390517140844]
[2024-04-20 13:15:35,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.006854774273779272]
[2024-04-20 13:15:35,286: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.004144133231739983]
[2024-04-20 13:15:35,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.002020589428392156]
[2024-04-20 13:15:35,700: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.0025634057313468233]
[2024-04-20 13:15:35,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.012318732404987728]
[2024-04-20 13:15:36,115: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.02669906001866824]
[2024-04-20 13:15:36,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.0028663584486807534]
[2024-04-20 13:15:36,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.003928761509116674]
[2024-04-20 13:15:36,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.004901323964919753]
[2024-04-20 13:15:36,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.005920383479238043]
[2024-04-20 13:15:37,148: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.002435515906679268]
[2024-04-20 13:15:37,354: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.005588262490335971]
[2024-04-20 13:15:37,561: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.00749603210727099]
[2024-04-20 13:15:37,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.02044701762441853]
[2024-04-20 13:15:37,978: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.008524493895922329]
[2024-04-20 13:15:38,187: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.007442502467039463]
[2024-04-20 13:15:38,393: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.006621270694938073]
[2024-04-20 13:15:38,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.008933111931084363]
[2024-04-20 13:15:38,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.0005710969461363321]
[2024-04-20 13:15:39,015: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.0022077812985021312]
[2024-04-20 13:15:39,224: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.006074776304810004]
[2024-04-20 13:15:39,433: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.006160736118646816]
[2024-04-20 13:15:39,641: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.005565823932287051]
[2024-04-20 13:15:39,848: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.0007298118631323038]
[2024-04-20 13:15:40,055: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.003300460909625194]
[2024-04-20 13:15:40,263: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.004356819701025984]
[2024-04-20 13:15:40,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.00558243300513044]
[2024-04-20 13:15:40,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.0005460126174587483]
[2024-04-20 13:15:40,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.02958242991881046]
[2024-04-20 13:15:41,089: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.009848140452190896]
[2024-04-20 13:15:41,295: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.007686644220481726]
[2024-04-20 13:15:41,502: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.00783249444963043]
[2024-04-20 13:15:41,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.005520395507639198]
[2024-04-20 13:15:41,915: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.012064424504560833]
[2024-04-20 13:15:42,122: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.01987704937052137]
[2024-04-20 13:15:42,328: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 0.010545822012209046]
[2024-04-20 13:15:42,534: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.006824701618654595]
[2024-04-20 13:15:42,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.03403633430125655]
[2024-04-20 13:15:42,955: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.005990524347848043]
[2024-04-20 13:15:43,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.010529001383800486]
[2024-04-20 13:15:43,384: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.003236848685018766]
[2024-04-20 13:15:43,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.013048034965736465]
[2024-04-20 13:15:43,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.0014008903189462272]
[2024-04-20 13:15:44,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.008182902843462719]
[2024-04-20 13:15:44,237: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.005620865536116687]
[2024-04-20 13:15:44,449: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.008203104090415452]
[2024-04-20 13:15:44,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.0011317293323498431]
[2024-04-20 13:15:44,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.0002419684376998404]
[2024-04-20 13:15:45,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.0009433758644952523]
[2024-04-20 13:15:45,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.004463443942285662]
[2024-04-20 13:15:45,531: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.0005109648312631151]
[2024-04-20 13:15:45,742: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.0005118256977626999]
[2024-04-20 13:15:45,962: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.00604644500868864]
[2024-04-20 13:15:46,171: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.0003946050751248634]
[2024-04-20 13:15:46,380: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.018761742325074073]
[2024-04-20 13:15:46,585: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.0063823744522349705]
[2024-04-20 13:15:46,795: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.010100940223793537]
[2024-04-20 13:15:47,008: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.0067440181385248]
[2024-04-20 13:15:47,216: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.015918420123172353]
[2024-04-20 13:15:47,423: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.0060724711268890065]
[2024-04-20 13:15:47,629: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.007951068114089703]
[2024-04-20 13:15:47,840: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.011118827087137543]
[2024-04-20 13:15:48,048: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.006026514333705461]
[2024-04-20 13:15:48,256: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.006534036645072461]
[2024-04-20 13:15:48,464: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.02001880530143879]
[2024-04-20 13:15:48,671: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.010388093394496721]
[2024-04-20 13:15:48,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.01392673576155228]
[2024-04-20 13:15:49,083: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.010298312404069164]
[2024-04-20 13:15:49,290: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.02270181957944786]
[2024-04-20 13:15:49,496: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.0014388445208153397]
[2024-04-20 13:15:49,706: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.005417504802869325]
[2024-04-20 13:15:49,916: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.003676380507847437]
[2024-04-20 13:15:50,124: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.003733527959853305]
[2024-04-20 13:15:50,330: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.0038707458207296063]
[2024-04-20 13:15:50,537: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.020369288138513485]
[2024-04-20 13:15:50,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.00017755757063018967]
[2024-04-20 13:15:50,950: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.005667477653399127]
[2024-04-20 13:15:51,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.008541852246363307]
[2024-04-20 13:15:51,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.002345413096895266]
[2024-04-20 13:15:51,568: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.007649779121813229]
[2024-04-20 13:15:51,775: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.00662556705909509]
[2024-04-20 13:15:51,980: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.008140754933072324]
[2024-04-20 13:15:52,188: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.004897008695795945]
[2024-04-20 13:15:52,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.0008326861089230045]
[2024-04-20 13:15:52,602: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.011917739147452484]
[2024-04-20 13:15:52,813: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.003649576593827017]
[2024-04-20 13:15:53,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.00018136998043137654]
[2024-04-20 13:15:53,227: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.00802308929695938]
[2024-04-20 13:15:53,437: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.03514797883049888]
[2024-04-20 13:15:53,647: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.011594799608176503]
[2024-04-20 13:15:53,853: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.006507494233964251]
[2024-04-20 13:15:54,058: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.001708754274687635]
[2024-04-20 13:15:54,264: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.005010790505122178]
[2024-04-20 13:15:54,471: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.0010357514783038719]
[2024-04-20 13:15:54,678: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.014449119763687419]
[2024-04-20 13:15:54,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.010987803812972959]
[2024-04-20 13:15:55,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.011112755613447108]
[2024-04-20 13:15:55,307: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.032458606812947655]
[2024-04-20 13:15:55,513: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.002596234809252352]
[2024-04-20 13:15:55,718: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.005042987061382268]
[2024-04-20 13:15:55,925: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.0008857714658453972]
[2024-04-20 13:15:56,129: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.0005887110688415912]
[2024-04-20 13:15:56,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.010377852701649107]
[2024-04-20 13:15:56,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.0011669043997864681]
[2024-04-20 13:15:56,775: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.0026670263347928582]
[2024-04-20 13:15:56,989: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.02731938587210855]
[2024-04-20 13:15:57,200: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.002546561455809094]
[2024-04-20 13:15:57,414: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.006071826668286942]
[2024-04-20 13:15:57,630: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.00040833675613677925]
[2024-04-20 13:15:57,846: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 0.004734722261481437]
[2024-04-20 13:15:58,056: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.01380336816621161]
[2024-04-20 13:15:58,269: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.02361121381175893]
[2024-04-20 13:15:58,478: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.0004935900469980552]
[2024-04-20 13:15:58,689: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.003818617261213932]
[2024-04-20 13:15:58,899: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.009596248038140706]
[2024-04-20 13:15:59,111: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.003997888017796891]
[2024-04-20 13:15:59,328: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.0015516102277015416]
[2024-04-20 13:15:59,547: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.008040258413091018]
[2024-04-20 13:15:59,771: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.002477807646637852]
[2024-04-20 13:15:59,984: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.016633713122928384]
[2024-04-20 13:16:00,194: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.0043130680520276935]
[2024-04-20 13:16:00,399: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 0.0018274723204148753]
[2024-04-20 13:16:00,614: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.008047609484967824]
[2024-04-20 13:16:00,822: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.0020172913779247007]
[2024-04-20 13:16:01,031: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.0014046631220201683]
[2024-04-20 13:16:01,236: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.0009063331963115136]
[2024-04-20 13:16:01,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.011434774251966753]
[2024-04-20 13:16:01,652: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.010272185301287613]
[2024-04-20 13:16:01,860: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.005302365516605012]
[2024-04-20 13:16:02,068: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.010848301701870193]
[2024-04-20 13:16:02,283: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.005499585543349409]
[2024-04-20 13:16:02,491: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.0005498085707919048]
[2024-04-20 13:16:02,697: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.004842477567110949]
[2024-04-20 13:16:02,905: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.011488714469061833]
[2024-04-20 13:16:03,113: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.00013838912547073652]
[2024-04-20 13:16:03,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.0008027198223032728]
[2024-04-20 13:16:03,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.001081465669142826]
[2024-04-20 13:16:03,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.010723702263390887]
[2024-04-20 13:16:03,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.0033796603230547458]
[2024-04-20 13:16:04,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.002338164014306683]
[2024-04-20 13:16:04,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.0013205700330916593]
[2024-04-20 13:16:04,567: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.015962602128316003]
[2024-04-20 13:16:04,774: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.05528878964785927]
[2024-04-20 13:16:04,988: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.006018431264859304]
[2024-04-20 13:16:05,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.012718319524615416]
[2024-04-20 13:16:05,402: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.0011439627125026043]
[2024-04-20 13:16:05,609: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.00014002955010084463]
[2024-04-20 13:16:05,820: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.015854701187598526]
[2024-04-20 13:16:06,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.00211633855751423]
[2024-04-20 13:16:06,237: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.009441233377944813]
[2024-04-20 13:16:06,445: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.006639328272675664]
[2024-04-20 13:16:06,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.0053747822715724865]
[2024-04-20 13:16:06,858: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.0015682784019183237]
[2024-04-20 13:16:07,066: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.008429376767962916]
[2024-04-20 13:16:07,273: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.0007061406373940499]
[2024-04-20 13:16:07,477: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.014293461371130753]
[2024-04-20 13:16:07,686: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.001651214076630312]
[2024-04-20 13:16:07,895: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.00043816857172381164]
[2024-04-20 13:16:08,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.003133341664949172]
[2024-04-20 13:16:08,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.00382779292511208]
[2024-04-20 13:16:08,520: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.006236683278252731]
[2024-04-20 13:16:08,727: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.0015292806044869725]
[2024-04-20 13:16:08,931: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.005964282700356775]
[2024-04-20 13:16:09,135: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.01350151678134668]
[2024-04-20 13:16:09,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.004017855696271104]
[2024-04-20 13:16:09,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.0004739547591832606]
[2024-04-20 13:16:09,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.008663491868951212]
[2024-04-20 13:16:09,961: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.014667851936148384]
[2024-04-20 13:16:10,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.00017888910964035336]
[2024-04-20 13:16:10,383: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.0030015589586442223]
[2024-04-20 13:16:10,607: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.014973242876144016]
[2024-04-20 13:16:10,821: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.0040727120648469395]
[2024-04-20 13:16:11,032: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.0015057126065263892]
[2024-04-20 13:16:11,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.0011248013786523637]
[2024-04-20 13:16:11,458: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.0002534604563699847]
[2024-04-20 13:16:11,668: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.003979134584675093]
[2024-04-20 13:16:11,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.0007275269770269813]
[2024-04-20 13:16:12,088: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.00022101286662046046]
[2024-04-20 13:16:12,306: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.00229545216312461]
[2024-04-20 13:16:12,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.003872812618841437]
[2024-04-20 13:16:12,727: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.0028439343733388696]
[2024-04-20 13:16:12,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.002562141572835126]
[2024-04-20 13:16:13,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 6.690344546268382e-05]
[2024-04-20 13:16:13,370: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.0026555223388130115]
[2024-04-20 13:16:13,578: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.018571036669115]
[2024-04-20 13:16:13,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.01731133256126459]
[2024-04-20 13:16:13,986: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.005453119934108614]
[2024-04-20 13:16:14,200: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.003685847269341411]
[2024-04-20 13:16:14,407: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.005424093651156999]
[2024-04-20 13:16:14,615: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.0021068321672908677]
[2024-04-20 13:16:14,819: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.0007840062677195731]
[2024-04-20 13:16:15,023: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.014865516925914602]
[2024-04-20 13:16:15,231: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.003371839809459633]
[2024-04-20 13:16:15,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.010189929892275615]
[2024-04-20 13:16:15,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.01585367521147199]
[2024-04-20 13:16:15,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.012618249493409641]
[2024-04-20 13:16:16,063: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.0011061373466927677]
[2024-04-20 13:16:16,270: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.011286637262648015]
[2024-04-20 13:16:16,479: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.0006227503780626198]
[2024-04-20 13:16:16,686: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.0020786829777487423]
[2024-04-20 13:16:16,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.012523306643731224]
[2024-04-20 13:16:17,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.00023609564425166327]
[2024-04-20 13:16:17,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.004883994318831164]
[2024-04-20 13:16:17,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.0014915531024791043]
[2024-04-20 13:16:17,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.003260574631534541]
[2024-04-20 13:16:17,923: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.0010931272986264655]
[2024-04-20 13:16:18,130: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.0032848211814129917]
[2024-04-20 13:16:18,340: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.0039061222330929015]
[2024-04-20 13:16:18,547: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.0018845696829524067]
[2024-04-20 13:16:18,754: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.006289704079862775]
[2024-04-20 13:16:18,961: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.014066176061551286]
[2024-04-20 13:16:19,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.0035031214690503295]
[2024-04-20 13:16:19,373: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.00027670914634590017]
[2024-04-20 13:16:19,579: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.0008582278963789383]
[2024-04-20 13:16:19,785: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.002795342647774854]
[2024-04-20 13:16:19,990: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.0004691995224534666]
[2024-04-20 13:16:20,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.006877367552147189]
[2024-04-20 13:16:20,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.002226120306136732]
[2024-04-20 13:16:20,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.009995983018163679]
[2024-04-20 13:16:20,823: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.0020718773771363076]
[2024-04-20 13:16:21,030: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.009491358708181836]
[2024-04-20 13:16:21,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.0025146887876372234]
[2024-04-20 13:16:21,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.008012499798754418]
[2024-04-20 13:16:21,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.0009924996672984144]
[2024-04-20 13:16:21,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.004389844950900531]
[2024-04-20 13:16:22,064: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.006265784351572283]
[2024-04-20 13:16:22,271: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.0028068028467181047]
[2024-04-20 13:16:22,478: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.004411241829744968]
[2024-04-20 13:16:22,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.005226734600734755]
[2024-04-20 13:16:22,892: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.0014013329422193869]
[2024-04-20 13:16:23,092: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.00027555185474045297]
[2024-04-20 13:16:23,295: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.0036855399830445497]
[2024-04-20 13:16:23,499: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.001343614612366194]
[2024-04-20 13:16:23,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.002804485898223191]
[2024-04-20 13:16:23,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.007992257023832147]
[2024-04-20 13:16:24,136: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.00541998274702885]
[2024-04-20 13:16:24,347: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.00020294636277807732]
[2024-04-20 13:16:24,556: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 3.0067178096564885e-05]
[2024-04-20 13:16:24,767: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.005454957019469443]
[2024-04-20 13:16:24,977: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.0075192679126948265]
[2024-04-20 13:16:25,190: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.0006821860831123083]
[2024-04-20 13:16:25,400: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 7.04582459744199e-05]
[2024-04-20 13:16:25,608: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.0070310373675553945]
[2024-04-20 13:16:25,817: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.0008165453806940646]
[2024-04-20 13:16:26,014: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 0.0010817632020055162]
[2024-04-20 13:16:50,625: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9955113433948433, 'precision': 0.8040190692681695, 'recall': 0.9102330402459075, 'f1': 0.8538355796955676}]
[2024-04-20 13:16:50,634: INFO: roberta_kFold_initial_lstm: Fold 3/3]
[2024-04-20 13:16:50,640: INFO: roberta_kFold_initial_lstm: Fold 3/3 , Epoch: 1/3]
[2024-04-20 13:16:51,352: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.004019999314935154]
[2024-04-20 13:16:51,992: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.007044652142541662]
[2024-04-20 13:16:52,622: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.0007880361491045101]
[2024-04-20 13:16:53,261: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.006810060148474823]
[2024-04-20 13:16:53,900: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.012727208772893838]
[2024-04-20 13:16:54,549: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.0007068605526659683]
[2024-04-20 13:16:55,195: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.010951366407309876]
[2024-04-20 13:16:55,844: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.003803756354380186]
[2024-04-20 13:16:56,496: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.004083847566709637]
[2024-04-20 13:16:57,138: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.008154330574319144]
[2024-04-20 13:16:57,779: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.002998076004963054]
[2024-04-20 13:16:58,409: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.01568117770825191]
[2024-04-20 13:16:59,047: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.002135139456937745]
[2024-04-20 13:16:59,689: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.007283215057352783]
[2024-04-20 13:17:00,326: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.0006921005275704736]
[2024-04-20 13:17:00,971: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.005036439230153476]
[2024-04-20 13:17:01,609: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.0002718214992959489]
[2024-04-20 13:17:02,244: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.006818680461042408]
[2024-04-20 13:17:02,887: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.017250672441020975]
[2024-04-20 13:17:03,528: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.0045112689679680275]
[2024-04-20 13:17:04,171: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.002742778450926349]
[2024-04-20 13:17:04,814: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.02367049466809824]
[2024-04-20 13:17:05,450: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.0006214257014038568]
[2024-04-20 13:17:06,097: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.0018443556198250014]
[2024-04-20 13:17:06,744: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.018706926398306057]
[2024-04-20 13:17:07,397: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.005752997433653249]
[2024-04-20 13:17:08,053: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.002716566170077413]
[2024-04-20 13:17:08,709: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.004584037787177602]
[2024-04-20 13:17:09,367: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.0032878166653014344]
[2024-04-20 13:17:10,017: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.002058615757476818]
[2024-04-20 13:17:10,667: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.015093509616961953]
[2024-04-20 13:17:11,313: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.009784155690907272]
[2024-04-20 13:17:11,961: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.0026028479074647463]
[2024-04-20 13:17:12,606: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.003996692258106275]
[2024-04-20 13:17:13,254: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.002504850419185599]
[2024-04-20 13:17:13,900: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.010232660188705176]
[2024-04-20 13:17:14,550: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.0012387880074241592]
[2024-04-20 13:17:15,200: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.003559825653732281]
[2024-04-20 13:17:15,843: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.0021388536917623436]
[2024-04-20 13:17:16,492: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.004871617854934189]
[2024-04-20 13:17:17,140: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.0019099773622379375]
[2024-04-20 13:17:17,791: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.0016997165862132858]
[2024-04-20 13:17:18,437: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.00593631573778669]
[2024-04-20 13:17:19,088: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.0005487753672452773]
[2024-04-20 13:17:19,738: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.0034146036609293967]
[2024-04-20 13:17:20,390: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.0008597538472126438]
[2024-04-20 13:17:21,039: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.03512553181995388]
[2024-04-20 13:17:21,690: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.00705845841938501]
[2024-04-20 13:17:22,339: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.005661189770276043]
[2024-04-20 13:17:22,994: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.001388811901208057]
[2024-04-20 13:17:23,644: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.004731844090877151]
[2024-04-20 13:17:24,284: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.011680370734600693]
[2024-04-20 13:17:24,931: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.003630837595798964]
[2024-04-20 13:17:25,575: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.01365170186724659]
[2024-04-20 13:17:26,216: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.0037472530990917737]
[2024-04-20 13:17:26,854: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.006983875024586984]
[2024-04-20 13:17:27,496: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.0029013517536039994]
[2024-04-20 13:17:28,142: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.029362142020854857]
[2024-04-20 13:17:28,786: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.002584463080857517]
[2024-04-20 13:17:29,424: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.012469266269204199]
[2024-04-20 13:17:30,069: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.00600893549999675]
[2024-04-20 13:17:30,713: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.012531529231048437]
[2024-04-20 13:17:31,355: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.0009126844616762853]
[2024-04-20 13:17:31,993: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.007636177063154892]
[2024-04-20 13:17:32,636: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.006118981642790384]
[2024-04-20 13:17:33,282: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.005899681218731803]
[2024-04-20 13:17:33,929: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.02425368358884395]
[2024-04-20 13:17:34,596: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.013531453249381493]
[2024-04-20 13:17:35,256: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.0029892758405169746]
[2024-04-20 13:17:35,905: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.0007672175124400122]
[2024-04-20 13:17:36,559: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.0032881660989396064]
[2024-04-20 13:17:37,214: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.006181345023281191]
[2024-04-20 13:17:37,857: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.0034636752612480395]
[2024-04-20 13:17:38,502: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.0035874488237487893]
[2024-04-20 13:17:39,145: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.006532146407669743]
[2024-04-20 13:17:39,789: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.006490422653853853]
[2024-04-20 13:17:40,428: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.0032913530004704717]
[2024-04-20 13:17:41,073: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.018207648224520402]
[2024-04-20 13:17:41,715: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.0021221598845513495]
[2024-04-20 13:17:42,350: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.002902591058173075]
[2024-04-20 13:17:42,992: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.0007210649441452414]
[2024-04-20 13:17:43,632: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.006671818726669143]
[2024-04-20 13:17:44,272: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.004785826662406502]
[2024-04-20 13:17:44,914: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.0028873832083732218]
[2024-04-20 13:17:45,559: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.002374913474448663]
[2024-04-20 13:17:46,198: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.010071995379694144]
[2024-04-20 13:17:46,841: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.009959528825221433]
[2024-04-20 13:17:47,492: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.003206188465778083]
[2024-04-20 13:17:48,141: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.006078978089299975]
[2024-04-20 13:17:48,787: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.07579430552124225]
[2024-04-20 13:17:49,436: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.002448821478977349]
[2024-04-20 13:17:50,091: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.010495300098924383]
[2024-04-20 13:17:50,742: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.010772880698433258]
[2024-04-20 13:17:51,384: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.004449419859235923]
[2024-04-20 13:17:52,025: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.0047186929819787275]
[2024-04-20 13:17:52,669: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.0069924536901466595]
[2024-04-20 13:17:53,313: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.014445122863121]
[2024-04-20 13:17:53,958: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.007444957462223268]
[2024-04-20 13:17:54,596: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.004003643531927739]
[2024-04-20 13:17:55,242: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.0016178965748898516]
[2024-04-20 13:17:55,884: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.0024666521619880325]
[2024-04-20 13:17:56,527: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.004761397951283267]
[2024-04-20 13:17:57,167: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.018292135451160277]
[2024-04-20 13:17:57,813: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.005865538957469651]
[2024-04-20 13:17:58,459: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.009142319112336319]
[2024-04-20 13:17:59,104: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.012345283369963005]
[2024-04-20 13:17:59,751: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.005531170066372244]
[2024-04-20 13:18:00,392: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.004857157260492449]
[2024-04-20 13:18:01,044: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.0008068469092058848]
[2024-04-20 13:18:01,696: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.00744231602981997]
[2024-04-20 13:18:02,349: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.004793816211759169]
[2024-04-20 13:18:03,005: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.012212937940691683]
[2024-04-20 13:18:03,659: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.005371146055115131]
[2024-04-20 13:18:04,301: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.015452250488343634]
[2024-04-20 13:18:04,943: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.0031274487084870725]
[2024-04-20 13:18:05,593: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.002211661138611968]
[2024-04-20 13:18:06,237: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.0008869746085894254]
[2024-04-20 13:18:06,885: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.0011970622260087983]
[2024-04-20 13:18:07,541: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.0100766901215845]
[2024-04-20 13:18:08,184: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.0014847230136153379]
[2024-04-20 13:18:08,830: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.0012459761780371844]
[2024-04-20 13:18:09,478: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.0022955746244938775]
[2024-04-20 13:18:10,129: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.03097306730227298]
[2024-04-20 13:18:10,778: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.0044278503646356816]
[2024-04-20 13:18:11,428: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.0036302498725887494]
[2024-04-20 13:18:12,075: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.001839285899650649]
[2024-04-20 13:18:12,727: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.018878369049398214]
[2024-04-20 13:18:13,373: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.009929417400036715]
[2024-04-20 13:18:14,034: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.00948290126315039]
[2024-04-20 13:18:14,699: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.020273276241422375]
[2024-04-20 13:18:15,347: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.0033733848676705367]
[2024-04-20 13:18:16,002: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.0019523044583893982]
[2024-04-20 13:18:16,660: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.002608878653640567]
[2024-04-20 13:18:17,313: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.0034873250290642344]
[2024-04-20 13:18:17,959: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.00046676190412630117]
[2024-04-20 13:18:18,598: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.0007389238462039104]
[2024-04-20 13:18:19,247: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.011685950201581094]
[2024-04-20 13:18:19,894: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.0002832667746211598]
[2024-04-20 13:18:20,543: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.004260480503812245]
[2024-04-20 13:18:21,191: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.0002097488790434769]
[2024-04-20 13:18:21,862: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.002678275629915171]
[2024-04-20 13:18:22,517: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.0028805974612509037]
[2024-04-20 13:18:23,159: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.0021536605893769253]
[2024-04-20 13:18:23,809: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.020049565238982364]
[2024-04-20 13:18:24,457: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.0013638482522775276]
[2024-04-20 13:18:25,103: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.0037297612510253262]
[2024-04-20 13:18:25,749: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.0015731316989201934]
[2024-04-20 13:18:26,399: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.011995681287245976]
[2024-04-20 13:18:27,044: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.005592704623079826]
[2024-04-20 13:18:27,695: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.013117444029449341]
[2024-04-20 13:18:28,350: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.00907020904265067]
[2024-04-20 13:18:29,005: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.00892421084989812]
[2024-04-20 13:18:29,665: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.04779081543950331]
[2024-04-20 13:18:30,321: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.01161799169414908]
[2024-04-20 13:18:30,969: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.006935814679889553]
[2024-04-20 13:18:31,617: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.005569847307689252]
[2024-04-20 13:18:32,267: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.008642701482628858]
[2024-04-20 13:18:32,916: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.0060348934304139245]
[2024-04-20 13:18:33,564: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.006095372628719174]
[2024-04-20 13:18:34,214: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.023709533273834973]
[2024-04-20 13:18:34,863: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.0011894872761035857]
[2024-04-20 13:18:35,509: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.004735479305419827]
[2024-04-20 13:18:36,158: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.005607472462501561]
[2024-04-20 13:18:36,809: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.0008547128274360991]
[2024-04-20 13:18:37,462: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.003678917708743901]
[2024-04-20 13:18:38,116: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.013821705276279793]
[2024-04-20 13:18:38,766: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.006492265913134513]
[2024-04-20 13:18:39,417: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.014021749127663253]
[2024-04-20 13:18:40,068: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.007418103046724396]
[2024-04-20 13:18:40,717: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.00840255972141158]
[2024-04-20 13:18:41,373: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.009144609836019857]
[2024-04-20 13:18:42,048: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.006035753598403199]
[2024-04-20 13:18:42,711: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.005665959307445508]
[2024-04-20 13:18:43,361: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.0075958432019166446]
[2024-04-20 13:18:44,017: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.004116090468176254]
[2024-04-20 13:18:44,666: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.014345350666326962]
[2024-04-20 13:18:45,318: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.0037685176441123376]
[2024-04-20 13:18:45,969: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.0010294702402484422]
[2024-04-20 13:18:46,614: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.023113464477081774]
[2024-04-20 13:18:47,263: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.006414831411414084]
[2024-04-20 13:18:47,911: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.0030488661365921576]
[2024-04-20 13:18:48,564: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.009559376650121085]
[2024-04-20 13:18:49,212: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.009475385175571366]
[2024-04-20 13:18:49,856: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.01448875281417672]
[2024-04-20 13:18:50,502: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.010756185906127499]
[2024-04-20 13:18:51,152: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.015831913786994462]
[2024-04-20 13:18:51,799: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.003629831134915515]
[2024-04-20 13:18:52,449: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.004192846535060039]
[2024-04-20 13:18:53,095: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.01813692951403115]
[2024-04-20 13:18:53,740: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.010656917878911218]
[2024-04-20 13:18:54,393: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.003158059197324626]
[2024-04-20 13:18:55,051: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.007987751517745684]
[2024-04-20 13:18:55,712: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.005915179914983731]
[2024-04-20 13:18:56,366: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.0030051589526223776]
[2024-04-20 13:18:57,024: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.0022372255569692106]
[2024-04-20 13:18:57,679: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.01440963729730439]
[2024-04-20 13:18:58,331: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.0028942391170081773]
[2024-04-20 13:18:58,981: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.0037446710318228345]
[2024-04-20 13:18:59,631: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.009735863836058446]
[2024-04-20 13:19:00,278: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.0035206028503934365]
[2024-04-20 13:19:00,928: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.014953224538921577]
[2024-04-20 13:19:01,572: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.011357358423193112]
[2024-04-20 13:19:02,223: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.0017906257342823286]
[2024-04-20 13:19:02,869: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.007751050016694464]
[2024-04-20 13:19:03,517: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.001435539300653863]
[2024-04-20 13:19:04,166: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.0020985875843093937]
[2024-04-20 13:19:04,816: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.010509407654598346]
[2024-04-20 13:19:05,470: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.002217072000089821]
[2024-04-20 13:19:06,122: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.0031992863292694615]
[2024-04-20 13:19:06,772: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.012680573654440471]
[2024-04-20 13:19:07,426: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.0016244073543410758]
[2024-04-20 13:19:08,087: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.004601060256149473]
[2024-04-20 13:19:08,743: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.001542190996954261]
[2024-04-20 13:19:09,406: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.009902484017838201]
[2024-04-20 13:19:10,061: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.002939558992204386]
[2024-04-20 13:19:10,740: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.0031661689649290226]
[2024-04-20 13:19:11,398: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.003906880043684507]
[2024-04-20 13:19:12,045: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.011522078746983671]
[2024-04-20 13:19:12,695: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.00245724706466559]
[2024-04-20 13:19:13,350: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.009930414274900823]
[2024-04-20 13:19:13,999: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.006818339093170009]
[2024-04-20 13:19:14,655: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.01159000251435916]
[2024-04-20 13:19:15,306: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.014865580854974986]
[2024-04-20 13:19:15,954: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.0013559922358867367]
[2024-04-20 13:19:16,601: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.002923383548931911]
[2024-04-20 13:19:17,251: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.017304908806065375]
[2024-04-20 13:19:17,902: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.005905509788195213]
[2024-04-20 13:19:18,553: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.015477084371084979]
[2024-04-20 13:19:19,205: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.0007945069896463207]
[2024-04-20 13:19:19,855: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.0028142679787489006]
[2024-04-20 13:19:20,507: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.003135789394126507]
[2024-04-20 13:19:21,176: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.004195751645877169]
[2024-04-20 13:19:21,837: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.0018707077665089192]
[2024-04-20 13:19:22,494: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.0009935488316793583]
[2024-04-20 13:19:23,153: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.000643704545446968]
[2024-04-20 13:19:23,819: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.009963760582449879]
[2024-04-20 13:19:24,476: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.021243699189686143]
[2024-04-20 13:19:25,130: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.0019042634062431463]
[2024-04-20 13:19:25,783: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.0006965851839208868]
[2024-04-20 13:19:26,436: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.004516842183975078]
[2024-04-20 13:19:27,088: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.008435923011946048]
[2024-04-20 13:19:27,741: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.017331004982064753]
[2024-04-20 13:19:28,397: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.0015402210715648136]
[2024-04-20 13:19:29,045: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.006308924540844727]
[2024-04-20 13:19:29,696: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.008141653227595622]
[2024-04-20 13:19:30,351: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.0031737777566048747]
[2024-04-20 13:19:31,007: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.008601326212655894]
[2024-04-20 13:19:31,655: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.004240333353764604]
[2024-04-20 13:19:32,307: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.00848220478163402]
[2024-04-20 13:19:32,962: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.009758713273244454]
[2024-04-20 13:19:33,616: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.0003061221718928328]
[2024-04-20 13:19:34,271: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.0012629472730866004]
[2024-04-20 13:19:34,934: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.003525102573948111]
[2024-04-20 13:19:35,592: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.005560278554157558]
[2024-04-20 13:19:36,253: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.0005989298090146135]
[2024-04-20 13:19:36,923: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.0057118192598227015]
[2024-04-20 13:19:37,594: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.022397267320226615]
[2024-04-20 13:19:38,247: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.006561003595668299]
[2024-04-20 13:19:38,897: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.00641169179299155]
[2024-04-20 13:19:39,548: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.01100148662639614]
[2024-04-20 13:19:40,204: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.0034056447979879593]
[2024-04-20 13:19:40,871: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.010383736351788023]
[2024-04-20 13:19:41,540: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.018044300656961904]
[2024-04-20 13:19:42,204: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.001620337267671827]
[2024-04-20 13:19:42,869: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.012985367310561751]
[2024-04-20 13:19:43,525: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.004570395310622415]
[2024-04-20 13:19:44,176: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.0005210911604125528]
[2024-04-20 13:19:44,832: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.0029964269263384764]
[2024-04-20 13:19:45,486: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.0017759398493714408]
[2024-04-20 13:19:46,136: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.006784011549191501]
[2024-04-20 13:19:46,788: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.003373068888253255]
[2024-04-20 13:19:47,443: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.017379480876631784]
[2024-04-20 13:19:48,103: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.0025258243109493716]
[2024-04-20 13:19:48,768: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.004443465239821265]
[2024-04-20 13:19:49,423: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.00182742630772101]
[2024-04-20 13:19:50,083: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.003258847454511627]
[2024-04-20 13:19:50,741: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.0032244866906453794]
[2024-04-20 13:19:51,397: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.0022823872661469125]
[2024-04-20 13:19:52,047: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.0008430012931173552]
[2024-04-20 13:19:52,702: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.011091574970891784]
[2024-04-20 13:19:53,356: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.009324414089735373]
[2024-04-20 13:19:54,010: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.00840542453499012]
[2024-04-20 13:19:54,665: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.001038444130153961]
[2024-04-20 13:19:55,315: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.0019170485971729003]
[2024-04-20 13:19:55,968: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.005893240553637452]
[2024-04-20 13:19:56,622: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.010802622015032945]
[2024-04-20 13:19:57,274: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.011471585657162452]
[2024-04-20 13:19:57,927: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.024653117798587556]
[2024-04-20 13:19:58,581: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.009961176999306208]
[2024-04-20 13:19:59,238: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.0034598429311373043]
[2024-04-20 13:19:59,893: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.040333972652231265]
[2024-04-20 13:20:00,545: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.008147473991469319]
[2024-04-20 13:20:01,200: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.015896325654184137]
[2024-04-20 13:20:01,861: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.002779716150545551]
[2024-04-20 13:20:02,529: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.0038193319992670073]
[2024-04-20 13:20:03,193: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.008565601815630533]
[2024-04-20 13:20:03,855: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.007239288298912523]
[2024-04-20 13:20:04,515: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.008434988830827769]
[2024-04-20 13:20:05,170: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.024430117781096234]
[2024-04-20 13:20:05,816: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.008124029440446316]
[2024-04-20 13:20:06,466: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.001865650173840402]
[2024-04-20 13:20:07,116: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.004673997982596301]
[2024-04-20 13:20:07,767: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.010493379926806122]
[2024-04-20 13:20:08,422: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.005626564990662425]
[2024-04-20 13:20:09,079: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.01159174154176565]
[2024-04-20 13:20:09,737: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.005681995444633586]
[2024-04-20 13:20:10,388: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.01185571787142334]
[2024-04-20 13:20:11,037: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.001461029525246727]
[2024-04-20 13:20:11,692: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.0012519756191435912]
[2024-04-20 13:20:12,345: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.00730422016899815]
[2024-04-20 13:20:12,998: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.012074730650495427]
[2024-04-20 13:20:13,647: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.0065188486740164545]
[2024-04-20 13:20:14,299: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.0041790570734320754]
[2024-04-20 13:20:14,957: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.018211574784110184]
[2024-04-20 13:20:15,618: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.009551022273860591]
[2024-04-20 13:20:16,278: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.0064008333058460255]
[2024-04-20 13:20:16,941: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.0018071070735182027]
[2024-04-20 13:20:17,599: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.004434094538074315]
[2024-04-20 13:20:18,250: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.004539615328327449]
[2024-04-20 13:20:18,900: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.010812646385333904]
[2024-04-20 13:20:19,555: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.008182116991713968]
[2024-04-20 13:20:20,210: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.012299118412865828]
[2024-04-20 13:20:20,866: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.007710884955159184]
[2024-04-20 13:20:21,519: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.0021061836564781927]
[2024-04-20 13:20:22,173: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.0021609269024012844]
[2024-04-20 13:20:22,820: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.00812103202937128]
[2024-04-20 13:20:23,473: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.016787111853478243]
[2024-04-20 13:20:24,124: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.014532555525123095]
[2024-04-20 13:20:24,774: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.02775125627929466]
[2024-04-20 13:20:25,428: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.010064330080910988]
[2024-04-20 13:20:26,080: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.0047001281086205444]
[2024-04-20 13:20:26,735: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.003956243181743735]
[2024-04-20 13:20:27,386: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.019764649220882502]
[2024-04-20 13:20:28,040: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.009104835597322423]
[2024-04-20 13:20:28,702: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.010294888761498424]
[2024-04-20 13:20:29,361: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.002502554370022183]
[2024-04-20 13:20:30,031: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.00045796536866626983]
[2024-04-20 13:20:30,688: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.0037897709177095525]
[2024-04-20 13:20:31,349: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.00831481044514582]
[2024-04-20 13:20:32,002: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.0028065720280752086]
[2024-04-20 13:20:32,654: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.011280301667760962]
[2024-04-20 13:20:33,307: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.004069884487003504]
[2024-04-20 13:20:33,961: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.009971098280154697]
[2024-04-20 13:20:34,613: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.005509753522703294]
[2024-04-20 13:20:35,267: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.007578613186973647]
[2024-04-20 13:20:35,917: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.008129735214149739]
[2024-04-20 13:20:36,568: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.014655241837666075]
[2024-04-20 13:20:37,223: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.019044844121647638]
[2024-04-20 13:20:37,879: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.002014036634617053]
[2024-04-20 13:20:38,530: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.0012678107282309609]
[2024-04-20 13:20:39,185: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.0010693032056680281]
[2024-04-20 13:20:39,835: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.004413716582199602]
[2024-04-20 13:20:40,494: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.010094300946515188]
[2024-04-20 13:20:41,145: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.002186290595263143]
[2024-04-20 13:20:41,818: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.010373618511494547]
[2024-04-20 13:20:42,486: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.012622447759064341]
[2024-04-20 13:20:43,142: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.015396598757630765]
[2024-04-20 13:20:43,804: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.016626889968842724]
[2024-04-20 13:20:44,466: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.006499214101390913]
[2024-04-20 13:20:45,116: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.0015290235257167278]
[2024-04-20 13:20:45,769: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.0015694765512737625]
[2024-04-20 13:20:46,421: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.012513860646373566]
[2024-04-20 13:20:47,072: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.0008606855120408625]
[2024-04-20 13:20:47,727: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.012096783512577676]
[2024-04-20 13:20:48,379: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.005691260943920658]
[2024-04-20 13:20:49,033: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.013312076089006307]
[2024-04-20 13:20:49,682: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.011691842275120616]
[2024-04-20 13:20:50,333: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.0028650098403897382]
[2024-04-20 13:20:50,985: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.001177548339112572]
[2024-04-20 13:20:51,640: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.002498064320602094]
[2024-04-20 13:20:52,296: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.00483548333802125]
[2024-04-20 13:20:52,951: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.008173911946756292]
[2024-04-20 13:20:53,603: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.001670584664131174]
[2024-04-20 13:20:54,258: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.015218315718384298]
[2024-04-20 13:20:54,918: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.0025714909910806217]
[2024-04-20 13:20:55,581: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.005286802488397748]
[2024-04-20 13:20:56,261: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.004304046796206901]
[2024-04-20 13:20:56,926: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.0021842352451210845]
[2024-04-20 13:20:57,581: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.02786218976991811]
[2024-04-20 13:20:58,241: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.0051188712404434174]
[2024-04-20 13:20:58,898: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.01826460773438282]
[2024-04-20 13:20:59,553: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.002108028218681253]
[2024-04-20 13:21:00,209: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.0011379680398940458]
[2024-04-20 13:21:00,860: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.003708705177910078]
[2024-04-20 13:21:01,513: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.004547804438115199]
[2024-04-20 13:21:02,167: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.0015336272446438274]
[2024-04-20 13:21:02,818: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.012712842086564525]
[2024-04-20 13:21:03,472: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.00909642447965836]
[2024-04-20 13:21:04,129: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.012383078572738071]
[2024-04-20 13:21:04,784: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.0009351453648472496]
[2024-04-20 13:21:05,436: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.00616085358763073]
[2024-04-20 13:21:06,089: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.00040056829292241323]
[2024-04-20 13:21:06,746: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.0027185973790395915]
[2024-04-20 13:21:07,404: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.009703040535267132]
[2024-04-20 13:21:08,063: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.0016614181889734031]
[2024-04-20 13:21:08,718: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.005878772185172372]
[2024-04-20 13:21:09,387: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.00818315608567243]
[2024-04-20 13:21:10,045: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.008281962778032744]
[2024-04-20 13:21:10,704: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.004217478294842701]
[2024-04-20 13:21:11,369: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.012337557014426629]
[2024-04-20 13:21:12,020: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.005479581914773265]
[2024-04-20 13:21:12,672: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.015513879019194687]
[2024-04-20 13:21:13,325: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.001418071683891019]
[2024-04-20 13:21:13,978: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.013530299482807179]
[2024-04-20 13:21:14,630: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.004544278170440306]
[2024-04-20 13:21:15,285: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.006614765687657472]
[2024-04-20 13:21:15,936: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.012426149557738473]
[2024-04-20 13:21:16,590: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.006027132698287523]
[2024-04-20 13:21:17,243: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.014090744009419877]
[2024-04-20 13:21:17,899: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.013418069798548793]
[2024-04-20 13:21:18,554: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.001791300268685637]
[2024-04-20 13:21:19,210: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.006506720020242875]
[2024-04-20 13:21:19,860: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.006535050355918117]
[2024-04-20 13:21:20,513: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.012810696067459377]
[2024-04-20 13:21:21,168: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.0004242984154209629]
[2024-04-20 13:21:21,831: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.0030243785869470967]
[2024-04-20 13:21:22,492: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.00574646950597845]
[2024-04-20 13:21:23,175: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.006551462197643215]
[2024-04-20 13:21:23,851: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.009283350134707689]
[2024-04-20 13:21:24,519: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.018740990872578998]
[2024-04-20 13:21:25,186: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.0003556436563590235]
[2024-04-20 13:21:25,840: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.004415760920338671]
[2024-04-20 13:21:26,492: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.021618229174594134]
[2024-04-20 13:21:27,147: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.004931635741632669]
[2024-04-20 13:21:27,797: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.0037651054514387674]
[2024-04-20 13:21:28,446: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.027837892177871294]
[2024-04-20 13:21:29,103: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.011081719878153179]
[2024-04-20 13:21:29,757: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.008112604707903169]
[2024-04-20 13:21:30,413: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.005143709678467273]
[2024-04-20 13:21:31,066: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.0005255763916960776]
[2024-04-20 13:21:31,720: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.01018937804063872]
[2024-04-20 13:21:32,373: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.008748693812867053]
[2024-04-20 13:21:33,023: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.00538935579982899]
[2024-04-20 13:21:33,675: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.010045961310888352]
[2024-04-20 13:21:34,330: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.004240987172459373]
[2024-04-20 13:21:34,983: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.0034638311876653166]
[2024-04-20 13:21:35,641: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.004913544067533502]
[2024-04-20 13:21:36,310: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.0013525857167288329]
[2024-04-20 13:21:36,975: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.00022080709091994174]
[2024-04-20 13:21:37,637: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.011313833320395499]
[2024-04-20 13:21:38,296: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.020726429694602838]
[2024-04-20 13:21:38,951: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.008618455212588878]
[2024-04-20 13:21:39,602: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.0032585591546341885]
[2024-04-20 13:21:40,255: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.004894651587067885]
[2024-04-20 13:21:40,907: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.009235968827069205]
[2024-04-20 13:21:41,562: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.01079329465155315]
[2024-04-20 13:21:42,220: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.024396554238974796]
[2024-04-20 13:21:42,873: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.0008089727758045253]
[2024-04-20 13:21:43,530: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.01687515726023734]
[2024-04-20 13:21:44,186: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.005389171051803966]
[2024-04-20 13:21:44,839: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.0017869776456143726]
[2024-04-20 13:21:45,494: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.003669804786010854]
[2024-04-20 13:21:46,151: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.004470895837587057]
[2024-04-20 13:21:46,800: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.006852214179617025]
[2024-04-20 13:21:47,455: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.01637319544360428]
[2024-04-20 13:21:48,107: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.004136325595604662]
[2024-04-20 13:21:48,773: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.012266436305007875]
[2024-04-20 13:21:49,437: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.008944970707358384]
[2024-04-20 13:21:50,096: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.0034522698088513847]
[2024-04-20 13:21:50,757: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.006787139344365195]
[2024-04-20 13:21:51,416: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.006996842989607485]
[2024-04-20 13:21:52,079: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.009721856500589841]
[2024-04-20 13:21:52,731: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.006166661073871371]
[2024-04-20 13:21:53,387: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.008578303961412011]
[2024-04-20 13:21:54,042: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.004616501553565082]
[2024-04-20 13:21:54,696: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.005239552580506134]
[2024-04-20 13:21:55,351: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.003261945892022342]
[2024-04-20 13:21:56,015: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.002546533885666913]
[2024-04-20 13:21:56,670: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.0007943458324887131]
[2024-04-20 13:21:57,326: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.009186591540074637]
[2024-04-20 13:21:57,984: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.00902934716175966]
[2024-04-20 13:21:58,637: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.011214898877427685]
[2024-04-20 13:21:59,287: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.0004655914320636503]
[2024-04-20 13:21:59,943: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.008400769888653497]
[2024-04-20 13:22:00,603: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.005121258693170586]
[2024-04-20 13:22:01,259: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.0019931129101740043]
[2024-04-20 13:22:01,918: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.0014258767580306595]
[2024-04-20 13:22:02,577: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.011775967582239345]
[2024-04-20 13:22:03,236: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.00797118577498864]
[2024-04-20 13:22:03,898: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.0011386451917836174]
[2024-04-20 13:22:04,565: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.002807794096587483]
[2024-04-20 13:22:05,234: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.0028554079887205858]
[2024-04-20 13:22:05,887: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.009612531334789771]
[2024-04-20 13:22:06,541: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.00891089853130519]
[2024-04-20 13:22:07,200: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.000450780496676143]
[2024-04-20 13:22:07,854: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.0003388672271228221]
[2024-04-20 13:22:08,507: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.010357451885894941]
[2024-04-20 13:22:09,165: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.002565765316602325]
[2024-04-20 13:22:09,820: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.018299519010092226]
[2024-04-20 13:22:10,487: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.005789550192405444]
[2024-04-20 13:22:11,145: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.0013968867721358127]
[2024-04-20 13:22:11,795: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.0008290124906987161]
[2024-04-20 13:22:12,451: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.007058991362259484]
[2024-04-20 13:22:13,105: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.01113779830322026]
[2024-04-20 13:22:13,760: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.008097905536810014]
[2024-04-20 13:22:14,415: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.0028511161617507347]
[2024-04-20 13:22:15,071: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.014990103117950043]
[2024-04-20 13:22:15,733: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.008588756552553386]
[2024-04-20 13:22:16,403: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.00527202358366383]
[2024-04-20 13:22:17,065: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.001488548753825644]
[2024-04-20 13:22:17,731: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.02426491639470044]
[2024-04-20 13:22:18,404: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.0016668861432427152]
[2024-04-20 13:22:19,061: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.007517785721160746]
[2024-04-20 13:22:19,711: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.0015494058689010744]
[2024-04-20 13:22:20,368: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.011135664237813262]
[2024-04-20 13:22:21,023: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.005388972788055508]
[2024-04-20 13:22:21,675: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.0065717965561135645]
[2024-04-20 13:22:22,331: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.00664508703670586]
[2024-04-20 13:22:22,985: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.005732669558882896]
[2024-04-20 13:22:23,637: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.008242422737173792]
[2024-04-20 13:22:24,287: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.013704735955611974]
[2024-04-20 13:22:24,942: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.0026885329084996587]
[2024-04-20 13:22:25,595: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.0017472769314558004]
[2024-04-20 13:22:26,247: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.01042060763960607]
[2024-04-20 13:22:26,906: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.009770091108550457]
[2024-04-20 13:22:27,561: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.012440177560445263]
[2024-04-20 13:22:28,212: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.007090979403548579]
[2024-04-20 13:22:28,893: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.01193894377736069]
[2024-04-20 13:22:29,563: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.005581982895104185]
[2024-04-20 13:22:30,222: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.002517060423183932]
[2024-04-20 13:22:30,890: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.006830957504545339]
[2024-04-20 13:22:31,558: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.009647004391807606]
[2024-04-20 13:22:32,218: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.009227276836436506]
[2024-04-20 13:22:32,879: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.025650774122343883]
[2024-04-20 13:22:33,537: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.007865141947294933]
[2024-04-20 13:22:34,189: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.011864914330090431]
[2024-04-20 13:22:34,843: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.0024996951764246047]
[2024-04-20 13:22:35,504: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.012579895337391334]
[2024-04-20 13:22:36,161: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.008978816714323901]
[2024-04-20 13:22:36,819: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.004087528871865812]
[2024-04-20 13:22:37,487: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.015041097040842782]
[2024-04-20 13:22:38,144: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.008492455651599097]
[2024-04-20 13:22:38,801: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.0057954507313351345]
[2024-04-20 13:22:39,453: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.01863526668884719]
[2024-04-20 13:22:40,111: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.007945123523524448]
[2024-04-20 13:22:40,770: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.027650172332755636]
[2024-04-20 13:22:41,427: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.0014851458260239292]
[2024-04-20 13:22:42,083: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.002942973874757551]
[2024-04-20 13:22:42,744: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.04284165760866132]
[2024-04-20 13:22:43,409: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.005097169432648811]
[2024-04-20 13:22:44,071: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.006180564354972564]
[2024-04-20 13:22:44,742: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.003745210766952116]
[2024-04-20 13:22:45,414: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.009652027754955715]
[2024-04-20 13:22:46,067: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.02949975774719389]
[2024-04-20 13:22:46,725: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.00293178347436373]
[2024-04-20 13:22:47,380: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.035442986003349566]
[2024-04-20 13:22:48,038: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.009390487700869683]
[2024-04-20 13:22:48,692: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.01810649371281029]
[2024-04-20 13:22:49,348: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.0018387861563998783]
[2024-04-20 13:22:50,004: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.003193773459483327]
[2024-04-20 13:22:50,655: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.00437380662470248]
[2024-04-20 13:22:51,310: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.006399842567868888]
[2024-04-20 13:22:51,965: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.009471852141980548]
[2024-04-20 13:22:52,615: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.006774483282578241]
[2024-04-20 13:22:53,269: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.006380369320408677]
[2024-04-20 13:22:53,922: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.0028308654049235067]
[2024-04-20 13:22:54,581: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.0005193215285493756]
[2024-04-20 13:22:55,239: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.013079407726960951]
[2024-04-20 13:22:55,906: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.005498998178262032]
[2024-04-20 13:22:56,574: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.005506616270731027]
[2024-04-20 13:22:57,241: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.009090909497830642]
[2024-04-20 13:22:57,917: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.009221121088094477]
[2024-04-20 13:22:58,592: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.008686817459678486]
[2024-04-20 13:22:59,260: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.006465689274653516]
[2024-04-20 13:22:59,927: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.004377039015870754]
[2024-04-20 13:23:00,602: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.008917426787553511]
[2024-04-20 13:23:01,266: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.0036491758991139493]
[2024-04-20 13:23:01,920: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.004531482350290397]
[2024-04-20 13:23:02,577: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.007169262521735548]
[2024-04-20 13:23:03,231: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.016131711538624124]
[2024-04-20 13:23:03,885: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.010045875441111168]
[2024-04-20 13:23:04,540: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.0037212105063859336]
[2024-04-20 13:23:05,191: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.002866327715679862]
[2024-04-20 13:23:05,844: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.0050174150135621895]
[2024-04-20 13:23:06,501: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.010030895133248148]
[2024-04-20 13:23:07,156: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.01685614715544082]
[2024-04-20 13:23:07,812: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.0013056727861211165]
[2024-04-20 13:23:08,466: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.00263644952887708]
[2024-04-20 13:23:09,128: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.007199740970655149]
[2024-04-20 13:23:09,787: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.001620496710609712]
[2024-04-20 13:23:10,443: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.0001344567916368574]
[2024-04-20 13:23:11,099: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.01979118495484057]
[2024-04-20 13:23:11,756: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.0015836856411370534]
[2024-04-20 13:23:12,421: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.00981109121178946]
[2024-04-20 13:23:13,081: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.014350835972715739]
[2024-04-20 13:23:13,750: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.004397135604333046]
[2024-04-20 13:23:14,415: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.005821521488574815]
[2024-04-20 13:23:15,068: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.0031343340871851618]
[2024-04-20 13:23:15,722: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.02599800074758734]
[2024-04-20 13:23:16,380: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.005078357876992223]
[2024-04-20 13:23:17,031: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.007600924718476695]
[2024-04-20 13:23:17,687: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.0022216184875003832]
[2024-04-20 13:23:18,341: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.0012514828054546818]
[2024-04-20 13:23:18,996: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.005091895075716874]
[2024-04-20 13:23:19,648: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.014100079347445603]
[2024-04-20 13:23:20,302: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.004097456627701512]
[2024-04-20 13:23:20,960: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.006599281902166968]
[2024-04-20 13:23:21,612: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.006788945789680295]
[2024-04-20 13:23:22,265: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.004619385795501902]
[2024-04-20 13:23:22,924: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.001076186082321546]
[2024-04-20 13:23:23,581: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.01215480996835331]
[2024-04-20 13:23:24,242: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.006161844393519275]
[2024-04-20 13:23:24,918: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.0027280267725677118]
[2024-04-20 13:23:25,586: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.004772800666688074]
[2024-04-20 13:23:26,245: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.014108511568679344]
[2024-04-20 13:23:26,917: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.016883630251339248]
[2024-04-20 13:23:27,593: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.0018735200751009268]
[2024-04-20 13:23:28,248: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.002962731645112291]
[2024-04-20 13:23:28,904: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.01098764998250659]
[2024-04-20 13:23:29,564: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.003002485904265482]
[2024-04-20 13:23:30,221: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.00901766923099813]
[2024-04-20 13:23:30,878: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.0015245879379847305]
[2024-04-20 13:23:31,540: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.028775212172962902]
[2024-04-20 13:23:32,192: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.026403402465010155]
[2024-04-20 13:23:32,847: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.0020707484910077066]
[2024-04-20 13:23:33,504: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.007795397069513263]
[2024-04-20 13:23:34,155: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.0066735072468564775]
[2024-04-20 13:23:34,810: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.013664490955431912]
[2024-04-20 13:23:35,464: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.015099987171663028]
[2024-04-20 13:23:36,120: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.0035364683594940123]
[2024-04-20 13:23:36,773: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.005160573205318102]
[2024-04-20 13:23:37,431: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.01519735928604383]
[2024-04-20 13:23:38,092: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.004571270513689392]
[2024-04-20 13:23:38,751: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.011810356779675282]
[2024-04-20 13:23:39,416: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.00406171781052846]
[2024-04-20 13:23:40,078: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.01186046894016367]
[2024-04-20 13:23:40,738: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.007644282995342116]
[2024-04-20 13:23:41,399: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.007413620021803497]
[2024-04-20 13:23:42,052: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.002962245147059572]
[2024-04-20 13:23:42,710: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.0010899270046690072]
[2024-04-20 13:23:43,366: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.006700832448500816]
[2024-04-20 13:23:44,022: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.004562094741843641]
[2024-04-20 13:23:44,675: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.0036834195264184287]
[2024-04-20 13:23:45,331: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.004821774404611551]
[2024-04-20 13:23:45,991: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.007405763911320898]
[2024-04-20 13:23:46,646: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.007439711587296784]
[2024-04-20 13:23:47,299: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.004489522439967838]
[2024-04-20 13:23:47,952: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.009835935413375435]
[2024-04-20 13:23:48,608: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.01411219376789913]
[2024-04-20 13:23:49,264: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.013096924603128066]
[2024-04-20 13:23:49,923: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.0033587426820054556]
[2024-04-20 13:23:50,573: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.0017506034556371553]
[2024-04-20 13:23:51,232: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.014179459364798868]
[2024-04-20 13:23:51,900: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.0029789807119592515]
[2024-04-20 13:23:52,565: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.005993468581935759]
[2024-04-20 13:23:53,230: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.003776554748888127]
[2024-04-20 13:23:53,900: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.0006890056169443239]
[2024-04-20 13:23:54,565: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.0013456544653624072]
[2024-04-20 13:23:55,215: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.006891598174521011]
[2024-04-20 13:23:55,871: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.004397426465369926]
[2024-04-20 13:23:56,522: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.005478407731834995]
[2024-04-20 13:23:57,180: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.007415172142996219]
[2024-04-20 13:23:57,838: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.0064223824186983944]
[2024-04-20 13:23:58,495: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.017980766729921535]
[2024-04-20 13:23:59,154: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.005417632497019846]
[2024-04-20 13:23:59,805: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.04571170149895157]
[2024-04-20 13:24:00,462: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.002374101535900399]
[2024-04-20 13:24:01,118: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.0032876054406226875]
[2024-04-20 13:24:01,768: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.005677944956400852]
[2024-04-20 13:24:02,423: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.002778302136777921]
[2024-04-20 13:24:03,081: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.008355045603110803]
[2024-04-20 13:24:03,735: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.0004515143022839463]
[2024-04-20 13:24:04,389: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.006942268406988751]
[2024-04-20 13:24:05,049: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.0025952963694002747]
[2024-04-20 13:24:05,720: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.007674935217962999]
[2024-04-20 13:24:06,393: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.00610092690150601]
[2024-04-20 13:24:07,062: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.0006258522676907725]
[2024-04-20 13:24:07,729: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.0004065599773047371]
[2024-04-20 13:24:08,382: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.0007644379744055375]
[2024-04-20 13:24:09,038: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.0023277324821681274]
[2024-04-20 13:24:09,694: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.003822776448682725]
[2024-04-20 13:24:10,347: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.0071424479846865655]
[2024-04-20 13:24:11,001: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.010011100878495417]
[2024-04-20 13:24:11,656: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.004681355599747122]
[2024-04-20 13:24:12,311: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.003024747293435308]
[2024-04-20 13:24:12,968: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.006448160400612463]
[2024-04-20 13:24:13,625: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.0019001144702223177]
[2024-04-20 13:24:14,276: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.015084084217059085]
[2024-04-20 13:24:14,931: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.006751736721012607]
[2024-04-20 13:24:15,588: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.002297547109106033]
[2024-04-20 13:24:16,240: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.015274016078704024]
[2024-04-20 13:24:16,895: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.002908693551982562]
[2024-04-20 13:24:17,551: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.005882255210428371]
[2024-04-20 13:24:18,202: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.003802711037111512]
[2024-04-20 13:24:18,863: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.004653117801511608]
[2024-04-20 13:24:19,527: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.0020291912126981157]
[2024-04-20 13:24:20,188: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.005991035094197431]
[2024-04-20 13:24:20,853: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.0016671736823455714]
[2024-04-20 13:24:21,525: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.006649228261067197]
[2024-04-20 13:24:22,179: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.001982901480292591]
[2024-04-20 13:24:22,828: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.013116954785430956]
[2024-04-20 13:24:23,487: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.010260312708620703]
[2024-04-20 13:24:24,139: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.0016389748960876185]
[2024-04-20 13:24:24,790: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.0020097188278893827]
[2024-04-20 13:24:25,444: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.005851234359157269]
[2024-04-20 13:24:26,098: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.003920350842056099]
[2024-04-20 13:24:26,752: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.0028363035789694263]
[2024-04-20 13:24:27,402: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.0052270466659285085]
[2024-04-20 13:24:28,066: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.012632526544878852]
[2024-04-20 13:24:28,721: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.004388005591389071]
[2024-04-20 13:24:29,369: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.00590489189560406]
[2024-04-20 13:24:30,024: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.01502314900397888]
[2024-04-20 13:24:30,673: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.002367354065379155]
[2024-04-20 13:24:31,327: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.0006798881634129138]
[2024-04-20 13:24:32,003: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.011497160942558577]
[2024-04-20 13:24:32,683: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.0029831033758678637]
[2024-04-20 13:24:33,347: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.004665574053921286]
[2024-04-20 13:24:34,008: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.00019043817503286146]
[2024-04-20 13:24:34,667: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.00037652149645639395]
[2024-04-20 13:24:35,321: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.0018721674211051428]
[2024-04-20 13:24:35,971: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.00633657752031346]
[2024-04-20 13:24:36,624: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.0017565468560562258]
[2024-04-20 13:24:37,279: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.0013317118892489392]
[2024-04-20 13:24:37,934: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.0008818247981285661]
[2024-04-20 13:24:38,590: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.001099761305859567]
[2024-04-20 13:24:39,245: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.0073208661302684]
[2024-04-20 13:24:39,898: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.005462357402014927]
[2024-04-20 13:24:40,553: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.004722601738675603]
[2024-04-20 13:24:41,207: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.0067970672362910505]
[2024-04-20 13:24:41,863: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.008818693673348237]
[2024-04-20 13:24:42,517: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.003324108182894569]
[2024-04-20 13:24:43,173: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.001987073187581503]
[2024-04-20 13:24:43,828: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.002732939955461457]
[2024-04-20 13:24:44,484: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.0195225050822895]
[2024-04-20 13:24:45,145: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.0003125219657393071]
[2024-04-20 13:24:45,818: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.0022015848991117698]
[2024-04-20 13:24:46,483: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.004431291507956327]
[2024-04-20 13:24:47,167: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.0008409266895171503]
[2024-04-20 13:24:47,841: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.0007534780762356139]
[2024-04-20 13:24:48,498: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.0003870338398767775]
[2024-04-20 13:24:49,151: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.005386986245260332]
[2024-04-20 13:24:49,805: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.006130916969307255]
[2024-04-20 13:24:50,461: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.0038509216332760533]
[2024-04-20 13:24:51,115: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.00027908726038493217]
[2024-04-20 13:24:51,768: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.0038053045000451375]
[2024-04-20 13:24:52,423: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.009019214904793514]
[2024-04-20 13:24:53,085: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.011175515898205417]
[2024-04-20 13:24:53,741: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.0046193312342555646]
[2024-04-20 13:24:54,396: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.0058733997112498035]
[2024-04-20 13:24:55,051: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.0015426843244018625]
[2024-04-20 13:24:55,706: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.008789989576538017]
[2024-04-20 13:24:56,363: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.005722969908310732]
[2024-04-20 13:24:57,018: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.0026942031193864153]
[2024-04-20 13:24:57,671: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.04356888876614266]
[2024-04-20 13:24:58,330: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.010174000075587103]
[2024-04-20 13:24:58,991: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.00460581918213845]
[2024-04-20 13:24:59,649: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.010255923210084186]
[2024-04-20 13:25:00,321: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.006800847771671295]
[2024-04-20 13:25:00,991: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.005491627047284086]
[2024-04-20 13:25:01,659: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.03653374567346906]
[2024-04-20 13:25:02,311: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.0037596400854995955]
[2024-04-20 13:25:02,968: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.0032390823622897645]
[2024-04-20 13:25:03,625: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.007855876941788935]
[2024-04-20 13:25:04,277: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.0024999270270044567]
[2024-04-20 13:25:04,935: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.0026261387397940902]
[2024-04-20 13:25:05,593: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.015568808633617993]
[2024-04-20 13:25:06,251: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.0031750693796599797]
[2024-04-20 13:25:06,907: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.004262579313429859]
[2024-04-20 13:25:07,571: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.009695831530361515]
[2024-04-20 13:25:08,231: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.0039034875187264873]
[2024-04-20 13:25:08,886: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.009934415047766503]
[2024-04-20 13:25:09,541: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.014752432439615383]
[2024-04-20 13:25:10,198: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.004856109347178078]
[2024-04-20 13:25:10,853: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.011421477849000808]
[2024-04-20 13:25:11,510: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.004705043691209858]
[2024-04-20 13:25:12,169: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.002888758326024469]
[2024-04-20 13:25:12,836: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.005230122547466886]
[2024-04-20 13:25:13,495: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.003971198287079915]
[2024-04-20 13:25:14,164: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.00902177730935413]
[2024-04-20 13:25:14,838: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.0007069952131342968]
[2024-04-20 13:25:15,496: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.016983964110253515]
[2024-04-20 13:25:16,149: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.019344631802280195]
[2024-04-20 13:25:16,806: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.006145337425603215]
[2024-04-20 13:25:17,466: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.004742526042362732]
[2024-04-20 13:25:18,118: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.0017375626045333043]
[2024-04-20 13:25:18,779: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.010134516933047833]
[2024-04-20 13:25:19,435: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.01239723052698715]
[2024-04-20 13:25:20,093: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.00012082134050002203]
[2024-04-20 13:25:20,751: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.019701183934341976]
[2024-04-20 13:25:21,407: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.007644580485751749]
[2024-04-20 13:25:22,067: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.00897870251373855]
[2024-04-20 13:25:22,724: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.003954399314342887]
[2024-04-20 13:25:23,380: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.02096963622489236]
[2024-04-20 13:25:24,045: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.003159056977378941]
[2024-04-20 13:25:24,696: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.002472006074903687]
[2024-04-20 13:25:25,359: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.006410697917253282]
[2024-04-20 13:25:26,025: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.00664437272225302]
[2024-04-20 13:25:26,696: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.006563630730466732]
[2024-04-20 13:25:27,368: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.007092769665522544]
[2024-04-20 13:25:28,034: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.005855480744025375]
[2024-04-20 13:25:28,696: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.020922337318378188]
[2024-04-20 13:25:29,353: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.0012635611186560987]
[2024-04-20 13:25:30,014: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.0026845532558494403]
[2024-04-20 13:25:30,673: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.010142908670060517]
[2024-04-20 13:25:31,325: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.01089926258965433]
[2024-04-20 13:25:31,980: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.004959851533639877]
[2024-04-20 13:25:32,638: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.004549565855434616]
[2024-04-20 13:25:33,294: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.006310952855043685]
[2024-04-20 13:25:33,952: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.010722685048864462]
[2024-04-20 13:25:34,606: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.011192788731503431]
[2024-04-20 13:25:35,262: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.006044031660459825]
[2024-04-20 13:25:35,919: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.0032450049030447233]
[2024-04-20 13:25:36,574: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.0012305390729758906]
[2024-04-20 13:25:37,237: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.0028422432507476643]
[2024-04-20 13:25:37,896: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.0010671351111294378]
[2024-04-20 13:25:38,552: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.018448804087128973]
[2024-04-20 13:25:39,220: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.02080060927962746]
[2024-04-20 13:25:39,884: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.01882383994000101]
[2024-04-20 13:25:40,548: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.017848729035663813]
[2024-04-20 13:25:41,208: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.0013088901024103047]
[2024-04-20 13:25:41,874: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.002938964226641216]
[2024-04-20 13:25:42,526: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.01050046003658152]
[2024-04-20 13:25:43,180: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.010781567451427778]
[2024-04-20 13:25:43,836: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.07630038037409152]
[2024-04-20 13:25:44,494: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.006941752186973805]
[2024-04-20 13:25:45,147: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.0075392729466425635]
[2024-04-20 13:25:45,802: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.0014329343833961092]
[2024-04-20 13:25:46,458: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.018443358046317103]
[2024-04-20 13:25:47,114: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.01834550154047771]
[2024-04-20 13:25:47,768: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.01154860076836442]
[2024-04-20 13:25:48,420: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.002888138227295754]
[2024-04-20 13:25:49,077: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.017353510009028014]
[2024-04-20 13:25:49,729: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.010226414220639924]
[2024-04-20 13:25:50,384: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.005994116956171643]
[2024-04-20 13:25:51,037: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.006657645409089667]
[2024-04-20 13:25:51,699: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.009222534584456226]
[2024-04-20 13:25:52,368: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.006772262013854198]
[2024-04-20 13:25:53,039: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.0054056271860933106]
[2024-04-20 13:25:53,710: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.008379452044341687]
[2024-04-20 13:25:54,374: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.01570040631468622]
[2024-04-20 13:25:55,038: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.00901504089347688]
[2024-04-20 13:25:55,700: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.00795534715598171]
[2024-04-20 13:25:56,354: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.009662424044817155]
[2024-04-20 13:25:57,006: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.004364831754692345]
[2024-04-20 13:25:57,660: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.002314257475727407]
[2024-04-20 13:25:58,317: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.012282403397379035]
[2024-04-20 13:25:58,969: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.005950684056340156]
[2024-04-20 13:25:59,625: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.02340673251930023]
[2024-04-20 13:26:00,280: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.000586183943309028]
[2024-04-20 13:26:00,931: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.0029152275025944112]
[2024-04-20 13:26:01,588: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.009452388429920595]
[2024-04-20 13:26:02,242: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.0021985850601032343]
[2024-04-20 13:26:02,901: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.0025017668497267806]
[2024-04-20 13:26:03,553: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.07728041834899102]
[2024-04-20 13:26:04,211: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.004891072645185674]
[2024-04-20 13:26:04,861: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.007174115851988406]
[2024-04-20 13:26:05,523: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.006133404796473442]
[2024-04-20 13:26:06,190: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.014417737090004592]
[2024-04-20 13:26:06,862: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.004076167913543311]
[2024-04-20 13:26:07,524: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.001931977056113303]
[2024-04-20 13:26:08,185: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.0016517751741728292]
[2024-04-20 13:26:08,844: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.005279255903489168]
[2024-04-20 13:26:09,501: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.029294982166775636]
[2024-04-20 13:26:10,154: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.018512779581730143]
[2024-04-20 13:26:10,810: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.004222346173793614]
[2024-04-20 13:26:11,460: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.006281609504511184]
[2024-04-20 13:26:12,116: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.007495023790693983]
[2024-04-20 13:26:12,775: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.0031044763439023234]
[2024-04-20 13:26:13,446: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.014833327240603517]
[2024-04-20 13:26:14,112: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.009930377528400033]
[2024-04-20 13:26:14,771: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.004596426257427547]
[2024-04-20 13:26:15,438: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.007508219983254383]
[2024-04-20 13:26:16,093: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.00729315563956229]
[2024-04-20 13:26:16,744: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.02483881011956873]
[2024-04-20 13:26:17,398: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.010710005504946897]
[2024-04-20 13:26:18,053: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.0129703808071656]
[2024-04-20 13:26:18,701: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.011600506259257876]
[2024-04-20 13:26:19,360: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.004851198778721943]
[2024-04-20 13:26:20,016: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.005072665975034645]
[2024-04-20 13:26:20,674: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.0010712205945438357]
[2024-04-20 13:26:21,333: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.015486626163052648]
[2024-04-20 13:26:22,009: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.003502025984247094]
[2024-04-20 13:26:22,670: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.004953636624386696]
[2024-04-20 13:26:23,321: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.000990814163378037]
[2024-04-20 13:26:23,977: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.011988503234273544]
[2024-04-20 13:26:24,637: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.006035024102321229]
[2024-04-20 13:26:25,288: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.0076484859405127285]
[2024-04-20 13:26:25,946: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.0016155761756925199]
[2024-04-20 13:26:26,600: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.0006001555164167766]
[2024-04-20 13:26:27,255: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.0009267767904768201]
[2024-04-20 13:26:27,907: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.006927813048085066]
[2024-04-20 13:26:28,562: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.0050920718307258485]
[2024-04-20 13:26:29,218: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.0022038183637610367]
[2024-04-20 13:26:29,869: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.002156812493208347]
[2024-04-20 13:26:30,527: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.011371571001882151]
[2024-04-20 13:26:31,186: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.0080082922251899]
[2024-04-20 13:26:31,839: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.00678184883499159]
[2024-04-20 13:26:32,502: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.0033040262956714373]
[2024-04-20 13:26:33,171: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.001363077039553918]
[2024-04-20 13:26:33,833: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.00040543083481673785]
[2024-04-20 13:26:34,496: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.010713827706807389]
[2024-04-20 13:26:35,157: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.014342653977998812]
[2024-04-20 13:26:35,816: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.0007141429533551492]
[2024-04-20 13:26:36,472: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.0006315859069093089]
[2024-04-20 13:26:37,124: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.0070620951343074575]
[2024-04-20 13:26:37,784: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.005160035219098346]
[2024-04-20 13:26:38,436: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.008862642222400581]
[2024-04-20 13:26:39,092: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.0014935454771074772]
[2024-04-20 13:26:39,743: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.028885982644422055]
[2024-04-20 13:26:40,397: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.016485147337692102]
[2024-04-20 13:26:41,051: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.0012700903670283918]
[2024-04-20 13:26:41,703: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.004392544147601234]
[2024-04-20 13:26:42,355: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.003027264307420008]
[2024-04-20 13:26:43,008: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.0009208238104598132]
[2024-04-20 13:26:43,661: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.009327598906577927]
[2024-04-20 13:26:44,315: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.006385629545920628]
[2024-04-20 13:26:44,968: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.006896783502931765]
[2024-04-20 13:26:45,622: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.0032293604240741245]
[2024-04-20 13:26:46,281: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.010144725916161373]
[2024-04-20 13:26:46,941: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.0014493006600148825]
[2024-04-20 13:26:47,603: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.019423301481518017]
[2024-04-20 13:26:48,266: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.007721946556244397]
[2024-04-20 13:26:48,931: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.005225783140018694]
[2024-04-20 13:26:49,587: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.010528828162411262]
[2024-04-20 13:26:50,239: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.008000490160630598]
[2024-04-20 13:26:50,896: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.012488590274592641]
[2024-04-20 13:26:51,550: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.006556153328962709]
[2024-04-20 13:26:52,204: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.005033602288139638]
[2024-04-20 13:26:52,863: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.004426503760960404]
[2024-04-20 13:26:53,517: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.016100114378186835]
[2024-04-20 13:26:54,176: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.012249851878232269]
[2024-04-20 13:26:54,833: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.013821076060896331]
[2024-04-20 13:26:55,491: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.008898528745786366]
[2024-04-20 13:26:56,147: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.006360561377922818]
[2024-04-20 13:26:56,802: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.002262988594111448]
[2024-04-20 13:26:57,457: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.00422234345008921]
[2024-04-20 13:26:58,112: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.003636574045325035]
[2024-04-20 13:26:58,764: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.0005084360124316152]
[2024-04-20 13:26:59,429: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.0037556642472824906]
[2024-04-20 13:27:00,095: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.008949176847081929]
[2024-04-20 13:27:00,757: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.012654401080053515]
[2024-04-20 13:27:01,421: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.0052234034902316675]
[2024-04-20 13:27:02,083: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.016165084543695862]
[2024-04-20 13:27:02,740: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.002275207394006583]
[2024-04-20 13:27:03,391: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.005941956659522911]
[2024-04-20 13:27:04,047: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.015455035132367451]
[2024-04-20 13:27:04,700: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.005953009204458491]
[2024-04-20 13:27:05,355: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.005964422194901554]
[2024-04-20 13:27:06,006: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.0014900653654949384]
[2024-04-20 13:27:06,661: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.0026307736154035596]
[2024-04-20 13:27:07,324: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.004980213580783513]
[2024-04-20 13:27:07,981: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.0006600470648919472]
[2024-04-20 13:27:08,638: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.007979271685322347]
[2024-04-20 13:27:09,291: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.004133634371304679]
[2024-04-20 13:27:09,945: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.009688333744551008]
[2024-04-20 13:27:10,602: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.004134749306136294]
[2024-04-20 13:27:11,255: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.018289099680716663]
[2024-04-20 13:27:11,909: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.0022578725192161295]
[2024-04-20 13:27:12,565: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.003803311043859861]
[2024-04-20 13:27:13,227: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.00026224887763914633]
[2024-04-20 13:27:13,909: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.006449198010832617]
[2024-04-20 13:27:14,590: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.0030633339793311324]
[2024-04-20 13:27:15,255: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.002784730953455107]
[2024-04-20 13:27:15,925: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.0033908666263787078]
[2024-04-20 13:27:16,593: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.005466052960507828]
[2024-04-20 13:27:17,248: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.006854397992190065]
[2024-04-20 13:27:17,905: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.0022249703590617887]
[2024-04-20 13:27:18,563: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.014029453730757993]
[2024-04-20 13:27:19,218: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.0030712890074566677]
[2024-04-20 13:27:19,874: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.0008636074158507068]
[2024-04-20 13:27:20,533: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.006765538840631801]
[2024-04-20 13:27:21,184: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.016773092123494652]
[2024-04-20 13:27:21,839: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.007144677541067606]
[2024-04-20 13:27:22,497: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.003197926006538217]
[2024-04-20 13:27:23,154: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.007757264177818818]
[2024-04-20 13:27:23,811: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.0016937135190175587]
[2024-04-20 13:27:24,465: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.014549943579210285]
[2024-04-20 13:27:25,127: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.006501557204370294]
[2024-04-20 13:27:25,780: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.012888642113735738]
[2024-04-20 13:27:26,458: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.013382685032456825]
[2024-04-20 13:27:27,123: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.003685553441430178]
[2024-04-20 13:27:27,778: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.0032991227120999743]
[2024-04-20 13:27:28,436: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.007337290174278757]
[2024-04-20 13:27:29,102: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.00537845068278799]
[2024-04-20 13:27:29,764: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.020095968734189253]
[2024-04-20 13:27:30,415: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.00396081022057242]
[2024-04-20 13:27:31,072: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.0009987016959784611]
[2024-04-20 13:27:31,730: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.03718084737324487]
[2024-04-20 13:27:32,384: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.008245197050465619]
[2024-04-20 13:27:33,042: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.001433277743433724]
[2024-04-20 13:27:33,694: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.002601849425682271]
[2024-04-20 13:27:34,350: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.008355838693974995]
[2024-04-20 13:27:35,003: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.0035464736956056036]
[2024-04-20 13:27:35,655: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.006686745500153382]
[2024-04-20 13:27:36,305: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.011304692941896757]
[2024-04-20 13:27:36,961: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.009341702383396593]
[2024-04-20 13:27:37,620: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.0074233609961729275]
[2024-04-20 13:27:38,274: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.008631029429324257]
[2024-04-20 13:27:38,932: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.003869411320236428]
[2024-04-20 13:27:39,593: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.008626311942436399]
[2024-04-20 13:27:40,256: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.00943618281855778]
[2024-04-20 13:27:40,932: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.004051859266335378]
[2024-04-20 13:27:41,599: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.0027829287853313248]
[2024-04-20 13:27:42,258: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.009700026969662011]
[2024-04-20 13:27:42,923: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.004314045962507896]
[2024-04-20 13:27:43,581: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.002064278198548137]
[2024-04-20 13:27:44,239: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.021832777568389007]
[2024-04-20 13:27:44,897: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.0018875995963647998]
[2024-04-20 13:27:45,554: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.002951012552343145]
[2024-04-20 13:27:46,214: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.005051629571751066]
[2024-04-20 13:27:46,866: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.0006896950326478908]
[2024-04-20 13:27:47,525: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.024019349314832076]
[2024-04-20 13:27:48,178: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.013178710000694078]
[2024-04-20 13:27:48,831: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.00046917400014166336]
[2024-04-20 13:27:49,483: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.00622220191825603]
[2024-04-20 13:27:50,138: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.0072418636512356785]
[2024-04-20 13:27:50,794: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.013740685647410721]
[2024-04-20 13:27:51,448: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.017183791810556823]
[2024-04-20 13:27:52,102: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.0034813729139869525]
[2024-04-20 13:27:52,760: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.0013552337062007261]
[2024-04-20 13:27:53,424: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.02995726924439407]
[2024-04-20 13:27:54,100: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.006527277822273393]
[2024-04-20 13:27:54,767: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.0025836562519561293]
[2024-04-20 13:27:55,435: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.0058961828938554495]
[2024-04-20 13:27:56,113: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.01742054852540674]
[2024-04-20 13:27:56,777: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.008132089781212383]
[2024-04-20 13:27:57,427: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.000525710687570029]
[2024-04-20 13:27:58,088: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.002195000338187944]
[2024-04-20 13:27:58,746: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.005324279859368678]
[2024-04-20 13:27:59,400: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.00475933193121517]
[2024-04-20 13:28:00,056: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.006924523528985583]
[2024-04-20 13:28:00,716: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.005044311411354594]
[2024-04-20 13:28:01,377: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.006458605545245651]
[2024-04-20 13:28:02,033: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.019647548867767553]
[2024-04-20 13:28:02,689: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.001428939245076688]
[2024-04-20 13:28:03,343: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.0017384546242887346]
[2024-04-20 13:28:04,001: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.0018577268248028095]
[2024-04-20 13:28:04,656: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.002442039544544563]
[2024-04-20 13:28:05,312: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.004378619435582177]
[2024-04-20 13:28:05,966: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.017656053595690707]
[2024-04-20 13:28:06,638: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.0028967249764325098]
[2024-04-20 13:28:07,316: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.007912630207062253]
[2024-04-20 13:28:07,983: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.0008008724871665065]
[2024-04-20 13:28:08,649: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.004491696443494045]
[2024-04-20 13:28:09,324: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.013571959584096559]
[2024-04-20 13:28:09,985: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.0074466666269488975]
[2024-04-20 13:28:10,641: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.0030413154553778103]
[2024-04-20 13:28:11,299: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.02446426518768024]
[2024-04-20 13:28:11,953: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.019398420905884756]
[2024-04-20 13:28:12,608: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.0036295789746716867]
[2024-04-20 13:28:13,264: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.0044536096916995595]
[2024-04-20 13:28:13,917: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.005190361614093006]
[2024-04-20 13:28:14,572: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.01649111357830621]
[2024-04-20 13:28:15,230: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.019787817291956153]
[2024-04-20 13:28:15,885: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.012275835553622001]
[2024-04-20 13:28:16,541: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.006322093056636591]
[2024-04-20 13:28:17,197: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.013417219176605035]
[2024-04-20 13:28:17,853: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.01225969241428276]
[2024-04-20 13:28:18,508: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.002628908972741626]
[2024-04-20 13:28:19,166: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.008350206511163468]
[2024-04-20 13:28:19,823: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.009105418700879072]
[2024-04-20 13:28:20,493: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.007150764526131331]
[2024-04-20 13:28:21,159: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.0013239975626513005]
[2024-04-20 13:28:21,827: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.013176223607304813]
[2024-04-20 13:28:22,499: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.009349541962189473]
[2024-04-20 13:28:23,169: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.004181212639918397]
[2024-04-20 13:28:23,826: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.000622402895104375]
[2024-04-20 13:28:24,484: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.007536285751145828]
[2024-04-20 13:28:25,137: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.001163943872653615]
[2024-04-20 13:28:25,794: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.0056393150686227436]
[2024-04-20 13:28:26,447: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.006880411277093757]
[2024-04-20 13:28:27,103: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.0034981496991002585]
[2024-04-20 13:28:27,761: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.023553416337512602]
[2024-04-20 13:28:28,418: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.0008841053608640271]
[2024-04-20 13:28:29,073: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.016914094437866557]
[2024-04-20 13:28:29,728: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.010407858633035144]
[2024-04-20 13:28:30,380: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.0015372194247840099]
[2024-04-20 13:28:31,039: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.004801506119509348]
[2024-04-20 13:28:31,691: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.004152627567753612]
[2024-04-20 13:28:32,346: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.03397966104496202]
[2024-04-20 13:28:33,004: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.0016142401907263861]
[2024-04-20 13:28:33,670: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.004978103732350928]
[2024-04-20 13:28:34,335: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.004256491659281255]
[2024-04-20 13:28:34,998: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.0028413497772058196]
[2024-04-20 13:28:35,662: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.0009782856543441593]
[2024-04-20 13:28:36,327: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.002802088858145453]
[2024-04-20 13:28:36,994: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.006140950616604416]
[2024-04-20 13:28:37,664: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.009126529196051345]
[2024-04-20 13:28:38,318: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.0025587842078669404]
[2024-04-20 13:28:38,974: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.0056901262079159685]
[2024-04-20 13:28:39,628: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.00453982067599598]
[2024-04-20 13:28:40,284: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.005781405430761852]
[2024-04-20 13:28:40,939: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.013739019647926296]
[2024-04-20 13:28:41,592: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.002354422573379693]
[2024-04-20 13:28:42,251: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.0013798870671187945]
[2024-04-20 13:28:42,908: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.013222838908689433]
[2024-04-20 13:28:43,564: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.011813313013998778]
[2024-04-20 13:28:44,215: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.009626061560272741]
[2024-04-20 13:28:44,872: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.0008409244241270608]
[2024-04-20 13:28:45,532: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.0018359326561658389]
[2024-04-20 13:28:46,185: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.00229917791398407]
[2024-04-20 13:28:46,841: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.00984711234474109]
[2024-04-20 13:28:47,499: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.0011147011215377081]
[2024-04-20 13:28:48,176: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.006218550954225951]
[2024-04-20 13:28:48,849: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.0005935237836992469]
[2024-04-20 13:28:49,509: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.0017419548242365536]
[2024-04-20 13:28:50,173: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.01940273578849619]
[2024-04-20 13:28:50,831: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.019114888664745238]
[2024-04-20 13:28:51,489: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.011484885807667728]
[2024-04-20 13:28:52,148: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.00477438912382905]
[2024-04-20 13:28:52,805: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.006786372493118427]
[2024-04-20 13:28:53,460: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.010748767014156932]
[2024-04-20 13:28:54,118: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.007400444910279665]
[2024-04-20 13:28:54,773: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.0036308770984189694]
[2024-04-20 13:28:55,430: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.007512118514615883]
[2024-04-20 13:28:56,085: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.004809852887978668]
[2024-04-20 13:28:56,740: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.013932063454320106]
[2024-04-20 13:28:57,394: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.0048279280599346965]
[2024-04-20 13:28:58,047: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.016943866481863797]
[2024-04-20 13:28:58,703: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.005407312275223452]
[2024-04-20 13:28:59,362: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.005967294468690199]
[2024-04-20 13:29:00,015: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.008048100046889831]
[2024-04-20 13:29:00,680: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.005848012678058856]
[2024-04-20 13:29:01,358: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.00045556654117691293]
[2024-04-20 13:29:02,038: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.006805093196617807]
[2024-04-20 13:29:02,701: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.01395943485527721]
[2024-04-20 13:29:03,369: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.005019757822807781]
[2024-04-20 13:29:04,033: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.009070436651534864]
[2024-04-20 13:29:04,690: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.006104577878078459]
[2024-04-20 13:29:05,353: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.014215861456860674]
[2024-04-20 13:29:06,012: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.0029512433182322917]
[2024-04-20 13:29:06,670: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.015017341257051075]
[2024-04-20 13:29:07,329: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.006538329716106602]
[2024-04-20 13:29:07,987: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.003008096185299226]
[2024-04-20 13:29:08,640: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.008361406458768641]
[2024-04-20 13:29:09,296: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.00475408224196518]
[2024-04-20 13:29:09,954: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.030782646874204136]
[2024-04-20 13:29:10,613: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.019844851444457016]
[2024-04-20 13:29:11,266: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.002555771203094057]
[2024-04-20 13:29:11,924: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.010110238898559736]
[2024-04-20 13:29:12,582: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.004793765510503007]
[2024-04-20 13:29:13,237: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.02711161872537935]
[2024-04-20 13:29:13,893: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.004005716033020615]
[2024-04-20 13:29:14,560: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.006442668063298376]
[2024-04-20 13:29:15,230: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.010802933875046102]
[2024-04-20 13:29:15,900: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.016617551869243775]
[2024-04-20 13:29:16,561: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.0018916009412535456]
[2024-04-20 13:29:17,225: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.0035862995081105903]
[2024-04-20 13:29:17,879: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.009234667367262759]
[2024-04-20 13:29:18,535: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.009608997594852545]
[2024-04-20 13:29:19,191: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.009719507025175083]
[2024-04-20 13:29:19,847: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.017308502765895593]
[2024-04-20 13:29:20,503: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.013906123341109178]
[2024-04-20 13:29:21,163: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.017098962256748552]
[2024-04-20 13:29:21,817: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.0094224372409737]
[2024-04-20 13:29:22,480: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.00586143543618845]
[2024-04-20 13:29:23,144: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.013101592705641414]
[2024-04-20 13:29:23,805: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.0018604872531235422]
[2024-04-20 13:29:24,462: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.010142491897370752]
[2024-04-20 13:29:25,116: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.0019115731073598339]
[2024-04-20 13:29:25,774: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.0012103064340468275]
[2024-04-20 13:29:26,432: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.005041807803850951]
[2024-04-20 13:29:27,088: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.0025570172527853447]
[2024-04-20 13:29:27,765: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.005117124648645294]
[2024-04-20 13:29:28,442: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.011762707099436968]
[2024-04-20 13:29:29,107: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.007717196688121594]
[2024-04-20 13:29:29,777: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.027936766435641608]
[2024-04-20 13:29:30,440: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.005430394844645906]
[2024-04-20 13:29:31,104: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.0053707138470617585]
[2024-04-20 13:29:31,771: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.009053063518947291]
[2024-04-20 13:29:32,431: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.006344898272654106]
[2024-04-20 13:29:33,094: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.0036434241038598267]
[2024-04-20 13:29:33,766: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.0012681380327169537]
[2024-04-20 13:29:34,434: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.003613116313283362]
[2024-04-20 13:29:35,092: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.010361563617687145]
[2024-04-20 13:29:35,749: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.0042801291336791916]
[2024-04-20 13:29:36,408: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.0027769828990752117]
[2024-04-20 13:29:37,062: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.0014960199059456253]
[2024-04-20 13:29:37,727: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.002282473599980349]
[2024-04-20 13:29:38,383: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.010410889199317569]
[2024-04-20 13:29:39,043: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.007735221912011017]
[2024-04-20 13:29:39,696: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.004913785465368815]
[2024-04-20 13:29:40,351: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.002455600701181526]
[2024-04-20 13:29:41,005: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.0025562475674644316]
[2024-04-20 13:29:41,674: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.002751510030974843]
[2024-04-20 13:29:42,344: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.01330782053785859]
[2024-04-20 13:29:43,021: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.0037017287284870737]
[2024-04-20 13:29:43,697: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.01246075410750827]
[2024-04-20 13:29:44,368: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.0007469901716511265]
[2024-04-20 13:29:45,024: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.003989644244050013]
[2024-04-20 13:29:45,684: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.03255901225363154]
[2024-04-20 13:29:46,341: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.012324008056319826]
[2024-04-20 13:29:46,999: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.0012187423742207309]
[2024-04-20 13:29:47,664: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.0077283778333383105]
[2024-04-20 13:29:48,322: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.0015753502629113354]
[2024-04-20 13:29:48,982: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.007857212753854297]
[2024-04-20 13:29:49,639: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.004240785431962094]
[2024-04-20 13:29:50,292: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.006311925334726003]
[2024-04-20 13:29:50,951: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.00819082923407879]
[2024-04-20 13:29:51,608: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.014053236089900913]
[2024-04-20 13:29:52,265: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.006596184367234863]
[2024-04-20 13:29:52,769: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.007572409821640235]
[2024-04-20 13:29:52,975: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.001811359120110597]
[2024-04-20 13:29:53,186: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.0030809893636583995]
[2024-04-20 13:29:53,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.006294950136080373]
[2024-04-20 13:29:53,595: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.0026586484946762635]
[2024-04-20 13:29:53,804: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.004588730801871505]
[2024-04-20 13:29:54,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.004462952841671528]
[2024-04-20 13:29:54,222: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.005921579284766019]
[2024-04-20 13:29:54,439: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.0016790940050589562]
[2024-04-20 13:29:54,647: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.0037443173413231534]
[2024-04-20 13:29:54,862: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.005258424802183138]
[2024-04-20 13:29:55,071: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.002210861617454261]
[2024-04-20 13:29:55,282: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.0008699119571560334]
[2024-04-20 13:29:55,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.0034908251810169696]
[2024-04-20 13:29:55,707: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.003399143173443924]
[2024-04-20 13:29:55,917: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.003132626887783903]
[2024-04-20 13:29:56,129: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.0003704940802105741]
[2024-04-20 13:29:56,339: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.0039338169208136585]
[2024-04-20 13:29:56,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.004355647973819217]
[2024-04-20 13:29:56,761: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.0014989247942195833]
[2024-04-20 13:29:56,977: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.005804768846700372]
[2024-04-20 13:29:57,194: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.0021194900848818927]
[2024-04-20 13:29:57,407: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.004880023168947899]
[2024-04-20 13:29:57,619: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.005981638000045557]
[2024-04-20 13:29:57,830: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.0026733716000481287]
[2024-04-20 13:29:58,036: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.003669205111980214]
[2024-04-20 13:29:58,243: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.004756018130964533]
[2024-04-20 13:29:58,451: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.0037773763129372354]
[2024-04-20 13:29:58,657: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.006211182346335638]
[2024-04-20 13:29:58,860: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.002238532401620502]
[2024-04-20 13:29:59,066: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.004038307288650575]
[2024-04-20 13:29:59,273: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.001217175524402464]
[2024-04-20 13:29:59,481: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.0019529839948339324]
[2024-04-20 13:29:59,692: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.003021655693245335]
[2024-04-20 13:29:59,897: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.004388117633174917]
[2024-04-20 13:30:00,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.0032852209125490005]
[2024-04-20 13:30:00,312: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.00460758667845007]
[2024-04-20 13:30:00,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.0013009678269657393]
[2024-04-20 13:30:00,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.0027888096197487586]
[2024-04-20 13:30:00,930: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.0023928162576839895]
[2024-04-20 13:30:01,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.0034492844182108344]
[2024-04-20 13:30:01,350: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.010614336046846749]
[2024-04-20 13:30:01,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.005655730914320501]
[2024-04-20 13:30:01,762: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.004144104959094049]
[2024-04-20 13:30:01,970: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.005097680978439051]
[2024-04-20 13:30:02,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.008644473908340762]
[2024-04-20 13:30:02,382: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.0027295611395259842]
[2024-04-20 13:30:02,587: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.0010236896484534836]
[2024-04-20 13:30:02,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.0041312838935799005]
[2024-04-20 13:30:02,997: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.003942923758723943]
[2024-04-20 13:30:03,208: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.003047453494895927]
[2024-04-20 13:30:03,414: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.004025275763265566]
[2024-04-20 13:30:03,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.0025509096478169187]
[2024-04-20 13:30:03,820: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.011487949907978206]
[2024-04-20 13:30:04,025: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.0032840804918910058]
[2024-04-20 13:30:04,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.005154200719926726]
[2024-04-20 13:30:04,443: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.007282373649031653]
[2024-04-20 13:30:04,647: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.010444826506057808]
[2024-04-20 13:30:04,855: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.0018098587870984126]
[2024-04-20 13:30:05,061: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.011201639440968482]
[2024-04-20 13:30:05,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.004148167439722148]
[2024-04-20 13:30:05,476: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.002697000048145162]
[2024-04-20 13:30:05,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.006468214189844321]
[2024-04-20 13:30:05,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.006185980329147056]
[2024-04-20 13:30:06,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.006553614902502442]
[2024-04-20 13:30:06,306: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.0020242160682867848]
[2024-04-20 13:30:06,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.0012866646808149533]
[2024-04-20 13:30:06,722: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.007019830400554384]
[2024-04-20 13:30:06,929: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.006774676504163216]
[2024-04-20 13:30:07,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.005190716039606428]
[2024-04-20 13:30:07,345: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.0009654883646105443]
[2024-04-20 13:30:07,553: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.00754533738063496]
[2024-04-20 13:30:07,758: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.00321980313444938]
[2024-04-20 13:30:07,964: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.006530449364278471]
[2024-04-20 13:30:08,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.001321925503490055]
[2024-04-20 13:30:08,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.003324838695578521]
[2024-04-20 13:30:08,606: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.009822053104176984]
[2024-04-20 13:30:08,815: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.004636453999445257]
[2024-04-20 13:30:09,027: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.0013244343294166465]
[2024-04-20 13:30:09,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.0035856498895671276]
[2024-04-20 13:30:09,452: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.005157601712641082]
[2024-04-20 13:30:09,663: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.0015326827863862142]
[2024-04-20 13:30:09,875: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.0023771003398336942]
[2024-04-20 13:30:10,085: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.002054725426931126]
[2024-04-20 13:30:10,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.003490655927336385]
[2024-04-20 13:30:10,509: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.006144832160028631]
[2024-04-20 13:30:10,720: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.007056563208306365]
[2024-04-20 13:30:10,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.0021814314435564105]
[2024-04-20 13:30:11,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.008783780396216693]
[2024-04-20 13:30:11,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.0042523091681403]
[2024-04-20 13:30:11,561: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.00016449849280434134]
[2024-04-20 13:30:11,768: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.005648646764258057]
[2024-04-20 13:30:11,976: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.0035878109209555287]
[2024-04-20 13:30:12,187: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.0030288857079041167]
[2024-04-20 13:30:12,394: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.004383705523328921]
[2024-04-20 13:30:12,598: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.007569400447278296]
[2024-04-20 13:30:12,803: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.0024832791509981156]
[2024-04-20 13:30:13,009: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.003174227063453504]
[2024-04-20 13:30:13,215: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.0035285024058020003]
[2024-04-20 13:30:13,419: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.003888770942644565]
[2024-04-20 13:30:13,630: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.003984308421266066]
[2024-04-20 13:30:13,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.0014685593274936838]
[2024-04-20 13:30:14,044: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.004388108693421538]
[2024-04-20 13:30:14,252: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.0027693113201434165]
[2024-04-20 13:30:14,463: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.006728823204531988]
[2024-04-20 13:30:14,669: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.0015516405356991107]
[2024-04-20 13:30:14,875: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.002423162365250459]
[2024-04-20 13:30:15,085: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.0023672518477436655]
[2024-04-20 13:30:15,293: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.005593794274306667]
[2024-04-20 13:30:15,500: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.00044733028434461016]
[2024-04-20 13:30:15,709: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.0016866740667225947]
[2024-04-20 13:30:15,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.010135188256994493]
[2024-04-20 13:30:16,121: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.007044192350823273]
[2024-04-20 13:30:16,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.0005750371136403171]
[2024-04-20 13:30:16,534: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.0038579419505231165]
[2024-04-20 13:30:16,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.0013847835512979733]
[2024-04-20 13:30:16,950: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.0012799585829322388]
[2024-04-20 13:30:17,158: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.01849427302959068]
[2024-04-20 13:30:17,365: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.010162172960517014]
[2024-04-20 13:30:17,574: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.017306736210692612]
[2024-04-20 13:30:17,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.000516960145538011]
[2024-04-20 13:30:17,991: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.00874579268868984]
[2024-04-20 13:30:18,202: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.004249837973054188]
[2024-04-20 13:30:18,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.010562956741161858]
[2024-04-20 13:30:18,618: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.015321907344245513]
[2024-04-20 13:30:18,823: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.0027718155992282945]
[2024-04-20 13:30:19,032: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.018548696859944584]
[2024-04-20 13:30:19,242: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.0011818147754372166]
[2024-04-20 13:30:19,452: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.002599988906521128]
[2024-04-20 13:30:19,659: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.0011191352867154167]
[2024-04-20 13:30:19,868: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.014507384691820426]
[2024-04-20 13:30:20,074: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.004772573754079354]
[2024-04-20 13:30:20,281: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.012836406171774582]
[2024-04-20 13:30:20,490: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.0009844669161000554]
[2024-04-20 13:30:20,698: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.005520582981401781]
[2024-04-20 13:30:20,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.001686955563584372]
[2024-04-20 13:30:21,112: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.00256203169358245]
[2024-04-20 13:30:21,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.004112421727311293]
[2024-04-20 13:30:21,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.006686514570223649]
[2024-04-20 13:30:21,742: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.0008350136957942321]
[2024-04-20 13:30:21,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.002241298814125952]
[2024-04-20 13:30:22,169: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.0018904243380228837]
[2024-04-20 13:30:22,379: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.00021766101474804926]
[2024-04-20 13:30:22,592: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.006730773938430305]
[2024-04-20 13:30:22,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.0006980902606445173]
[2024-04-20 13:30:23,015: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.0018588490040475278]
[2024-04-20 13:30:23,232: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.004146265599201929]
[2024-04-20 13:30:23,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.002199980867503019]
[2024-04-20 13:30:23,664: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.004707471759716756]
[2024-04-20 13:30:23,872: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.003403887317196961]
[2024-04-20 13:30:24,080: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.0061734796921139755]
[2024-04-20 13:30:24,291: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.0032485492912590177]
[2024-04-20 13:30:24,505: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.0022460459940984055]
[2024-04-20 13:30:24,720: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.001995975082992976]
[2024-04-20 13:30:24,931: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.029830626492927455]
[2024-04-20 13:30:25,135: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.0101498117221885]
[2024-04-20 13:30:25,344: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.01086926020940689]
[2024-04-20 13:30:25,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.0026539937571243184]
[2024-04-20 13:30:25,765: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.004813654113687065]
[2024-04-20 13:30:25,971: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.005699239480281083]
[2024-04-20 13:30:26,178: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.006844762088308169]
[2024-04-20 13:30:26,383: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.0017175195516789068]
[2024-04-20 13:30:26,591: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.0020669894324162577]
[2024-04-20 13:30:26,795: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.00214158203242153]
[2024-04-20 13:30:27,000: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.00014128338234672098]
[2024-04-20 13:30:27,207: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.012000931201960061]
[2024-04-20 13:30:27,411: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.002186305669733406]
[2024-04-20 13:30:27,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.01305370441234763]
[2024-04-20 13:30:27,820: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.0041296400222441]
[2024-04-20 13:30:28,027: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.0040384475872734344]
[2024-04-20 13:30:28,232: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.0033498763380615916]
[2024-04-20 13:30:28,443: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.003320905815884998]
[2024-04-20 13:30:28,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.0018160254025262744]
[2024-04-20 13:30:28,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.002997650577095898]
[2024-04-20 13:30:29,065: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.0019177959804014995]
[2024-04-20 13:30:29,281: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.001697615801006205]
[2024-04-20 13:30:29,491: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.011869723248722286]
[2024-04-20 13:30:29,697: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.003964873621075237]
[2024-04-20 13:30:29,904: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.0011729871975301649]
[2024-04-20 13:30:30,112: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.002247307240702235]
[2024-04-20 13:30:30,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.0014891839917318855]
[2024-04-20 13:30:30,525: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.0005752622791387055]
[2024-04-20 13:30:30,730: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.002442235680131433]
[2024-04-20 13:30:30,933: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.006174294519742964]
[2024-04-20 13:30:31,139: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.003328604742364405]
[2024-04-20 13:30:31,346: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.0019889892618759147]
[2024-04-20 13:30:31,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.0023392899045745342]
[2024-04-20 13:30:31,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.0009634523947656711]
[2024-04-20 13:30:31,969: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.0024164274666026524]
[2024-04-20 13:30:32,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 0.00018999065577236478]
[2024-04-20 13:30:32,389: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.002191274824414625]
[2024-04-20 13:30:32,594: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.0026325786595839742]
[2024-04-20 13:30:32,802: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.0013141555546476616]
[2024-04-20 13:30:33,007: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.000912438191744758]
[2024-04-20 13:30:33,214: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.008014450317068657]
[2024-04-20 13:30:33,420: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.0006954706976081801]
[2024-04-20 13:30:33,623: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.0028262931910104237]
[2024-04-20 13:30:33,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.001695398020956418]
[2024-04-20 13:30:34,036: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.00017781415958361815]
[2024-04-20 13:30:34,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.00014529380098012089]
[2024-04-20 13:30:34,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.0010138314317825678]
[2024-04-20 13:30:34,662: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.0010697459093367504]
[2024-04-20 13:30:34,870: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.0006299612504788333]
[2024-04-20 13:30:35,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.001678070936787555]
[2024-04-20 13:30:35,292: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.0017900803096659703]
[2024-04-20 13:30:35,510: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.0024665617524731198]
[2024-04-20 13:30:35,722: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.007872529329661421]
[2024-04-20 13:30:35,934: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.0007376354476111742]
[2024-04-20 13:30:36,148: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.001469278561417702]
[2024-04-20 13:30:36,361: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.0027409494979270233]
[2024-04-20 13:30:36,572: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.002992302432301628]
[2024-04-20 13:30:36,783: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.006262043604855228]
[2024-04-20 13:30:36,991: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.0008526031240901594]
[2024-04-20 13:30:37,202: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.002148416055534029]
[2024-04-20 13:30:37,414: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.0026479331527276442]
[2024-04-20 13:30:37,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.003283107147970855]
[2024-04-20 13:30:37,835: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.0009352065027843784]
[2024-04-20 13:30:38,041: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.007717721773884011]
[2024-04-20 13:30:38,254: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.002410399132405277]
[2024-04-20 13:30:38,466: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.0027825920411573535]
[2024-04-20 13:30:38,678: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.005067555006101603]
[2024-04-20 13:30:38,884: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.001573932066836114]
[2024-04-20 13:30:39,090: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.008288021792406277]
[2024-04-20 13:30:39,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.003185710430569045]
[2024-04-20 13:30:39,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.005346074834676832]
[2024-04-20 13:30:39,721: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.0035683923606159938]
[2024-04-20 13:30:39,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.007151922551708513]
[2024-04-20 13:30:40,127: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.002382838867721075]
[2024-04-20 13:30:40,331: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.00200550418253223]
[2024-04-20 13:30:40,544: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.0006499466093443815]
[2024-04-20 13:30:40,749: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 0.00021672242367977508]
[2024-04-20 13:30:40,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.0036471223772274863]
[2024-04-20 13:30:41,162: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 0.00017049896757584428]
[2024-04-20 13:30:41,365: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.004072205897915738]
[2024-04-20 13:30:41,571: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.0010679448000463]
[2024-04-20 13:30:41,780: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.0025901666408092707]
[2024-04-20 13:30:41,987: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.00035322755392427744]
[2024-04-20 13:30:42,193: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.011349090015267176]
[2024-04-20 13:30:42,400: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.003860684581026574]
[2024-04-20 13:30:42,604: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.004286935428691628]
[2024-04-20 13:30:42,812: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.0006044227461964545]
[2024-04-20 13:30:43,022: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 0.00020848655423172645]
[2024-04-20 13:30:43,236: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.004253119206210938]
[2024-04-20 13:30:43,443: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.002340114416412538]
[2024-04-20 13:30:43,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.0019971944957225267]
[2024-04-20 13:30:43,854: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.0015515560334178721]
[2024-04-20 13:30:44,063: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.0015946402072722185]
[2024-04-20 13:30:44,271: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.0028345792247041475]
[2024-04-20 13:30:44,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.002113497088275848]
[2024-04-20 13:30:44,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.0005674289449272665]
[2024-04-20 13:30:44,883: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.008187032103080487]
[2024-04-20 13:30:45,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.0016788532686291546]
[2024-04-20 13:30:45,299: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.006279896884002623]
[2024-04-20 13:30:45,504: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.0025001402079472463]
[2024-04-20 13:30:45,711: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.004760136331087608]
[2024-04-20 13:30:45,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.006549709873809843]
[2024-04-20 13:30:46,118: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.0063462928116177555]
[2024-04-20 13:30:46,325: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.006906809262967207]
[2024-04-20 13:30:46,531: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.002969747972978206]
[2024-04-20 13:30:46,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.004451633369644696]
[2024-04-20 13:30:46,950: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.0019026282577669917]
[2024-04-20 13:30:47,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.007087444942511922]
[2024-04-20 13:30:47,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.00028922614974574403]
[2024-04-20 13:30:47,573: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.0014446600527044128]
[2024-04-20 13:30:47,781: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.0026487260046700665]
[2024-04-20 13:30:47,985: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.0005947724464201359]
[2024-04-20 13:30:48,192: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.004409724999861497]
[2024-04-20 13:30:48,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.003175127344093778]
[2024-04-20 13:30:48,604: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.0056553050473763375]
[2024-04-20 13:30:48,812: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.003091305752693516]
[2024-04-20 13:30:49,023: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.007813477110705009]
[2024-04-20 13:30:49,235: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.0058693514378391175]
[2024-04-20 13:30:49,450: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.004315059301782803]
[2024-04-20 13:30:49,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.0030331245089488305]
[2024-04-20 13:30:49,874: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.0020833547355157017]
[2024-04-20 13:30:50,084: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.015881031928594646]
[2024-04-20 13:30:50,296: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.0010112923497759198]
[2024-04-20 13:30:50,507: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.001758854201847625]
[2024-04-20 13:30:50,716: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.0007626841294096831]
[2024-04-20 13:30:50,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.015571860992020417]
[2024-04-20 13:30:51,143: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 0.0001851123023618345]
[2024-04-20 13:30:51,351: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.0006402096634154922]
[2024-04-20 13:30:51,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.00016849534435119302]
[2024-04-20 13:30:51,774: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.00148385274931698]
[2024-04-20 13:30:51,994: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.006057272011867619]
[2024-04-20 13:30:52,205: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.01852539854640293]
[2024-04-20 13:30:52,410: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.001272774760726843]
[2024-04-20 13:30:52,618: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.009083717521532654]
[2024-04-20 13:30:52,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.003261780538825725]
[2024-04-20 13:30:53,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.009456609405166202]
[2024-04-20 13:30:53,245: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.006972434038378158]
[2024-04-20 13:30:53,451: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.008436218304207531]
[2024-04-20 13:30:53,656: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.01175889288806245]
[2024-04-20 13:30:53,867: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.0034690115190981795]
[2024-04-20 13:30:54,072: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.003965563197549013]
[2024-04-20 13:30:54,281: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.011403030470263404]
[2024-04-20 13:30:54,489: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.010533589494547677]
[2024-04-20 13:30:54,698: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.0049314625172579936]
[2024-04-20 13:30:54,903: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.015381838094117944]
[2024-04-20 13:30:55,112: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.0045962508033710525]
[2024-04-20 13:30:55,322: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.0023028896301312426]
[2024-04-20 13:30:55,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.00723664286870179]
[2024-04-20 13:30:55,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.018679762722950535]
[2024-04-20 13:30:55,945: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.003082143169846168]
[2024-04-20 13:30:56,151: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.014225763773367612]
[2024-04-20 13:30:56,358: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.0025850581382323707]
[2024-04-20 13:30:56,565: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.002389060047097734]
[2024-04-20 13:30:56,778: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.00894034887087646]
[2024-04-20 13:30:56,985: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.00629990996281526]
[2024-04-20 13:30:57,191: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.005492305676432868]
[2024-04-20 13:30:57,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.004496487333002299]
[2024-04-20 13:30:57,606: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.019144553652113348]
[2024-04-20 13:30:57,814: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.011229318779277837]
[2024-04-20 13:30:58,023: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.004916984918126962]
[2024-04-20 13:30:58,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.00544563580792871]
[2024-04-20 13:30:58,433: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.0014422026243079628]
[2024-04-20 13:30:58,641: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.004200468650077368]
[2024-04-20 13:30:58,846: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.008628568071161158]
[2024-04-20 13:30:59,052: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.005889437588933857]
[2024-04-20 13:30:59,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.009543301852278014]
[2024-04-20 13:30:59,466: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.00554196476238462]
[2024-04-20 13:30:59,673: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.010638576139996987]
[2024-04-20 13:30:59,881: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.005811320201702878]
[2024-04-20 13:31:00,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.01195638278992121]
[2024-04-20 13:31:00,299: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.007292529171060094]
[2024-04-20 13:31:00,506: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.005089774308612556]
[2024-04-20 13:31:00,710: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.003542804487347539]
[2024-04-20 13:31:00,919: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.010512032121560178]
[2024-04-20 13:31:01,125: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.007657188997442594]
[2024-04-20 13:31:01,333: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.006563315174277332]
[2024-04-20 13:31:01,541: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.021979489081286538]
[2024-04-20 13:31:01,747: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.00966642619435944]
[2024-04-20 13:31:01,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.0031476675790018103]
[2024-04-20 13:31:02,162: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.002758595843630589]
[2024-04-20 13:31:02,366: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.01058681249919307]
[2024-04-20 13:31:02,574: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.02103730920715154]
[2024-04-20 13:31:02,786: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.010206800213167335]
[2024-04-20 13:31:03,000: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.002860479584998515]
[2024-04-20 13:31:03,209: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.007462989247808709]
[2024-04-20 13:31:03,418: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.004380188319947014]
[2024-04-20 13:31:03,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.011660663915373837]
[2024-04-20 13:31:03,839: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.0044051162602267505]
[2024-04-20 13:31:04,050: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.0014240228794532741]
[2024-04-20 13:31:04,260: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.01257423011861399]
[2024-04-20 13:31:04,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.010044127906767704]
[2024-04-20 13:31:04,686: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.004544908905315528]
[2024-04-20 13:31:04,893: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.005013841917410676]
[2024-04-20 13:31:05,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.004981624630700612]
[2024-04-20 13:31:05,317: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.003195152724626226]
[2024-04-20 13:31:05,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.005159553826672321]
[2024-04-20 13:31:05,751: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.004867829281037002]
[2024-04-20 13:31:05,958: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.011991295338757728]
[2024-04-20 13:31:06,165: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.01955346548688985]
[2024-04-20 13:31:06,366: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.008478204731472804]
[2024-04-20 13:31:06,574: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.00662233371431124]
[2024-04-20 13:31:06,781: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.0012645138067776775]
[2024-04-20 13:31:06,990: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.010522715109807143]
[2024-04-20 13:31:07,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.008426531301409808]
[2024-04-20 13:31:07,400: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.008708172044717603]
[2024-04-20 13:31:07,607: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.005525025204860867]
[2024-04-20 13:31:07,813: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.009481598048465198]
[2024-04-20 13:31:08,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.005421582237405611]
[2024-04-20 13:31:08,228: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.005307102693413842]
[2024-04-20 13:31:08,432: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.0004382682027952303]
[2024-04-20 13:31:08,640: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.0033228027319865535]
[2024-04-20 13:31:08,848: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.0005758869587851826]
[2024-04-20 13:31:09,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.0006518023103286596]
[2024-04-20 13:31:09,262: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.0031755193309533154]
[2024-04-20 13:31:09,470: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.006187664057012295]
[2024-04-20 13:31:09,675: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.0005717407693540006]
[2024-04-20 13:31:09,881: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.01905125303171855]
[2024-04-20 13:31:10,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.00025639322989209434]
[2024-04-20 13:31:10,292: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.003980349684749942]
[2024-04-20 13:31:10,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.003323905068430085]
[2024-04-20 13:31:10,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.0030773211483240497]
[2024-04-20 13:31:10,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.003723315404999994]
[2024-04-20 13:31:11,115: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.0002588017513916104]
[2024-04-20 13:31:11,323: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.007952783692542166]
[2024-04-20 13:31:11,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.010052590249768845]
[2024-04-20 13:31:11,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.00024873761285742823]
[2024-04-20 13:31:11,949: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.0004259559062558196]
[2024-04-20 13:31:12,162: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.004963484090977743]
[2024-04-20 13:31:12,367: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.003932072722275224]
[2024-04-20 13:31:12,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.00028665223705490655]
[2024-04-20 13:31:12,784: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.0038502715696941236]
[2024-04-20 13:31:12,990: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.011007831932328193]
[2024-04-20 13:31:13,196: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.00308201487782958]
[2024-04-20 13:31:13,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 0.00022205170857337157]
[2024-04-20 13:31:13,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.0008947153045086085]
[2024-04-20 13:31:13,816: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.004210515958980265]
[2024-04-20 13:31:14,020: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.00955834336698591]
[2024-04-20 13:31:14,224: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.016045312621479478]
[2024-04-20 13:31:14,433: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.0033336355340439204]
[2024-04-20 13:31:14,640: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.002822603817191423]
[2024-04-20 13:31:14,847: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.007956937426349724]
[2024-04-20 13:31:15,055: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.0002045647749748631]
[2024-04-20 13:31:15,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.006487555705954513]
[2024-04-20 13:31:15,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.004538081435706109]
[2024-04-20 13:31:15,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.0013272491520863253]
[2024-04-20 13:31:15,893: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.0038449930132734927]
[2024-04-20 13:31:16,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.01647902499691299]
[2024-04-20 13:31:16,317: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.003373639041027324]
[2024-04-20 13:31:16,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.002193499930753472]
[2024-04-20 13:31:16,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.0026652254334245105]
[2024-04-20 13:31:16,953: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.014543141712237119]
[2024-04-20 13:31:17,163: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.002731371486957647]
[2024-04-20 13:31:17,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.00438165285814539]
[2024-04-20 13:31:17,585: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.00032905626538511253]
[2024-04-20 13:31:17,794: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.008439033308166661]
[2024-04-20 13:31:18,007: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.004892674047859583]
[2024-04-20 13:31:18,217: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.0029659940074667906]
[2024-04-20 13:31:18,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.0027719075487631535]
[2024-04-20 13:31:18,650: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.0005242277614419328]
[2024-04-20 13:31:18,864: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.0030696248552860633]
[2024-04-20 13:31:19,076: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.012708125757544833]
[2024-04-20 13:31:19,288: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.009487437138488784]
[2024-04-20 13:31:19,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.0095637152716668]
[2024-04-20 13:31:19,703: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.0016261275007822729]
[2024-04-20 13:31:19,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.0045719374328200505]
[2024-04-20 13:31:20,116: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.00219797561951793]
[2024-04-20 13:31:20,321: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.004077204392292697]
[2024-04-20 13:31:20,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.0244193261262673]
[2024-04-20 13:31:20,736: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.004796707512364373]
[2024-04-20 13:31:20,942: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.010418217840047763]
[2024-04-20 13:31:21,153: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.008528363442440725]
[2024-04-20 13:31:21,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.007357597809148368]
[2024-04-20 13:31:21,573: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.01613508476156344]
[2024-04-20 13:31:21,778: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.0043417332238530485]
[2024-04-20 13:31:21,989: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.009976099372764193]
[2024-04-20 13:31:22,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.0017145204927548217]
[2024-04-20 13:31:22,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.000734020527951098]
[2024-04-20 13:31:22,609: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.004225101049579061]
[2024-04-20 13:31:22,815: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.0024969660655127313]
[2024-04-20 13:31:23,023: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.0069931021323833675]
[2024-04-20 13:31:23,231: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.0035938553772085296]
[2024-04-20 13:31:23,439: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.006801202841473273]
[2024-04-20 13:31:23,645: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.008067536917722551]
[2024-04-20 13:31:23,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.006908423148306354]
[2024-04-20 13:31:24,056: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.006302382222371269]
[2024-04-20 13:31:24,264: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.005245852958511308]
[2024-04-20 13:31:24,470: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.01745378244828998]
[2024-04-20 13:31:24,678: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.009737029465605389]
[2024-04-20 13:31:24,885: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.004612009156195779]
[2024-04-20 13:31:25,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.006457850566107787]
[2024-04-20 13:31:25,297: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.0010999510658855774]
[2024-04-20 13:31:25,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.007425510905354724]
[2024-04-20 13:31:25,714: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.005369637770523027]
[2024-04-20 13:31:25,923: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.005093464846445014]
[2024-04-20 13:31:26,136: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.005245312133679544]
[2024-04-20 13:31:26,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.0034573344486851297]
[2024-04-20 13:31:26,546: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.0028082388414257743]
[2024-04-20 13:31:26,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.002655459162766593]
[2024-04-20 13:31:26,961: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.0022837615145322493]
[2024-04-20 13:31:27,170: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.005517083384044397]
[2024-04-20 13:31:27,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.0009162067273718435]
[2024-04-20 13:31:27,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.005650456957450529]
[2024-04-20 13:31:27,789: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.0040162014380445265]
[2024-04-20 13:31:27,998: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.0005446064179288892]
[2024-04-20 13:31:28,206: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.0010025713276675368]
[2024-04-20 13:31:28,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.002071697081822184]
[2024-04-20 13:31:28,632: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.0012959885477662881]
[2024-04-20 13:31:28,841: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 0.000225883254453984]
[2024-04-20 13:31:29,046: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.0026199673343984863]
[2024-04-20 13:31:29,252: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.0032168085553859415]
[2024-04-20 13:31:29,469: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.0032305586473376216]
[2024-04-20 13:31:29,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.012135070146525637]
[2024-04-20 13:31:29,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.0072919954323203045]
[2024-04-20 13:31:30,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.000704237048158659]
[2024-04-20 13:31:30,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.004934651256733531]
[2024-04-20 13:31:30,531: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.0007098468313098989]
[2024-04-20 13:31:30,742: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.002363184431067386]
[2024-04-20 13:31:30,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.0015201540163775687]
[2024-04-20 13:31:31,167: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.0031039618236107765]
[2024-04-20 13:31:31,378: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 3.339384720981869e-05]
[2024-04-20 13:31:31,592: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.005294337356534432]
[2024-04-20 13:31:31,804: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.0056054405536995425]
[2024-04-20 13:31:32,016: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.0009382671733636976]
[2024-04-20 13:31:32,228: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.0021315594436050063]
[2024-04-20 13:31:32,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.003130435660738938]
[2024-04-20 13:31:32,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.0010697499874650438]
[2024-04-20 13:31:32,869: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.004914233825796492]
[2024-04-20 13:31:33,080: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.005811962275252796]
[2024-04-20 13:31:33,284: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.0064365288310961315]
[2024-04-20 13:31:33,493: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.004295532502536567]
[2024-04-20 13:31:33,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.002643768007360337]
[2024-04-20 13:31:33,907: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.0054746673225476855]
[2024-04-20 13:31:34,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.0031261633244456127]
[2024-04-20 13:31:34,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.004490767349174016]
[2024-04-20 13:31:34,528: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.0013094860535350931]
[2024-04-20 13:31:34,737: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.007314159456198196]
[2024-04-20 13:31:34,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.0013480383882622517]
[2024-04-20 13:31:35,159: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.007085801992596635]
[2024-04-20 13:31:35,366: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.003916277505868444]
[2024-04-20 13:31:35,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.0021342751672867714]
[2024-04-20 13:31:35,788: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.001449768246280792]
[2024-04-20 13:31:35,995: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.0014886985089657637]
[2024-04-20 13:31:36,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.0050276353196698625]
[2024-04-20 13:31:36,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.0049284785288675765]
[2024-04-20 13:31:36,619: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.004410733332334741]
[2024-04-20 13:31:36,827: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.002114909949134841]
[2024-04-20 13:31:37,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.0008451713933214183]
[2024-04-20 13:31:37,245: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.000542465945235319]
[2024-04-20 13:31:37,456: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.0030138719026914333]
[2024-04-20 13:31:37,664: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.0009676025426870183]
[2024-04-20 13:31:37,873: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.006314262127051764]
[2024-04-20 13:31:38,080: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.003956507371896824]
[2024-04-20 13:31:38,290: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.0033174591073807705]
[2024-04-20 13:31:38,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.0035241918738226235]
[2024-04-20 13:31:38,699: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.003650076050464647]
[2024-04-20 13:31:38,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.0036269404605991117]
[2024-04-20 13:31:39,111: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.00828366616046963]
[2024-04-20 13:31:39,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.0027137218946507555]
[2024-04-20 13:31:39,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.010891601478899183]
[2024-04-20 13:31:39,736: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.0008088777257609837]
[2024-04-20 13:31:39,940: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.0001391974497826129]
[2024-04-20 13:31:40,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.016785648168782762]
[2024-04-20 13:31:40,347: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.003862483746563598]
[2024-04-20 13:31:40,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.0010712498277666907]
[2024-04-20 13:31:40,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.0005990183940915123]
[2024-04-20 13:31:40,975: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.000685539243681864]
[2024-04-20 13:31:41,189: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.0033649678599881384]
[2024-04-20 13:31:41,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.007514641619306509]
[2024-04-20 13:31:41,602: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.003932542968094743]
[2024-04-20 13:31:41,809: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.00044699051330107116]
[2024-04-20 13:31:42,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.0004044384301690321]
[2024-04-20 13:31:42,224: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.0003605078527535554]
[2024-04-20 13:31:42,430: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.0014712663231840409]
[2024-04-20 13:31:42,634: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.0019575157940692933]
[2024-04-20 13:31:42,843: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.009046705092380347]
[2024-04-20 13:31:43,054: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.0015192252509669585]
[2024-04-20 13:31:43,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.0005882862196797995]
[2024-04-20 13:31:43,482: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.00027118107496504557]
[2024-04-20 13:31:43,692: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.000820099259233916]
[2024-04-20 13:31:43,905: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.00038950439711388473]
[2024-04-20 13:31:44,118: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.0005922987031027244]
[2024-04-20 13:31:44,327: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.010674519845116519]
[2024-04-20 13:31:44,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.0017441128350613453]
[2024-04-20 13:31:44,745: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.0013656369498036406]
[2024-04-20 13:31:44,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.00283484806584562]
[2024-04-20 13:31:45,166: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.003810526920614934]
[2024-04-20 13:31:45,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.006496541190551094]
[2024-04-20 13:31:45,592: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.003303881014799528]
[2024-04-20 13:31:45,801: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.0012184177491562985]
[2024-04-20 13:31:46,015: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.0013909901417748652]
[2024-04-20 13:31:46,229: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.0005962315085964982]
[2024-04-20 13:31:46,435: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.002207338423943051]
[2024-04-20 13:31:46,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.003579677391175141]
[2024-04-20 13:31:46,850: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.00024149109434803994]
[2024-04-20 13:31:47,060: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.0017801374209167119]
[2024-04-20 13:31:47,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.0003617602225691834]
[2024-04-20 13:31:47,469: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.005072424710024447]
[2024-04-20 13:31:47,676: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.004579498580392886]
[2024-04-20 13:31:47,884: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.0041665351380699555]
[2024-04-20 13:31:48,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.000529946850703975]
[2024-04-20 13:31:48,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.012185402312166985]
[2024-04-20 13:31:48,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.001663567235465103]
[2024-04-20 13:31:48,721: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.005002045651402173]
[2024-04-20 13:31:48,926: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.0005066577227627886]
[2024-04-20 13:31:49,131: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.0016614221867284702]
[2024-04-20 13:31:49,336: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.03772132145056017]
[2024-04-20 13:31:49,546: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.0010098608492757246]
[2024-04-20 13:31:49,754: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.00953900793879843]
[2024-04-20 13:31:49,960: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.0023521489348182355]
[2024-04-20 13:31:50,164: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.0036029022609218656]
[2024-04-20 13:31:50,368: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.0011747297100250056]
[2024-04-20 13:31:50,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.004423116988746218]
[2024-04-20 13:31:50,782: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.0025060477814744376]
[2024-04-20 13:31:50,987: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.003824442657455879]
[2024-04-20 13:31:51,195: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.0034225087073053223]
[2024-04-20 13:31:51,404: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.0003837329468108329]
[2024-04-20 13:31:51,609: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.0051380238488771]
[2024-04-20 13:31:51,814: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.012194469046314252]
[2024-04-20 13:31:52,024: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.009342056982839173]
[2024-04-20 13:31:52,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.0031787811278205925]
[2024-04-20 13:31:52,442: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.0018305005608010973]
[2024-04-20 13:31:52,648: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.0006723853830010112]
[2024-04-20 13:31:52,852: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.0032484213557255927]
[2024-04-20 13:31:53,059: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.0004145846628366337]
[2024-04-20 13:31:53,265: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.006748013420111607]
[2024-04-20 13:31:53,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.0038968327574221092]
[2024-04-20 13:31:53,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.0007170386445663594]
[2024-04-20 13:31:53,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.0010262896139329836]
[2024-04-20 13:31:54,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.005827593902548218]
[2024-04-20 13:31:54,301: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.004345846181144055]
[2024-04-20 13:31:54,505: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.0035214758351308564]
[2024-04-20 13:31:54,708: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.0005631148054213826]
[2024-04-20 13:31:54,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.0012221188297835276]
[2024-04-20 13:31:55,119: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.0006948375489844519]
[2024-04-20 13:31:55,328: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.0006545290219724377]
[2024-04-20 13:31:55,532: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 0.0010693026661014648]
[2024-04-20 13:31:55,742: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.0006901638603461914]
[2024-04-20 13:31:55,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.0003728680921084248]
[2024-04-20 13:31:56,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.010336105882151793]
[2024-04-20 13:31:56,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.0012063941551965836]
[2024-04-20 13:31:56,568: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.005507825374169766]
[2024-04-20 13:31:56,779: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.003392865887020332]
[2024-04-20 13:31:56,938: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 9.475628337399223e-05]
[2024-04-20 13:32:20,322: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9963899658879649, 'precision': 0.8216870346330035, 'recall': 0.9632149728878783, 'f1': 0.8868400074081827}]
[2024-04-20 13:32:23,245: INFO: roberta_kFold_initial_lstm: Fold 3/3 , Epoch: 2/3]
[2024-04-20 13:32:23,961: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.0026134146672418222]
[2024-04-20 13:32:24,600: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.003412448984424928]
[2024-04-20 13:32:25,241: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.01956283759455175]
[2024-04-20 13:32:25,883: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.009169370239213685]
[2024-04-20 13:32:26,510: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.007047577067613324]
[2024-04-20 13:32:27,139: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.0033012419897814585]
[2024-04-20 13:32:27,771: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.002908986691338064]
[2024-04-20 13:32:28,402: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.002972402460447929]
[2024-04-20 13:32:29,035: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.00599176209890342]
[2024-04-20 13:32:29,670: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.0006298905936489719]
[2024-04-20 13:32:30,304: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.006600487206741402]
[2024-04-20 13:32:30,939: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.004109814410003981]
[2024-04-20 13:32:31,570: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.0026006800014205154]
[2024-04-20 13:32:32,204: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.004862793930048784]
[2024-04-20 13:32:32,841: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.004543687088564259]
[2024-04-20 13:32:33,474: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.01906810001387623]
[2024-04-20 13:32:34,118: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.004713699476140489]
[2024-04-20 13:32:34,757: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.006653902067365819]
[2024-04-20 13:32:35,405: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.006359584702549672]
[2024-04-20 13:32:36,069: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.0013811815537454616]
[2024-04-20 13:32:36,734: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.00011974799246454425]
[2024-04-20 13:32:37,395: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.002954429394273478]
[2024-04-20 13:32:38,038: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.0027304175919472175]
[2024-04-20 13:32:38,678: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.01193938976744543]
[2024-04-20 13:32:39,321: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 0.003300983441474382]
[2024-04-20 13:32:39,961: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.005155979899474441]
[2024-04-20 13:32:40,594: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.016056168874792474]
[2024-04-20 13:32:41,233: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.0011037482015458563]
[2024-04-20 13:32:41,872: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.000525021488929308]
[2024-04-20 13:32:42,505: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.003423485652282325]
[2024-04-20 13:32:43,143: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.01034032796907992]
[2024-04-20 13:32:43,774: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.019255019700458308]
[2024-04-20 13:32:44,407: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.004282386024485883]
[2024-04-20 13:32:45,047: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.0020742473347209653]
[2024-04-20 13:32:45,679: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.005155298605612002]
[2024-04-20 13:32:46,317: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.005105463038667703]
[2024-04-20 13:32:46,957: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.009377435879226431]
[2024-04-20 13:32:47,592: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.002427022216090007]
[2024-04-20 13:32:48,230: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.0017793585408922708]
[2024-04-20 13:32:48,870: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.004228810021181361]
[2024-04-20 13:32:49,513: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.00028194843182033596]
[2024-04-20 13:32:50,165: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.006927042411847075]
[2024-04-20 13:32:50,809: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.003836941011071097]
[2024-04-20 13:32:51,462: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.0039330359422399715]
[2024-04-20 13:32:52,111: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.0033395665831097193]
[2024-04-20 13:32:52,752: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 0.01216805265060404]
[2024-04-20 13:32:53,402: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.003977518536517454]
[2024-04-20 13:32:54,059: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.008460311718988214]
[2024-04-20 13:32:54,729: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.0031948802593312654]
[2024-04-20 13:32:55,380: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.003183262102928862]
[2024-04-20 13:32:56,018: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.0039911523080385656]
[2024-04-20 13:32:56,670: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.005979674506978129]
[2024-04-20 13:32:57,312: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.0011513281155665922]
[2024-04-20 13:32:57,953: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.0017743306160227829]
[2024-04-20 13:32:58,589: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.0004791750539046608]
[2024-04-20 13:32:59,229: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.0013071691465110936]
[2024-04-20 13:32:59,863: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.0021663749458053477]
[2024-04-20 13:33:00,506: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.0012263692825911915]
[2024-04-20 13:33:01,142: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.000585587539150362]
[2024-04-20 13:33:01,784: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.005174350062398815]
[2024-04-20 13:33:02,424: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.0009931275849341772]
[2024-04-20 13:33:03,064: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.0026248872135827116]
[2024-04-20 13:33:03,704: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.06739031433746366]
[2024-04-20 13:33:04,342: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.006053389178228672]
[2024-04-20 13:33:04,983: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.009247198477163475]
[2024-04-20 13:33:05,642: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.004447032972132619]
[2024-04-20 13:33:06,292: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.0018621093914384275]
[2024-04-20 13:33:06,941: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.00496863748096635]
[2024-04-20 13:33:07,591: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.005633930380010564]
[2024-04-20 13:33:08,248: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.0030073708059813547]
[2024-04-20 13:33:08,894: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.0014505886426923289]
[2024-04-20 13:33:09,536: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.012499309783952401]
[2024-04-20 13:33:10,181: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.0024156446395590626]
[2024-04-20 13:33:10,823: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.003880428784592252]
[2024-04-20 13:33:11,464: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.00614219550401516]
[2024-04-20 13:33:12,106: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.0020631316505106377]
[2024-04-20 13:33:12,744: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.0069895872872192425]
[2024-04-20 13:33:13,386: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.011651278643121004]
[2024-04-20 13:33:14,028: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.00025507861106421155]
[2024-04-20 13:33:14,665: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.009201345033618876]
[2024-04-20 13:33:15,310: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.0038849081961502855]
[2024-04-20 13:33:15,952: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.014600775206068766]
[2024-04-20 13:33:16,605: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.0028632303967676444]
[2024-04-20 13:33:17,250: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.0030240336489373337]
[2024-04-20 13:33:17,895: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.00435892156029929]
[2024-04-20 13:33:18,543: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.010919933078632312]
[2024-04-20 13:33:19,198: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.00468847969539421]
[2024-04-20 13:33:19,844: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.0013879159092146192]
[2024-04-20 13:33:20,505: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.0085153979864404]
[2024-04-20 13:33:21,164: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.006997387697724232]
[2024-04-20 13:33:21,812: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.001281673099412374]
[2024-04-20 13:33:22,452: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.00373551294832778]
[2024-04-20 13:33:23,093: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.0010666192584636537]
[2024-04-20 13:33:23,740: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.00035877561393567983]
[2024-04-20 13:33:24,382: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.0009434206816600829]
[2024-04-20 13:33:25,021: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.004914527666070331]
[2024-04-20 13:33:25,667: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.009267375758828005]
[2024-04-20 13:33:26,309: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.0027605984095657055]
[2024-04-20 13:33:26,953: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.0007103283699013083]
[2024-04-20 13:33:27,593: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.0016743515047530735]
[2024-04-20 13:33:28,239: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.0005502902996472818]
[2024-04-20 13:33:28,884: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.01032829449125222]
[2024-04-20 13:33:29,531: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.00211365125307835]
[2024-04-20 13:33:30,175: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.004408955047157392]
[2024-04-20 13:33:30,813: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.0017343378564766028]
[2024-04-20 13:33:31,455: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.04138604092811504]
[2024-04-20 13:33:32,107: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.017050404229841498]
[2024-04-20 13:33:32,758: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.0015660283711343328]
[2024-04-20 13:33:33,407: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.013336446504105164]
[2024-04-20 13:33:34,068: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.00122662357943006]
[2024-04-20 13:33:34,720: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.0005896524005781077]
[2024-04-20 13:33:35,363: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.0011496266466637993]
[2024-04-20 13:33:36,007: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.0008708914871758787]
[2024-04-20 13:33:36,654: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.002047582072225172]
[2024-04-20 13:33:37,299: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.0025092316735921528]
[2024-04-20 13:33:37,948: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.006536159095374395]
[2024-04-20 13:33:38,591: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.017283819157664505]
[2024-04-20 13:33:39,232: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.0012331551813276169]
[2024-04-20 13:33:39,879: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.00523240475626909]
[2024-04-20 13:33:40,526: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.0037924117610724684]
[2024-04-20 13:33:41,173: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.0025610656666973756]
[2024-04-20 13:33:41,821: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.0036632660504164905]
[2024-04-20 13:33:42,464: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.008209996309164122]
[2024-04-20 13:33:43,107: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.010110448444223144]
[2024-04-20 13:33:43,745: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.007988823377169151]
[2024-04-20 13:33:44,392: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.012354430220744277]
[2024-04-20 13:33:45,046: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.004289493815064713]
[2024-04-20 13:33:45,702: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.01436753267625824]
[2024-04-20 13:33:46,354: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.001048464190830329]
[2024-04-20 13:33:47,008: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.0021672748215012926]
[2024-04-20 13:33:47,669: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.00726118041201852]
[2024-04-20 13:33:48,314: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.01437550445309078]
[2024-04-20 13:33:48,954: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.0015122219151011897]
[2024-04-20 13:33:49,602: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.007101526363364303]
[2024-04-20 13:33:50,250: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.004735184546764331]
[2024-04-20 13:33:50,898: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.016655591650007226]
[2024-04-20 13:33:51,544: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.006194200863568574]
[2024-04-20 13:33:52,192: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.010588997863467784]
[2024-04-20 13:33:52,843: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.0027323956430122132]
[2024-04-20 13:33:53,491: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.011847718162031926]
[2024-04-20 13:33:54,139: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.003424380865652732]
[2024-04-20 13:33:54,789: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 0.007042093701371637]
[2024-04-20 13:33:55,437: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.0023373345568175495]
[2024-04-20 13:33:56,088: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.0024119332217957417]
[2024-04-20 13:33:56,736: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.006651600921924731]
[2024-04-20 13:33:57,385: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.0019637800358260045]
[2024-04-20 13:33:58,041: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.013337379055314564]
[2024-04-20 13:33:58,704: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.0006100465226206622]
[2024-04-20 13:33:59,368: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.024457931880965577]
[2024-04-20 13:34:00,040: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.0022220777940102497]
[2024-04-20 13:34:00,694: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.00676069865258483]
[2024-04-20 13:34:01,344: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.009930334137884656]
[2024-04-20 13:34:01,987: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.004365083240862544]
[2024-04-20 13:34:02,633: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.0021641305435491135]
[2024-04-20 13:34:03,283: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.0049044892947759456]
[2024-04-20 13:34:03,932: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.0046467400117244]
[2024-04-20 13:34:04,581: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.006819589688254176]
[2024-04-20 13:34:05,230: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.0009502649281607263]
[2024-04-20 13:34:05,879: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.002652219517052932]
[2024-04-20 13:34:06,529: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.015476516239602946]
[2024-04-20 13:34:07,176: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.005272249372024697]
[2024-04-20 13:34:07,824: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.006946845200419136]
[2024-04-20 13:34:08,467: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.01197395773901484]
[2024-04-20 13:34:09,114: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.010365491643221614]
[2024-04-20 13:34:09,762: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.0009578580808847338]
[2024-04-20 13:34:10,410: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.011364141417224482]
[2024-04-20 13:34:11,066: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.008725780835219389]
[2024-04-20 13:34:11,735: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.008044401317005912]
[2024-04-20 13:34:12,398: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.002520613195554172]
[2024-04-20 13:34:13,051: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.008897712545765732]
[2024-04-20 13:34:13,712: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.007045075418089173]
[2024-04-20 13:34:14,371: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.0016735972591803918]
[2024-04-20 13:34:15,021: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.00957880739865142]
[2024-04-20 13:34:15,669: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.00395586688389185]
[2024-04-20 13:34:16,322: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.0018404231689461204]
[2024-04-20 13:34:16,973: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.008804936428294554]
[2024-04-20 13:34:17,625: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.00602316069514203]
[2024-04-20 13:34:18,274: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.006314973471323056]
[2024-04-20 13:34:18,920: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.003543061718744726]
[2024-04-20 13:34:19,565: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.0006473985142037561]
[2024-04-20 13:34:20,212: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.010557685688345192]
[2024-04-20 13:34:20,859: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.0013343905767241107]
[2024-04-20 13:34:21,507: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.014465110699031433]
[2024-04-20 13:34:22,159: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.0017871531048645462]
[2024-04-20 13:34:22,805: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.0013337793396786017]
[2024-04-20 13:34:23,456: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.0008373211566112423]
[2024-04-20 13:34:24,102: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.002001007409561345]
[2024-04-20 13:34:24,761: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.003329044239409814]
[2024-04-20 13:34:25,422: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.002603558259309953]
[2024-04-20 13:34:26,082: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.004151955478147696]
[2024-04-20 13:34:26,741: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.007023952063943868]
[2024-04-20 13:34:27,396: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.00481107049696915]
[2024-04-20 13:34:28,044: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.0004347624657705584]
[2024-04-20 13:34:28,696: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.011197784317072712]
[2024-04-20 13:34:29,342: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.01092247526915378]
[2024-04-20 13:34:29,995: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.0030262149423225925]
[2024-04-20 13:34:30,644: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.0014222933461990968]
[2024-04-20 13:34:31,293: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.0011033782452579974]
[2024-04-20 13:34:31,945: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.0020988750567064655]
[2024-04-20 13:34:32,597: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.0018660409135382791]
[2024-04-20 13:34:33,246: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.007785564391926011]
[2024-04-20 13:34:33,899: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.00706731354952316]
[2024-04-20 13:34:34,547: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.004441648761941007]
[2024-04-20 13:34:35,199: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.0021090559126501905]
[2024-04-20 13:34:35,852: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 0.00857437548644206]
[2024-04-20 13:34:36,504: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.002844179002977724]
[2024-04-20 13:34:37,154: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.00949560647653301]
[2024-04-20 13:34:37,819: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.003443914756081649]
[2024-04-20 13:34:38,481: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.00788563386780213]
[2024-04-20 13:34:39,135: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.02097247535113964]
[2024-04-20 13:34:39,798: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.0014012512847178396]
[2024-04-20 13:34:40,456: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.0038837601310663804]
[2024-04-20 13:34:41,103: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.0025580244310614343]
[2024-04-20 13:34:41,749: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.004144394761940421]
[2024-04-20 13:34:42,396: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.00858142384279148]
[2024-04-20 13:34:43,048: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.003955200053579226]
[2024-04-20 13:34:43,696: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.0007634216061874322]
[2024-04-20 13:34:44,350: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.002838272377373198]
[2024-04-20 13:34:45,003: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.0030572136504669455]
[2024-04-20 13:34:45,655: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.0046036318595474605]
[2024-04-20 13:34:46,307: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.0004459707523050317]
[2024-04-20 13:34:46,964: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.0002900699553007423]
[2024-04-20 13:34:47,616: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.014383830193189711]
[2024-04-20 13:34:48,268: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.0051442134093583666]
[2024-04-20 13:34:48,922: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.007369665914830347]
[2024-04-20 13:34:49,577: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.0064664131975710045]
[2024-04-20 13:34:50,231: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.002499133984215533]
[2024-04-20 13:34:50,893: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.006637019174615863]
[2024-04-20 13:34:51,555: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.00479659209551674]
[2024-04-20 13:34:52,214: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.003435493229359071]
[2024-04-20 13:34:52,874: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.0028586025121340327]
[2024-04-20 13:34:53,536: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.021811734736987047]
[2024-04-20 13:34:54,189: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.005494976493051012]
[2024-04-20 13:34:54,844: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.0033521612232155122]
[2024-04-20 13:34:55,497: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.006034062312993733]
[2024-04-20 13:34:56,149: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.0020671054902864677]
[2024-04-20 13:34:56,803: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.00491176610752726]
[2024-04-20 13:34:57,456: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.004393151498796008]
[2024-04-20 13:34:58,104: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.0011469034508095248]
[2024-04-20 13:34:58,755: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.009037282555193933]
[2024-04-20 13:34:59,407: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.00561781562961436]
[2024-04-20 13:35:00,061: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.01387716512867007]
[2024-04-20 13:35:00,715: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.0015707794337762628]
[2024-04-20 13:35:01,368: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.006953372604752065]
[2024-04-20 13:35:02,027: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.0007439728221163278]
[2024-04-20 13:35:02,679: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.0021470427408728635]
[2024-04-20 13:35:03,330: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 0.0003544940121429962]
[2024-04-20 13:35:03,980: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.009863270035965684]
[2024-04-20 13:35:04,638: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.01637153267037186]
[2024-04-20 13:35:05,297: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.001242372944291353]
[2024-04-20 13:35:05,960: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.010824132741508787]
[2024-04-20 13:35:06,623: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.006882171551372616]
[2024-04-20 13:35:07,280: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.03635987086447504]
[2024-04-20 13:35:07,937: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.006321084164797319]
[2024-04-20 13:35:08,586: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.0020937240511804274]
[2024-04-20 13:35:09,235: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.0008627918324080012]
[2024-04-20 13:35:09,882: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.001093331211635662]
[2024-04-20 13:35:10,533: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.005625988412999513]
[2024-04-20 13:35:11,185: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.0038358245654173976]
[2024-04-20 13:35:11,842: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.002097966281722005]
[2024-04-20 13:35:12,495: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.002433848540806064]
[2024-04-20 13:35:13,145: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.009460548880547466]
[2024-04-20 13:35:13,798: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.0006283681698940874]
[2024-04-20 13:35:14,449: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.0028259090686388647]
[2024-04-20 13:35:15,100: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.0018530080745206101]
[2024-04-20 13:35:15,753: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.017302088514295665]
[2024-04-20 13:35:16,406: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.0011262725027378023]
[2024-04-20 13:35:17,059: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.003421145821496295]
[2024-04-20 13:35:17,723: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.005746664712126472]
[2024-04-20 13:35:18,401: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.004757644405684293]
[2024-04-20 13:35:19,083: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.013608564511385497]
[2024-04-20 13:35:19,745: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.0007317015871165827]
[2024-04-20 13:35:20,402: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.00010350654465764008]
[2024-04-20 13:35:21,060: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.004144003031997239]
[2024-04-20 13:35:21,713: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.008922357679773207]
[2024-04-20 13:35:22,366: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.0019194283781962718]
[2024-04-20 13:35:23,018: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.0051538207835956475]
[2024-04-20 13:35:23,670: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.0034729225271393845]
[2024-04-20 13:35:24,321: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.0029090275313837046]
[2024-04-20 13:35:24,976: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.011009688963938571]
[2024-04-20 13:35:25,627: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.0024233692525668852]
[2024-04-20 13:35:26,280: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.0049786995698806735]
[2024-04-20 13:35:26,934: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.0017766278549522189]
[2024-04-20 13:35:27,589: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.0031800985033053277]
[2024-04-20 13:35:28,243: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.0013512238863654733]
[2024-04-20 13:35:28,897: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.0007026948091309153]
[2024-04-20 13:35:29,553: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.0025445835526451267]
[2024-04-20 13:35:30,204: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.00041259333951702446]
[2024-04-20 13:35:30,863: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.0017747052817286804]
[2024-04-20 13:35:31,523: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.006786916801634094]
[2024-04-20 13:35:32,178: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.0038001918732237495]
[2024-04-20 13:35:32,838: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.001108566601106474]
[2024-04-20 13:35:33,497: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.010897472321951705]
[2024-04-20 13:35:34,146: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.005636969801382616]
[2024-04-20 13:35:34,797: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.009213710567678625]
[2024-04-20 13:35:35,451: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.0029295161890554302]
[2024-04-20 13:35:36,104: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.0013238917456578929]
[2024-04-20 13:35:36,756: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.0005674136136311092]
[2024-04-20 13:35:37,409: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.006427395551080311]
[2024-04-20 13:35:38,062: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.0034552148297773426]
[2024-04-20 13:35:38,717: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.0012333427274867927]
[2024-04-20 13:35:39,367: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.014482062197499814]
[2024-04-20 13:35:40,023: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.003658709346052044]
[2024-04-20 13:35:40,677: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.004986580091004967]
[2024-04-20 13:35:41,332: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.0014514303796855884]
[2024-04-20 13:35:41,982: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.008793734932307933]
[2024-04-20 13:35:42,635: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.0073043318604909925]
[2024-04-20 13:35:43,288: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.007136705819744248]
[2024-04-20 13:35:43,947: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.0006022916419865624]
[2024-04-20 13:35:44,609: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.006744085504361895]
[2024-04-20 13:35:45,271: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.01922629133589944]
[2024-04-20 13:35:45,937: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.004867862969368438]
[2024-04-20 13:35:46,601: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.004119976774623785]
[2024-04-20 13:35:47,257: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.002162488688068383]
[2024-04-20 13:35:47,911: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.002240111420025852]
[2024-04-20 13:35:48,568: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.0016422944515564254]
[2024-04-20 13:35:49,224: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.006459737158622533]
[2024-04-20 13:35:49,876: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.007677728442733704]
[2024-04-20 13:35:50,525: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.01049559556715254]
[2024-04-20 13:35:51,179: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.000520904866788682]
[2024-04-20 13:35:51,832: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.0023121073818701773]
[2024-04-20 13:35:52,489: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.01666559069080636]
[2024-04-20 13:35:53,140: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.010269061288560463]
[2024-04-20 13:35:53,794: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.003935283788145153]
[2024-04-20 13:35:54,446: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.001961953389467957]
[2024-04-20 13:35:55,104: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.009532113651945362]
[2024-04-20 13:35:55,762: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.004582492144387564]
[2024-04-20 13:35:56,418: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.005391838730454247]
[2024-04-20 13:35:57,077: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.0009334206065674648]
[2024-04-20 13:35:57,742: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.0020027638288896933]
[2024-04-20 13:35:58,409: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.00620123782762463]
[2024-04-20 13:35:59,069: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.002076668192144858]
[2024-04-20 13:35:59,740: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.007338582021169031]
[2024-04-20 13:36:00,399: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.01294583458165907]
[2024-04-20 13:36:01,052: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.005057985342285219]
[2024-04-20 13:36:01,703: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.008745678456601463]
[2024-04-20 13:36:02,357: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.02224216469197556]
[2024-04-20 13:36:03,010: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.005108919678269231]
[2024-04-20 13:36:03,665: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.0029384145555703643]
[2024-04-20 13:36:04,315: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.0030009241788936346]
[2024-04-20 13:36:04,965: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.0030985591041437634]
[2024-04-20 13:36:05,621: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.00250677146061513]
[2024-04-20 13:36:06,274: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.01279231314725904]
[2024-04-20 13:36:06,937: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.0017284239367627025]
[2024-04-20 13:36:07,592: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.007478524244366768]
[2024-04-20 13:36:08,245: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.0021511415878080697]
[2024-04-20 13:36:08,897: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.002982021404039105]
[2024-04-20 13:36:09,553: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.006764605504904097]
[2024-04-20 13:36:10,220: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.003867198648475051]
[2024-04-20 13:36:10,881: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.003184821636605364]
[2024-04-20 13:36:11,544: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.010160883760241263]
[2024-04-20 13:36:12,206: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.0028794452606234434]
[2024-04-20 13:36:12,874: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.009410755894971154]
[2024-04-20 13:36:13,557: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.007022330479924019]
[2024-04-20 13:36:14,235: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.008194842239036635]
[2024-04-20 13:36:14,893: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.0003254258161396981]
[2024-04-20 13:36:15,563: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.0006181528609790699]
[2024-04-20 13:36:16,228: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.005816034270386822]
[2024-04-20 13:36:16,878: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.009110369560257507]
[2024-04-20 13:36:17,530: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.008049952860727282]
[2024-04-20 13:36:18,187: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.0008390438985265327]
[2024-04-20 13:36:18,844: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.0039999135940347015]
[2024-04-20 13:36:19,501: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.01235004141366571]
[2024-04-20 13:36:20,154: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.01452302856063197]
[2024-04-20 13:36:20,811: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.004085114296649555]
[2024-04-20 13:36:21,468: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.0048481345895127915]
[2024-04-20 13:36:22,124: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.0031503102921259097]
[2024-04-20 13:36:22,774: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.005286657651049824]
[2024-04-20 13:36:23,425: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.0015978141875668732]
[2024-04-20 13:36:24,096: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.0016126309953950597]
[2024-04-20 13:36:24,764: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.006716519356478033]
[2024-04-20 13:36:25,424: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.013048809447147133]
[2024-04-20 13:36:26,082: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.0064457444935036275]
[2024-04-20 13:36:26,748: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.0017911034625701723]
[2024-04-20 13:36:27,402: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.011463874443165878]
[2024-04-20 13:36:28,055: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.0010571914129368686]
[2024-04-20 13:36:28,707: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.005172110311713061]
[2024-04-20 13:36:29,363: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.001264398626121914]
[2024-04-20 13:36:30,019: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.005718144060139824]
[2024-04-20 13:36:30,672: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.001957770330460836]
[2024-04-20 13:36:31,327: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.006709868381306898]
[2024-04-20 13:36:31,980: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.004523984733315862]
[2024-04-20 13:36:32,639: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.006987114877025758]
[2024-04-20 13:36:33,292: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.01216099895160259]
[2024-04-20 13:36:33,957: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.0029509221135845054]
[2024-04-20 13:36:34,614: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.0013045241161139677]
[2024-04-20 13:36:35,260: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.0007401512272011595]
[2024-04-20 13:36:35,914: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.004792705666758756]
[2024-04-20 13:36:36,571: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.012557956968100156]
[2024-04-20 13:36:37,232: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.0008790262144608817]
[2024-04-20 13:36:37,902: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.007499516120535796]
[2024-04-20 13:36:38,574: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.0020334807295415117]
[2024-04-20 13:36:39,242: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.004130420506025938]
[2024-04-20 13:36:39,900: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.014250538713723216]
[2024-04-20 13:36:40,559: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.0021877518025713986]
[2024-04-20 13:36:41,210: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.00321873303029502]
[2024-04-20 13:36:41,867: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.0009387319549089416]
[2024-04-20 13:36:42,530: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.002999789150373701]
[2024-04-20 13:36:43,185: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.0024636242752446302]
[2024-04-20 13:36:43,838: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.004467215549239205]
[2024-04-20 13:36:44,495: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.0031882451500015734]
[2024-04-20 13:36:45,153: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.0017215171470490638]
[2024-04-20 13:36:45,807: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.004526415494461491]
[2024-04-20 13:36:46,464: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.00180557842770132]
[2024-04-20 13:36:47,116: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.0027978745789533277]
[2024-04-20 13:36:47,769: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.001955446066873611]
[2024-04-20 13:36:48,423: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.0017347808517365322]
[2024-04-20 13:36:49,076: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.011365301545184938]
[2024-04-20 13:36:49,735: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.002968067684612125]
[2024-04-20 13:36:50,406: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.007757993071336513]
[2024-04-20 13:36:51,078: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.014633219701144095]
[2024-04-20 13:36:51,750: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.0031710226712866963]
[2024-04-20 13:36:52,415: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.0034391234198201445]
[2024-04-20 13:36:53,069: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.002759409390299224]
[2024-04-20 13:36:53,729: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.0012683688549946363]
[2024-04-20 13:36:54,382: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.006255167172951444]
[2024-04-20 13:36:55,036: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.0006801780597559181]
[2024-04-20 13:36:55,692: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.0013356519178975657]
[2024-04-20 13:36:56,351: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.008080356152936013]
[2024-04-20 13:36:57,009: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.011262761990852655]
[2024-04-20 13:36:57,667: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.01456918966839314]
[2024-04-20 13:36:58,321: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.0037630515559880823]
[2024-04-20 13:36:58,975: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.003519713155499969]
[2024-04-20 13:36:59,633: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.006839245913105097]
[2024-04-20 13:37:00,290: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.0113077503038785]
[2024-04-20 13:37:00,952: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.000954377734252927]
[2024-04-20 13:37:01,605: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.005739008283606195]
[2024-04-20 13:37:02,261: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.0023230404052102054]
[2024-04-20 13:37:02,921: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.014309746996848813]
[2024-04-20 13:37:03,585: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.00508227200766907]
[2024-04-20 13:37:04,251: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.0012907549844264345]
[2024-04-20 13:37:04,916: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.00896986790978841]
[2024-04-20 13:37:05,584: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.0021084192900815506]
[2024-04-20 13:37:06,251: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.011684292490552285]
[2024-04-20 13:37:06,907: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.00039220465930005395]
[2024-04-20 13:37:07,563: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.003063345235357591]
[2024-04-20 13:37:08,215: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.0019095851432751345]
[2024-04-20 13:37:08,870: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.006027599462364096]
[2024-04-20 13:37:09,525: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.012183831609554188]
[2024-04-20 13:37:10,177: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.0027690390827768297]
[2024-04-20 13:37:10,831: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.00676616013931044]
[2024-04-20 13:37:11,483: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.0009453024455860239]
[2024-04-20 13:37:12,137: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.0014348918461005427]
[2024-04-20 13:37:12,789: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.005030502393254154]
[2024-04-20 13:37:13,446: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.009426844322826542]
[2024-04-20 13:37:14,104: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.012171464361542138]
[2024-04-20 13:37:14,753: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.01567765975721352]
[2024-04-20 13:37:15,404: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.007076178177718129]
[2024-04-20 13:37:16,059: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.0072416849168848475]
[2024-04-20 13:37:16,735: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.007207838440601141]
[2024-04-20 13:37:17,401: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.0004952798099986997]
[2024-04-20 13:37:18,059: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.008650116769787651]
[2024-04-20 13:37:18,722: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.001129841662263]
[2024-04-20 13:37:19,384: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.0046726084315922515]
[2024-04-20 13:37:20,037: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.00704620144874141]
[2024-04-20 13:37:20,693: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.010103404595498213]
[2024-04-20 13:37:21,344: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.0012482034750520093]
[2024-04-20 13:37:21,999: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.0039108599044028365]
[2024-04-20 13:37:22,654: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.004035838178106655]
[2024-04-20 13:37:23,311: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.002864268679399935]
[2024-04-20 13:37:23,967: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.0015911812750903228]
[2024-04-20 13:37:24,625: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.0058557493454104576]
[2024-04-20 13:37:25,281: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.0013283540911779414]
[2024-04-20 13:37:25,938: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.0009989954849592415]
[2024-04-20 13:37:26,592: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.015242833220646674]
[2024-04-20 13:37:27,250: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.014444452512264692]
[2024-04-20 13:37:27,908: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.010192734509464828]
[2024-04-20 13:37:28,566: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.017944080107078795]
[2024-04-20 13:37:29,224: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.0011510053909083082]
[2024-04-20 13:37:29,895: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.004855244715159691]
[2024-04-20 13:37:30,563: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.03224443248879038]
[2024-04-20 13:37:31,227: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.0016875562777776154]
[2024-04-20 13:37:31,887: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.011068701948643178]
[2024-04-20 13:37:32,544: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.0066530337693246275]
[2024-04-20 13:37:33,203: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.012711687781957035]
[2024-04-20 13:37:33,857: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.008307781687384542]
[2024-04-20 13:37:34,516: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.0014720374029491936]
[2024-04-20 13:37:35,171: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.006953618798887857]
[2024-04-20 13:37:35,825: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.007811439925141663]
[2024-04-20 13:37:36,481: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.001987525552948404]
[2024-04-20 13:37:37,136: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.0018744111136784064]
[2024-04-20 13:37:37,787: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.012223880426219715]
[2024-04-20 13:37:38,442: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.001062630717545004]
[2024-04-20 13:37:39,100: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.011904701212867543]
[2024-04-20 13:37:39,751: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.0037771594496733957]
[2024-04-20 13:37:40,406: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.005865102060243411]
[2024-04-20 13:37:41,065: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.004096770501682619]
[2024-04-20 13:37:41,720: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.0023657844048234522]
[2024-04-20 13:37:42,375: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.002661942788948513]
[2024-04-20 13:37:43,042: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.01305462190236959]
[2024-04-20 13:37:43,709: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.008696549569781435]
[2024-04-20 13:37:44,375: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.020644073853087575]
[2024-04-20 13:37:45,039: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.008564191445139023]
[2024-04-20 13:37:45,704: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.006497584934713057]
[2024-04-20 13:37:46,362: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.007884256091661473]
[2024-04-20 13:37:47,019: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.0023962319308104964]
[2024-04-20 13:37:47,680: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.0018465388081613356]
[2024-04-20 13:37:48,337: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.003540381004232914]
[2024-04-20 13:37:48,998: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.0018005963711323397]
[2024-04-20 13:37:49,654: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.00022169752751375553]
[2024-04-20 13:37:50,314: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.0013765824818462687]
[2024-04-20 13:37:50,969: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.0025524043955748696]
[2024-04-20 13:37:51,629: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 0.0004877023591035751]
[2024-04-20 13:37:52,286: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.0018991270469015812]
[2024-04-20 13:37:52,946: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.009462170117981252]
[2024-04-20 13:37:53,609: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.00021905977932676915]
[2024-04-20 13:37:54,268: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.006119232458825879]
[2024-04-20 13:37:54,927: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.0034904052973144836]
[2024-04-20 13:37:55,587: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.03728022480476256]
[2024-04-20 13:37:56,254: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.00192260758373376]
[2024-04-20 13:37:56,918: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.004735333713832866]
[2024-04-20 13:37:57,585: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.002144334507693901]
[2024-04-20 13:37:58,255: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.016609795471967278]
[2024-04-20 13:37:58,918: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.009661897409535146]
[2024-04-20 13:37:59,582: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.0015100131070238756]
[2024-04-20 13:38:00,243: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.028712316266854103]
[2024-04-20 13:38:00,902: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.003812456353349552]
[2024-04-20 13:38:01,560: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.0052801067788783495]
[2024-04-20 13:38:02,218: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.004401488473059012]
[2024-04-20 13:38:02,878: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.002838641911139739]
[2024-04-20 13:38:03,541: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.005427272041102674]
[2024-04-20 13:38:04,198: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.004429990406718139]
[2024-04-20 13:38:04,853: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.006732277626097731]
[2024-04-20 13:38:05,510: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.0003386503381375698]
[2024-04-20 13:38:06,175: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.002701669316849946]
[2024-04-20 13:38:06,831: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.0023043632414488247]
[2024-04-20 13:38:07,490: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.004130447997774632]
[2024-04-20 13:38:08,145: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.002859645981193882]
[2024-04-20 13:38:08,804: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.005513671681633517]
[2024-04-20 13:38:09,469: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.011247878269647146]
[2024-04-20 13:38:10,140: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.011523821542427808]
[2024-04-20 13:38:10,805: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.012810962739816564]
[2024-04-20 13:38:11,475: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.006962182873033254]
[2024-04-20 13:38:12,136: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.014250155139313164]
[2024-04-20 13:38:12,794: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.0004907083268832062]
[2024-04-20 13:38:13,448: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.004649235856520068]
[2024-04-20 13:38:14,105: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.005082805182393733]
[2024-04-20 13:38:14,759: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.03847445183787541]
[2024-04-20 13:38:15,415: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.007088925680803485]
[2024-04-20 13:38:16,072: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.00022398416797627632]
[2024-04-20 13:38:16,731: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.007069523791313542]
[2024-04-20 13:38:17,388: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.0007236655654311882]
[2024-04-20 13:38:18,046: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.021497736315222823]
[2024-04-20 13:38:18,703: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.00567776057914182]
[2024-04-20 13:38:19,361: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.0029557592522355004]
[2024-04-20 13:38:20,018: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.0034829381605916833]
[2024-04-20 13:38:20,681: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.004793117368209182]
[2024-04-20 13:38:21,337: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.0013266658236649655]
[2024-04-20 13:38:21,991: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.004426161865419485]
[2024-04-20 13:38:22,665: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.004714406323135496]
[2024-04-20 13:38:23,330: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.00540029686159331]
[2024-04-20 13:38:23,998: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.00319311100920546]
[2024-04-20 13:38:24,673: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.007399875542229343]
[2024-04-20 13:38:25,331: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.0008337221042311111]
[2024-04-20 13:38:25,988: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.010647583822944794]
[2024-04-20 13:38:26,640: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.010297305846715246]
[2024-04-20 13:38:27,294: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.0009249741379199319]
[2024-04-20 13:38:27,947: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.005330880932531869]
[2024-04-20 13:38:28,602: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.0029675206935894805]
[2024-04-20 13:38:29,258: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.009500910528022218]
[2024-04-20 13:38:29,914: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.013045335898252465]
[2024-04-20 13:38:30,564: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.0037912182503853347]
[2024-04-20 13:38:31,215: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.008851450230672905]
[2024-04-20 13:38:31,868: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.0015358668746118167]
[2024-04-20 13:38:32,526: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.0029793185109238244]
[2024-04-20 13:38:33,176: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.0083460061484345]
[2024-04-20 13:38:33,828: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.004526545967813872]
[2024-04-20 13:38:34,478: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.008552771412846664]
[2024-04-20 13:38:35,131: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.00519784149621076]
[2024-04-20 13:38:35,793: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.010638192940802557]
[2024-04-20 13:38:36,456: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.0039017603482002943]
[2024-04-20 13:38:37,117: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.004980457084475401]
[2024-04-20 13:38:37,779: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.003194124760722574]
[2024-04-20 13:38:38,446: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.0011290918758114254]
[2024-04-20 13:38:39,102: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.014609414363171418]
[2024-04-20 13:38:39,754: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.003894034060632071]
[2024-04-20 13:38:40,407: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.004139665887169114]
[2024-04-20 13:38:41,057: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.0010628800249310188]
[2024-04-20 13:38:41,707: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.013095729800385281]
[2024-04-20 13:38:42,359: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.002476646128176374]
[2024-04-20 13:38:43,011: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.002330991660104221]
[2024-04-20 13:38:43,663: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.0027257542290744625]
[2024-04-20 13:38:44,307: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.0034829239693460403]
[2024-04-20 13:38:44,962: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.008202674909686392]
[2024-04-20 13:38:45,616: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.0017576011099224881]
[2024-04-20 13:38:46,267: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.0003715197694666124]
[2024-04-20 13:38:46,918: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.0016805067990244822]
[2024-04-20 13:38:47,571: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.005462954987060076]
[2024-04-20 13:38:48,218: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.012373495294451592]
[2024-04-20 13:38:48,883: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.014943019539969592]
[2024-04-20 13:38:49,544: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.005694088300365259]
[2024-04-20 13:38:50,201: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.004541973512617933]
[2024-04-20 13:38:50,867: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.00538377356460066]
[2024-04-20 13:38:51,524: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.01937536555671689]
[2024-04-20 13:38:52,175: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.007096786465081834]
[2024-04-20 13:38:52,828: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.018635256817505032]
[2024-04-20 13:38:53,482: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.0034352753840926277]
[2024-04-20 13:38:54,132: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.007324942573865765]
[2024-04-20 13:38:54,785: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.005709042438443096]
[2024-04-20 13:38:55,436: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.004316019893882301]
[2024-04-20 13:38:56,091: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.006703930388091424]
[2024-04-20 13:38:56,741: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.0021277720113966523]
[2024-04-20 13:38:57,395: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.0013778472097808702]
[2024-04-20 13:38:58,048: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.0011633350533349096]
[2024-04-20 13:38:58,704: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.01874557835564225]
[2024-04-20 13:38:59,358: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.009508671125117529]
[2024-04-20 13:39:00,011: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.004731634669470603]
[2024-04-20 13:39:00,663: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.0012012333063594906]
[2024-04-20 13:39:01,320: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.005041968958304119]
[2024-04-20 13:39:01,982: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.009149188703376276]
[2024-04-20 13:39:02,645: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.0029319861393157136]
[2024-04-20 13:39:03,318: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.006230226625189034]
[2024-04-20 13:39:03,983: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.005396456128976818]
[2024-04-20 13:39:04,641: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.007524450865645955]
[2024-04-20 13:39:05,297: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.0027646224103545854]
[2024-04-20 13:39:05,943: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.0019853005320256824]
[2024-04-20 13:39:06,597: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.004459357967766582]
[2024-04-20 13:39:07,249: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.011909936586088602]
[2024-04-20 13:39:07,900: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.008714407007547685]
[2024-04-20 13:39:08,556: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.003723863773392496]
[2024-04-20 13:39:09,208: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.005615162395682234]
[2024-04-20 13:39:09,861: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.006031614634650054]
[2024-04-20 13:39:10,511: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.003563346094696764]
[2024-04-20 13:39:11,166: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.015140156100747457]
[2024-04-20 13:39:11,815: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.0047811054978276]
[2024-04-20 13:39:12,465: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.007816726953533719]
[2024-04-20 13:39:13,118: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.0037306899764686188]
[2024-04-20 13:39:13,773: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.0033043557944505758]
[2024-04-20 13:39:14,424: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.0025466562113483377]
[2024-04-20 13:39:15,099: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.007400759311708351]
[2024-04-20 13:39:15,778: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.0004443994238787475]
[2024-04-20 13:39:16,441: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.014299714275560862]
[2024-04-20 13:39:17,096: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.010710432224836914]
[2024-04-20 13:39:17,758: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.014549415703919863]
[2024-04-20 13:39:18,412: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.0038104866751077593]
[2024-04-20 13:39:19,061: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.0067700356040828885]
[2024-04-20 13:39:19,711: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.011343308149090466]
[2024-04-20 13:39:20,366: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.0021725493002168745]
[2024-04-20 13:39:21,019: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.02256613683837227]
[2024-04-20 13:39:21,673: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.012165932884447707]
[2024-04-20 13:39:22,322: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.0023855659754396055]
[2024-04-20 13:39:22,976: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.0006808149959167308]
[2024-04-20 13:39:23,630: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.00347706429997911]
[2024-04-20 13:39:24,282: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.001173672882366943]
[2024-04-20 13:39:24,937: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.002422943662524548]
[2024-04-20 13:39:25,595: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.007916893532687656]
[2024-04-20 13:39:26,251: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.004099587126985131]
[2024-04-20 13:39:26,906: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.008234361180667537]
[2024-04-20 13:39:27,565: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.007964870265738196]
[2024-04-20 13:39:28,234: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.004320201975155819]
[2024-04-20 13:39:28,902: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.002295067674691161]
[2024-04-20 13:39:29,565: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.010543412295764417]
[2024-04-20 13:39:30,241: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.003775341820224056]
[2024-04-20 13:39:30,908: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.00810100628088155]
[2024-04-20 13:39:31,561: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.0032637092274181885]
[2024-04-20 13:39:32,212: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.0061032300814605955]
[2024-04-20 13:39:32,870: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.003199343332411722]
[2024-04-20 13:39:33,525: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.0003303591947838822]
[2024-04-20 13:39:34,186: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.01185610036466147]
[2024-04-20 13:39:34,852: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.007312055739188758]
[2024-04-20 13:39:35,535: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.002907488377436729]
[2024-04-20 13:39:36,205: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.016094358540006272]
[2024-04-20 13:39:36,869: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.0023204742094104992]
[2024-04-20 13:39:37,533: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.004643171945292622]
[2024-04-20 13:39:38,198: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.04384039579325259]
[2024-04-20 13:39:38,856: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.001387939544740846]
[2024-04-20 13:39:39,515: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.006976247726261378]
[2024-04-20 13:39:40,168: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.006411767349748174]
[2024-04-20 13:39:40,831: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.010693766798950337]
[2024-04-20 13:39:41,496: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.0071217234962425635]
[2024-04-20 13:39:42,169: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.004119325846628951]
[2024-04-20 13:39:42,830: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.00689218243392216]
[2024-04-20 13:39:43,503: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.006601370251643584]
[2024-04-20 13:39:44,162: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.0009143614846381214]
[2024-04-20 13:39:44,817: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.00735804541301745]
[2024-04-20 13:39:45,470: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.0021903301749486817]
[2024-04-20 13:39:46,126: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.008983217492584643]
[2024-04-20 13:39:46,787: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.0018814296146212463]
[2024-04-20 13:39:47,442: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.0038231004059423057]
[2024-04-20 13:39:48,102: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.01729463915154262]
[2024-04-20 13:39:48,759: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.013950682951353916]
[2024-04-20 13:39:49,418: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.018697422976759852]
[2024-04-20 13:39:50,078: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.010331449610983418]
[2024-04-20 13:39:50,732: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.0038071988853803033]
[2024-04-20 13:39:51,393: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.003348213547931205]
[2024-04-20 13:39:52,049: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.0007547702529108631]
[2024-04-20 13:39:52,707: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.0028391047447791687]
[2024-04-20 13:39:53,362: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.0030604143528604566]
[2024-04-20 13:39:54,023: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.002692969226507184]
[2024-04-20 13:39:54,684: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.007602782254408808]
[2024-04-20 13:39:55,345: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.009229219079023557]
[2024-04-20 13:39:56,009: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.010128416467191313]
[2024-04-20 13:39:56,676: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.003520558592061388]
[2024-04-20 13:39:57,338: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.007790806113611739]
[2024-04-20 13:39:57,992: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.00023097544004289935]
[2024-04-20 13:39:58,649: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.0033234022234418736]
[2024-04-20 13:39:59,301: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.0033501620333252664]
[2024-04-20 13:39:59,955: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.0013685947439583718]
[2024-04-20 13:40:00,610: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.005416133737013246]
[2024-04-20 13:40:01,267: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.004125415682970006]
[2024-04-20 13:40:01,920: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.0020609975315531784]
[2024-04-20 13:40:02,577: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.007728616903120807]
[2024-04-20 13:40:03,234: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.06996680948698347]
[2024-04-20 13:40:03,889: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.0033887421995522594]
[2024-04-20 13:40:04,542: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.0030587612291631985]
[2024-04-20 13:40:05,202: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.004851911366356701]
[2024-04-20 13:40:05,860: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.022719631863996736]
[2024-04-20 13:40:06,514: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.006061399001969051]
[2024-04-20 13:40:07,172: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.009200047668604185]
[2024-04-20 13:40:07,847: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.004258869404253241]
[2024-04-20 13:40:08,514: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.0026607601229199926]
[2024-04-20 13:40:09,174: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.0026173679076819745]
[2024-04-20 13:40:09,847: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.011958893673828226]
[2024-04-20 13:40:10,511: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.016268520629760523]
[2024-04-20 13:40:11,166: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.003107750500007749]
[2024-04-20 13:40:11,821: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.0035628580669776664]
[2024-04-20 13:40:12,474: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.004236451226268501]
[2024-04-20 13:40:13,132: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.0067834311680350185]
[2024-04-20 13:40:13,785: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.0019521497425770207]
[2024-04-20 13:40:14,435: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.0027044128340762193]
[2024-04-20 13:40:15,091: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.0017875028792759542]
[2024-04-20 13:40:15,744: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.0067069241904599555]
[2024-04-20 13:40:16,400: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.003920885388893445]
[2024-04-20 13:40:17,057: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.007881405152651257]
[2024-04-20 13:40:17,709: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.00954184050076496]
[2024-04-20 13:40:18,362: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.002580207127013695]
[2024-04-20 13:40:19,012: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.007083725297202237]
[2024-04-20 13:40:19,668: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.0041275192107514975]
[2024-04-20 13:40:20,324: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.004899939460218959]
[2024-04-20 13:40:20,992: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.011432489847068636]
[2024-04-20 13:40:21,656: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.00153271762427337]
[2024-04-20 13:40:22,323: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.00192751557265444]
[2024-04-20 13:40:22,986: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.004887091355749415]
[2024-04-20 13:40:23,646: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.014049770625833973]
[2024-04-20 13:40:24,303: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.005645733871477104]
[2024-04-20 13:40:24,958: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.02535648537634561]
[2024-04-20 13:40:25,613: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.025177657001848083]
[2024-04-20 13:40:26,271: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.0024727708935240304]
[2024-04-20 13:40:26,928: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.0032087046919025333]
[2024-04-20 13:40:27,583: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.004748406847748494]
[2024-04-20 13:40:28,238: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.002139763322864104]
[2024-04-20 13:40:28,889: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.005866690208368751]
[2024-04-20 13:40:29,543: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.0028130314913916914]
[2024-04-20 13:40:30,195: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.007383289718319921]
[2024-04-20 13:40:30,852: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.011111674417272007]
[2024-04-20 13:40:31,503: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.006237480901583634]
[2024-04-20 13:40:32,160: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.003217053400351414]
[2024-04-20 13:40:32,811: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.007915904843257214]
[2024-04-20 13:40:33,476: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.02495687575982932]
[2024-04-20 13:40:34,142: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.007335169561296418]
[2024-04-20 13:40:34,803: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.0023953207382769424]
[2024-04-20 13:40:35,463: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.004680824669027429]
[2024-04-20 13:40:36,129: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.0016261933619740412]
[2024-04-20 13:40:36,792: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.003447250339920879]
[2024-04-20 13:40:37,448: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.000495266351814494]
[2024-04-20 13:40:38,105: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.0030968590118150632]
[2024-04-20 13:40:38,761: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.0015742510206726485]
[2024-04-20 13:40:39,417: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.0042628696278565435]
[2024-04-20 13:40:40,074: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.002676591707929209]
[2024-04-20 13:40:40,726: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.007105527350297303]
[2024-04-20 13:40:41,381: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.0025059743946088653]
[2024-04-20 13:40:42,034: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.004729978077519346]
[2024-04-20 13:40:42,689: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.001552762462379167]
[2024-04-20 13:40:43,340: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.0029100049899846467]
[2024-04-20 13:40:43,996: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.01742148722753587]
[2024-04-20 13:40:44,647: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.0011781739161880061]
[2024-04-20 13:40:45,312: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.002644745648969287]
[2024-04-20 13:40:45,967: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.003564814434147614]
[2024-04-20 13:40:46,622: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.01258488058293602]
[2024-04-20 13:40:47,285: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.001042940617904945]
[2024-04-20 13:40:47,955: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.0075551764948282845]
[2024-04-20 13:40:48,630: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.004504098577909589]
[2024-04-20 13:40:49,307: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.0018768722151822155]
[2024-04-20 13:40:49,958: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.001955131288822528]
[2024-04-20 13:40:50,620: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.0028532044074624304]
[2024-04-20 13:40:51,272: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.0017511973342620526]
[2024-04-20 13:40:51,930: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.0018970579206369893]
[2024-04-20 13:40:52,588: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.002273589364370931]
[2024-04-20 13:40:53,245: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.012271854926410728]
[2024-04-20 13:40:53,900: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.0023857371346737884]
[2024-04-20 13:40:54,557: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.011225453720561296]
[2024-04-20 13:40:55,212: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.013411055555673287]
[2024-04-20 13:40:55,863: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.001684310250264906]
[2024-04-20 13:40:56,517: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.010152491386572187]
[2024-04-20 13:40:57,168: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.00771295549530185]
[2024-04-20 13:40:57,819: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.009021471627941575]
[2024-04-20 13:40:58,474: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.001243731506047433]
[2024-04-20 13:40:59,125: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.01528385808263072]
[2024-04-20 13:40:59,781: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.0013798424979085601]
[2024-04-20 13:41:00,440: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.0031289802683222836]
[2024-04-20 13:41:01,099: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.002256475370891071]
[2024-04-20 13:41:01,763: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.00807222625635101]
[2024-04-20 13:41:02,420: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.01108584685114679]
[2024-04-20 13:41:03,088: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.0030060277276250874]
[2024-04-20 13:41:03,741: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.007572503471922742]
[2024-04-20 13:41:04,396: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.008459580209017444]
[2024-04-20 13:41:05,042: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.005641144840925548]
[2024-04-20 13:41:05,697: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.0011624982835573077]
[2024-04-20 13:41:06,352: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.0007790480175236198]
[2024-04-20 13:41:07,009: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.025644517703750123]
[2024-04-20 13:41:07,660: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.005395622942623817]
[2024-04-20 13:41:08,311: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.005301478395836948]
[2024-04-20 13:41:08,965: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.010328624543168392]
[2024-04-20 13:41:09,619: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.004939159137703174]
[2024-04-20 13:41:10,271: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.002337509523323927]
[2024-04-20 13:41:10,921: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.0008058638083395319]
[2024-04-20 13:41:11,574: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.014423900586664432]
[2024-04-20 13:41:12,231: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.001139040467315508]
[2024-04-20 13:41:12,882: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.0038314332820833753]
[2024-04-20 13:41:13,544: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.003109919649994112]
[2024-04-20 13:41:14,206: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.014003339162451691]
[2024-04-20 13:41:14,868: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.004539048980743922]
[2024-04-20 13:41:15,528: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.0005543477098595775]
[2024-04-20 13:41:16,192: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.002297595831963167]
[2024-04-20 13:41:16,846: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.002530128442144207]
[2024-04-20 13:41:17,495: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.004856732869564385]
[2024-04-20 13:41:18,144: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.001584211777787185]
[2024-04-20 13:41:18,793: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.001514749097296758]
[2024-04-20 13:41:19,449: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.011423839225216496]
[2024-04-20 13:41:20,103: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.0035505039938014673]
[2024-04-20 13:41:20,756: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.0024307717667296264]
[2024-04-20 13:41:21,410: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.011528107559282894]
[2024-04-20 13:41:22,067: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.01034791401495085]
[2024-04-20 13:41:22,720: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.011414281277878609]
[2024-04-20 13:41:23,378: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.004450719629371619]
[2024-04-20 13:41:24,032: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.005096791629813867]
[2024-04-20 13:41:24,684: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.018382989296391757]
[2024-04-20 13:41:25,336: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.01884122595206479]
[2024-04-20 13:41:25,990: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.005043628524107337]
[2024-04-20 13:41:26,653: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.008388687900155824]
[2024-04-20 13:41:27,312: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.007296651165665069]
[2024-04-20 13:41:27,982: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.010022560241027625]
[2024-04-20 13:41:28,652: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.010776175613646492]
[2024-04-20 13:41:29,319: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.003714273251807272]
[2024-04-20 13:41:29,976: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.00673607062810691]
[2024-04-20 13:41:30,628: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.0009744170678531435]
[2024-04-20 13:41:31,283: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.0052595274695764185]
[2024-04-20 13:41:31,940: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.004004276424905619]
[2024-04-20 13:41:32,601: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.014178977467177079]
[2024-04-20 13:41:33,253: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.00402773586318863]
[2024-04-20 13:41:33,917: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.004232651851658891]
[2024-04-20 13:41:34,579: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.004623874908632809]
[2024-04-20 13:41:35,240: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.00321894477823657]
[2024-04-20 13:41:35,898: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.0004756052437003551]
[2024-04-20 13:41:36,549: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.013222248083900962]
[2024-04-20 13:41:37,209: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.0002584051962836419]
[2024-04-20 13:41:37,864: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.005308880062576177]
[2024-04-20 13:41:38,523: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.0015027732589739725]
[2024-04-20 13:41:39,173: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.006792189899577894]
[2024-04-20 13:41:39,841: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.006167956637249811]
[2024-04-20 13:41:40,505: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.010463839620324945]
[2024-04-20 13:41:41,165: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.003984224947038555]
[2024-04-20 13:41:41,830: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.009162204290770465]
[2024-04-20 13:41:42,503: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.005837056182063341]
[2024-04-20 13:41:43,156: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.010167006634088847]
[2024-04-20 13:41:43,811: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.00527650906441363]
[2024-04-20 13:41:44,462: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.0030310247124865543]
[2024-04-20 13:41:45,113: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.015673043137486808]
[2024-04-20 13:41:45,768: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.0033642871372936613]
[2024-04-20 13:41:46,426: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.0034857649809338967]
[2024-04-20 13:41:47,076: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.025540136793794965]
[2024-04-20 13:41:47,725: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.003263422796603054]
[2024-04-20 13:41:48,376: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.0032309207599920935]
[2024-04-20 13:41:49,031: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.010777630592572588]
[2024-04-20 13:41:49,684: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.009240133442600457]
[2024-04-20 13:41:50,340: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.009553735019629583]
[2024-04-20 13:41:50,991: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.004329272527138398]
[2024-04-20 13:41:51,644: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.02295678930823296]
[2024-04-20 13:41:52,299: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.016826302378485054]
[2024-04-20 13:41:52,959: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.007194043629407807]
[2024-04-20 13:41:53,629: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.007736985047130703]
[2024-04-20 13:41:54,293: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.009323638463776167]
[2024-04-20 13:41:54,951: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.0020420490993684256]
[2024-04-20 13:41:55,610: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.005200423268026361]
[2024-04-20 13:41:56,265: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.017150892280765506]
[2024-04-20 13:41:56,919: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.003672211085311124]
[2024-04-20 13:41:57,578: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.003622757307776758]
[2024-04-20 13:41:58,233: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.007466512006351104]
[2024-04-20 13:41:58,900: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.0067049047246631336]
[2024-04-20 13:41:59,561: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.020106809106627672]
[2024-04-20 13:42:00,214: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.012295579141825495]
[2024-04-20 13:42:00,872: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.006581467044136922]
[2024-04-20 13:42:01,525: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.005172760750066823]
[2024-04-20 13:42:02,177: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.00461865317439233]
[2024-04-20 13:42:02,832: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.013548749310284746]
[2024-04-20 13:42:03,486: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.00212055762614196]
[2024-04-20 13:42:04,141: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.006847851964521155]
[2024-04-20 13:42:04,798: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.001613162465489355]
[2024-04-20 13:42:05,452: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.013804049977067611]
[2024-04-20 13:42:06,112: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.0040927900132095235]
[2024-04-20 13:42:06,775: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.002215204834415977]
[2024-04-20 13:42:07,444: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.009548266236387635]
[2024-04-20 13:42:08,114: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.003698680405065727]
[2024-04-20 13:42:08,768: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.012011738371465488]
[2024-04-20 13:42:09,428: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.004108434814513034]
[2024-04-20 13:42:10,080: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.0024932735987619045]
[2024-04-20 13:42:10,731: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.012595310724389495]
[2024-04-20 13:42:11,384: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.0373516189725782]
[2024-04-20 13:42:12,039: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.0012326808879249342]
[2024-04-20 13:42:12,695: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.0005170893461126979]
[2024-04-20 13:42:13,351: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.0044735761189126895]
[2024-04-20 13:42:14,004: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.0023911818548975248]
[2024-04-20 13:42:14,664: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.0010450225214262139]
[2024-04-20 13:42:15,316: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.0026871238175789967]
[2024-04-20 13:42:15,975: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.01070596810752068]
[2024-04-20 13:42:16,629: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.0031362469594641]
[2024-04-20 13:42:17,284: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.005276089316062624]
[2024-04-20 13:42:17,938: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.0039036197071531872]
[2024-04-20 13:42:18,591: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.008440742680776802]
[2024-04-20 13:42:19,250: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.0023836161127488717]
[2024-04-20 13:42:19,911: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.0035479653304417266]
[2024-04-20 13:42:20,571: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.004445897902699006]
[2024-04-20 13:42:21,237: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.0034272357368757625]
[2024-04-20 13:42:21,906: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.0019512131645876103]
[2024-04-20 13:42:22,572: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.011720949071840783]
[2024-04-20 13:42:23,231: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.016000940937983966]
[2024-04-20 13:42:23,887: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.0010892104204153405]
[2024-04-20 13:42:24,542: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.001064895806264791]
[2024-04-20 13:42:25,202: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.0010338486780072968]
[2024-04-20 13:42:25,859: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.018539897780898627]
[2024-04-20 13:42:26,516: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.008388344188008419]
[2024-04-20 13:42:27,169: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.006702989836356131]
[2024-04-20 13:42:27,821: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.010862745114593323]
[2024-04-20 13:42:28,486: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.006522753807868644]
[2024-04-20 13:42:29,139: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.014479586753595513]
[2024-04-20 13:42:29,796: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.015320704929224433]
[2024-04-20 13:42:30,452: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.0032398255241505316]
[2024-04-20 13:42:31,109: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.01783526007336802]
[2024-04-20 13:42:31,760: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.0073605497302827285]
[2024-04-20 13:42:32,420: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.006632633070845421]
[2024-04-20 13:42:33,086: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.0031631166574212725]
[2024-04-20 13:42:33,742: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.005637922962005718]
[2024-04-20 13:42:34,403: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.016512961130601963]
[2024-04-20 13:42:35,066: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.0049608598835824596]
[2024-04-20 13:42:35,730: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.004336404050716132]
[2024-04-20 13:42:36,386: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.0022822919348818825]
[2024-04-20 13:42:37,046: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.006420387760608801]
[2024-04-20 13:42:37,703: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.007956750679777176]
[2024-04-20 13:42:38,362: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.0074921786809689335]
[2024-04-20 13:42:39,015: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.003463588449734695]
[2024-04-20 13:42:39,674: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.0172625453713696]
[2024-04-20 13:42:40,327: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.00012818808963611673]
[2024-04-20 13:42:40,980: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.017041141469396136]
[2024-04-20 13:42:41,636: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.011625572062064445]
[2024-04-20 13:42:42,291: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.019479379094272338]
[2024-04-20 13:42:42,945: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.009929775164615715]
[2024-04-20 13:42:43,601: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.0007777262635192961]
[2024-04-20 13:42:44,252: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.007796362587955438]
[2024-04-20 13:42:44,908: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.00233270446740971]
[2024-04-20 13:42:45,567: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.0044529540327926075]
[2024-04-20 13:42:46,231: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.008134948622841002]
[2024-04-20 13:42:46,894: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.004482462381840799]
[2024-04-20 13:42:47,553: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.007535477620889871]
[2024-04-20 13:42:48,217: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.004249477674165091]
[2024-04-20 13:42:48,881: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.0025029815699678737]
[2024-04-20 13:42:49,539: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.0012578923915708485]
[2024-04-20 13:42:50,191: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.0011081341314475867]
[2024-04-20 13:42:50,848: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.0033485732580863406]
[2024-04-20 13:42:51,504: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.004807596052588003]
[2024-04-20 13:42:52,156: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.01010309465602945]
[2024-04-20 13:42:52,814: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.007121152412509395]
[2024-04-20 13:42:53,467: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.005971591340444905]
[2024-04-20 13:42:54,122: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.0034512857622799663]
[2024-04-20 13:42:54,779: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.001143296355576074]
[2024-04-20 13:42:55,430: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.00336639181481323]
[2024-04-20 13:42:56,085: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.008868373067061805]
[2024-04-20 13:42:56,737: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.000790597394772299]
[2024-04-20 13:42:57,393: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.00037728613647030284]
[2024-04-20 13:42:58,045: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.0014717058759649217]
[2024-04-20 13:42:58,701: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.0035306758606407575]
[2024-04-20 13:42:59,373: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.003440584148175854]
[2024-04-20 13:43:00,068: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.004554965697934122]
[2024-04-20 13:43:00,750: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.0007324785737416431]
[2024-04-20 13:43:01,430: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.001734388852705165]
[2024-04-20 13:43:02,104: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.016938551525566586]
[2024-04-20 13:43:02,785: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.006062693323743809]
[2024-04-20 13:43:03,462: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.0022548019967338975]
[2024-04-20 13:43:04,135: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 7.537620971756896e-05]
[2024-04-20 13:43:04,792: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.00040764410602616737]
[2024-04-20 13:43:05,441: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.005676873127051842]
[2024-04-20 13:43:06,100: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.002726585205279995]
[2024-04-20 13:43:06,753: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.007959659169949658]
[2024-04-20 13:43:07,406: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.00011736135201836109]
[2024-04-20 13:43:08,061: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.007424176892544904]
[2024-04-20 13:43:08,716: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.00023373511408532037]
[2024-04-20 13:43:09,374: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.008509254197906008]
[2024-04-20 13:43:10,030: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.006961487332283788]
[2024-04-20 13:43:10,689: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.009974266154605239]
[2024-04-20 13:43:11,345: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.0037982152977065844]
[2024-04-20 13:43:11,999: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.04800286194229658]
[2024-04-20 13:43:12,659: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.007511957269531499]
[2024-04-20 13:43:13,315: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.007518059094521623]
[2024-04-20 13:43:13,970: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.0031476996534436992]
[2024-04-20 13:43:14,632: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.004917117836025607]
[2024-04-20 13:43:15,292: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.008252273505641184]
[2024-04-20 13:43:15,958: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.0016845616315438081]
[2024-04-20 13:43:16,623: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.003523713660756401]
[2024-04-20 13:43:17,298: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.00048749144638480575]
[2024-04-20 13:43:17,956: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.012362672823822798]
[2024-04-20 13:43:18,610: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.004996248990764819]
[2024-04-20 13:43:19,264: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.0017113635212415033]
[2024-04-20 13:43:19,922: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.0032034707422982905]
[2024-04-20 13:43:20,581: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.007049797555464637]
[2024-04-20 13:43:21,239: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.0016514617879541565]
[2024-04-20 13:43:21,896: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.005689671887238484]
[2024-04-20 13:43:22,554: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.0031254456258334277]
[2024-04-20 13:43:23,210: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.014335260603491582]
[2024-04-20 13:43:23,867: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.0006264879312754174]
[2024-04-20 13:43:24,524: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.00227693212341051]
[2024-04-20 13:43:25,179: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.006794438565523626]
[2024-04-20 13:43:25,842: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.00797221265088127]
[2024-04-20 13:43:26,502: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.006922252276737265]
[2024-04-20 13:43:27,158: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.0080046867600527]
[2024-04-20 13:43:27,825: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.014442667969430088]
[2024-04-20 13:43:28,493: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.02105266606302837]
[2024-04-20 13:43:29,156: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.0039118110295304235]
[2024-04-20 13:43:29,826: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.002734154696290705]
[2024-04-20 13:43:30,495: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.005463712174370676]
[2024-04-20 13:43:31,152: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.0005074068345813522]
[2024-04-20 13:43:31,811: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.00406213542284842]
[2024-04-20 13:43:32,464: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.002181511907377476]
[2024-04-20 13:43:33,125: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 0.002914412907427051]
[2024-04-20 13:43:33,780: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.01995725428021151]
[2024-04-20 13:43:34,439: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.0059604735987365595]
[2024-04-20 13:43:35,090: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.008438388092318833]
[2024-04-20 13:43:35,750: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.004014051489370864]
[2024-04-20 13:43:36,406: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.0018672090335436174]
[2024-04-20 13:43:37,064: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.000261383960220705]
[2024-04-20 13:43:37,719: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.009822509155904349]
[2024-04-20 13:43:38,371: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.0032800723652977046]
[2024-04-20 13:43:39,026: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.011758260224190341]
[2024-04-20 13:43:39,677: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.004618961758099439]
[2024-04-20 13:43:40,333: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.000345571785531029]
[2024-04-20 13:43:40,999: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.011617428264750233]
[2024-04-20 13:43:41,663: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.007130144288505469]
[2024-04-20 13:43:42,320: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.0006267746971125176]
[2024-04-20 13:43:42,983: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.007564624977126668]
[2024-04-20 13:43:43,650: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.004795775494235586]
[2024-04-20 13:43:44,303: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.0022327933948016114]
[2024-04-20 13:43:44,959: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.011404621007633]
[2024-04-20 13:43:45,614: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.0032911448221681766]
[2024-04-20 13:43:46,272: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.0018299344888838766]
[2024-04-20 13:43:46,927: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.013594925853665712]
[2024-04-20 13:43:47,584: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.0023383592162027553]
[2024-04-20 13:43:48,243: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.008043089216448921]
[2024-04-20 13:43:48,895: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.003466586268786881]
[2024-04-20 13:43:49,551: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.0021253180854431623]
[2024-04-20 13:43:50,206: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.0012213707455493302]
[2024-04-20 13:43:50,861: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.01706457536014768]
[2024-04-20 13:43:51,520: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.007316974346774264]
[2024-04-20 13:43:52,177: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.0054531659279748925]
[2024-04-20 13:43:52,832: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.0011663902596278002]
[2024-04-20 13:43:53,490: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.0025627739557671507]
[2024-04-20 13:43:54,167: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.005080870381722131]
[2024-04-20 13:43:54,843: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.007145494570163523]
[2024-04-20 13:43:55,504: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.01353851299151641]
[2024-04-20 13:43:56,173: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.004094624472357317]
[2024-04-20 13:43:56,835: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.0085366660864539]
[2024-04-20 13:43:57,490: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.011909237027319653]
[2024-04-20 13:43:58,144: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.010605838531624933]
[2024-04-20 13:43:58,796: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.00953158160514783]
[2024-04-20 13:43:59,457: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.003211757397627941]
[2024-04-20 13:44:00,110: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.007531904231803112]
[2024-04-20 13:44:00,767: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.004116829188150354]
[2024-04-20 13:44:01,420: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.0017779685924199278]
[2024-04-20 13:44:02,076: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.008902685278927526]
[2024-04-20 13:44:02,739: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.003557871365939656]
[2024-04-20 13:44:03,392: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.004050616247576868]
[2024-04-20 13:44:04,053: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.00280903339668497]
[2024-04-20 13:44:04,707: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.008405516949672695]
[2024-04-20 13:44:05,371: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.003767243488426476]
[2024-04-20 13:44:06,029: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.01565405213590618]
[2024-04-20 13:44:06,684: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.010329248628527242]
[2024-04-20 13:44:07,343: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.0033390409844690446]
[2024-04-20 13:44:08,021: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.0017178672468410423]
[2024-04-20 13:44:08,687: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.004338611108088527]
[2024-04-20 13:44:09,344: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.0007832265516240105]
[2024-04-20 13:44:10,014: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.0017819173015045954]
[2024-04-20 13:44:10,669: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.001017425444356768]
[2024-04-20 13:44:11,324: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.00030158028375598157]
[2024-04-20 13:44:11,975: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.0005569089280010394]
[2024-04-20 13:44:12,631: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.002384969805400057]
[2024-04-20 13:44:13,291: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.002934291496422419]
[2024-04-20 13:44:13,949: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.011666281152056226]
[2024-04-20 13:44:14,607: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.015756475402955612]
[2024-04-20 13:44:15,263: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.0007196141501800183]
[2024-04-20 13:44:15,917: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.006924395013373118]
[2024-04-20 13:44:16,571: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.00161263755671999]
[2024-04-20 13:44:17,226: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.003511029838205839]
[2024-04-20 13:44:17,882: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.0016318430173542955]
[2024-04-20 13:44:18,535: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.007187219355143528]
[2024-04-20 13:44:19,189: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.00032207876658424747]
[2024-04-20 13:44:19,848: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.004923625587463394]
[2024-04-20 13:44:20,512: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.004807863030888797]
[2024-04-20 13:44:21,177: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.003157379798726569]
[2024-04-20 13:44:21,840: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.004194316353100158]
[2024-04-20 13:44:22,499: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.0015926158154959118]
[2024-04-20 13:44:23,162: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.006959421759977414]
[2024-04-20 13:44:23,816: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.0038082124474128403]
[2024-04-20 13:44:24,471: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.003112312703088507]
[2024-04-20 13:44:25,129: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.001250938325975006]
[2024-04-20 13:44:25,785: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.0014003294563789137]
[2024-04-20 13:44:26,440: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.007270262897666262]
[2024-04-20 13:44:27,092: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.00473718098918143]
[2024-04-20 13:44:27,746: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.0017908560853099862]
[2024-04-20 13:44:28,399: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.00014369344136772727]
[2024-04-20 13:44:29,054: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.0016686087246420565]
[2024-04-20 13:44:29,709: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.0017716174552473666]
[2024-04-20 13:44:30,362: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.0024099672792077197]
[2024-04-20 13:44:31,021: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.0007999806891003092]
[2024-04-20 13:44:31,675: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.0004992081261347946]
[2024-04-20 13:44:32,330: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.008755957840587221]
[2024-04-20 13:44:32,993: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.005708784186595166]
[2024-04-20 13:44:33,649: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.0018279885757403747]
[2024-04-20 13:44:34,328: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.002018089693122418]
[2024-04-20 13:44:34,994: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.0024558418401599965]
[2024-04-20 13:44:35,656: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.006079901082939172]
[2024-04-20 13:44:36,321: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.0038949442841808087]
[2024-04-20 13:44:36,978: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.007701139849139284]
[2024-04-20 13:44:37,632: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.001826262835953507]
[2024-04-20 13:44:38,282: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.005580174142371908]
[2024-04-20 13:44:38,936: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.0033986647258842984]
[2024-04-20 13:44:39,595: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.006118692248009652]
[2024-04-20 13:44:40,248: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.00045270322928223436]
[2024-04-20 13:44:40,903: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.007941685565303957]
[2024-04-20 13:44:41,564: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.004479838664885853]
[2024-04-20 13:44:42,218: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.0050195803249496905]
[2024-04-20 13:44:42,877: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.001976821105446039]
[2024-04-20 13:44:43,536: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.005715242757615279]
[2024-04-20 13:44:44,189: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.0029868414454824878]
[2024-04-20 13:44:44,847: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.001736254341875356]
[2024-04-20 13:44:45,500: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.005927498124508109]
[2024-04-20 13:44:46,162: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.00012064962495474794]
[2024-04-20 13:44:46,831: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.0007748545975152712]
[2024-04-20 13:44:47,498: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.013695306484511168]
[2024-04-20 13:44:48,165: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.007288954584849833]
[2024-04-20 13:44:48,833: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.004608985604745744]
[2024-04-20 13:44:49,489: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.0005266628810311686]
[2024-04-20 13:44:50,147: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.03519250449762246]
[2024-04-20 13:44:50,800: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.016133281195745638]
[2024-04-20 13:44:51,461: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.005623652217238786]
[2024-04-20 13:44:52,119: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.009447196832264962]
[2024-04-20 13:44:52,776: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.011687653469753421]
[2024-04-20 13:44:53,433: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.0048368575235264765]
[2024-04-20 13:44:54,088: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.0017446498934602613]
[2024-04-20 13:44:54,743: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.02187629770244996]
[2024-04-20 13:44:55,399: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.0023083157706137755]
[2024-04-20 13:44:56,053: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.007130623281256652]
[2024-04-20 13:44:56,707: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.00031674073146794923]
[2024-04-20 13:44:57,361: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.00387000991553855]
[2024-04-20 13:44:58,019: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.019410898375668582]
[2024-04-20 13:44:58,673: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 7.98433346649713e-05]
[2024-04-20 13:44:59,333: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.0007176837148074962]
[2024-04-20 13:45:00,005: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.0019646758018537257]
[2024-04-20 13:45:00,672: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.0033296534851176324]
[2024-04-20 13:45:01,331: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.0014079073060047054]
[2024-04-20 13:45:01,991: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.012746350060010125]
[2024-04-20 13:45:02,659: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.007468685773056375]
[2024-04-20 13:45:03,314: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.006227602465778568]
[2024-04-20 13:45:03,970: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.0034789054007588385]
[2024-04-20 13:45:04,625: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.010160899116635704]
[2024-04-20 13:45:05,279: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.01300290043303702]
[2024-04-20 13:45:05,933: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.00315188557751232]
[2024-04-20 13:45:06,588: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.00434085704814605]
[2024-04-20 13:45:07,239: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.003302664586505159]
[2024-04-20 13:45:07,894: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.010184335891418365]
[2024-04-20 13:45:08,552: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.0015394079445685419]
[2024-04-20 13:45:09,203: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.0018343289894325145]
[2024-04-20 13:45:09,861: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.004398139758951446]
[2024-04-20 13:45:10,517: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 0.0028021289056277114]
[2024-04-20 13:45:11,172: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.00022811463085864944]
[2024-04-20 13:45:11,826: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.0057916158689607315]
[2024-04-20 13:45:12,481: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.00773429590819129]
[2024-04-20 13:45:13,150: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.006501063509715506]
[2024-04-20 13:45:13,813: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.00582738512236886]
[2024-04-20 13:45:14,477: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.014416339482982767]
[2024-04-20 13:45:15,149: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.0010661037563782527]
[2024-04-20 13:45:15,805: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.0042041516702659475]
[2024-04-20 13:45:16,466: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.009828898611904772]
[2024-04-20 13:45:17,126: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.0010354372567412328]
[2024-04-20 13:45:17,781: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.002230682039372278]
[2024-04-20 13:45:18,438: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.002781383557095893]
[2024-04-20 13:45:19,093: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.0050703590452667304]
[2024-04-20 13:45:19,749: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.012279232984624064]
[2024-04-20 13:45:20,404: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.0015714035651463762]
[2024-04-20 13:45:21,054: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.013160194819926873]
[2024-04-20 13:45:21,708: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.0019670068048646045]
[2024-04-20 13:45:22,363: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.007898506534075894]
[2024-04-20 13:45:23,021: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.010329059814930465]
[2024-04-20 13:45:23,674: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 0.0204105635742537]
[2024-04-20 13:45:24,329: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.0002725101843903862]
[2024-04-20 13:45:24,836: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.00021776015852317186]
[2024-04-20 13:45:25,043: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.0021782045570093674]
[2024-04-20 13:45:25,255: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.004871943382695953]
[2024-04-20 13:45:25,467: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.004824193463757648]
[2024-04-20 13:45:25,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.0012212836963725843]
[2024-04-20 13:45:25,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.003565202481229255]
[2024-04-20 13:45:26,106: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.005918843655134805]
[2024-04-20 13:45:26,317: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.006927097201058142]
[2024-04-20 13:45:26,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.0011011129530852691]
[2024-04-20 13:45:26,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.00460875410135813]
[2024-04-20 13:45:26,951: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.002223449506722252]
[2024-04-20 13:45:27,161: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.0006308192999352473]
[2024-04-20 13:45:27,369: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.00044908251870004034]
[2024-04-20 13:45:27,580: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.004093163552833105]
[2024-04-20 13:45:27,791: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.004886992511934824]
[2024-04-20 13:45:28,008: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.0033130174839493876]
[2024-04-20 13:45:28,218: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.0008904805061546916]
[2024-04-20 13:45:28,429: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.006534449989628003]
[2024-04-20 13:45:28,643: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.0045002750297573075]
[2024-04-20 13:45:28,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.001121135072261996]
[2024-04-20 13:45:29,063: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.005612241507518681]
[2024-04-20 13:45:29,269: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.0021109414360541592]
[2024-04-20 13:45:29,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.0064838553855682095]
[2024-04-20 13:45:29,688: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.007612760344516733]
[2024-04-20 13:45:29,892: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.005498091773028491]
[2024-04-20 13:45:30,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.003116876775236216]
[2024-04-20 13:45:30,302: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.002691816728971157]
[2024-04-20 13:45:30,512: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.00518443451913489]
[2024-04-20 13:45:30,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.011729508335728408]
[2024-04-20 13:45:30,922: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.0020897276194088727]
[2024-04-20 13:45:31,127: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.0033151408204785777]
[2024-04-20 13:45:31,336: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.0013897914038786899]
[2024-04-20 13:45:31,543: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.0010648914927229233]
[2024-04-20 13:45:31,750: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.005045107613497766]
[2024-04-20 13:45:31,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.0021935341903241024]
[2024-04-20 13:45:32,165: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.003092310839809073]
[2024-04-20 13:45:32,373: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.0047820904562245505]
[2024-04-20 13:45:32,579: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.0007719694672041632]
[2024-04-20 13:45:32,786: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.0025661284571789644]
[2024-04-20 13:45:32,989: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.0018620793208850728]
[2024-04-20 13:45:33,199: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.00207018100372919]
[2024-04-20 13:45:33,408: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.008978796637507423]
[2024-04-20 13:45:33,615: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.004376751274718488]
[2024-04-20 13:45:33,824: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.007627258567675005]
[2024-04-20 13:45:34,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.004586956131467761]
[2024-04-20 13:45:34,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.005590593306393363]
[2024-04-20 13:45:34,440: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.002548678209126541]
[2024-04-20 13:45:34,648: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.0012507888833273452]
[2024-04-20 13:45:34,853: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.001235097482143045]
[2024-04-20 13:45:35,059: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.004422240433831732]
[2024-04-20 13:45:35,268: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.003295497253820021]
[2024-04-20 13:45:35,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.007445627086177215]
[2024-04-20 13:45:35,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.0012825761715235372]
[2024-04-20 13:45:35,887: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.016039747440260578]
[2024-04-20 13:45:36,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.003981024706673464]
[2024-04-20 13:45:36,300: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.006679366240836477]
[2024-04-20 13:45:36,506: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.00881458146076771]
[2024-04-20 13:45:36,714: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.011275727103953236]
[2024-04-20 13:45:36,918: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.0006092511250175669]
[2024-04-20 13:45:37,127: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.01182242465304997]
[2024-04-20 13:45:37,332: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.006042898581814839]
[2024-04-20 13:45:37,543: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.004340717066212696]
[2024-04-20 13:45:37,747: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.00657082478852437]
[2024-04-20 13:45:37,955: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.007381849104369237]
[2024-04-20 13:45:38,159: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.006953644692444887]
[2024-04-20 13:45:38,366: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.0010424473791494897]
[2024-04-20 13:45:38,575: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.0005269732496987288]
[2024-04-20 13:45:38,783: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.008409414627706183]
[2024-04-20 13:45:38,991: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.007836195927047108]
[2024-04-20 13:45:39,206: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.002252712959198438]
[2024-04-20 13:45:39,417: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.00061777892095045]
[2024-04-20 13:45:39,630: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.004554250679239898]
[2024-04-20 13:45:39,842: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.0034011871645612305]
[2024-04-20 13:45:40,053: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.0045367361523184985]
[2024-04-20 13:45:40,267: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.0008980255272437925]
[2024-04-20 13:45:40,478: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.003370240252042594]
[2024-04-20 13:45:40,686: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.01000868355565686]
[2024-04-20 13:45:40,897: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.004321218765329419]
[2024-04-20 13:45:41,107: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.0010990044802561083]
[2024-04-20 13:45:41,319: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.004992495872156119]
[2024-04-20 13:45:41,531: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.0077251189197230655]
[2024-04-20 13:45:41,744: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.0006682675617806995]
[2024-04-20 13:45:41,959: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.00320128906503424]
[2024-04-20 13:45:42,172: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.0017150814316881638]
[2024-04-20 13:45:42,383: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.003200657883225893]
[2024-04-20 13:45:42,596: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.007811261756796435]
[2024-04-20 13:45:42,803: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.0030452915675698382]
[2024-04-20 13:45:43,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.005399029659398972]
[2024-04-20 13:45:43,218: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.013254093312335239]
[2024-04-20 13:45:43,428: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.004899789435375084]
[2024-04-20 13:45:43,634: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 0.00013103764612504377]
[2024-04-20 13:45:43,840: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.006980212461666742]
[2024-04-20 13:45:44,046: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.0023868403317159636]
[2024-04-20 13:45:44,252: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.004824315185146869]
[2024-04-20 13:45:44,462: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.005535317280261376]
[2024-04-20 13:45:44,668: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.0075906263782590635]
[2024-04-20 13:45:44,873: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.004618759470309777]
[2024-04-20 13:45:45,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.002427956819106769]
[2024-04-20 13:45:45,284: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.0043284427952719135]
[2024-04-20 13:45:45,490: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.005226249577322722]
[2024-04-20 13:45:45,699: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.0061232580354064975]
[2024-04-20 13:45:45,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.0011427256397865506]
[2024-04-20 13:45:46,113: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.006461879082488441]
[2024-04-20 13:45:46,321: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.003988818011461509]
[2024-04-20 13:45:46,527: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.009848683457961995]
[2024-04-20 13:45:46,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.001328635375145477]
[2024-04-20 13:45:46,943: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.003009177709834994]
[2024-04-20 13:45:47,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.001627957368176066]
[2024-04-20 13:45:47,358: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.004367967629849726]
[2024-04-20 13:45:47,564: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.000849097408094216]
[2024-04-20 13:45:47,768: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.0033297341564783797]
[2024-04-20 13:45:47,977: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.023371471040538903]
[2024-04-20 13:45:48,189: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.015307542227105108]
[2024-04-20 13:45:48,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.0006588622762871586]
[2024-04-20 13:45:48,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.004428231696344602]
[2024-04-20 13:45:48,808: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.00046595272878858823]
[2024-04-20 13:45:49,017: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.002365136204027777]
[2024-04-20 13:45:49,223: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.011919261735742585]
[2024-04-20 13:45:49,432: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.01122219014355139]
[2024-04-20 13:45:49,640: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.017927658639253278]
[2024-04-20 13:45:49,846: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.0031200383452661923]
[2024-04-20 13:45:50,056: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.009185716540795096]
[2024-04-20 13:45:50,263: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.0051310639797920886]
[2024-04-20 13:45:50,469: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.01242816802971284]
[2024-04-20 13:45:50,674: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.01661404149549282]
[2024-04-20 13:45:50,881: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.0032945665841260996]
[2024-04-20 13:45:51,090: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.020008032184405368]
[2024-04-20 13:45:51,296: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.0010041347381922027]
[2024-04-20 13:45:51,510: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.0023293828257221105]
[2024-04-20 13:45:51,718: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.001497923057098196]
[2024-04-20 13:45:51,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.017068824073116298]
[2024-04-20 13:45:52,129: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.0073599246037660045]
[2024-04-20 13:45:52,335: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.00968601170621736]
[2024-04-20 13:45:52,542: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.0008769637364128695]
[2024-04-20 13:45:52,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.009424489215796982]
[2024-04-20 13:45:52,967: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.001677844177148792]
[2024-04-20 13:45:53,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.002253813852535512]
[2024-04-20 13:45:53,385: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.008182450838032181]
[2024-04-20 13:45:53,597: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.0062759712126129645]
[2024-04-20 13:45:53,815: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.0001892089930016702]
[2024-04-20 13:45:54,029: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.0016951630090484544]
[2024-04-20 13:45:54,242: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.005672293906019076]
[2024-04-20 13:45:54,451: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.003282750946479371]
[2024-04-20 13:45:54,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.0067639223578880026]
[2024-04-20 13:45:54,879: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.0015761884826980756]
[2024-04-20 13:45:55,091: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.0019007642601182005]
[2024-04-20 13:45:55,301: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.0029291971057927696]
[2024-04-20 13:45:55,514: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.0036508690639976034]
[2024-04-20 13:45:55,728: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.006041575884391623]
[2024-04-20 13:45:55,937: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.00317371151468511]
[2024-04-20 13:45:56,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.008899904252428419]
[2024-04-20 13:45:56,355: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.002125445278554972]
[2024-04-20 13:45:56,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.0019422979842266474]
[2024-04-20 13:45:56,771: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.0024339984420194624]
[2024-04-20 13:45:56,981: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.03185523608122494]
[2024-04-20 13:45:57,186: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.01461741935755023]
[2024-04-20 13:45:57,391: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.00801372512835064]
[2024-04-20 13:45:57,595: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.004609825824693168]
[2024-04-20 13:45:57,803: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.006443761747965212]
[2024-04-20 13:45:58,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.006387715676021899]
[2024-04-20 13:45:58,218: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.004526306516725345]
[2024-04-20 13:45:58,425: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.001655933202281782]
[2024-04-20 13:45:58,632: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.0018762710917556494]
[2024-04-20 13:45:58,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.00085741802890433]
[2024-04-20 13:45:59,040: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 0.00010765048231760597]
[2024-04-20 13:45:59,244: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.011422629752366938]
[2024-04-20 13:45:59,449: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.001748347521988536]
[2024-04-20 13:45:59,655: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.013330308089157762]
[2024-04-20 13:45:59,859: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.0046580655564609575]
[2024-04-20 13:46:00,067: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.005005901162864054]
[2024-04-20 13:46:00,275: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.0026878446749321666]
[2024-04-20 13:46:00,482: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.00297160528788952]
[2024-04-20 13:46:00,689: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.00194190938884232]
[2024-04-20 13:46:00,895: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.0023500992169574863]
[2024-04-20 13:46:01,105: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.0013353287783227836]
[2024-04-20 13:46:01,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.0012134771404220229]
[2024-04-20 13:46:01,523: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.014091596187920821]
[2024-04-20 13:46:01,730: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.004245404334851354]
[2024-04-20 13:46:01,939: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.0017593627025551542]
[2024-04-20 13:46:02,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.00145557527465946]
[2024-04-20 13:46:02,363: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.0006339822684062521]
[2024-04-20 13:46:02,567: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.0003292901083887014]
[2024-04-20 13:46:02,771: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.0033953710949087426]
[2024-04-20 13:46:02,978: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.00998903565303827]
[2024-04-20 13:46:03,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.0030314877953004616]
[2024-04-20 13:46:03,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.0009456680061781367]
[2024-04-20 13:46:03,594: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.003938567249094757]
[2024-04-20 13:46:03,802: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.0008697739544120765]
[2024-04-20 13:46:04,009: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.001056325270671676]
[2024-04-20 13:46:04,216: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 3.736186206925414e-05]
[2024-04-20 13:46:04,425: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.0020727982831043523]
[2024-04-20 13:46:04,633: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.0033443989776113627]
[2024-04-20 13:46:04,839: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.0010901291814616185]
[2024-04-20 13:46:05,044: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.0003531800039840719]
[2024-04-20 13:46:05,249: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.013945206421952652]
[2024-04-20 13:46:05,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.00045915732203068204]
[2024-04-20 13:46:05,663: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.0016115683118708285]
[2024-04-20 13:46:05,870: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.002898839962697366]
[2024-04-20 13:46:06,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 0.0004752795122943565]
[2024-04-20 13:46:06,288: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 0.00011261259600269635]
[2024-04-20 13:46:06,501: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.0010737431870716364]
[2024-04-20 13:46:06,712: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.0006359990420844207]
[2024-04-20 13:46:06,925: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.00027955776080266647]
[2024-04-20 13:46:07,138: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.0009402719194288406]
[2024-04-20 13:46:07,349: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.001057147962688132]
[2024-04-20 13:46:07,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.0018199241065291161]
[2024-04-20 13:46:07,780: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.008577268747707782]
[2024-04-20 13:46:07,993: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.0006577646606680996]
[2024-04-20 13:46:08,204: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.001205847472489278]
[2024-04-20 13:46:08,420: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.004733089838847083]
[2024-04-20 13:46:08,628: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.0016650796441938928]
[2024-04-20 13:46:08,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.005341654095211087]
[2024-04-20 13:46:09,047: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.0015913405883206692]
[2024-04-20 13:46:09,258: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.003063038000706552]
[2024-04-20 13:46:09,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.0019951455410415855]
[2024-04-20 13:46:09,674: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.0028736421433145287]
[2024-04-20 13:46:09,884: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.00022494398770840749]
[2024-04-20 13:46:10,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.009822268795778877]
[2024-04-20 13:46:10,293: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.0016973023173434388]
[2024-04-20 13:46:10,503: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.0059091924487670346]
[2024-04-20 13:46:10,709: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.007241231082031647]
[2024-04-20 13:46:10,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.0009689027051911414]
[2024-04-20 13:46:11,120: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.009740334689252065]
[2024-04-20 13:46:11,328: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.0028273814639594797]
[2024-04-20 13:46:11,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.00518254355875082]
[2024-04-20 13:46:11,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.0015352938886118255]
[2024-04-20 13:46:11,941: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.009763774613635747]
[2024-04-20 13:46:12,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.002028394163209421]
[2024-04-20 13:46:12,351: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.001160789953959249]
[2024-04-20 13:46:12,559: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.0023241204670935074]
[2024-04-20 13:46:12,765: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 9.540407472308998e-05]
[2024-04-20 13:46:12,974: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.0014461685925434634]
[2024-04-20 13:46:13,176: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 8.52237707163031e-05]
[2024-04-20 13:46:13,380: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.002348572557499619]
[2024-04-20 13:46:13,584: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.0014097346522132037]
[2024-04-20 13:46:13,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.00045594706786973403]
[2024-04-20 13:46:14,003: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.000266686644993092]
[2024-04-20 13:46:14,209: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.014427639851828527]
[2024-04-20 13:46:14,416: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.0053357856932282665]
[2024-04-20 13:46:14,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.0029977410220647796]
[2024-04-20 13:46:14,830: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.000840204399761981]
[2024-04-20 13:46:15,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 7.50238230237221e-05]
[2024-04-20 13:46:15,245: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.003044287144341695]
[2024-04-20 13:46:15,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.0014705969749432193]
[2024-04-20 13:46:15,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.0009361543109862396]
[2024-04-20 13:46:15,866: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.0027044632451997696]
[2024-04-20 13:46:16,072: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.0011196672750264209]
[2024-04-20 13:46:16,276: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.0034722108844376116]
[2024-04-20 13:46:16,482: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.001309461707583754]
[2024-04-20 13:46:16,688: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 0.00015357464467013882]
[2024-04-20 13:46:16,897: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.00623909760053087]
[2024-04-20 13:46:17,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.0016219707653600019]
[2024-04-20 13:46:17,312: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.007120698077873023]
[2024-04-20 13:46:17,518: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.0056838400677211905]
[2024-04-20 13:46:17,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.007206701336661708]
[2024-04-20 13:46:17,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.0042856255713596735]
[2024-04-20 13:46:18,138: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.004275249812247013]
[2024-04-20 13:46:18,343: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.009324010892792141]
[2024-04-20 13:46:18,548: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.0008031564354952706]
[2024-04-20 13:46:18,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.004555262703745846]
[2024-04-20 13:46:18,959: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.0012551545722447243]
[2024-04-20 13:46:19,168: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.006570186833078395]
[2024-04-20 13:46:19,373: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.0002761427318328796]
[2024-04-20 13:46:19,580: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.001198749812093152]
[2024-04-20 13:46:19,794: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.0016166034843309192]
[2024-04-20 13:46:20,002: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 0.0007893274777895616]
[2024-04-20 13:46:20,212: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.004781444914046266]
[2024-04-20 13:46:20,422: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.002595193591627593]
[2024-04-20 13:46:20,635: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.00912060339501713]
[2024-04-20 13:46:20,846: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.0036524189245012535]
[2024-04-20 13:46:21,055: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.006371370573934266]
[2024-04-20 13:46:21,265: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.005347490902749426]
[2024-04-20 13:46:21,480: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.0034951741452635948]
[2024-04-20 13:46:21,691: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.002981576107370414]
[2024-04-20 13:46:21,901: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.001826479177461307]
[2024-04-20 13:46:22,110: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.01733906156029505]
[2024-04-20 13:46:22,326: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.004027376129429391]
[2024-04-20 13:46:22,546: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.0020835524443332722]
[2024-04-20 13:46:22,758: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.0009845220430337405]
[2024-04-20 13:46:22,972: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.012951046769441182]
[2024-04-20 13:46:23,189: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 9.930803946293709e-05]
[2024-04-20 13:46:23,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.0006427658272037878]
[2024-04-20 13:46:23,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 0.0001480391037303748]
[2024-04-20 13:46:23,845: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.0013002786151911157]
[2024-04-20 13:46:24,058: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.021641573815827674]
[2024-04-20 13:46:24,277: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.01605413619894887]
[2024-04-20 13:46:24,493: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.00466943893969186]
[2024-04-20 13:46:24,705: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.009453928446909912]
[2024-04-20 13:46:24,914: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.003521389435942057]
[2024-04-20 13:46:25,126: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.013187085383398517]
[2024-04-20 13:46:25,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.010718868681351523]
[2024-04-20 13:46:25,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.0069883409522602385]
[2024-04-20 13:46:25,763: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.015765418962350917]
[2024-04-20 13:46:25,975: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.0024718253637136993]
[2024-04-20 13:46:26,186: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.004660944891225545]
[2024-04-20 13:46:26,398: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.01904810422446173]
[2024-04-20 13:46:26,609: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.011119791132354074]
[2024-04-20 13:46:26,818: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.005318297774932378]
[2024-04-20 13:46:27,027: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.014713912327654519]
[2024-04-20 13:46:27,239: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.0024591283119500106]
[2024-04-20 13:46:27,445: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.00331877833369738]
[2024-04-20 13:46:27,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.011782541903043748]
[2024-04-20 13:46:27,860: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.01686101968608009]
[2024-04-20 13:46:28,067: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.004042286335402248]
[2024-04-20 13:46:28,273: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.011929704219182737]
[2024-04-20 13:46:28,483: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.0035491297148158726]
[2024-04-20 13:46:28,690: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.0037273753773114844]
[2024-04-20 13:46:28,895: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.01155294574711121]
[2024-04-20 13:46:29,100: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.007493774101956568]
[2024-04-20 13:46:29,308: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.004016653291078724]
[2024-04-20 13:46:29,516: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.0042525387666891195]
[2024-04-20 13:46:29,725: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.02684867140687572]
[2024-04-20 13:46:29,931: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.012058166712324079]
[2024-04-20 13:46:30,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.005918042717819107]
[2024-04-20 13:46:30,343: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.007942958500700818]
[2024-04-20 13:46:30,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.0016863595968135308]
[2024-04-20 13:46:30,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.006012812372320165]
[2024-04-20 13:46:30,970: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.007479221955752972]
[2024-04-20 13:46:31,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.007581307790280954]
[2024-04-20 13:46:31,382: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.014161122742684088]
[2024-04-20 13:46:31,588: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.006395303732694473]
[2024-04-20 13:46:31,797: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.008288040576285802]
[2024-04-20 13:46:32,003: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.010179299981207727]
[2024-04-20 13:46:32,210: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.010915032374130919]
[2024-04-20 13:46:32,416: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.010537117084925583]
[2024-04-20 13:46:32,623: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.0035000992191953624]
[2024-04-20 13:46:32,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.004135956238946908]
[2024-04-20 13:46:33,037: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.014383128827195772]
[2024-04-20 13:46:33,242: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.007944130390307615]
[2024-04-20 13:46:33,449: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.007269582204060641]
[2024-04-20 13:46:33,655: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.026890471088156703]
[2024-04-20 13:46:33,860: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.00864628247123957]
[2024-04-20 13:46:34,070: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.005636339916888026]
[2024-04-20 13:46:34,278: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.0037339939955172924]
[2024-04-20 13:46:34,483: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.012302581860090554]
[2024-04-20 13:46:34,694: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.019120257266976193]
[2024-04-20 13:46:34,904: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.010758343105263685]
[2024-04-20 13:46:35,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.004781951699755043]
[2024-04-20 13:46:35,333: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.005107150192227166]
[2024-04-20 13:46:35,543: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.006570710252830672]
[2024-04-20 13:46:35,754: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.011248160603434944]
[2024-04-20 13:46:35,966: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.004860842407284076]
[2024-04-20 13:46:36,178: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.002675478618002828]
[2024-04-20 13:46:36,385: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.017727444505634203]
[2024-04-20 13:46:36,597: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.008682476648506353]
[2024-04-20 13:46:36,806: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.008312202078089312]
[2024-04-20 13:46:37,014: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.004358447211264082]
[2024-04-20 13:46:37,234: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.009888440795265501]
[2024-04-20 13:46:37,444: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.006073417889168733]
[2024-04-20 13:46:37,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.004744967580658143]
[2024-04-20 13:46:37,880: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.005861123542422372]
[2024-04-20 13:46:38,084: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.010214062354096567]
[2024-04-20 13:46:38,286: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.019782592716464008]
[2024-04-20 13:46:38,490: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.007691082665930397]
[2024-04-20 13:46:38,699: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.007595109939792573]
[2024-04-20 13:46:38,911: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.0021199814119360963]
[2024-04-20 13:46:39,115: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.009298158663514512]
[2024-04-20 13:46:39,318: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.008066891231365093]
[2024-04-20 13:46:39,522: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.010141613263852956]
[2024-04-20 13:46:39,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.004419776046428599]
[2024-04-20 13:46:39,939: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.00946234350816616]
[2024-04-20 13:46:40,146: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.0021269862678735354]
[2024-04-20 13:46:40,354: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.0067207084125364604]
[2024-04-20 13:46:40,558: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.0006033274495619183]
[2024-04-20 13:46:40,765: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.003895748411652227]
[2024-04-20 13:46:40,973: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.0006797515119343585]
[2024-04-20 13:46:41,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.0005124820799026357]
[2024-04-20 13:46:41,389: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.0037012199868214704]
[2024-04-20 13:46:41,598: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.006910644152702694]
[2024-04-20 13:46:41,804: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.000950218054237431]
[2024-04-20 13:46:42,013: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.024518033627316273]
[2024-04-20 13:46:42,220: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.00046188826047368817]
[2024-04-20 13:46:42,426: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.002943229827470209]
[2024-04-20 13:46:42,631: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.0046393350040109475]
[2024-04-20 13:46:42,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.0032589028518657252]
[2024-04-20 13:46:43,045: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.0023759986208574447]
[2024-04-20 13:46:43,252: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.0005448617307072521]
[2024-04-20 13:46:43,462: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.008044315371611653]
[2024-04-20 13:46:43,670: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.005958831398913707]
[2024-04-20 13:46:43,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.0008339136173827125]
[2024-04-20 13:46:44,083: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.0007076488592531241]
[2024-04-20 13:46:44,289: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.008060070139827657]
[2024-04-20 13:46:44,495: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.003906490347303636]
[2024-04-20 13:46:44,704: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 0.0002988042909425837]
[2024-04-20 13:46:44,910: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.013650372975434772]
[2024-04-20 13:46:45,115: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.0036064358631511203]
[2024-04-20 13:46:45,323: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.0015134920864407527]
[2024-04-20 13:46:45,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 7.28528474429704e-05]
[2024-04-20 13:46:45,741: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.0006315630052853294]
[2024-04-20 13:46:45,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.003957939610508555]
[2024-04-20 13:46:46,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.0037780921979456697]
[2024-04-20 13:46:46,351: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.020249814564837123]
[2024-04-20 13:46:46,556: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.004004741432642235]
[2024-04-20 13:46:46,766: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.001655796014141342]
[2024-04-20 13:46:46,975: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.00641498228709162]
[2024-04-20 13:46:47,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 0.0003653029071427173]
[2024-04-20 13:46:47,393: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.006928243071809557]
[2024-04-20 13:46:47,599: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.008356504420291733]
[2024-04-20 13:46:47,805: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.0012342084493724456]
[2024-04-20 13:46:48,018: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.004409526913506287]
[2024-04-20 13:46:48,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.02518922637704079]
[2024-04-20 13:46:48,444: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.002739984231168821]
[2024-04-20 13:46:48,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.002196604733424289]
[2024-04-20 13:46:48,876: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.0030287749218530966]
[2024-04-20 13:46:49,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.009654316236894115]
[2024-04-20 13:46:49,296: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.007073029285683728]
[2024-04-20 13:46:49,513: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.020975979302845373]
[2024-04-20 13:46:49,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 7.387120521679028e-05]
[2024-04-20 13:46:49,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.007984468374757045]
[2024-04-20 13:46:50,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.003334872880012716]
[2024-04-20 13:46:50,354: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.0012364147619148978]
[2024-04-20 13:46:50,565: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.0013130179179629718]
[2024-04-20 13:46:50,780: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.0005990519421232464]
[2024-04-20 13:46:50,998: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.002376949989029961]
[2024-04-20 13:46:51,209: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.014990131301237202]
[2024-04-20 13:46:51,422: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.011263026088731113]
[2024-04-20 13:46:51,628: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.010589210439595589]
[2024-04-20 13:46:51,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.0009576326495464117]
[2024-04-20 13:46:52,045: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.00436843262401736]
[2024-04-20 13:46:52,252: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.0026069877951710144]
[2024-04-20 13:46:52,458: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.005256852509879848]
[2024-04-20 13:46:52,670: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.02657550702185069]
[2024-04-20 13:46:52,876: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.005829208373069935]
[2024-04-20 13:46:53,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.009034115888902754]
[2024-04-20 13:46:53,290: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.01002976046049231]
[2024-04-20 13:46:53,501: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.009593841611132761]
[2024-04-20 13:46:53,706: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.012261082429883084]
[2024-04-20 13:46:53,911: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.003960674703760929]
[2024-04-20 13:46:54,116: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.01374828069252069]
[2024-04-20 13:46:54,321: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.0016999569272688417]
[2024-04-20 13:46:54,532: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.000881445492279183]
[2024-04-20 13:46:54,737: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.005626958901302714]
[2024-04-20 13:46:54,945: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.002218021077780641]
[2024-04-20 13:46:55,153: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.0038877528784990343]
[2024-04-20 13:46:55,360: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.003317583571539176]
[2024-04-20 13:46:55,569: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.016327767024098817]
[2024-04-20 13:46:55,776: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.009024691770754743]
[2024-04-20 13:46:55,990: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.0060997121311336736]
[2024-04-20 13:46:56,196: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.007200412304228708]
[2024-04-20 13:46:56,401: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.002357745441059034]
[2024-04-20 13:46:56,609: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.0185339670513028]
[2024-04-20 13:46:56,817: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.008013478230775839]
[2024-04-20 13:46:57,025: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.005739820283041364]
[2024-04-20 13:46:57,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.006484883238324047]
[2024-04-20 13:46:57,436: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 0.0004963404794778804]
[2024-04-20 13:46:57,642: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.011637236682961943]
[2024-04-20 13:46:57,849: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.005812824490249662]
[2024-04-20 13:46:58,058: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.014592920140375863]
[2024-04-20 13:46:58,267: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.004302479096346236]
[2024-04-20 13:46:58,472: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.004256783701943013]
[2024-04-20 13:46:58,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.005750622946671708]
[2024-04-20 13:46:58,885: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.0011671537027356752]
[2024-04-20 13:46:59,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.003155236520198173]
[2024-04-20 13:46:59,305: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.01180391911478367]
[2024-04-20 13:46:59,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.0007916569547909664]
[2024-04-20 13:46:59,715: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.004604852605777897]
[2024-04-20 13:46:59,921: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.004931690250582495]
[2024-04-20 13:47:00,131: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 0.0003240937028747458]
[2024-04-20 13:47:00,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.0025585278231980636]
[2024-04-20 13:47:00,550: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.0024407579958207574]
[2024-04-20 13:47:00,758: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.0008371909821209603]
[2024-04-20 13:47:00,965: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 7.028257716540838e-05]
[2024-04-20 13:47:01,174: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.0019126466082754067]
[2024-04-20 13:47:01,380: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.001327122597813251]
[2024-04-20 13:47:01,593: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.004907795284484122]
[2024-04-20 13:47:01,812: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.010996798670812885]
[2024-04-20 13:47:02,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.005001882612314486]
[2024-04-20 13:47:02,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.0004493003111615574]
[2024-04-20 13:47:02,448: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.0040751198268494555]
[2024-04-20 13:47:02,660: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.0008277685377279713]
[2024-04-20 13:47:02,872: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.0018493261650219769]
[2024-04-20 13:47:03,084: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.0015225042239996442]
[2024-04-20 13:47:03,296: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.003363221822144796]
[2024-04-20 13:47:03,505: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 2.2041858440695923e-05]
[2024-04-20 13:47:03,719: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.006108249089536956]
[2024-04-20 13:47:03,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.005239404007701603]
[2024-04-20 13:47:04,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.00126665679216707]
[2024-04-20 13:47:04,354: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.0024143461381103026]
[2024-04-20 13:47:04,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.00401941202649304]
[2024-04-20 13:47:04,779: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.0007894790924128836]
[2024-04-20 13:47:04,995: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.00729033696390571]
[2024-04-20 13:47:05,204: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.007777067807561859]
[2024-04-20 13:47:05,410: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.00387954535502202]
[2024-04-20 13:47:05,624: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.003944479272636071]
[2024-04-20 13:47:05,833: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.003911779227561105]
[2024-04-20 13:47:06,041: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.00657173127225568]
[2024-04-20 13:47:06,245: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.0016999420579688204]
[2024-04-20 13:47:06,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.005023682529647433]
[2024-04-20 13:47:06,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.00017084327316993912]
[2024-04-20 13:47:06,872: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.011595087655640197]
[2024-04-20 13:47:07,081: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.0011976705873733137]
[2024-04-20 13:47:07,290: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.004186313675035725]
[2024-04-20 13:47:07,498: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.0033339654644461156]
[2024-04-20 13:47:07,711: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.004517910343087562]
[2024-04-20 13:47:07,922: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.003952633128410194]
[2024-04-20 13:47:08,135: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.0020206948354250217]
[2024-04-20 13:47:08,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.006280596529697482]
[2024-04-20 13:47:08,549: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.0017775569436153896]
[2024-04-20 13:47:08,756: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.0030217663593032854]
[2024-04-20 13:47:08,967: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.001864473336811981]
[2024-04-20 13:47:09,174: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.0006841849331177513]
[2024-04-20 13:47:09,380: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 0.0001648962251489425]
[2024-04-20 13:47:09,591: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.0023354749129806517]
[2024-04-20 13:47:09,798: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.00048320653259329295]
[2024-04-20 13:47:10,007: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.0057072629024836966]
[2024-04-20 13:47:10,214: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.00572165120816546]
[2024-04-20 13:47:10,423: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.004801580716117909]
[2024-04-20 13:47:10,631: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.0028938804411202976]
[2024-04-20 13:47:10,835: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.0039693989009276735]
[2024-04-20 13:47:11,041: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.008030531802240526]
[2024-04-20 13:47:11,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.005898433748932818]
[2024-04-20 13:47:11,458: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.0030991099382401926]
[2024-04-20 13:47:11,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.012557317379046883]
[2024-04-20 13:47:11,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.0003191009743409759]
[2024-04-20 13:47:12,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.00014087103346343164]
[2024-04-20 13:47:12,284: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.020878626940880714]
[2024-04-20 13:47:12,490: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.0029330855151917822]
[2024-04-20 13:47:12,697: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.0019721347595469656]
[2024-04-20 13:47:12,902: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.000496181711151442]
[2024-04-20 13:47:13,110: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.0005451608711477068]
[2024-04-20 13:47:13,320: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.004377738868300443]
[2024-04-20 13:47:13,530: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.009565368737901555]
[2024-04-20 13:47:13,741: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.0032878609183796927]
[2024-04-20 13:47:13,947: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.0007391906176328155]
[2024-04-20 13:47:14,152: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.00028092648013420505]
[2024-04-20 13:47:14,356: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 0.00017685772586414295]
[2024-04-20 13:47:14,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.0013588106306263626]
[2024-04-20 13:47:14,770: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.0027292663277370456]
[2024-04-20 13:47:14,977: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.009758256745908536]
[2024-04-20 13:47:15,190: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.00032085836566877183]
[2024-04-20 13:47:15,405: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.000386538667535368]
[2024-04-20 13:47:15,616: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.001014188429381284]
[2024-04-20 13:47:15,825: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.00029706701971515635]
[2024-04-20 13:47:16,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.0002754642179241711]
[2024-04-20 13:47:16,250: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.0005135475954479742]
[2024-04-20 13:47:16,460: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.01076716929233847]
[2024-04-20 13:47:16,670: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.0036989692436120527]
[2024-04-20 13:47:16,889: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.000867345591983771]
[2024-04-20 13:47:17,102: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.0024513044425175773]
[2024-04-20 13:47:17,309: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.004067317860448525]
[2024-04-20 13:47:17,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.006455696597953647]
[2024-04-20 13:47:17,730: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.0010319226077927404]
[2024-04-20 13:47:17,944: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.0024946500647121724]
[2024-04-20 13:47:18,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.0013653445459297937]
[2024-04-20 13:47:18,364: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.0003184335012998292]
[2024-04-20 13:47:18,569: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.0033755043096514873]
[2024-04-20 13:47:18,776: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.0021932120571178937]
[2024-04-20 13:47:18,987: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 0.0003225770461483535]
[2024-04-20 13:47:19,203: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.002577508142494748]
[2024-04-20 13:47:19,410: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 0.00013208781514129788]
[2024-04-20 13:47:19,614: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.004854937494304519]
[2024-04-20 13:47:19,819: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.0055652263403950354]
[2024-04-20 13:47:20,028: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.0046917004158632996]
[2024-04-20 13:47:20,235: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.00021406816483521323]
[2024-04-20 13:47:20,441: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.012655214699518911]
[2024-04-20 13:47:20,647: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.002132978740840228]
[2024-04-20 13:47:20,851: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.0031741353186024173]
[2024-04-20 13:47:21,059: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.000589962644378182]
[2024-04-20 13:47:21,265: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.001506812576797481]
[2024-04-20 13:47:21,473: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.043725964939543414]
[2024-04-20 13:47:21,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.0009806890226619572]
[2024-04-20 13:47:21,890: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.009647399115151532]
[2024-04-20 13:47:22,096: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.002461512224006481]
[2024-04-20 13:47:22,306: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.003787812853646696]
[2024-04-20 13:47:22,511: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.0012439985662592089]
[2024-04-20 13:47:22,719: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.006470303051229663]
[2024-04-20 13:47:22,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.0017515164089938488]
[2024-04-20 13:47:23,132: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.002330566565330867]
[2024-04-20 13:47:23,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.002951884393085377]
[2024-04-20 13:47:23,548: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 0.0010562962461911783]
[2024-04-20 13:47:23,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.004101825801282337]
[2024-04-20 13:47:23,957: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.01593625505327044]
[2024-04-20 13:47:24,164: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.008235534969026716]
[2024-04-20 13:47:24,371: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.002407179714119012]
[2024-04-20 13:47:24,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.0016815206289870282]
[2024-04-20 13:47:24,783: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.0008713273326542837]
[2024-04-20 13:47:24,991: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.002387767593105023]
[2024-04-20 13:47:25,199: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.00020467650999983006]
[2024-04-20 13:47:25,406: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.007788674677584938]
[2024-04-20 13:47:25,613: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.0034549770488086547]
[2024-04-20 13:47:25,826: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.00047119949072222165]
[2024-04-20 13:47:26,031: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.0011819124208167179]
[2024-04-20 13:47:26,238: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.007440678878573403]
[2024-04-20 13:47:26,445: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.007345660937180917]
[2024-04-20 13:47:26,652: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.003902009107922019]
[2024-04-20 13:47:26,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 0.0002234569387085319]
[2024-04-20 13:47:27,061: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.0013128433982134368]
[2024-04-20 13:47:27,267: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.0015928698477811623]
[2024-04-20 13:47:27,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.0010621414062692218]
[2024-04-20 13:47:27,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 0.000773110262107221]
[2024-04-20 13:47:27,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.000979983237577838]
[2024-04-20 13:47:28,094: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 0.00174011472263948]
[2024-04-20 13:47:28,298: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.009883113756365665]
[2024-04-20 13:47:28,498: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.00037324614110738184]
[2024-04-20 13:47:28,708: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.004766615577742953]
[2024-04-20 13:47:28,923: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.0050235977359553135]
[2024-04-20 13:47:29,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 4.8421682200009505e-05]
[2024-04-20 13:47:52,238: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9959912771423676, 'precision': 0.8049567858662636, 'recall': 0.9595417176841, 'f1': 0.8754777807036442}]
[2024-04-20 13:47:52,256: INFO: roberta_kFold_initial_lstm: Fold 3/3 , Epoch: 3/3]
[2024-04-20 13:47:52,954: INFO: roberta_kFold_initial_lstm: Training : batch 0 Loss: 0.0022542350689075123]
[2024-04-20 13:47:53,587: INFO: roberta_kFold_initial_lstm: Training : batch 1 Loss: 0.005873796939937171]
[2024-04-20 13:47:54,218: INFO: roberta_kFold_initial_lstm: Training : batch 2 Loss: 0.011734146453898133]
[2024-04-20 13:47:54,850: INFO: roberta_kFold_initial_lstm: Training : batch 3 Loss: 0.009843888074861029]
[2024-04-20 13:47:55,487: INFO: roberta_kFold_initial_lstm: Training : batch 4 Loss: 0.007366538516861938]
[2024-04-20 13:47:56,127: INFO: roberta_kFold_initial_lstm: Training : batch 5 Loss: 0.004307638698978886]
[2024-04-20 13:47:56,772: INFO: roberta_kFold_initial_lstm: Training : batch 6 Loss: 0.004211366123862165]
[2024-04-20 13:47:57,410: INFO: roberta_kFold_initial_lstm: Training : batch 7 Loss: 0.001776403621533148]
[2024-04-20 13:47:58,054: INFO: roberta_kFold_initial_lstm: Training : batch 8 Loss: 0.002283542949594529]
[2024-04-20 13:47:58,687: INFO: roberta_kFold_initial_lstm: Training : batch 9 Loss: 0.018177541400469906]
[2024-04-20 13:47:59,316: INFO: roberta_kFold_initial_lstm: Training : batch 10 Loss: 0.000339274046862222]
[2024-04-20 13:47:59,953: INFO: roberta_kFold_initial_lstm: Training : batch 11 Loss: 0.002400954868177697]
[2024-04-20 13:48:00,587: INFO: roberta_kFold_initial_lstm: Training : batch 12 Loss: 0.0024502966700705566]
[2024-04-20 13:48:01,222: INFO: roberta_kFold_initial_lstm: Training : batch 13 Loss: 0.0003308528293230689]
[2024-04-20 13:48:01,857: INFO: roberta_kFold_initial_lstm: Training : batch 14 Loss: 0.0006369669607782025]
[2024-04-20 13:48:02,493: INFO: roberta_kFold_initial_lstm: Training : batch 15 Loss: 0.0008820987857661552]
[2024-04-20 13:48:03,126: INFO: roberta_kFold_initial_lstm: Training : batch 16 Loss: 0.01197299343291409]
[2024-04-20 13:48:03,763: INFO: roberta_kFold_initial_lstm: Training : batch 17 Loss: 0.0004568064361690049]
[2024-04-20 13:48:04,401: INFO: roberta_kFold_initial_lstm: Training : batch 18 Loss: 0.007323904962882168]
[2024-04-20 13:48:05,042: INFO: roberta_kFold_initial_lstm: Training : batch 19 Loss: 0.007499647119599985]
[2024-04-20 13:48:05,682: INFO: roberta_kFold_initial_lstm: Training : batch 20 Loss: 0.003863031130111751]
[2024-04-20 13:48:06,320: INFO: roberta_kFold_initial_lstm: Training : batch 21 Loss: 0.0018663985890786164]
[2024-04-20 13:48:06,957: INFO: roberta_kFold_initial_lstm: Training : batch 22 Loss: 0.011030708883883985]
[2024-04-20 13:48:07,596: INFO: roberta_kFold_initial_lstm: Training : batch 23 Loss: 0.00022128329823553923]
[2024-04-20 13:48:08,231: INFO: roberta_kFold_initial_lstm: Training : batch 24 Loss: 9.190385909010159e-05]
[2024-04-20 13:48:08,894: INFO: roberta_kFold_initial_lstm: Training : batch 25 Loss: 0.005524220402561684]
[2024-04-20 13:48:09,547: INFO: roberta_kFold_initial_lstm: Training : batch 26 Loss: 0.0009367662591646468]
[2024-04-20 13:48:10,192: INFO: roberta_kFold_initial_lstm: Training : batch 27 Loss: 0.0009703859445640465]
[2024-04-20 13:48:10,842: INFO: roberta_kFold_initial_lstm: Training : batch 28 Loss: 0.009601791039871736]
[2024-04-20 13:48:11,487: INFO: roberta_kFold_initial_lstm: Training : batch 29 Loss: 0.013760425556263493]
[2024-04-20 13:48:12,128: INFO: roberta_kFold_initial_lstm: Training : batch 30 Loss: 0.00468156927131373]
[2024-04-20 13:48:12,761: INFO: roberta_kFold_initial_lstm: Training : batch 31 Loss: 0.008200680622775902]
[2024-04-20 13:48:13,401: INFO: roberta_kFold_initial_lstm: Training : batch 32 Loss: 0.0038781218228752285]
[2024-04-20 13:48:14,034: INFO: roberta_kFold_initial_lstm: Training : batch 33 Loss: 0.0004573243164634982]
[2024-04-20 13:48:14,673: INFO: roberta_kFold_initial_lstm: Training : batch 34 Loss: 0.004956726909609683]
[2024-04-20 13:48:15,309: INFO: roberta_kFold_initial_lstm: Training : batch 35 Loss: 0.0039242877437081205]
[2024-04-20 13:48:15,950: INFO: roberta_kFold_initial_lstm: Training : batch 36 Loss: 0.005712740085490601]
[2024-04-20 13:48:16,590: INFO: roberta_kFold_initial_lstm: Training : batch 37 Loss: 0.0009444605233209191]
[2024-04-20 13:48:17,230: INFO: roberta_kFold_initial_lstm: Training : batch 38 Loss: 0.00014294492895840062]
[2024-04-20 13:48:17,870: INFO: roberta_kFold_initial_lstm: Training : batch 39 Loss: 0.0001529125175722606]
[2024-04-20 13:48:18,513: INFO: roberta_kFold_initial_lstm: Training : batch 40 Loss: 0.0035047095182072475]
[2024-04-20 13:48:19,153: INFO: roberta_kFold_initial_lstm: Training : batch 41 Loss: 0.004045155001324824]
[2024-04-20 13:48:19,789: INFO: roberta_kFold_initial_lstm: Training : batch 42 Loss: 0.006290505739816201]
[2024-04-20 13:48:20,433: INFO: roberta_kFold_initial_lstm: Training : batch 43 Loss: 0.006642907832530251]
[2024-04-20 13:48:21,074: INFO: roberta_kFold_initial_lstm: Training : batch 44 Loss: 0.0020615604138557292]
[2024-04-20 13:48:21,727: INFO: roberta_kFold_initial_lstm: Training : batch 45 Loss: 6.115435179788752e-05]
[2024-04-20 13:48:22,373: INFO: roberta_kFold_initial_lstm: Training : batch 46 Loss: 0.00014999628422469194]
[2024-04-20 13:48:23,026: INFO: roberta_kFold_initial_lstm: Training : batch 47 Loss: 0.008728340533571532]
[2024-04-20 13:48:23,684: INFO: roberta_kFold_initial_lstm: Training : batch 48 Loss: 0.00564857719162057]
[2024-04-20 13:48:24,347: INFO: roberta_kFold_initial_lstm: Training : batch 49 Loss: 0.004280988547251621]
[2024-04-20 13:48:24,988: INFO: roberta_kFold_initial_lstm: Training : batch 50 Loss: 0.0034052011749536285]
[2024-04-20 13:48:25,627: INFO: roberta_kFold_initial_lstm: Training : batch 51 Loss: 0.005202713939376762]
[2024-04-20 13:48:26,266: INFO: roberta_kFold_initial_lstm: Training : batch 52 Loss: 0.014726694128247253]
[2024-04-20 13:48:26,903: INFO: roberta_kFold_initial_lstm: Training : batch 53 Loss: 0.0001609512251489704]
[2024-04-20 13:48:27,540: INFO: roberta_kFold_initial_lstm: Training : batch 54 Loss: 0.0007119414937053376]
[2024-04-20 13:48:28,186: INFO: roberta_kFold_initial_lstm: Training : batch 55 Loss: 0.0089768082286252]
[2024-04-20 13:48:28,829: INFO: roberta_kFold_initial_lstm: Training : batch 56 Loss: 0.001048866820866164]
[2024-04-20 13:48:29,473: INFO: roberta_kFold_initial_lstm: Training : batch 57 Loss: 0.001441083876939818]
[2024-04-20 13:48:30,109: INFO: roberta_kFold_initial_lstm: Training : batch 58 Loss: 0.002538748450031821]
[2024-04-20 13:48:30,751: INFO: roberta_kFold_initial_lstm: Training : batch 59 Loss: 0.0019212533883908322]
[2024-04-20 13:48:31,386: INFO: roberta_kFold_initial_lstm: Training : batch 60 Loss: 0.018544616944453786]
[2024-04-20 13:48:32,030: INFO: roberta_kFold_initial_lstm: Training : batch 61 Loss: 0.0028213308222263464]
[2024-04-20 13:48:32,669: INFO: roberta_kFold_initial_lstm: Training : batch 62 Loss: 0.0011156016822276595]
[2024-04-20 13:48:33,311: INFO: roberta_kFold_initial_lstm: Training : batch 63 Loss: 0.003194273746593509]
[2024-04-20 13:48:33,955: INFO: roberta_kFold_initial_lstm: Training : batch 64 Loss: 0.002160571352916794]
[2024-04-20 13:48:34,594: INFO: roberta_kFold_initial_lstm: Training : batch 65 Loss: 0.0008790758254049547]
[2024-04-20 13:48:35,237: INFO: roberta_kFold_initial_lstm: Training : batch 66 Loss: 0.0004833935841624266]
[2024-04-20 13:48:35,897: INFO: roberta_kFold_initial_lstm: Training : batch 67 Loss: 0.0010408110517276786]
[2024-04-20 13:48:36,541: INFO: roberta_kFold_initial_lstm: Training : batch 68 Loss: 0.0056417338441402546]
[2024-04-20 13:48:37,198: INFO: roberta_kFold_initial_lstm: Training : batch 69 Loss: 0.0009767579749329386]
[2024-04-20 13:48:37,847: INFO: roberta_kFold_initial_lstm: Training : batch 70 Loss: 0.006428601033567036]
[2024-04-20 13:48:38,486: INFO: roberta_kFold_initial_lstm: Training : batch 71 Loss: 0.005178884521809845]
[2024-04-20 13:48:39,131: INFO: roberta_kFold_initial_lstm: Training : batch 72 Loss: 0.0013951706216683507]
[2024-04-20 13:48:39,767: INFO: roberta_kFold_initial_lstm: Training : batch 73 Loss: 0.0027152180937693665]
[2024-04-20 13:48:40,409: INFO: roberta_kFold_initial_lstm: Training : batch 74 Loss: 0.0019509758661048705]
[2024-04-20 13:48:41,052: INFO: roberta_kFold_initial_lstm: Training : batch 75 Loss: 0.013194775008997163]
[2024-04-20 13:48:41,686: INFO: roberta_kFold_initial_lstm: Training : batch 76 Loss: 0.0037780139794285914]
[2024-04-20 13:48:42,328: INFO: roberta_kFold_initial_lstm: Training : batch 77 Loss: 0.01071203895222017]
[2024-04-20 13:48:42,970: INFO: roberta_kFold_initial_lstm: Training : batch 78 Loss: 0.004477004308548499]
[2024-04-20 13:48:43,615: INFO: roberta_kFold_initial_lstm: Training : batch 79 Loss: 0.004182346830394985]
[2024-04-20 13:48:44,258: INFO: roberta_kFold_initial_lstm: Training : batch 80 Loss: 0.0015727304269214032]
[2024-04-20 13:48:44,901: INFO: roberta_kFold_initial_lstm: Training : batch 81 Loss: 0.0006216431884230738]
[2024-04-20 13:48:45,546: INFO: roberta_kFold_initial_lstm: Training : batch 82 Loss: 0.0024060366233235116]
[2024-04-20 13:48:46,191: INFO: roberta_kFold_initial_lstm: Training : batch 83 Loss: 0.003320465640999627]
[2024-04-20 13:48:46,835: INFO: roberta_kFold_initial_lstm: Training : batch 84 Loss: 0.012542707623068545]
[2024-04-20 13:48:47,480: INFO: roberta_kFold_initial_lstm: Training : batch 85 Loss: 0.0026778547482209057]
[2024-04-20 13:48:48,142: INFO: roberta_kFold_initial_lstm: Training : batch 86 Loss: 0.006524407741308806]
[2024-04-20 13:48:48,801: INFO: roberta_kFold_initial_lstm: Training : batch 87 Loss: 0.0005130955596047054]
[2024-04-20 13:48:49,454: INFO: roberta_kFold_initial_lstm: Training : batch 88 Loss: 0.0010898569151673266]
[2024-04-20 13:48:50,113: INFO: roberta_kFold_initial_lstm: Training : batch 89 Loss: 0.0035893137408229345]
[2024-04-20 13:48:50,761: INFO: roberta_kFold_initial_lstm: Training : batch 90 Loss: 0.005156794360476923]
[2024-04-20 13:48:51,408: INFO: roberta_kFold_initial_lstm: Training : batch 91 Loss: 0.004044371493763781]
[2024-04-20 13:48:52,052: INFO: roberta_kFold_initial_lstm: Training : batch 92 Loss: 0.006458959728908363]
[2024-04-20 13:48:52,699: INFO: roberta_kFold_initial_lstm: Training : batch 93 Loss: 0.008676497608438378]
[2024-04-20 13:48:53,347: INFO: roberta_kFold_initial_lstm: Training : batch 94 Loss: 0.003549409405199858]
[2024-04-20 13:48:53,993: INFO: roberta_kFold_initial_lstm: Training : batch 95 Loss: 0.0011287399003549645]
[2024-04-20 13:48:54,642: INFO: roberta_kFold_initial_lstm: Training : batch 96 Loss: 0.0013133582868921705]
[2024-04-20 13:48:55,285: INFO: roberta_kFold_initial_lstm: Training : batch 97 Loss: 0.0018010124726588808]
[2024-04-20 13:48:55,931: INFO: roberta_kFold_initial_lstm: Training : batch 98 Loss: 0.010855464248693006]
[2024-04-20 13:48:56,577: INFO: roberta_kFold_initial_lstm: Training : batch 99 Loss: 0.00046491048139773365]
[2024-04-20 13:48:57,226: INFO: roberta_kFold_initial_lstm: Training : batch 100 Loss: 0.0015333230962573277]
[2024-04-20 13:48:57,873: INFO: roberta_kFold_initial_lstm: Training : batch 101 Loss: 0.0034717467766410067]
[2024-04-20 13:48:58,520: INFO: roberta_kFold_initial_lstm: Training : batch 102 Loss: 0.008108203938720589]
[2024-04-20 13:48:59,169: INFO: roberta_kFold_initial_lstm: Training : batch 103 Loss: 0.010209388159797694]
[2024-04-20 13:48:59,819: INFO: roberta_kFold_initial_lstm: Training : batch 104 Loss: 0.004355702200022471]
[2024-04-20 13:49:00,472: INFO: roberta_kFold_initial_lstm: Training : batch 105 Loss: 0.002250624973993054]
[2024-04-20 13:49:01,122: INFO: roberta_kFold_initial_lstm: Training : batch 106 Loss: 0.004330227896319997]
[2024-04-20 13:49:01,799: INFO: roberta_kFold_initial_lstm: Training : batch 107 Loss: 0.006503859906374608]
[2024-04-20 13:49:02,465: INFO: roberta_kFold_initial_lstm: Training : batch 108 Loss: 0.005744398143581227]
[2024-04-20 13:49:03,118: INFO: roberta_kFold_initial_lstm: Training : batch 109 Loss: 0.0003267199675951994]
[2024-04-20 13:49:03,778: INFO: roberta_kFold_initial_lstm: Training : batch 110 Loss: 0.0002841655202026999]
[2024-04-20 13:49:04,425: INFO: roberta_kFold_initial_lstm: Training : batch 111 Loss: 0.006963821351673746]
[2024-04-20 13:49:05,067: INFO: roberta_kFold_initial_lstm: Training : batch 112 Loss: 0.0010647681854074728]
[2024-04-20 13:49:05,713: INFO: roberta_kFold_initial_lstm: Training : batch 113 Loss: 0.0030088194285119146]
[2024-04-20 13:49:06,360: INFO: roberta_kFold_initial_lstm: Training : batch 114 Loss: 0.0009628068077701472]
[2024-04-20 13:49:07,008: INFO: roberta_kFold_initial_lstm: Training : batch 115 Loss: 0.001768312286427656]
[2024-04-20 13:49:07,656: INFO: roberta_kFold_initial_lstm: Training : batch 116 Loss: 0.020693538290062527]
[2024-04-20 13:49:08,305: INFO: roberta_kFold_initial_lstm: Training : batch 117 Loss: 0.0023367121859019227]
[2024-04-20 13:49:08,947: INFO: roberta_kFold_initial_lstm: Training : batch 118 Loss: 0.013717197477471835]
[2024-04-20 13:49:09,593: INFO: roberta_kFold_initial_lstm: Training : batch 119 Loss: 0.00651744366308021]
[2024-04-20 13:49:10,238: INFO: roberta_kFold_initial_lstm: Training : batch 120 Loss: 0.005785874890523253]
[2024-04-20 13:49:10,887: INFO: roberta_kFold_initial_lstm: Training : batch 121 Loss: 0.00021927917278421937]
[2024-04-20 13:49:11,534: INFO: roberta_kFold_initial_lstm: Training : batch 122 Loss: 0.005190892265357043]
[2024-04-20 13:49:12,182: INFO: roberta_kFold_initial_lstm: Training : batch 123 Loss: 0.0036600877280239343]
[2024-04-20 13:49:12,831: INFO: roberta_kFold_initial_lstm: Training : batch 124 Loss: 0.005243175838775035]
[2024-04-20 13:49:13,482: INFO: roberta_kFold_initial_lstm: Training : batch 125 Loss: 0.002553525416863628]
[2024-04-20 13:49:14,130: INFO: roberta_kFold_initial_lstm: Training : batch 126 Loss: 0.004051475011689333]
[2024-04-20 13:49:14,779: INFO: roberta_kFold_initial_lstm: Training : batch 127 Loss: 0.009940513254140984]
[2024-04-20 13:49:15,445: INFO: roberta_kFold_initial_lstm: Training : batch 128 Loss: 0.0024565323165002644]
[2024-04-20 13:49:16,102: INFO: roberta_kFold_initial_lstm: Training : batch 129 Loss: 0.0007125984245612287]
[2024-04-20 13:49:16,754: INFO: roberta_kFold_initial_lstm: Training : batch 130 Loss: 0.001722650456868942]
[2024-04-20 13:49:17,410: INFO: roberta_kFold_initial_lstm: Training : batch 131 Loss: 0.00847046764531875]
[2024-04-20 13:49:18,056: INFO: roberta_kFold_initial_lstm: Training : batch 132 Loss: 0.0020166657713795895]
[2024-04-20 13:49:18,704: INFO: roberta_kFold_initial_lstm: Training : batch 133 Loss: 0.0030144001004498546]
[2024-04-20 13:49:19,351: INFO: roberta_kFold_initial_lstm: Training : batch 134 Loss: 0.0006087089362004808]
[2024-04-20 13:49:20,000: INFO: roberta_kFold_initial_lstm: Training : batch 135 Loss: 0.0026081573839961034]
[2024-04-20 13:49:20,648: INFO: roberta_kFold_initial_lstm: Training : batch 136 Loss: 0.0077879714383877145]
[2024-04-20 13:49:21,294: INFO: roberta_kFold_initial_lstm: Training : batch 137 Loss: 0.00254100087287352]
[2024-04-20 13:49:21,943: INFO: roberta_kFold_initial_lstm: Training : batch 138 Loss: 0.0006511837549038499]
[2024-04-20 13:49:22,589: INFO: roberta_kFold_initial_lstm: Training : batch 139 Loss: 0.003789795259169122]
[2024-04-20 13:49:23,238: INFO: roberta_kFold_initial_lstm: Training : batch 140 Loss: 0.009942227573378374]
[2024-04-20 13:49:23,885: INFO: roberta_kFold_initial_lstm: Training : batch 141 Loss: 3.194860342877708e-05]
[2024-04-20 13:49:24,532: INFO: roberta_kFold_initial_lstm: Training : batch 142 Loss: 0.006033232463024439]
[2024-04-20 13:49:25,181: INFO: roberta_kFold_initial_lstm: Training : batch 143 Loss: 0.0010095388724166725]
[2024-04-20 13:49:25,826: INFO: roberta_kFold_initial_lstm: Training : batch 144 Loss: 0.011365831457537714]
[2024-04-20 13:49:26,481: INFO: roberta_kFold_initial_lstm: Training : batch 145 Loss: 0.0049334679176363415]
[2024-04-20 13:49:27,123: INFO: roberta_kFold_initial_lstm: Training : batch 146 Loss: 0.00038092539980742095]
[2024-04-20 13:49:27,784: INFO: roberta_kFold_initial_lstm: Training : batch 147 Loss: 0.0020246109893826292]
[2024-04-20 13:49:28,447: INFO: roberta_kFold_initial_lstm: Training : batch 148 Loss: 0.005779982845992083]
[2024-04-20 13:49:29,102: INFO: roberta_kFold_initial_lstm: Training : batch 149 Loss: 0.008784424339955604]
[2024-04-20 13:49:29,761: INFO: roberta_kFold_initial_lstm: Training : batch 150 Loss: 0.01695089685986648]
[2024-04-20 13:49:30,415: INFO: roberta_kFold_initial_lstm: Training : batch 151 Loss: 0.001727902612932328]
[2024-04-20 13:49:31,064: INFO: roberta_kFold_initial_lstm: Training : batch 152 Loss: 0.003034041924963147]
[2024-04-20 13:49:31,714: INFO: roberta_kFold_initial_lstm: Training : batch 153 Loss: 0.004001251076280348]
[2024-04-20 13:49:32,365: INFO: roberta_kFold_initial_lstm: Training : batch 154 Loss: 0.0004149290097283646]
[2024-04-20 13:49:33,016: INFO: roberta_kFold_initial_lstm: Training : batch 155 Loss: 0.003228737026182469]
[2024-04-20 13:49:33,665: INFO: roberta_kFold_initial_lstm: Training : batch 156 Loss: 0.0018509589416142033]
[2024-04-20 13:49:34,312: INFO: roberta_kFold_initial_lstm: Training : batch 157 Loss: 0.004921691252418394]
[2024-04-20 13:49:34,957: INFO: roberta_kFold_initial_lstm: Training : batch 158 Loss: 0.011926365849285041]
[2024-04-20 13:49:35,609: INFO: roberta_kFold_initial_lstm: Training : batch 159 Loss: 0.0009271945690072303]
[2024-04-20 13:49:36,259: INFO: roberta_kFold_initial_lstm: Training : batch 160 Loss: 0.00136065032072576]
[2024-04-20 13:49:36,907: INFO: roberta_kFold_initial_lstm: Training : batch 161 Loss: 0.006349140383154394]
[2024-04-20 13:49:37,555: INFO: roberta_kFold_initial_lstm: Training : batch 162 Loss: 0.00078680601318647]
[2024-04-20 13:49:38,205: INFO: roberta_kFold_initial_lstm: Training : batch 163 Loss: 0.0010975932873194282]
[2024-04-20 13:49:38,847: INFO: roberta_kFold_initial_lstm: Training : batch 164 Loss: 0.0008425285826917666]
[2024-04-20 13:49:39,491: INFO: roberta_kFold_initial_lstm: Training : batch 165 Loss: 0.004069578539982275]
[2024-04-20 13:49:40,143: INFO: roberta_kFold_initial_lstm: Training : batch 166 Loss: 0.0015161464504151966]
[2024-04-20 13:49:40,801: INFO: roberta_kFold_initial_lstm: Training : batch 167 Loss: 0.002849833805568724]
[2024-04-20 13:49:41,464: INFO: roberta_kFold_initial_lstm: Training : batch 168 Loss: 0.00197316322693933]
[2024-04-20 13:49:42,136: INFO: roberta_kFold_initial_lstm: Training : batch 169 Loss: 0.002449153355568277]
[2024-04-20 13:49:42,800: INFO: roberta_kFold_initial_lstm: Training : batch 170 Loss: 0.013621609761431999]
[2024-04-20 13:49:43,452: INFO: roberta_kFold_initial_lstm: Training : batch 171 Loss: 0.0055367448377440145]
[2024-04-20 13:49:44,102: INFO: roberta_kFold_initial_lstm: Training : batch 172 Loss: 0.009542864722104518]
[2024-04-20 13:49:44,743: INFO: roberta_kFold_initial_lstm: Training : batch 173 Loss: 0.0035817936037204493]
[2024-04-20 13:49:45,394: INFO: roberta_kFold_initial_lstm: Training : batch 174 Loss: 0.009762826236157554]
[2024-04-20 13:49:46,047: INFO: roberta_kFold_initial_lstm: Training : batch 175 Loss: 0.0018581764129705542]
[2024-04-20 13:49:46,690: INFO: roberta_kFold_initial_lstm: Training : batch 176 Loss: 0.009468309579118612]
[2024-04-20 13:49:47,341: INFO: roberta_kFold_initial_lstm: Training : batch 177 Loss: 0.0022621952512529558]
[2024-04-20 13:49:47,984: INFO: roberta_kFold_initial_lstm: Training : batch 178 Loss: 0.0020834614307255286]
[2024-04-20 13:49:48,635: INFO: roberta_kFold_initial_lstm: Training : batch 179 Loss: 0.0005093566414105388]
[2024-04-20 13:49:49,289: INFO: roberta_kFold_initial_lstm: Training : batch 180 Loss: 0.010017849245267878]
[2024-04-20 13:49:49,933: INFO: roberta_kFold_initial_lstm: Training : batch 181 Loss: 0.0012880242370384614]
[2024-04-20 13:49:50,583: INFO: roberta_kFold_initial_lstm: Training : batch 182 Loss: 0.0036113255862355582]
[2024-04-20 13:49:51,232: INFO: roberta_kFold_initial_lstm: Training : batch 183 Loss: 0.0004905835220637133]
[2024-04-20 13:49:51,876: INFO: roberta_kFold_initial_lstm: Training : batch 184 Loss: 0.0008995784610081868]
[2024-04-20 13:49:52,524: INFO: roberta_kFold_initial_lstm: Training : batch 185 Loss: 0.0016780758741348288]
[2024-04-20 13:49:53,168: INFO: roberta_kFold_initial_lstm: Training : batch 186 Loss: 0.0014675143333092065]
[2024-04-20 13:49:53,823: INFO: roberta_kFold_initial_lstm: Training : batch 187 Loss: 0.004843581945187709]
[2024-04-20 13:49:54,482: INFO: roberta_kFold_initial_lstm: Training : batch 188 Loss: 0.001371376988247826]
[2024-04-20 13:49:55,138: INFO: roberta_kFold_initial_lstm: Training : batch 189 Loss: 0.015080906838879554]
[2024-04-20 13:49:55,792: INFO: roberta_kFold_initial_lstm: Training : batch 190 Loss: 0.003665436684978576]
[2024-04-20 13:49:56,452: INFO: roberta_kFold_initial_lstm: Training : batch 191 Loss: 0.00025991793441807945]
[2024-04-20 13:49:57,103: INFO: roberta_kFold_initial_lstm: Training : batch 192 Loss: 0.0005618033216760731]
[2024-04-20 13:49:57,753: INFO: roberta_kFold_initial_lstm: Training : batch 193 Loss: 0.0007629189038334229]
[2024-04-20 13:49:58,403: INFO: roberta_kFold_initial_lstm: Training : batch 194 Loss: 0.0017789474285153557]
[2024-04-20 13:49:59,055: INFO: roberta_kFold_initial_lstm: Training : batch 195 Loss: 0.015599366423742135]
[2024-04-20 13:49:59,702: INFO: roberta_kFold_initial_lstm: Training : batch 196 Loss: 0.0032967042544696265]
[2024-04-20 13:50:00,351: INFO: roberta_kFold_initial_lstm: Training : batch 197 Loss: 0.0085816441816026]
[2024-04-20 13:50:01,002: INFO: roberta_kFold_initial_lstm: Training : batch 198 Loss: 0.010762074581288594]
[2024-04-20 13:50:01,649: INFO: roberta_kFold_initial_lstm: Training : batch 199 Loss: 0.0008294221790787304]
[2024-04-20 13:50:02,301: INFO: roberta_kFold_initial_lstm: Training : batch 200 Loss: 0.0037131110495298757]
[2024-04-20 13:50:02,955: INFO: roberta_kFold_initial_lstm: Training : batch 201 Loss: 0.0027910827036369784]
[2024-04-20 13:50:03,607: INFO: roberta_kFold_initial_lstm: Training : batch 202 Loss: 0.0028990053573359252]
[2024-04-20 13:50:04,260: INFO: roberta_kFold_initial_lstm: Training : batch 203 Loss: 0.010666591900810653]
[2024-04-20 13:50:04,911: INFO: roberta_kFold_initial_lstm: Training : batch 204 Loss: 3.581771677561304e-05]
[2024-04-20 13:50:05,559: INFO: roberta_kFold_initial_lstm: Training : batch 205 Loss: 0.020936203085417188]
[2024-04-20 13:50:06,207: INFO: roberta_kFold_initial_lstm: Training : batch 206 Loss: 0.0050811623051960075]
[2024-04-20 13:50:06,865: INFO: roberta_kFold_initial_lstm: Training : batch 207 Loss: 0.0037169346473978327]
[2024-04-20 13:50:07,544: INFO: roberta_kFold_initial_lstm: Training : batch 208 Loss: 0.0021166264806239273]
[2024-04-20 13:50:08,206: INFO: roberta_kFold_initial_lstm: Training : batch 209 Loss: 0.002622355757275374]
[2024-04-20 13:50:08,855: INFO: roberta_kFold_initial_lstm: Training : batch 210 Loss: 0.006946751240308834]
[2024-04-20 13:50:09,525: INFO: roberta_kFold_initial_lstm: Training : batch 211 Loss: 0.009662177651613736]
[2024-04-20 13:50:10,178: INFO: roberta_kFold_initial_lstm: Training : batch 212 Loss: 0.004085174100328302]
[2024-04-20 13:50:10,827: INFO: roberta_kFold_initial_lstm: Training : batch 213 Loss: 0.0073659849906988735]
[2024-04-20 13:50:11,481: INFO: roberta_kFold_initial_lstm: Training : batch 214 Loss: 0.011672235285216657]
[2024-04-20 13:50:12,132: INFO: roberta_kFold_initial_lstm: Training : batch 215 Loss: 0.0021689732259188442]
[2024-04-20 13:50:12,781: INFO: roberta_kFold_initial_lstm: Training : batch 216 Loss: 0.006402547361173109]
[2024-04-20 13:50:13,439: INFO: roberta_kFold_initial_lstm: Training : batch 217 Loss: 0.00040547929468254853]
[2024-04-20 13:50:14,089: INFO: roberta_kFold_initial_lstm: Training : batch 218 Loss: 0.0007390505721915867]
[2024-04-20 13:50:14,744: INFO: roberta_kFold_initial_lstm: Training : batch 219 Loss: 0.003886172279101988]
[2024-04-20 13:50:15,396: INFO: roberta_kFold_initial_lstm: Training : batch 220 Loss: 0.006106640397940845]
[2024-04-20 13:50:16,048: INFO: roberta_kFold_initial_lstm: Training : batch 221 Loss: 0.003321480817303002]
[2024-04-20 13:50:16,701: INFO: roberta_kFold_initial_lstm: Training : batch 222 Loss: 0.004378023006288131]
[2024-04-20 13:50:17,357: INFO: roberta_kFold_initial_lstm: Training : batch 223 Loss: 0.0049066183641109885]
[2024-04-20 13:50:18,010: INFO: roberta_kFold_initial_lstm: Training : batch 224 Loss: 0.0021354389052029832]
[2024-04-20 13:50:18,658: INFO: roberta_kFold_initial_lstm: Training : batch 225 Loss: 0.004908741880101491]
[2024-04-20 13:50:19,312: INFO: roberta_kFold_initial_lstm: Training : batch 226 Loss: 0.008079604685405159]
[2024-04-20 13:50:19,982: INFO: roberta_kFold_initial_lstm: Training : batch 227 Loss: 0.0011624386893019723]
[2024-04-20 13:50:20,647: INFO: roberta_kFold_initial_lstm: Training : batch 228 Loss: 0.004053418107077211]
[2024-04-20 13:50:21,306: INFO: roberta_kFold_initial_lstm: Training : batch 229 Loss: 0.0023004474197384824]
[2024-04-20 13:50:21,974: INFO: roberta_kFold_initial_lstm: Training : batch 230 Loss: 0.001838956915030241]
[2024-04-20 13:50:22,636: INFO: roberta_kFold_initial_lstm: Training : batch 231 Loss: 0.0056359663350681755]
[2024-04-20 13:50:23,284: INFO: roberta_kFold_initial_lstm: Training : batch 232 Loss: 0.0021725712121770137]
[2024-04-20 13:50:23,939: INFO: roberta_kFold_initial_lstm: Training : batch 233 Loss: 0.0029378235961736144]
[2024-04-20 13:50:24,595: INFO: roberta_kFold_initial_lstm: Training : batch 234 Loss: 0.00987074200037948]
[2024-04-20 13:50:25,247: INFO: roberta_kFold_initial_lstm: Training : batch 235 Loss: 0.006043278809789989]
[2024-04-20 13:50:25,902: INFO: roberta_kFold_initial_lstm: Training : batch 236 Loss: 0.004833076958140207]
[2024-04-20 13:50:26,553: INFO: roberta_kFold_initial_lstm: Training : batch 237 Loss: 0.0008211591942117806]
[2024-04-20 13:50:27,207: INFO: roberta_kFold_initial_lstm: Training : batch 238 Loss: 0.0005528232532202909]
[2024-04-20 13:50:27,857: INFO: roberta_kFold_initial_lstm: Training : batch 239 Loss: 0.003527328049859596]
[2024-04-20 13:50:28,509: INFO: roberta_kFold_initial_lstm: Training : batch 240 Loss: 0.0071180132477956706]
[2024-04-20 13:50:29,158: INFO: roberta_kFold_initial_lstm: Training : batch 241 Loss: 0.006119539844207284]
[2024-04-20 13:50:29,805: INFO: roberta_kFold_initial_lstm: Training : batch 242 Loss: 0.004986742611829955]
[2024-04-20 13:50:30,454: INFO: roberta_kFold_initial_lstm: Training : batch 243 Loss: 0.00892850912838748]
[2024-04-20 13:50:31,103: INFO: roberta_kFold_initial_lstm: Training : batch 244 Loss: 0.008030580548657594]
[2024-04-20 13:50:31,753: INFO: roberta_kFold_initial_lstm: Training : batch 245 Loss: 0.016208843997398813]
[2024-04-20 13:50:32,407: INFO: roberta_kFold_initial_lstm: Training : batch 246 Loss: 3.2265251105779104e-05]
[2024-04-20 13:50:33,069: INFO: roberta_kFold_initial_lstm: Training : batch 247 Loss: 0.003140432294050308]
[2024-04-20 13:50:33,731: INFO: roberta_kFold_initial_lstm: Training : batch 248 Loss: 0.005071956532011323]
[2024-04-20 13:50:34,391: INFO: roberta_kFold_initial_lstm: Training : batch 249 Loss: 0.005925717809659073]
[2024-04-20 13:50:35,049: INFO: roberta_kFold_initial_lstm: Training : batch 250 Loss: 0.03665922601784707]
[2024-04-20 13:50:35,724: INFO: roberta_kFold_initial_lstm: Training : batch 251 Loss: 0.000654741586983463]
[2024-04-20 13:50:36,384: INFO: roberta_kFold_initial_lstm: Training : batch 252 Loss: 0.014431166244824286]
[2024-04-20 13:50:37,025: INFO: roberta_kFold_initial_lstm: Training : batch 253 Loss: 0.006882661837096406]
[2024-04-20 13:50:37,682: INFO: roberta_kFold_initial_lstm: Training : batch 254 Loss: 0.0036625243209896454]
[2024-04-20 13:50:38,335: INFO: roberta_kFold_initial_lstm: Training : batch 255 Loss: 0.01173961654942325]
[2024-04-20 13:50:38,986: INFO: roberta_kFold_initial_lstm: Training : batch 256 Loss: 0.00365866539252659]
[2024-04-20 13:50:39,640: INFO: roberta_kFold_initial_lstm: Training : batch 257 Loss: 0.0032230057892482923]
[2024-04-20 13:50:40,289: INFO: roberta_kFold_initial_lstm: Training : batch 258 Loss: 0.0006477990576813355]
[2024-04-20 13:50:40,943: INFO: roberta_kFold_initial_lstm: Training : batch 259 Loss: 0.00676035412235377]
[2024-04-20 13:50:41,596: INFO: roberta_kFold_initial_lstm: Training : batch 260 Loss: 0.0013558777225194016]
[2024-04-20 13:50:42,251: INFO: roberta_kFold_initial_lstm: Training : batch 261 Loss: 0.007284905838668646]
[2024-04-20 13:50:42,904: INFO: roberta_kFold_initial_lstm: Training : batch 262 Loss: 0.004086192293923216]
[2024-04-20 13:50:43,555: INFO: roberta_kFold_initial_lstm: Training : batch 263 Loss: 0.001837094033387916]
[2024-04-20 13:50:44,205: INFO: roberta_kFold_initial_lstm: Training : batch 264 Loss: 0.005754755360240197]
[2024-04-20 13:50:44,853: INFO: roberta_kFold_initial_lstm: Training : batch 265 Loss: 0.002128686311523877]
[2024-04-20 13:50:45,499: INFO: roberta_kFold_initial_lstm: Training : batch 266 Loss: 0.010709978830516494]
[2024-04-20 13:50:46,157: INFO: roberta_kFold_initial_lstm: Training : batch 267 Loss: 0.0019803008372923383]
[2024-04-20 13:50:46,818: INFO: roberta_kFold_initial_lstm: Training : batch 268 Loss: 0.002910704484631549]
[2024-04-20 13:50:47,477: INFO: roberta_kFold_initial_lstm: Training : batch 269 Loss: 0.00037440042237371195]
[2024-04-20 13:50:48,141: INFO: roberta_kFold_initial_lstm: Training : batch 270 Loss: 0.007323101050294242]
[2024-04-20 13:50:48,803: INFO: roberta_kFold_initial_lstm: Training : batch 271 Loss: 0.006152590652288315]
[2024-04-20 13:50:49,457: INFO: roberta_kFold_initial_lstm: Training : batch 272 Loss: 0.0023238670468035336]
[2024-04-20 13:50:50,106: INFO: roberta_kFold_initial_lstm: Training : batch 273 Loss: 0.00040789760142732125]
[2024-04-20 13:50:50,754: INFO: roberta_kFold_initial_lstm: Training : batch 274 Loss: 0.0022179699488319524]
[2024-04-20 13:50:51,406: INFO: roberta_kFold_initial_lstm: Training : batch 275 Loss: 0.0010352401907852697]
[2024-04-20 13:50:52,057: INFO: roberta_kFold_initial_lstm: Training : batch 276 Loss: 0.005588870792045451]
[2024-04-20 13:50:52,710: INFO: roberta_kFold_initial_lstm: Training : batch 277 Loss: 0.004027487058267993]
[2024-04-20 13:50:53,364: INFO: roberta_kFold_initial_lstm: Training : batch 278 Loss: 0.013168179645068608]
[2024-04-20 13:50:54,016: INFO: roberta_kFold_initial_lstm: Training : batch 279 Loss: 0.010604280254090024]
[2024-04-20 13:50:54,666: INFO: roberta_kFold_initial_lstm: Training : batch 280 Loss: 0.006760725392361522]
[2024-04-20 13:50:55,317: INFO: roberta_kFold_initial_lstm: Training : batch 281 Loss: 0.00608956321264554]
[2024-04-20 13:50:55,971: INFO: roberta_kFold_initial_lstm: Training : batch 282 Loss: 0.002886215547835541]
[2024-04-20 13:50:56,625: INFO: roberta_kFold_initial_lstm: Training : batch 283 Loss: 0.000834324811410355]
[2024-04-20 13:50:57,282: INFO: roberta_kFold_initial_lstm: Training : batch 284 Loss: 0.0031027040752233306]
[2024-04-20 13:50:57,936: INFO: roberta_kFold_initial_lstm: Training : batch 285 Loss: 0.00047795316970947253]
[2024-04-20 13:50:58,589: INFO: roberta_kFold_initial_lstm: Training : batch 286 Loss: 0.006724263431648284]
[2024-04-20 13:50:59,244: INFO: roberta_kFold_initial_lstm: Training : batch 287 Loss: 0.05958735150130861]
[2024-04-20 13:50:59,916: INFO: roberta_kFold_initial_lstm: Training : batch 288 Loss: 0.005014277678096083]
[2024-04-20 13:51:00,584: INFO: roberta_kFold_initial_lstm: Training : batch 289 Loss: 0.0007089536624358275]
[2024-04-20 13:51:01,244: INFO: roberta_kFold_initial_lstm: Training : batch 290 Loss: 0.001691581730912585]
[2024-04-20 13:51:01,907: INFO: roberta_kFold_initial_lstm: Training : batch 291 Loss: 0.0023651684001763525]
[2024-04-20 13:51:02,566: INFO: roberta_kFold_initial_lstm: Training : batch 292 Loss: 0.005074940693006674]
[2024-04-20 13:51:03,219: INFO: roberta_kFold_initial_lstm: Training : batch 293 Loss: 0.0028075640704164667]
[2024-04-20 13:51:03,874: INFO: roberta_kFold_initial_lstm: Training : batch 294 Loss: 0.0036904175769989457]
[2024-04-20 13:51:04,530: INFO: roberta_kFold_initial_lstm: Training : batch 295 Loss: 0.001928161354126983]
[2024-04-20 13:51:05,182: INFO: roberta_kFold_initial_lstm: Training : batch 296 Loss: 0.010432921796819662]
[2024-04-20 13:51:05,836: INFO: roberta_kFold_initial_lstm: Training : batch 297 Loss: 0.0011168774476287523]
[2024-04-20 13:51:06,488: INFO: roberta_kFold_initial_lstm: Training : batch 298 Loss: 0.00020243872987393745]
[2024-04-20 13:51:07,142: INFO: roberta_kFold_initial_lstm: Training : batch 299 Loss: 0.0029272675824255088]
[2024-04-20 13:51:07,795: INFO: roberta_kFold_initial_lstm: Training : batch 300 Loss: 0.0004117864579275507]
[2024-04-20 13:51:08,444: INFO: roberta_kFold_initial_lstm: Training : batch 301 Loss: 0.002126522274585041]
[2024-04-20 13:51:09,097: INFO: roberta_kFold_initial_lstm: Training : batch 302 Loss: 0.004139829330412959]
[2024-04-20 13:51:09,749: INFO: roberta_kFold_initial_lstm: Training : batch 303 Loss: 0.005062630190932221]
[2024-04-20 13:51:10,404: INFO: roberta_kFold_initial_lstm: Training : batch 304 Loss: 0.003769300524310457]
[2024-04-20 13:51:11,059: INFO: roberta_kFold_initial_lstm: Training : batch 305 Loss: 0.003497751544585963]
[2024-04-20 13:51:11,710: INFO: roberta_kFold_initial_lstm: Training : batch 306 Loss: 0.013433251182776329]
[2024-04-20 13:51:12,368: INFO: roberta_kFold_initial_lstm: Training : batch 307 Loss: 0.003130460332309338]
[2024-04-20 13:51:13,022: INFO: roberta_kFold_initial_lstm: Training : batch 308 Loss: 0.004467986574922083]
[2024-04-20 13:51:13,680: INFO: roberta_kFold_initial_lstm: Training : batch 309 Loss: 0.0027800709907622716]
[2024-04-20 13:51:14,346: INFO: roberta_kFold_initial_lstm: Training : batch 310 Loss: 0.0034951859869808764]
[2024-04-20 13:51:15,011: INFO: roberta_kFold_initial_lstm: Training : batch 311 Loss: 0.0021304178243316714]
[2024-04-20 13:51:15,675: INFO: roberta_kFold_initial_lstm: Training : batch 312 Loss: 0.012128788714252218]
[2024-04-20 13:51:16,331: INFO: roberta_kFold_initial_lstm: Training : batch 313 Loss: 0.005351031130512317]
[2024-04-20 13:51:16,981: INFO: roberta_kFold_initial_lstm: Training : batch 314 Loss: 0.0029142499585049766]
[2024-04-20 13:51:17,633: INFO: roberta_kFold_initial_lstm: Training : batch 315 Loss: 0.011387690975388142]
[2024-04-20 13:51:18,288: INFO: roberta_kFold_initial_lstm: Training : batch 316 Loss: 0.003801141033647342]
[2024-04-20 13:51:18,942: INFO: roberta_kFold_initial_lstm: Training : batch 317 Loss: 0.0016705972713497643]
[2024-04-20 13:51:19,597: INFO: roberta_kFold_initial_lstm: Training : batch 318 Loss: 0.0030044965462598093]
[2024-04-20 13:51:20,248: INFO: roberta_kFold_initial_lstm: Training : batch 319 Loss: 0.00872150524872091]
[2024-04-20 13:51:20,898: INFO: roberta_kFold_initial_lstm: Training : batch 320 Loss: 0.013320064960405689]
[2024-04-20 13:51:21,554: INFO: roberta_kFold_initial_lstm: Training : batch 321 Loss: 0.007009681155887163]
[2024-04-20 13:51:22,206: INFO: roberta_kFold_initial_lstm: Training : batch 322 Loss: 0.0045283133953766645]
[2024-04-20 13:51:22,860: INFO: roberta_kFold_initial_lstm: Training : batch 323 Loss: 0.00511606966932407]
[2024-04-20 13:51:23,513: INFO: roberta_kFold_initial_lstm: Training : batch 324 Loss: 0.0033093952624624686]
[2024-04-20 13:51:24,166: INFO: roberta_kFold_initial_lstm: Training : batch 325 Loss: 0.01826346282278475]
[2024-04-20 13:51:24,821: INFO: roberta_kFold_initial_lstm: Training : batch 326 Loss: 0.006494205849050389]
[2024-04-20 13:51:25,472: INFO: roberta_kFold_initial_lstm: Training : batch 327 Loss: 0.004801614281002877]
[2024-04-20 13:51:26,127: INFO: roberta_kFold_initial_lstm: Training : batch 328 Loss: 0.00010793142695796629]
[2024-04-20 13:51:26,798: INFO: roberta_kFold_initial_lstm: Training : batch 329 Loss: 0.0019476388075685314]
[2024-04-20 13:51:27,460: INFO: roberta_kFold_initial_lstm: Training : batch 330 Loss: 0.002690421271630596]
[2024-04-20 13:51:28,143: INFO: roberta_kFold_initial_lstm: Training : batch 331 Loss: 0.002181604856628553]
[2024-04-20 13:51:28,810: INFO: roberta_kFold_initial_lstm: Training : batch 332 Loss: 0.004394111475304842]
[2024-04-20 13:51:29,463: INFO: roberta_kFold_initial_lstm: Training : batch 333 Loss: 0.0013800482840672942]
[2024-04-20 13:51:30,119: INFO: roberta_kFold_initial_lstm: Training : batch 334 Loss: 0.0016776152176622827]
[2024-04-20 13:51:30,776: INFO: roberta_kFold_initial_lstm: Training : batch 335 Loss: 0.00651002437944395]
[2024-04-20 13:51:31,425: INFO: roberta_kFold_initial_lstm: Training : batch 336 Loss: 0.0025291442439405116]
[2024-04-20 13:51:32,083: INFO: roberta_kFold_initial_lstm: Training : batch 337 Loss: 0.00599241959257543]
[2024-04-20 13:51:32,735: INFO: roberta_kFold_initial_lstm: Training : batch 338 Loss: 0.0016591870072319409]
[2024-04-20 13:51:33,389: INFO: roberta_kFold_initial_lstm: Training : batch 339 Loss: 0.0017910618591730214]
[2024-04-20 13:51:34,046: INFO: roberta_kFold_initial_lstm: Training : batch 340 Loss: 0.011191281882159022]
[2024-04-20 13:51:34,696: INFO: roberta_kFold_initial_lstm: Training : batch 341 Loss: 0.0006314783640054421]
[2024-04-20 13:51:35,350: INFO: roberta_kFold_initial_lstm: Training : batch 342 Loss: 0.010062578461889177]
[2024-04-20 13:51:36,001: INFO: roberta_kFold_initial_lstm: Training : batch 343 Loss: 0.0071835150429309875]
[2024-04-20 13:51:36,657: INFO: roberta_kFold_initial_lstm: Training : batch 344 Loss: 0.003267300027908805]
[2024-04-20 13:51:37,317: INFO: roberta_kFold_initial_lstm: Training : batch 345 Loss: 0.0012793389612671166]
[2024-04-20 13:51:37,971: INFO: roberta_kFold_initial_lstm: Training : batch 346 Loss: 0.013316877785834349]
[2024-04-20 13:51:38,625: INFO: roberta_kFold_initial_lstm: Training : batch 347 Loss: 0.0028542419627587395]
[2024-04-20 13:51:39,285: INFO: roberta_kFold_initial_lstm: Training : batch 348 Loss: 0.006753907524311419]
[2024-04-20 13:51:39,964: INFO: roberta_kFold_initial_lstm: Training : batch 349 Loss: 0.002537341944968551]
[2024-04-20 13:51:40,629: INFO: roberta_kFold_initial_lstm: Training : batch 350 Loss: 0.0014468474897689492]
[2024-04-20 13:51:41,280: INFO: roberta_kFold_initial_lstm: Training : batch 351 Loss: 0.008452580623685473]
[2024-04-20 13:51:41,939: INFO: roberta_kFold_initial_lstm: Training : batch 352 Loss: 0.0024579358977488267]
[2024-04-20 13:51:42,597: INFO: roberta_kFold_initial_lstm: Training : batch 353 Loss: 0.0024826845759922146]
[2024-04-20 13:51:43,247: INFO: roberta_kFold_initial_lstm: Training : batch 354 Loss: 0.0017016277573642707]
[2024-04-20 13:51:43,903: INFO: roberta_kFold_initial_lstm: Training : batch 355 Loss: 0.00220762960180928]
[2024-04-20 13:51:44,560: INFO: roberta_kFold_initial_lstm: Training : batch 356 Loss: 0.008315771531381189]
[2024-04-20 13:51:45,218: INFO: roberta_kFold_initial_lstm: Training : batch 357 Loss: 0.014649506881264688]
[2024-04-20 13:51:45,877: INFO: roberta_kFold_initial_lstm: Training : batch 358 Loss: 0.0003548430274146716]
[2024-04-20 13:51:46,526: INFO: roberta_kFold_initial_lstm: Training : batch 359 Loss: 0.0016201914088688051]
[2024-04-20 13:51:47,180: INFO: roberta_kFold_initial_lstm: Training : batch 360 Loss: 0.001018762392348735]
[2024-04-20 13:51:47,835: INFO: roberta_kFold_initial_lstm: Training : batch 361 Loss: 0.009881884994587491]
[2024-04-20 13:51:48,487: INFO: roberta_kFold_initial_lstm: Training : batch 362 Loss: 0.002580795353652441]
[2024-04-20 13:51:49,143: INFO: roberta_kFold_initial_lstm: Training : batch 363 Loss: 0.002718493002059145]
[2024-04-20 13:51:49,799: INFO: roberta_kFold_initial_lstm: Training : batch 364 Loss: 0.0047564192024555285]
[2024-04-20 13:51:50,457: INFO: roberta_kFold_initial_lstm: Training : batch 365 Loss: 0.019836783750620843]
[2024-04-20 13:51:51,112: INFO: roberta_kFold_initial_lstm: Training : batch 366 Loss: 0.001746549779473366]
[2024-04-20 13:51:51,764: INFO: roberta_kFold_initial_lstm: Training : batch 367 Loss: 0.00346951761467468]
[2024-04-20 13:51:52,427: INFO: roberta_kFold_initial_lstm: Training : batch 368 Loss: 0.0016456442010842265]
[2024-04-20 13:51:53,093: INFO: roberta_kFold_initial_lstm: Training : batch 369 Loss: 0.004843970377493179]
[2024-04-20 13:51:53,753: INFO: roberta_kFold_initial_lstm: Training : batch 370 Loss: 0.00045582008805635486]
[2024-04-20 13:51:54,426: INFO: roberta_kFold_initial_lstm: Training : batch 371 Loss: 0.007471965066130403]
[2024-04-20 13:51:55,090: INFO: roberta_kFold_initial_lstm: Training : batch 372 Loss: 0.005793067779110011]
[2024-04-20 13:51:55,738: INFO: roberta_kFold_initial_lstm: Training : batch 373 Loss: 0.01024912933027924]
[2024-04-20 13:51:56,396: INFO: roberta_kFold_initial_lstm: Training : batch 374 Loss: 0.009639992220947764]
[2024-04-20 13:51:57,050: INFO: roberta_kFold_initial_lstm: Training : batch 375 Loss: 0.0013006644526548177]
[2024-04-20 13:51:57,700: INFO: roberta_kFold_initial_lstm: Training : batch 376 Loss: 0.004459070365647551]
[2024-04-20 13:51:58,358: INFO: roberta_kFold_initial_lstm: Training : batch 377 Loss: 0.00020231787716107244]
[2024-04-20 13:51:59,010: INFO: roberta_kFold_initial_lstm: Training : batch 378 Loss: 0.007452822594867757]
[2024-04-20 13:51:59,667: INFO: roberta_kFold_initial_lstm: Training : batch 379 Loss: 0.0002465561566665628]
[2024-04-20 13:52:00,323: INFO: roberta_kFold_initial_lstm: Training : batch 380 Loss: 0.011822861699715442]
[2024-04-20 13:52:00,977: INFO: roberta_kFold_initial_lstm: Training : batch 381 Loss: 0.002063587938721828]
[2024-04-20 13:52:01,634: INFO: roberta_kFold_initial_lstm: Training : batch 382 Loss: 0.018243100238858084]
[2024-04-20 13:52:02,287: INFO: roberta_kFold_initial_lstm: Training : batch 383 Loss: 0.0023997097507392966]
[2024-04-20 13:52:02,936: INFO: roberta_kFold_initial_lstm: Training : batch 384 Loss: 0.00940421568538751]
[2024-04-20 13:52:03,587: INFO: roberta_kFold_initial_lstm: Training : batch 385 Loss: 0.0024394564671717236]
[2024-04-20 13:52:04,239: INFO: roberta_kFold_initial_lstm: Training : batch 386 Loss: 0.0038260848827072294]
[2024-04-20 13:52:04,893: INFO: roberta_kFold_initial_lstm: Training : batch 387 Loss: 0.008680076260586415]
[2024-04-20 13:52:05,558: INFO: roberta_kFold_initial_lstm: Training : batch 388 Loss: 0.011973172139840504]
[2024-04-20 13:52:06,226: INFO: roberta_kFold_initial_lstm: Training : batch 389 Loss: 0.001460252534049628]
[2024-04-20 13:52:06,890: INFO: roberta_kFold_initial_lstm: Training : batch 390 Loss: 0.0032084964665963765]
[2024-04-20 13:52:07,565: INFO: roberta_kFold_initial_lstm: Training : batch 391 Loss: 0.009046151935298128]
[2024-04-20 13:52:08,229: INFO: roberta_kFold_initial_lstm: Training : batch 392 Loss: 0.0036501631702232683]
[2024-04-20 13:52:08,878: INFO: roberta_kFold_initial_lstm: Training : batch 393 Loss: 0.010727274946154533]
[2024-04-20 13:52:09,530: INFO: roberta_kFold_initial_lstm: Training : batch 394 Loss: 0.001896687034452213]
[2024-04-20 13:52:10,185: INFO: roberta_kFold_initial_lstm: Training : batch 395 Loss: 0.0014930894955446777]
[2024-04-20 13:52:10,837: INFO: roberta_kFold_initial_lstm: Training : batch 396 Loss: 0.0011077107506598696]
[2024-04-20 13:52:11,490: INFO: roberta_kFold_initial_lstm: Training : batch 397 Loss: 0.0016260276444033871]
[2024-04-20 13:52:12,142: INFO: roberta_kFold_initial_lstm: Training : batch 398 Loss: 0.00478946411706049]
[2024-04-20 13:52:12,794: INFO: roberta_kFold_initial_lstm: Training : batch 399 Loss: 0.009711993745088734]
[2024-04-20 13:52:13,447: INFO: roberta_kFold_initial_lstm: Training : batch 400 Loss: 0.002513338964973301]
[2024-04-20 13:52:14,100: INFO: roberta_kFold_initial_lstm: Training : batch 401 Loss: 0.002115799569787547]
[2024-04-20 13:52:14,751: INFO: roberta_kFold_initial_lstm: Training : batch 402 Loss: 0.004674242023317177]
[2024-04-20 13:52:15,405: INFO: roberta_kFold_initial_lstm: Training : batch 403 Loss: 0.0021329124078885357]
[2024-04-20 13:52:16,059: INFO: roberta_kFold_initial_lstm: Training : batch 404 Loss: 0.0006006984737883844]
[2024-04-20 13:52:16,715: INFO: roberta_kFold_initial_lstm: Training : batch 405 Loss: 0.010454286245903117]
[2024-04-20 13:52:17,371: INFO: roberta_kFold_initial_lstm: Training : batch 406 Loss: 0.0007670635526688582]
[2024-04-20 13:52:18,028: INFO: roberta_kFold_initial_lstm: Training : batch 407 Loss: 0.014962483234487026]
[2024-04-20 13:52:18,686: INFO: roberta_kFold_initial_lstm: Training : batch 408 Loss: 0.0013835757938714215]
[2024-04-20 13:52:19,346: INFO: roberta_kFold_initial_lstm: Training : batch 409 Loss: 0.005859175929527149]
[2024-04-20 13:52:20,005: INFO: roberta_kFold_initial_lstm: Training : batch 410 Loss: 0.012778322865788757]
[2024-04-20 13:52:20,666: INFO: roberta_kFold_initial_lstm: Training : batch 411 Loss: 0.005138965507656092]
[2024-04-20 13:52:21,326: INFO: roberta_kFold_initial_lstm: Training : batch 412 Loss: 0.003154170615439258]
[2024-04-20 13:52:21,984: INFO: roberta_kFold_initial_lstm: Training : batch 413 Loss: 0.009225624230868028]
[2024-04-20 13:52:22,640: INFO: roberta_kFold_initial_lstm: Training : batch 414 Loss: 0.008509944740341897]
[2024-04-20 13:52:23,294: INFO: roberta_kFold_initial_lstm: Training : batch 415 Loss: 0.006895442183532293]
[2024-04-20 13:52:23,947: INFO: roberta_kFold_initial_lstm: Training : batch 416 Loss: 0.005090955488307595]
[2024-04-20 13:52:24,597: INFO: roberta_kFold_initial_lstm: Training : batch 417 Loss: 0.00409402361639604]
[2024-04-20 13:52:25,251: INFO: roberta_kFold_initial_lstm: Training : batch 418 Loss: 0.001433487727087433]
[2024-04-20 13:52:25,908: INFO: roberta_kFold_initial_lstm: Training : batch 419 Loss: 0.0046019485408180264]
[2024-04-20 13:52:26,560: INFO: roberta_kFold_initial_lstm: Training : batch 420 Loss: 0.001796577319707366]
[2024-04-20 13:52:27,210: INFO: roberta_kFold_initial_lstm: Training : batch 421 Loss: 0.006531721350999554]
[2024-04-20 13:52:27,864: INFO: roberta_kFold_initial_lstm: Training : batch 422 Loss: 0.0022272539557394192]
[2024-04-20 13:52:28,522: INFO: roberta_kFold_initial_lstm: Training : batch 423 Loss: 0.005797336327821302]
[2024-04-20 13:52:29,174: INFO: roberta_kFold_initial_lstm: Training : batch 424 Loss: 0.01340178747250632]
[2024-04-20 13:52:29,828: INFO: roberta_kFold_initial_lstm: Training : batch 425 Loss: 0.005869327934411608]
[2024-04-20 13:52:30,484: INFO: roberta_kFold_initial_lstm: Training : batch 426 Loss: 0.005787070968700318]
[2024-04-20 13:52:31,136: INFO: roberta_kFold_initial_lstm: Training : batch 427 Loss: 0.0016059487762516617]
[2024-04-20 13:52:31,798: INFO: roberta_kFold_initial_lstm: Training : batch 428 Loss: 0.0008181618034997073]
[2024-04-20 13:52:32,458: INFO: roberta_kFold_initial_lstm: Training : batch 429 Loss: 0.002187923136624224]
[2024-04-20 13:52:33,125: INFO: roberta_kFold_initial_lstm: Training : batch 430 Loss: 0.010273332996925602]
[2024-04-20 13:52:33,790: INFO: roberta_kFold_initial_lstm: Training : batch 431 Loss: 0.0045994524774768146]
[2024-04-20 13:52:34,460: INFO: roberta_kFold_initial_lstm: Training : batch 432 Loss: 0.005036599203586722]
[2024-04-20 13:52:35,118: INFO: roberta_kFold_initial_lstm: Training : batch 433 Loss: 0.008488346884859629]
[2024-04-20 13:52:35,775: INFO: roberta_kFold_initial_lstm: Training : batch 434 Loss: 0.003426598537344089]
[2024-04-20 13:52:36,427: INFO: roberta_kFold_initial_lstm: Training : batch 435 Loss: 0.0014302765786153638]
[2024-04-20 13:52:37,082: INFO: roberta_kFold_initial_lstm: Training : batch 436 Loss: 0.006855225368536075]
[2024-04-20 13:52:37,733: INFO: roberta_kFold_initial_lstm: Training : batch 437 Loss: 0.0027083757374857147]
[2024-04-20 13:52:38,388: INFO: roberta_kFold_initial_lstm: Training : batch 438 Loss: 0.00660630908820398]
[2024-04-20 13:52:39,042: INFO: roberta_kFold_initial_lstm: Training : batch 439 Loss: 0.004276424080172947]
[2024-04-20 13:52:39,695: INFO: roberta_kFold_initial_lstm: Training : batch 440 Loss: 0.00254052452918264]
[2024-04-20 13:52:40,350: INFO: roberta_kFold_initial_lstm: Training : batch 441 Loss: 0.0014913353223520093]
[2024-04-20 13:52:41,003: INFO: roberta_kFold_initial_lstm: Training : batch 442 Loss: 0.005080354864660185]
[2024-04-20 13:52:41,659: INFO: roberta_kFold_initial_lstm: Training : batch 443 Loss: 0.007094384927528709]
[2024-04-20 13:52:42,314: INFO: roberta_kFold_initial_lstm: Training : batch 444 Loss: 0.010265733535783474]
[2024-04-20 13:52:42,972: INFO: roberta_kFold_initial_lstm: Training : batch 445 Loss: 0.0004935328142838739]
[2024-04-20 13:52:43,623: INFO: roberta_kFold_initial_lstm: Training : batch 446 Loss: 0.01585227298296897]
[2024-04-20 13:52:44,278: INFO: roberta_kFold_initial_lstm: Training : batch 447 Loss: 0.0005077298457488229]
[2024-04-20 13:52:44,940: INFO: roberta_kFold_initial_lstm: Training : batch 448 Loss: 0.01217605760815313]
[2024-04-20 13:52:45,605: INFO: roberta_kFold_initial_lstm: Training : batch 449 Loss: 0.0040738018972813275]
[2024-04-20 13:52:46,262: INFO: roberta_kFold_initial_lstm: Training : batch 450 Loss: 0.003835449304388412]
[2024-04-20 13:52:46,921: INFO: roberta_kFold_initial_lstm: Training : batch 451 Loss: 0.0015541663305761063]
[2024-04-20 13:52:47,582: INFO: roberta_kFold_initial_lstm: Training : batch 452 Loss: 0.00613652799625851]
[2024-04-20 13:52:48,244: INFO: roberta_kFold_initial_lstm: Training : batch 453 Loss: 0.004317104207697329]
[2024-04-20 13:52:48,900: INFO: roberta_kFold_initial_lstm: Training : batch 454 Loss: 0.005987360331131188]
[2024-04-20 13:52:49,556: INFO: roberta_kFold_initial_lstm: Training : batch 455 Loss: 0.0027323656690674968]
[2024-04-20 13:52:50,210: INFO: roberta_kFold_initial_lstm: Training : batch 456 Loss: 0.010760936735553226]
[2024-04-20 13:52:50,863: INFO: roberta_kFold_initial_lstm: Training : batch 457 Loss: 0.01608456098296576]
[2024-04-20 13:52:51,515: INFO: roberta_kFold_initial_lstm: Training : batch 458 Loss: 0.005598000771798]
[2024-04-20 13:52:52,171: INFO: roberta_kFold_initial_lstm: Training : batch 459 Loss: 0.0006471985927257242]
[2024-04-20 13:52:52,832: INFO: roberta_kFold_initial_lstm: Training : batch 460 Loss: 0.005707180992405899]
[2024-04-20 13:52:53,488: INFO: roberta_kFold_initial_lstm: Training : batch 461 Loss: 0.0027225200456100517]
[2024-04-20 13:52:54,142: INFO: roberta_kFold_initial_lstm: Training : batch 462 Loss: 0.003953480545071302]
[2024-04-20 13:52:54,796: INFO: roberta_kFold_initial_lstm: Training : batch 463 Loss: 0.005517277114474238]
[2024-04-20 13:52:55,452: INFO: roberta_kFold_initial_lstm: Training : batch 464 Loss: 0.0046687549261792746]
[2024-04-20 13:52:56,109: INFO: roberta_kFold_initial_lstm: Training : batch 465 Loss: 0.007111864367333612]
[2024-04-20 13:52:56,764: INFO: roberta_kFold_initial_lstm: Training : batch 466 Loss: 0.001738969206693391]
[2024-04-20 13:52:57,420: INFO: roberta_kFold_initial_lstm: Training : batch 467 Loss: 0.004455321703064793]
[2024-04-20 13:52:58,077: INFO: roberta_kFold_initial_lstm: Training : batch 468 Loss: 0.005986341426707656]
[2024-04-20 13:52:58,742: INFO: roberta_kFold_initial_lstm: Training : batch 469 Loss: 0.004703870545363197]
[2024-04-20 13:52:59,403: INFO: roberta_kFold_initial_lstm: Training : batch 470 Loss: 0.00585841468817177]
[2024-04-20 13:53:00,065: INFO: roberta_kFold_initial_lstm: Training : batch 471 Loss: 0.0037363293567302547]
[2024-04-20 13:53:00,730: INFO: roberta_kFold_initial_lstm: Training : batch 472 Loss: 0.00969108101373423]
[2024-04-20 13:53:01,383: INFO: roberta_kFold_initial_lstm: Training : batch 473 Loss: 0.0020354741415914857]
[2024-04-20 13:53:02,040: INFO: roberta_kFold_initial_lstm: Training : batch 474 Loss: 0.0026497298093781456]
[2024-04-20 13:53:02,696: INFO: roberta_kFold_initial_lstm: Training : batch 475 Loss: 0.0030374642139378996]
[2024-04-20 13:53:03,347: INFO: roberta_kFold_initial_lstm: Training : batch 476 Loss: 0.0003808827284340038]
[2024-04-20 13:53:04,003: INFO: roberta_kFold_initial_lstm: Training : batch 477 Loss: 0.0007850340270845871]
[2024-04-20 13:53:04,663: INFO: roberta_kFold_initial_lstm: Training : batch 478 Loss: 0.001156438179761887]
[2024-04-20 13:53:05,317: INFO: roberta_kFold_initial_lstm: Training : batch 479 Loss: 0.0011966734606978647]
[2024-04-20 13:53:05,971: INFO: roberta_kFold_initial_lstm: Training : batch 480 Loss: 0.00715373164879636]
[2024-04-20 13:53:06,625: INFO: roberta_kFold_initial_lstm: Training : batch 481 Loss: 0.000616067972636148]
[2024-04-20 13:53:07,275: INFO: roberta_kFold_initial_lstm: Training : batch 482 Loss: 0.00384991739639941]
[2024-04-20 13:53:07,934: INFO: roberta_kFold_initial_lstm: Training : batch 483 Loss: 0.0054533669957874675]
[2024-04-20 13:53:08,587: INFO: roberta_kFold_initial_lstm: Training : batch 484 Loss: 0.0032817971556589527]
[2024-04-20 13:53:09,242: INFO: roberta_kFold_initial_lstm: Training : batch 485 Loss: 0.008218089160896567]
[2024-04-20 13:53:09,900: INFO: roberta_kFold_initial_lstm: Training : batch 486 Loss: 0.014515765077903812]
[2024-04-20 13:53:10,553: INFO: roberta_kFold_initial_lstm: Training : batch 487 Loss: 0.00024310002551862172]
[2024-04-20 13:53:11,216: INFO: roberta_kFold_initial_lstm: Training : batch 488 Loss: 0.004327727148842703]
[2024-04-20 13:53:11,896: INFO: roberta_kFold_initial_lstm: Training : batch 489 Loss: 0.005167516136095284]
[2024-04-20 13:53:12,565: INFO: roberta_kFold_initial_lstm: Training : batch 490 Loss: 0.009478640597821646]
[2024-04-20 13:53:13,229: INFO: roberta_kFold_initial_lstm: Training : batch 491 Loss: 0.0012899884879693758]
[2024-04-20 13:53:13,894: INFO: roberta_kFold_initial_lstm: Training : batch 492 Loss: 0.0068236570813207]
[2024-04-20 13:53:14,556: INFO: roberta_kFold_initial_lstm: Training : batch 493 Loss: 0.0033679218250788484]
[2024-04-20 13:53:15,211: INFO: roberta_kFold_initial_lstm: Training : batch 494 Loss: 0.018019314907274386]
[2024-04-20 13:53:15,871: INFO: roberta_kFold_initial_lstm: Training : batch 495 Loss: 0.0062580298352275686]
[2024-04-20 13:53:16,528: INFO: roberta_kFold_initial_lstm: Training : batch 496 Loss: 0.004666928049304072]
[2024-04-20 13:53:17,183: INFO: roberta_kFold_initial_lstm: Training : batch 497 Loss: 0.01392336872579128]
[2024-04-20 13:53:17,838: INFO: roberta_kFold_initial_lstm: Training : batch 498 Loss: 0.004939229892968714]
[2024-04-20 13:53:18,494: INFO: roberta_kFold_initial_lstm: Training : batch 499 Loss: 0.009986349381514721]
[2024-04-20 13:53:19,150: INFO: roberta_kFold_initial_lstm: Training : batch 500 Loss: 0.004216858126607938]
[2024-04-20 13:53:19,806: INFO: roberta_kFold_initial_lstm: Training : batch 501 Loss: 0.0018866123849381753]
[2024-04-20 13:53:20,460: INFO: roberta_kFold_initial_lstm: Training : batch 502 Loss: 8.294547507547519e-05]
[2024-04-20 13:53:21,115: INFO: roberta_kFold_initial_lstm: Training : batch 503 Loss: 0.009644723101007386]
[2024-04-20 13:53:21,771: INFO: roberta_kFold_initial_lstm: Training : batch 504 Loss: 0.004521500442890438]
[2024-04-20 13:53:22,428: INFO: roberta_kFold_initial_lstm: Training : batch 505 Loss: 0.00677317857101556]
[2024-04-20 13:53:23,081: INFO: roberta_kFold_initial_lstm: Training : batch 506 Loss: 0.0053296163804482715]
[2024-04-20 13:53:23,739: INFO: roberta_kFold_initial_lstm: Training : batch 507 Loss: 0.007807632744376983]
[2024-04-20 13:53:24,403: INFO: roberta_kFold_initial_lstm: Training : batch 508 Loss: 0.0011432051300942353]
[2024-04-20 13:53:25,063: INFO: roberta_kFold_initial_lstm: Training : batch 509 Loss: 0.003810795839137039]
[2024-04-20 13:53:25,725: INFO: roberta_kFold_initial_lstm: Training : batch 510 Loss: 0.0009839927752348717]
[2024-04-20 13:53:26,388: INFO: roberta_kFold_initial_lstm: Training : batch 511 Loss: 0.007278896997819797]
[2024-04-20 13:53:27,055: INFO: roberta_kFold_initial_lstm: Training : batch 512 Loss: 0.002408818422792014]
[2024-04-20 13:53:27,713: INFO: roberta_kFold_initial_lstm: Training : batch 513 Loss: 0.0014483664598299807]
[2024-04-20 13:53:28,368: INFO: roberta_kFold_initial_lstm: Training : batch 514 Loss: 0.00940948110790426]
[2024-04-20 13:53:29,021: INFO: roberta_kFold_initial_lstm: Training : batch 515 Loss: 0.003718516864269436]
[2024-04-20 13:53:29,676: INFO: roberta_kFold_initial_lstm: Training : batch 516 Loss: 0.004631632011479897]
[2024-04-20 13:53:30,333: INFO: roberta_kFold_initial_lstm: Training : batch 517 Loss: 0.012134876528860887]
[2024-04-20 13:53:30,986: INFO: roberta_kFold_initial_lstm: Training : batch 518 Loss: 0.003037230355596752]
[2024-04-20 13:53:31,641: INFO: roberta_kFold_initial_lstm: Training : batch 519 Loss: 0.002828649516848903]
[2024-04-20 13:53:32,298: INFO: roberta_kFold_initial_lstm: Training : batch 520 Loss: 0.002418696464673876]
[2024-04-20 13:53:32,962: INFO: roberta_kFold_initial_lstm: Training : batch 521 Loss: 0.003457410569160012]
[2024-04-20 13:53:33,626: INFO: roberta_kFold_initial_lstm: Training : batch 522 Loss: 0.006591615718265631]
[2024-04-20 13:53:34,278: INFO: roberta_kFold_initial_lstm: Training : batch 523 Loss: 0.000570073318623156]
[2024-04-20 13:53:34,935: INFO: roberta_kFold_initial_lstm: Training : batch 524 Loss: 0.004218360871671601]
[2024-04-20 13:53:35,594: INFO: roberta_kFold_initial_lstm: Training : batch 525 Loss: 0.007154577541004216]
[2024-04-20 13:53:36,250: INFO: roberta_kFold_initial_lstm: Training : batch 526 Loss: 0.0007181989322685501]
[2024-04-20 13:53:36,906: INFO: roberta_kFold_initial_lstm: Training : batch 527 Loss: 0.00024750390991990574]
[2024-04-20 13:53:37,568: INFO: roberta_kFold_initial_lstm: Training : batch 528 Loss: 0.0024773310173808686]
[2024-04-20 13:53:38,236: INFO: roberta_kFold_initial_lstm: Training : batch 529 Loss: 0.0020712132335705354]
[2024-04-20 13:53:38,910: INFO: roberta_kFold_initial_lstm: Training : batch 530 Loss: 0.005367534536750077]
[2024-04-20 13:53:39,578: INFO: roberta_kFold_initial_lstm: Training : batch 531 Loss: 0.000801082580215065]
[2024-04-20 13:53:40,234: INFO: roberta_kFold_initial_lstm: Training : batch 532 Loss: 0.010556346241542818]
[2024-04-20 13:53:40,896: INFO: roberta_kFold_initial_lstm: Training : batch 533 Loss: 0.008603279331445153]
[2024-04-20 13:53:41,552: INFO: roberta_kFold_initial_lstm: Training : batch 534 Loss: 0.00602753800405336]
[2024-04-20 13:53:42,206: INFO: roberta_kFold_initial_lstm: Training : batch 535 Loss: 0.026862438926865233]
[2024-04-20 13:53:42,862: INFO: roberta_kFold_initial_lstm: Training : batch 536 Loss: 0.0018236676133668638]
[2024-04-20 13:53:43,520: INFO: roberta_kFold_initial_lstm: Training : batch 537 Loss: 0.006037675615806233]
[2024-04-20 13:53:44,171: INFO: roberta_kFold_initial_lstm: Training : batch 538 Loss: 0.0076858075223288766]
[2024-04-20 13:53:44,834: INFO: roberta_kFold_initial_lstm: Training : batch 539 Loss: 0.004896386119298416]
[2024-04-20 13:53:45,488: INFO: roberta_kFold_initial_lstm: Training : batch 540 Loss: 0.0036615264606386206]
[2024-04-20 13:53:46,144: INFO: roberta_kFold_initial_lstm: Training : batch 541 Loss: 0.004546965929139852]
[2024-04-20 13:53:46,798: INFO: roberta_kFold_initial_lstm: Training : batch 542 Loss: 0.0004878029122516258]
[2024-04-20 13:53:47,452: INFO: roberta_kFold_initial_lstm: Training : batch 543 Loss: 0.009411008028510009]
[2024-04-20 13:53:48,112: INFO: roberta_kFold_initial_lstm: Training : batch 544 Loss: 0.007129778564472126]
[2024-04-20 13:53:48,772: INFO: roberta_kFold_initial_lstm: Training : batch 545 Loss: 0.0036508200001382687]
[2024-04-20 13:53:49,427: INFO: roberta_kFold_initial_lstm: Training : batch 546 Loss: 0.005679078814957829]
[2024-04-20 13:53:50,085: INFO: roberta_kFold_initial_lstm: Training : batch 547 Loss: 0.005376757969757996]
[2024-04-20 13:53:50,760: INFO: roberta_kFold_initial_lstm: Training : batch 548 Loss: 0.03642421534586336]
[2024-04-20 13:53:51,428: INFO: roberta_kFold_initial_lstm: Training : batch 549 Loss: 0.007710926120363676]
[2024-04-20 13:53:52,093: INFO: roberta_kFold_initial_lstm: Training : batch 550 Loss: 0.004115338508537343]
[2024-04-20 13:53:52,771: INFO: roberta_kFold_initial_lstm: Training : batch 551 Loss: 0.004849606890638903]
[2024-04-20 13:53:53,432: INFO: roberta_kFold_initial_lstm: Training : batch 552 Loss: 0.013247064946039706]
[2024-04-20 13:53:54,084: INFO: roberta_kFold_initial_lstm: Training : batch 553 Loss: 0.004474975600619699]
[2024-04-20 13:53:54,747: INFO: roberta_kFold_initial_lstm: Training : batch 554 Loss: 0.00591586004348858]
[2024-04-20 13:53:55,404: INFO: roberta_kFold_initial_lstm: Training : batch 555 Loss: 0.0012114772793752765]
[2024-04-20 13:53:56,060: INFO: roberta_kFold_initial_lstm: Training : batch 556 Loss: 0.0001988811101640652]
[2024-04-20 13:53:56,718: INFO: roberta_kFold_initial_lstm: Training : batch 557 Loss: 0.010236310027563086]
[2024-04-20 13:53:57,377: INFO: roberta_kFold_initial_lstm: Training : batch 558 Loss: 0.009458636476454401]
[2024-04-20 13:53:58,033: INFO: roberta_kFold_initial_lstm: Training : batch 559 Loss: 0.0005195639624379634]
[2024-04-20 13:53:58,691: INFO: roberta_kFold_initial_lstm: Training : batch 560 Loss: 0.0024109077328572917]
[2024-04-20 13:53:59,347: INFO: roberta_kFold_initial_lstm: Training : batch 561 Loss: 0.0006336088332624553]
[2024-04-20 13:54:00,004: INFO: roberta_kFold_initial_lstm: Training : batch 562 Loss: 0.0057623230270093155]
[2024-04-20 13:54:00,657: INFO: roberta_kFold_initial_lstm: Training : batch 563 Loss: 0.006046413403672253]
[2024-04-20 13:54:01,314: INFO: roberta_kFold_initial_lstm: Training : batch 564 Loss: 0.0015592348916679257]
[2024-04-20 13:54:01,970: INFO: roberta_kFold_initial_lstm: Training : batch 565 Loss: 0.0052219217835726564]
[2024-04-20 13:54:02,622: INFO: roberta_kFold_initial_lstm: Training : batch 566 Loss: 0.005580012362844644]
[2024-04-20 13:54:03,289: INFO: roberta_kFold_initial_lstm: Training : batch 567 Loss: 0.001968516254050439]
[2024-04-20 13:54:03,952: INFO: roberta_kFold_initial_lstm: Training : batch 568 Loss: 0.004355443840131838]
[2024-04-20 13:54:04,614: INFO: roberta_kFold_initial_lstm: Training : batch 569 Loss: 0.004139845232565289]
[2024-04-20 13:54:05,286: INFO: roberta_kFold_initial_lstm: Training : batch 570 Loss: 0.0034227371114450116]
[2024-04-20 13:54:05,953: INFO: roberta_kFold_initial_lstm: Training : batch 571 Loss: 0.007387476984041946]
[2024-04-20 13:54:06,603: INFO: roberta_kFold_initial_lstm: Training : batch 572 Loss: 0.003182994687795528]
[2024-04-20 13:54:07,259: INFO: roberta_kFold_initial_lstm: Training : batch 573 Loss: 0.004426260679247615]
[2024-04-20 13:54:07,917: INFO: roberta_kFold_initial_lstm: Training : batch 574 Loss: 0.0012777701863520704]
[2024-04-20 13:54:08,573: INFO: roberta_kFold_initial_lstm: Training : batch 575 Loss: 0.007921872835265652]
[2024-04-20 13:54:09,223: INFO: roberta_kFold_initial_lstm: Training : batch 576 Loss: 0.009456204454680282]
[2024-04-20 13:54:09,881: INFO: roberta_kFold_initial_lstm: Training : batch 577 Loss: 0.005953206849274414]
[2024-04-20 13:54:10,535: INFO: roberta_kFold_initial_lstm: Training : batch 578 Loss: 0.000499892626847657]
[2024-04-20 13:54:11,190: INFO: roberta_kFold_initial_lstm: Training : batch 579 Loss: 0.00229615652348185]
[2024-04-20 13:54:11,845: INFO: roberta_kFold_initial_lstm: Training : batch 580 Loss: 0.017394367786984586]
[2024-04-20 13:54:12,502: INFO: roberta_kFold_initial_lstm: Training : batch 581 Loss: 0.007003870336494942]
[2024-04-20 13:54:13,160: INFO: roberta_kFold_initial_lstm: Training : batch 582 Loss: 0.008301580956654096]
[2024-04-20 13:54:13,812: INFO: roberta_kFold_initial_lstm: Training : batch 583 Loss: 0.003104462402623353]
[2024-04-20 13:54:14,469: INFO: roberta_kFold_initial_lstm: Training : batch 584 Loss: 0.0008276282887837993]
[2024-04-20 13:54:15,126: INFO: roberta_kFold_initial_lstm: Training : batch 585 Loss: 0.0037132380340024543]
[2024-04-20 13:54:15,777: INFO: roberta_kFold_initial_lstm: Training : batch 586 Loss: 0.004073712272070485]
[2024-04-20 13:54:16,444: INFO: roberta_kFold_initial_lstm: Training : batch 587 Loss: 0.008284085025937131]
[2024-04-20 13:54:17,115: INFO: roberta_kFold_initial_lstm: Training : batch 588 Loss: 0.012926000696493302]
[2024-04-20 13:54:17,770: INFO: roberta_kFold_initial_lstm: Training : batch 589 Loss: 0.008482129192835202]
[2024-04-20 13:54:18,432: INFO: roberta_kFold_initial_lstm: Training : batch 590 Loss: 0.005338455646574351]
[2024-04-20 13:54:19,090: INFO: roberta_kFold_initial_lstm: Training : batch 591 Loss: 0.0003280260890742179]
[2024-04-20 13:54:19,743: INFO: roberta_kFold_initial_lstm: Training : batch 592 Loss: 0.0002455731775323494]
[2024-04-20 13:54:20,394: INFO: roberta_kFold_initial_lstm: Training : batch 593 Loss: 0.0005759680808723866]
[2024-04-20 13:54:21,055: INFO: roberta_kFold_initial_lstm: Training : batch 594 Loss: 0.0022313085274994356]
[2024-04-20 13:54:21,712: INFO: roberta_kFold_initial_lstm: Training : batch 595 Loss: 0.004015356310892424]
[2024-04-20 13:54:22,364: INFO: roberta_kFold_initial_lstm: Training : batch 596 Loss: 0.00016434273351902579]
[2024-04-20 13:54:23,020: INFO: roberta_kFold_initial_lstm: Training : batch 597 Loss: 0.0032331881446376865]
[2024-04-20 13:54:23,676: INFO: roberta_kFold_initial_lstm: Training : batch 598 Loss: 0.004577582247963604]
[2024-04-20 13:54:24,326: INFO: roberta_kFold_initial_lstm: Training : batch 599 Loss: 0.012959004860983857]
[2024-04-20 13:54:24,983: INFO: roberta_kFold_initial_lstm: Training : batch 600 Loss: 0.004983831992679913]
[2024-04-20 13:54:25,636: INFO: roberta_kFold_initial_lstm: Training : batch 601 Loss: 0.009101359146159362]
[2024-04-20 13:54:26,292: INFO: roberta_kFold_initial_lstm: Training : batch 602 Loss: 0.003966461250800494]
[2024-04-20 13:54:26,941: INFO: roberta_kFold_initial_lstm: Training : batch 603 Loss: 0.0011967021788660262]
[2024-04-20 13:54:27,593: INFO: roberta_kFold_initial_lstm: Training : batch 604 Loss: 0.00852153997623252]
[2024-04-20 13:54:28,249: INFO: roberta_kFold_initial_lstm: Training : batch 605 Loss: 0.00390103515134118]
[2024-04-20 13:54:28,904: INFO: roberta_kFold_initial_lstm: Training : batch 606 Loss: 0.0019256699273126246]
[2024-04-20 13:54:29,569: INFO: roberta_kFold_initial_lstm: Training : batch 607 Loss: 0.0021923370622984116]
[2024-04-20 13:54:30,233: INFO: roberta_kFold_initial_lstm: Training : batch 608 Loss: 0.013633665549878216]
[2024-04-20 13:54:30,891: INFO: roberta_kFold_initial_lstm: Training : batch 609 Loss: 0.007001786791064233]
[2024-04-20 13:54:31,557: INFO: roberta_kFold_initial_lstm: Training : batch 610 Loss: 0.0023868055191311344]
[2024-04-20 13:54:32,222: INFO: roberta_kFold_initial_lstm: Training : batch 611 Loss: 0.0013693074333839482]
[2024-04-20 13:54:32,881: INFO: roberta_kFold_initial_lstm: Training : batch 612 Loss: 0.002108656247991175]
[2024-04-20 13:54:33,532: INFO: roberta_kFold_initial_lstm: Training : batch 613 Loss: 0.006243307763007248]
[2024-04-20 13:54:34,191: INFO: roberta_kFold_initial_lstm: Training : batch 614 Loss: 0.005810527864828011]
[2024-04-20 13:54:34,844: INFO: roberta_kFold_initial_lstm: Training : batch 615 Loss: 0.0026893087931817933]
[2024-04-20 13:54:35,503: INFO: roberta_kFold_initial_lstm: Training : batch 616 Loss: 0.0021980747069942196]
[2024-04-20 13:54:36,160: INFO: roberta_kFold_initial_lstm: Training : batch 617 Loss: 0.009860474164463248]
[2024-04-20 13:54:36,812: INFO: roberta_kFold_initial_lstm: Training : batch 618 Loss: 0.002581176226222712]
[2024-04-20 13:54:37,465: INFO: roberta_kFold_initial_lstm: Training : batch 619 Loss: 0.003863362184858458]
[2024-04-20 13:54:38,120: INFO: roberta_kFold_initial_lstm: Training : batch 620 Loss: 0.005045656372659727]
[2024-04-20 13:54:38,773: INFO: roberta_kFold_initial_lstm: Training : batch 621 Loss: 0.003761980360627232]
[2024-04-20 13:54:39,431: INFO: roberta_kFold_initial_lstm: Training : batch 622 Loss: 0.004270783009958589]
[2024-04-20 13:54:40,081: INFO: roberta_kFold_initial_lstm: Training : batch 623 Loss: 0.0010741362900967045]
[2024-04-20 13:54:40,736: INFO: roberta_kFold_initial_lstm: Training : batch 624 Loss: 0.0004975643068802223]
[2024-04-20 13:54:41,390: INFO: roberta_kFold_initial_lstm: Training : batch 625 Loss: 0.0015524824774189466]
[2024-04-20 13:54:42,051: INFO: roberta_kFold_initial_lstm: Training : batch 626 Loss: 0.008569056455036366]
[2024-04-20 13:54:42,717: INFO: roberta_kFold_initial_lstm: Training : batch 627 Loss: 0.004133296602090767]
[2024-04-20 13:54:43,383: INFO: roberta_kFold_initial_lstm: Training : batch 628 Loss: 0.0044277594728704414]
[2024-04-20 13:54:44,050: INFO: roberta_kFold_initial_lstm: Training : batch 629 Loss: 0.0023522266118094644]
[2024-04-20 13:54:44,715: INFO: roberta_kFold_initial_lstm: Training : batch 630 Loss: 0.0008502885766995324]
[2024-04-20 13:54:45,373: INFO: roberta_kFold_initial_lstm: Training : batch 631 Loss: 0.0010561880687279175]
[2024-04-20 13:54:46,030: INFO: roberta_kFold_initial_lstm: Training : batch 632 Loss: 0.004624682115758303]
[2024-04-20 13:54:46,681: INFO: roberta_kFold_initial_lstm: Training : batch 633 Loss: 0.009879116478537788]
[2024-04-20 13:54:47,336: INFO: roberta_kFold_initial_lstm: Training : batch 634 Loss: 0.012125398247747813]
[2024-04-20 13:54:47,988: INFO: roberta_kFold_initial_lstm: Training : batch 635 Loss: 0.010628666011566647]
[2024-04-20 13:54:48,642: INFO: roberta_kFold_initial_lstm: Training : batch 636 Loss: 0.005271665764667967]
[2024-04-20 13:54:49,295: INFO: roberta_kFold_initial_lstm: Training : batch 637 Loss: 0.004340257651168306]
[2024-04-20 13:54:49,952: INFO: roberta_kFold_initial_lstm: Training : batch 638 Loss: 0.04304513324408301]
[2024-04-20 13:54:50,601: INFO: roberta_kFold_initial_lstm: Training : batch 639 Loss: 0.0015702144745779743]
[2024-04-20 13:54:51,255: INFO: roberta_kFold_initial_lstm: Training : batch 640 Loss: 0.010754583295770672]
[2024-04-20 13:54:51,908: INFO: roberta_kFold_initial_lstm: Training : batch 641 Loss: 0.008095502730811702]
[2024-04-20 13:54:52,561: INFO: roberta_kFold_initial_lstm: Training : batch 642 Loss: 0.005778198530245857]
[2024-04-20 13:54:53,210: INFO: roberta_kFold_initial_lstm: Training : batch 643 Loss: 0.0012737211180463425]
[2024-04-20 13:54:53,860: INFO: roberta_kFold_initial_lstm: Training : batch 644 Loss: 0.002588155717982331]
[2024-04-20 13:54:54,515: INFO: roberta_kFold_initial_lstm: Training : batch 645 Loss: 0.0013122795456721433]
[2024-04-20 13:54:55,173: INFO: roberta_kFold_initial_lstm: Training : batch 646 Loss: 0.0010783197539538027]
[2024-04-20 13:54:55,825: INFO: roberta_kFold_initial_lstm: Training : batch 647 Loss: 0.0036520266627424075]
[2024-04-20 13:54:56,491: INFO: roberta_kFold_initial_lstm: Training : batch 648 Loss: 0.0016900831734516578]
[2024-04-20 13:54:57,159: INFO: roberta_kFold_initial_lstm: Training : batch 649 Loss: 0.003048434945611841]
[2024-04-20 13:54:57,819: INFO: roberta_kFold_initial_lstm: Training : batch 650 Loss: 0.0046564677837727005]
[2024-04-20 13:54:58,480: INFO: roberta_kFold_initial_lstm: Training : batch 651 Loss: 0.009983877742748606]
[2024-04-20 13:54:59,134: INFO: roberta_kFold_initial_lstm: Training : batch 652 Loss: 0.015150095802437489]
[2024-04-20 13:54:59,790: INFO: roberta_kFold_initial_lstm: Training : batch 653 Loss: 0.0016580286659566956]
[2024-04-20 13:55:00,443: INFO: roberta_kFold_initial_lstm: Training : batch 654 Loss: 0.002879828833527657]
[2024-04-20 13:55:01,096: INFO: roberta_kFold_initial_lstm: Training : batch 655 Loss: 0.0049282415467188445]
[2024-04-20 13:55:01,751: INFO: roberta_kFold_initial_lstm: Training : batch 656 Loss: 0.000765861980624949]
[2024-04-20 13:55:02,409: INFO: roberta_kFold_initial_lstm: Training : batch 657 Loss: 0.001981104147816143]
[2024-04-20 13:55:03,065: INFO: roberta_kFold_initial_lstm: Training : batch 658 Loss: 0.0016030859004896724]
[2024-04-20 13:55:03,718: INFO: roberta_kFold_initial_lstm: Training : batch 659 Loss: 0.0028803913535240325]
[2024-04-20 13:55:04,373: INFO: roberta_kFold_initial_lstm: Training : batch 660 Loss: 0.000789948083768374]
[2024-04-20 13:55:05,029: INFO: roberta_kFold_initial_lstm: Training : batch 661 Loss: 0.0013671192522418918]
[2024-04-20 13:55:05,684: INFO: roberta_kFold_initial_lstm: Training : batch 662 Loss: 0.007604654603681676]
[2024-04-20 13:55:06,337: INFO: roberta_kFold_initial_lstm: Training : batch 663 Loss: 0.00039931088992812555]
[2024-04-20 13:55:06,994: INFO: roberta_kFold_initial_lstm: Training : batch 664 Loss: 0.01717063663835103]
[2024-04-20 13:55:07,649: INFO: roberta_kFold_initial_lstm: Training : batch 665 Loss: 0.005297500541419547]
[2024-04-20 13:55:08,309: INFO: roberta_kFold_initial_lstm: Training : batch 666 Loss: 0.0008248193165679391]
[2024-04-20 13:55:08,962: INFO: roberta_kFold_initial_lstm: Training : batch 667 Loss: 0.006513548034267858]
[2024-04-20 13:55:09,622: INFO: roberta_kFold_initial_lstm: Training : batch 668 Loss: 0.00786934618320489]
[2024-04-20 13:55:10,279: INFO: roberta_kFold_initial_lstm: Training : batch 669 Loss: 0.0012725584251308637]
[2024-04-20 13:55:10,946: INFO: roberta_kFold_initial_lstm: Training : batch 670 Loss: 0.0015968784644545984]
[2024-04-20 13:55:11,606: INFO: roberta_kFold_initial_lstm: Training : batch 671 Loss: 0.00564235353352181]
[2024-04-20 13:55:12,264: INFO: roberta_kFold_initial_lstm: Training : batch 672 Loss: 0.005762294696969372]
[2024-04-20 13:55:12,919: INFO: roberta_kFold_initial_lstm: Training : batch 673 Loss: 0.0007315549571181293]
[2024-04-20 13:55:13,574: INFO: roberta_kFold_initial_lstm: Training : batch 674 Loss: 0.010381930799065082]
[2024-04-20 13:55:14,228: INFO: roberta_kFold_initial_lstm: Training : batch 675 Loss: 0.007823526794297738]
[2024-04-20 13:55:14,881: INFO: roberta_kFold_initial_lstm: Training : batch 676 Loss: 0.006488032988191099]
[2024-04-20 13:55:15,537: INFO: roberta_kFold_initial_lstm: Training : batch 677 Loss: 0.00575718346682474]
[2024-04-20 13:55:16,191: INFO: roberta_kFold_initial_lstm: Training : batch 678 Loss: 0.0017419750205918893]
[2024-04-20 13:55:16,847: INFO: roberta_kFold_initial_lstm: Training : batch 679 Loss: 0.0008395394775023063]
[2024-04-20 13:55:17,501: INFO: roberta_kFold_initial_lstm: Training : batch 680 Loss: 0.0015699695367739368]
[2024-04-20 13:55:18,152: INFO: roberta_kFold_initial_lstm: Training : batch 681 Loss: 0.0023771088408183535]
[2024-04-20 13:55:18,804: INFO: roberta_kFold_initial_lstm: Training : batch 682 Loss: 0.004918780098048134]
[2024-04-20 13:55:19,456: INFO: roberta_kFold_initial_lstm: Training : batch 683 Loss: 0.0003054290538425479]
[2024-04-20 13:55:20,105: INFO: roberta_kFold_initial_lstm: Training : batch 684 Loss: 0.012762461221610377]
[2024-04-20 13:55:20,756: INFO: roberta_kFold_initial_lstm: Training : batch 685 Loss: 0.008555852805805007]
[2024-04-20 13:55:21,407: INFO: roberta_kFold_initial_lstm: Training : batch 686 Loss: 0.0019401152731527455]
[2024-04-20 13:55:22,063: INFO: roberta_kFold_initial_lstm: Training : batch 687 Loss: 0.001222991903492142]
[2024-04-20 13:55:22,727: INFO: roberta_kFold_initial_lstm: Training : batch 688 Loss: 0.01952112257397839]
[2024-04-20 13:55:23,390: INFO: roberta_kFold_initial_lstm: Training : batch 689 Loss: 0.0020148461410413347]
[2024-04-20 13:55:24,051: INFO: roberta_kFold_initial_lstm: Training : batch 690 Loss: 0.01554612177027914]
[2024-04-20 13:55:24,719: INFO: roberta_kFold_initial_lstm: Training : batch 691 Loss: 0.004790907766198442]
[2024-04-20 13:55:25,383: INFO: roberta_kFold_initial_lstm: Training : batch 692 Loss: 0.030464701243353053]
[2024-04-20 13:55:26,035: INFO: roberta_kFold_initial_lstm: Training : batch 693 Loss: 0.007169008460459197]
[2024-04-20 13:55:26,690: INFO: roberta_kFold_initial_lstm: Training : batch 694 Loss: 0.005371951375257785]
[2024-04-20 13:55:27,345: INFO: roberta_kFold_initial_lstm: Training : batch 695 Loss: 0.00496914429738448]
[2024-04-20 13:55:27,997: INFO: roberta_kFold_initial_lstm: Training : batch 696 Loss: 0.012689760941554168]
[2024-04-20 13:55:28,649: INFO: roberta_kFold_initial_lstm: Training : batch 697 Loss: 0.00201041476265026]
[2024-04-20 13:55:29,308: INFO: roberta_kFold_initial_lstm: Training : batch 698 Loss: 0.007611452572688798]
[2024-04-20 13:55:29,963: INFO: roberta_kFold_initial_lstm: Training : batch 699 Loss: 0.0012229439687999446]
[2024-04-20 13:55:30,620: INFO: roberta_kFold_initial_lstm: Training : batch 700 Loss: 0.008179587443296221]
[2024-04-20 13:55:31,274: INFO: roberta_kFold_initial_lstm: Training : batch 701 Loss: 0.00502702987192389]
[2024-04-20 13:55:31,927: INFO: roberta_kFold_initial_lstm: Training : batch 702 Loss: 0.0023886688855783056]
[2024-04-20 13:55:32,583: INFO: roberta_kFold_initial_lstm: Training : batch 703 Loss: 0.002698829568531111]
[2024-04-20 13:55:33,237: INFO: roberta_kFold_initial_lstm: Training : batch 704 Loss: 0.006545807265796083]
[2024-04-20 13:55:33,888: INFO: roberta_kFold_initial_lstm: Training : batch 705 Loss: 0.003076854822033437]
[2024-04-20 13:55:34,543: INFO: roberta_kFold_initial_lstm: Training : batch 706 Loss: 0.0032167127987642865]
[2024-04-20 13:55:35,197: INFO: roberta_kFold_initial_lstm: Training : batch 707 Loss: 0.012795504356968712]
[2024-04-20 13:55:35,870: INFO: roberta_kFold_initial_lstm: Training : batch 708 Loss: 0.0035493906319964603]
[2024-04-20 13:55:36,540: INFO: roberta_kFold_initial_lstm: Training : batch 709 Loss: 0.0003842316331071004]
[2024-04-20 13:55:37,200: INFO: roberta_kFold_initial_lstm: Training : batch 710 Loss: 0.000813967805113971]
[2024-04-20 13:55:37,876: INFO: roberta_kFold_initial_lstm: Training : batch 711 Loss: 0.0004892036254358021]
[2024-04-20 13:55:38,539: INFO: roberta_kFold_initial_lstm: Training : batch 712 Loss: 0.0006522746891008013]
[2024-04-20 13:55:39,190: INFO: roberta_kFold_initial_lstm: Training : batch 713 Loss: 0.001775573704615006]
[2024-04-20 13:55:39,858: INFO: roberta_kFold_initial_lstm: Training : batch 714 Loss: 0.006348922438380255]
[2024-04-20 13:55:40,516: INFO: roberta_kFold_initial_lstm: Training : batch 715 Loss: 0.0027704028439368387]
[2024-04-20 13:55:41,169: INFO: roberta_kFold_initial_lstm: Training : batch 716 Loss: 0.00587326379752483]
[2024-04-20 13:55:41,824: INFO: roberta_kFold_initial_lstm: Training : batch 717 Loss: 0.009028190337326242]
[2024-04-20 13:55:42,481: INFO: roberta_kFold_initial_lstm: Training : batch 718 Loss: 0.004589867920122355]
[2024-04-20 13:55:43,131: INFO: roberta_kFold_initial_lstm: Training : batch 719 Loss: 0.005371685276135925]
[2024-04-20 13:55:43,788: INFO: roberta_kFold_initial_lstm: Training : batch 720 Loss: 0.0016667244088628163]
[2024-04-20 13:55:44,442: INFO: roberta_kFold_initial_lstm: Training : batch 721 Loss: 0.004053002788862719]
[2024-04-20 13:55:45,094: INFO: roberta_kFold_initial_lstm: Training : batch 722 Loss: 0.014280109972771172]
[2024-04-20 13:55:45,744: INFO: roberta_kFold_initial_lstm: Training : batch 723 Loss: 0.0032334035258198683]
[2024-04-20 13:55:46,398: INFO: roberta_kFold_initial_lstm: Training : batch 724 Loss: 0.006832854212160618]
[2024-04-20 13:55:47,055: INFO: roberta_kFold_initial_lstm: Training : batch 725 Loss: 0.0026746347599850362]
[2024-04-20 13:55:47,713: INFO: roberta_kFold_initial_lstm: Training : batch 726 Loss: 0.008476998426281234]
[2024-04-20 13:55:48,363: INFO: roberta_kFold_initial_lstm: Training : batch 727 Loss: 0.0013155083947503762]
[2024-04-20 13:55:49,023: INFO: roberta_kFold_initial_lstm: Training : batch 728 Loss: 0.005173070821356473]
[2024-04-20 13:55:49,694: INFO: roberta_kFold_initial_lstm: Training : batch 729 Loss: 0.005438149466920862]
[2024-04-20 13:55:50,358: INFO: roberta_kFold_initial_lstm: Training : batch 730 Loss: 0.001574418212256287]
[2024-04-20 13:55:51,026: INFO: roberta_kFold_initial_lstm: Training : batch 731 Loss: 0.011295674341354915]
[2024-04-20 13:55:51,692: INFO: roberta_kFold_initial_lstm: Training : batch 732 Loss: 0.0031486157252875136]
[2024-04-20 13:55:52,343: INFO: roberta_kFold_initial_lstm: Training : batch 733 Loss: 0.00699133103213233]
[2024-04-20 13:55:52,995: INFO: roberta_kFold_initial_lstm: Training : batch 734 Loss: 0.0037614690832856222]
[2024-04-20 13:55:53,654: INFO: roberta_kFold_initial_lstm: Training : batch 735 Loss: 0.0016334053120213247]
[2024-04-20 13:55:54,304: INFO: roberta_kFold_initial_lstm: Training : batch 736 Loss: 0.003402137153116334]
[2024-04-20 13:55:54,959: INFO: roberta_kFold_initial_lstm: Training : batch 737 Loss: 0.005779950739061473]
[2024-04-20 13:55:55,615: INFO: roberta_kFold_initial_lstm: Training : batch 738 Loss: 0.008630089184398318]
[2024-04-20 13:55:56,268: INFO: roberta_kFold_initial_lstm: Training : batch 739 Loss: 0.002575128146861572]
[2024-04-20 13:55:56,928: INFO: roberta_kFold_initial_lstm: Training : batch 740 Loss: 0.0015149948831077304]
[2024-04-20 13:55:57,590: INFO: roberta_kFold_initial_lstm: Training : batch 741 Loss: 0.001355277398491891]
[2024-04-20 13:55:58,250: INFO: roberta_kFold_initial_lstm: Training : batch 742 Loss: 0.001827294541040965]
[2024-04-20 13:55:58,908: INFO: roberta_kFold_initial_lstm: Training : batch 743 Loss: 0.001340244794875781]
[2024-04-20 13:55:59,563: INFO: roberta_kFold_initial_lstm: Training : batch 744 Loss: 0.002094184537400774]
[2024-04-20 13:56:00,216: INFO: roberta_kFold_initial_lstm: Training : batch 745 Loss: 0.007540926191756428]
[2024-04-20 13:56:00,875: INFO: roberta_kFold_initial_lstm: Training : batch 746 Loss: 0.013272276392494836]
[2024-04-20 13:56:01,533: INFO: roberta_kFold_initial_lstm: Training : batch 747 Loss: 0.00737789937735887]
[2024-04-20 13:56:02,196: INFO: roberta_kFold_initial_lstm: Training : batch 748 Loss: 0.0017667463591155307]
[2024-04-20 13:56:02,869: INFO: roberta_kFold_initial_lstm: Training : batch 749 Loss: 0.004175274555931138]
[2024-04-20 13:56:03,542: INFO: roberta_kFold_initial_lstm: Training : batch 750 Loss: 0.002048555846098523]
[2024-04-20 13:56:04,203: INFO: roberta_kFold_initial_lstm: Training : batch 751 Loss: 0.001383208654821684]
[2024-04-20 13:56:04,872: INFO: roberta_kFold_initial_lstm: Training : batch 752 Loss: 0.011800662214383643]
[2024-04-20 13:56:05,531: INFO: roberta_kFold_initial_lstm: Training : batch 753 Loss: 0.0023297469121166237]
[2024-04-20 13:56:06,187: INFO: roberta_kFold_initial_lstm: Training : batch 754 Loss: 0.004371787147738705]
[2024-04-20 13:56:06,839: INFO: roberta_kFold_initial_lstm: Training : batch 755 Loss: 0.0039599276134099715]
[2024-04-20 13:56:07,496: INFO: roberta_kFold_initial_lstm: Training : batch 756 Loss: 0.0073174341674385815]
[2024-04-20 13:56:08,146: INFO: roberta_kFold_initial_lstm: Training : batch 757 Loss: 0.005836859469029379]
[2024-04-20 13:56:08,797: INFO: roberta_kFold_initial_lstm: Training : batch 758 Loss: 0.004141091436018223]
[2024-04-20 13:56:09,454: INFO: roberta_kFold_initial_lstm: Training : batch 759 Loss: 0.0004997498409173185]
[2024-04-20 13:56:10,111: INFO: roberta_kFold_initial_lstm: Training : batch 760 Loss: 0.0003218431315475251]
[2024-04-20 13:56:10,767: INFO: roberta_kFold_initial_lstm: Training : batch 761 Loss: 0.0028486984402969714]
[2024-04-20 13:56:11,425: INFO: roberta_kFold_initial_lstm: Training : batch 762 Loss: 0.003936213101991986]
[2024-04-20 13:56:12,083: INFO: roberta_kFold_initial_lstm: Training : batch 763 Loss: 0.020125574638340884]
[2024-04-20 13:56:12,739: INFO: roberta_kFold_initial_lstm: Training : batch 764 Loss: 0.0049431359331613325]
[2024-04-20 13:56:13,392: INFO: roberta_kFold_initial_lstm: Training : batch 765 Loss: 0.008949439803726013]
[2024-04-20 13:56:14,050: INFO: roberta_kFold_initial_lstm: Training : batch 766 Loss: 0.019517104955499874]
[2024-04-20 13:56:14,706: INFO: roberta_kFold_initial_lstm: Training : batch 767 Loss: 0.0028962803221481218]
[2024-04-20 13:56:15,367: INFO: roberta_kFold_initial_lstm: Training : batch 768 Loss: 0.016641020842356316]
[2024-04-20 13:56:16,025: INFO: roberta_kFold_initial_lstm: Training : batch 769 Loss: 0.00812259144557377]
[2024-04-20 13:56:16,690: INFO: roberta_kFold_initial_lstm: Training : batch 770 Loss: 0.0012957366786429001]
[2024-04-20 13:56:17,351: INFO: roberta_kFold_initial_lstm: Training : batch 771 Loss: 0.0020946666434238466]
[2024-04-20 13:56:18,011: INFO: roberta_kFold_initial_lstm: Training : batch 772 Loss: 0.0016895492408439733]
[2024-04-20 13:56:18,666: INFO: roberta_kFold_initial_lstm: Training : batch 773 Loss: 0.0017060637172435379]
[2024-04-20 13:56:19,323: INFO: roberta_kFold_initial_lstm: Training : batch 774 Loss: 0.0016447399866859618]
[2024-04-20 13:56:19,973: INFO: roberta_kFold_initial_lstm: Training : batch 775 Loss: 0.008706528797415703]
[2024-04-20 13:56:20,630: INFO: roberta_kFold_initial_lstm: Training : batch 776 Loss: 0.0033060422664625204]
[2024-04-20 13:56:21,294: INFO: roberta_kFold_initial_lstm: Training : batch 777 Loss: 0.003973309822475725]
[2024-04-20 13:56:21,949: INFO: roberta_kFold_initial_lstm: Training : batch 778 Loss: 0.0002859617933443789]
[2024-04-20 13:56:22,607: INFO: roberta_kFold_initial_lstm: Training : batch 779 Loss: 0.0008922616209760293]
[2024-04-20 13:56:23,258: INFO: roberta_kFold_initial_lstm: Training : batch 780 Loss: 0.002031834729140889]
[2024-04-20 13:56:23,915: INFO: roberta_kFold_initial_lstm: Training : batch 781 Loss: 0.0006161873740179817]
[2024-04-20 13:56:24,569: INFO: roberta_kFold_initial_lstm: Training : batch 782 Loss: 0.002173829052821549]
[2024-04-20 13:56:25,221: INFO: roberta_kFold_initial_lstm: Training : batch 783 Loss: 0.01732538110733366]
[2024-04-20 13:56:25,879: INFO: roberta_kFold_initial_lstm: Training : batch 784 Loss: 0.0034368484471323907]
[2024-04-20 13:56:26,539: INFO: roberta_kFold_initial_lstm: Training : batch 785 Loss: 0.004042346923109793]
[2024-04-20 13:56:27,195: INFO: roberta_kFold_initial_lstm: Training : batch 786 Loss: 0.016249159358314717]
[2024-04-20 13:56:27,849: INFO: roberta_kFold_initial_lstm: Training : batch 787 Loss: 0.0030292165725437845]
[2024-04-20 13:56:28,511: INFO: roberta_kFold_initial_lstm: Training : batch 788 Loss: 0.0050846859718067525]
[2024-04-20 13:56:29,171: INFO: roberta_kFold_initial_lstm: Training : batch 789 Loss: 0.008126524979508196]
[2024-04-20 13:56:29,836: INFO: roberta_kFold_initial_lstm: Training : batch 790 Loss: 0.002757826952922486]
[2024-04-20 13:56:30,497: INFO: roberta_kFold_initial_lstm: Training : batch 791 Loss: 0.005468931646494634]
[2024-04-20 13:56:31,156: INFO: roberta_kFold_initial_lstm: Training : batch 792 Loss: 0.0017043353432814369]
[2024-04-20 13:56:31,813: INFO: roberta_kFold_initial_lstm: Training : batch 793 Loss: 0.013467771430632321]
[2024-04-20 13:56:32,469: INFO: roberta_kFold_initial_lstm: Training : batch 794 Loss: 0.00022672763576877855]
[2024-04-20 13:56:33,126: INFO: roberta_kFold_initial_lstm: Training : batch 795 Loss: 0.003579312732926814]
[2024-04-20 13:56:33,784: INFO: roberta_kFold_initial_lstm: Training : batch 796 Loss: 0.008015043747777315]
[2024-04-20 13:56:34,445: INFO: roberta_kFold_initial_lstm: Training : batch 797 Loss: 0.002132673404361815]
[2024-04-20 13:56:35,097: INFO: roberta_kFold_initial_lstm: Training : batch 798 Loss: 0.011512748472343206]
[2024-04-20 13:56:35,753: INFO: roberta_kFold_initial_lstm: Training : batch 799 Loss: 0.0017755157128438001]
[2024-04-20 13:56:36,409: INFO: roberta_kFold_initial_lstm: Training : batch 800 Loss: 0.0011717736278527493]
[2024-04-20 13:56:37,069: INFO: roberta_kFold_initial_lstm: Training : batch 801 Loss: 0.0016505120744129452]
[2024-04-20 13:56:37,726: INFO: roberta_kFold_initial_lstm: Training : batch 802 Loss: 0.005622248626826531]
[2024-04-20 13:56:38,381: INFO: roberta_kFold_initial_lstm: Training : batch 803 Loss: 0.003925395614306973]
[2024-04-20 13:56:39,038: INFO: roberta_kFold_initial_lstm: Training : batch 804 Loss: 0.003309592409493324]
[2024-04-20 13:56:39,698: INFO: roberta_kFold_initial_lstm: Training : batch 805 Loss: 0.010998831323186919]
[2024-04-20 13:56:40,351: INFO: roberta_kFold_initial_lstm: Training : batch 806 Loss: 0.004967211868360485]
[2024-04-20 13:56:41,006: INFO: roberta_kFold_initial_lstm: Training : batch 807 Loss: 0.0008160022646839587]
[2024-04-20 13:56:41,673: INFO: roberta_kFold_initial_lstm: Training : batch 808 Loss: 0.0024221733772637234]
[2024-04-20 13:56:42,340: INFO: roberta_kFold_initial_lstm: Training : batch 809 Loss: 0.00982812818115222]
[2024-04-20 13:56:43,012: INFO: roberta_kFold_initial_lstm: Training : batch 810 Loss: 0.008025777921820196]
[2024-04-20 13:56:43,677: INFO: roberta_kFold_initial_lstm: Training : batch 811 Loss: 0.031337261024016294]
[2024-04-20 13:56:44,334: INFO: roberta_kFold_initial_lstm: Training : batch 812 Loss: 0.00842640805597751]
[2024-04-20 13:56:44,988: INFO: roberta_kFold_initial_lstm: Training : batch 813 Loss: 0.005883418105668307]
[2024-04-20 13:56:45,646: INFO: roberta_kFold_initial_lstm: Training : batch 814 Loss: 0.013404507219592828]
[2024-04-20 13:56:46,302: INFO: roberta_kFold_initial_lstm: Training : batch 815 Loss: 0.00832342636751432]
[2024-04-20 13:56:46,959: INFO: roberta_kFold_initial_lstm: Training : batch 816 Loss: 0.009667273709289766]
[2024-04-20 13:56:47,613: INFO: roberta_kFold_initial_lstm: Training : batch 817 Loss: 0.005321299806085405]
[2024-04-20 13:56:48,268: INFO: roberta_kFold_initial_lstm: Training : batch 818 Loss: 0.0028121556502661107]
[2024-04-20 13:56:48,923: INFO: roberta_kFold_initial_lstm: Training : batch 819 Loss: 0.00972760604543633]
[2024-04-20 13:56:49,582: INFO: roberta_kFold_initial_lstm: Training : batch 820 Loss: 0.0003679175618165905]
[2024-04-20 13:56:50,238: INFO: roberta_kFold_initial_lstm: Training : batch 821 Loss: 0.017535947655181933]
[2024-04-20 13:56:50,895: INFO: roberta_kFold_initial_lstm: Training : batch 822 Loss: 0.001700919418655931]
[2024-04-20 13:56:51,544: INFO: roberta_kFold_initial_lstm: Training : batch 823 Loss: 0.0016002464855763793]
[2024-04-20 13:56:52,196: INFO: roberta_kFold_initial_lstm: Training : batch 824 Loss: 0.0017026698713896425]
[2024-04-20 13:56:52,854: INFO: roberta_kFold_initial_lstm: Training : batch 825 Loss: 0.004099625784617793]
[2024-04-20 13:56:53,509: INFO: roberta_kFold_initial_lstm: Training : batch 826 Loss: 0.01897050937446978]
[2024-04-20 13:56:54,162: INFO: roberta_kFold_initial_lstm: Training : batch 827 Loss: 0.0036127359603183038]
[2024-04-20 13:56:54,835: INFO: roberta_kFold_initial_lstm: Training : batch 828 Loss: 0.0024801603392876855]
[2024-04-20 13:56:55,502: INFO: roberta_kFold_initial_lstm: Training : batch 829 Loss: 0.0005071096511272929]
[2024-04-20 13:56:56,162: INFO: roberta_kFold_initial_lstm: Training : batch 830 Loss: 0.0023388010926987486]
[2024-04-20 13:56:56,821: INFO: roberta_kFold_initial_lstm: Training : batch 831 Loss: 0.014083833278967919]
[2024-04-20 13:56:57,484: INFO: roberta_kFold_initial_lstm: Training : batch 832 Loss: 0.0038879825620723807]
[2024-04-20 13:56:58,139: INFO: roberta_kFold_initial_lstm: Training : batch 833 Loss: 0.0013170392929654092]
[2024-04-20 13:56:58,797: INFO: roberta_kFold_initial_lstm: Training : batch 834 Loss: 0.011047902410164758]
[2024-04-20 13:56:59,456: INFO: roberta_kFold_initial_lstm: Training : batch 835 Loss: 0.0017089505206798123]
[2024-04-20 13:57:00,111: INFO: roberta_kFold_initial_lstm: Training : batch 836 Loss: 0.008428083472353243]
[2024-04-20 13:57:00,765: INFO: roberta_kFold_initial_lstm: Training : batch 837 Loss: 0.004892650971037007]
[2024-04-20 13:57:01,425: INFO: roberta_kFold_initial_lstm: Training : batch 838 Loss: 0.0018779038161960227]
[2024-04-20 13:57:02,083: INFO: roberta_kFold_initial_lstm: Training : batch 839 Loss: 0.005100901537330942]
[2024-04-20 13:57:02,747: INFO: roberta_kFold_initial_lstm: Training : batch 840 Loss: 0.008964836053478578]
[2024-04-20 13:57:03,400: INFO: roberta_kFold_initial_lstm: Training : batch 841 Loss: 0.006881472676432631]
[2024-04-20 13:57:04,056: INFO: roberta_kFold_initial_lstm: Training : batch 842 Loss: 0.0064621429077744525]
[2024-04-20 13:57:04,710: INFO: roberta_kFold_initial_lstm: Training : batch 843 Loss: 0.005024282779207502]
[2024-04-20 13:57:05,371: INFO: roberta_kFold_initial_lstm: Training : batch 844 Loss: 0.0064521906525303275]
[2024-04-20 13:57:06,029: INFO: roberta_kFold_initial_lstm: Training : batch 845 Loss: 0.004996239423549968]
[2024-04-20 13:57:06,687: INFO: roberta_kFold_initial_lstm: Training : batch 846 Loss: 0.0018967493833641587]
[2024-04-20 13:57:07,342: INFO: roberta_kFold_initial_lstm: Training : batch 847 Loss: 0.004403098632974995]
[2024-04-20 13:57:08,021: INFO: roberta_kFold_initial_lstm: Training : batch 848 Loss: 0.0058271313491570255]
[2024-04-20 13:57:08,699: INFO: roberta_kFold_initial_lstm: Training : batch 849 Loss: 0.001421947125818654]
[2024-04-20 13:57:09,357: INFO: roberta_kFold_initial_lstm: Training : batch 850 Loss: 0.006303882752229094]
[2024-04-20 13:57:10,025: INFO: roberta_kFold_initial_lstm: Training : batch 851 Loss: 0.0015497161159444956]
[2024-04-20 13:57:10,692: INFO: roberta_kFold_initial_lstm: Training : batch 852 Loss: 0.0053563782425652216]
[2024-04-20 13:57:11,348: INFO: roberta_kFold_initial_lstm: Training : batch 853 Loss: 0.0055185679588702664]
[2024-04-20 13:57:12,003: INFO: roberta_kFold_initial_lstm: Training : batch 854 Loss: 0.001557183405926704]
[2024-04-20 13:57:12,654: INFO: roberta_kFold_initial_lstm: Training : batch 855 Loss: 0.0039219802774971895]
[2024-04-20 13:57:13,310: INFO: roberta_kFold_initial_lstm: Training : batch 856 Loss: 0.0031143486944619765]
[2024-04-20 13:57:13,964: INFO: roberta_kFold_initial_lstm: Training : batch 857 Loss: 0.004165690450601768]
[2024-04-20 13:57:14,619: INFO: roberta_kFold_initial_lstm: Training : batch 858 Loss: 0.0016953818363914868]
[2024-04-20 13:57:15,272: INFO: roberta_kFold_initial_lstm: Training : batch 859 Loss: 0.0032279951265437425]
[2024-04-20 13:57:15,932: INFO: roberta_kFold_initial_lstm: Training : batch 860 Loss: 0.0011685150111839532]
[2024-04-20 13:57:16,587: INFO: roberta_kFold_initial_lstm: Training : batch 861 Loss: 0.00505185109291797]
[2024-04-20 13:57:17,241: INFO: roberta_kFold_initial_lstm: Training : batch 862 Loss: 0.007320535165587199]
[2024-04-20 13:57:17,901: INFO: roberta_kFold_initial_lstm: Training : batch 863 Loss: 0.020373875186202196]
[2024-04-20 13:57:18,552: INFO: roberta_kFold_initial_lstm: Training : batch 864 Loss: 0.00029717250161659533]
[2024-04-20 13:57:19,205: INFO: roberta_kFold_initial_lstm: Training : batch 865 Loss: 0.007475896427118747]
[2024-04-20 13:57:19,857: INFO: roberta_kFold_initial_lstm: Training : batch 866 Loss: 0.006562768790898309]
[2024-04-20 13:57:20,512: INFO: roberta_kFold_initial_lstm: Training : batch 867 Loss: 0.0015498156122529985]
[2024-04-20 13:57:21,175: INFO: roberta_kFold_initial_lstm: Training : batch 868 Loss: 0.0007776014437398203]
[2024-04-20 13:57:21,838: INFO: roberta_kFold_initial_lstm: Training : batch 869 Loss: 0.009290388185752955]
[2024-04-20 13:57:22,496: INFO: roberta_kFold_initial_lstm: Training : batch 870 Loss: 0.004231256005787236]
[2024-04-20 13:57:23,156: INFO: roberta_kFold_initial_lstm: Training : batch 871 Loss: 0.011937538716929144]
[2024-04-20 13:57:23,823: INFO: roberta_kFold_initial_lstm: Training : batch 872 Loss: 0.000310597875813139]
[2024-04-20 13:57:24,475: INFO: roberta_kFold_initial_lstm: Training : batch 873 Loss: 0.00100680097507787]
[2024-04-20 13:57:25,128: INFO: roberta_kFold_initial_lstm: Training : batch 874 Loss: 0.012278598705291716]
[2024-04-20 13:57:25,782: INFO: roberta_kFold_initial_lstm: Training : batch 875 Loss: 0.0033953390138573535]
[2024-04-20 13:57:26,438: INFO: roberta_kFold_initial_lstm: Training : batch 876 Loss: 0.0003629067128474414]
[2024-04-20 13:57:27,093: INFO: roberta_kFold_initial_lstm: Training : batch 877 Loss: 0.007157228474132919]
[2024-04-20 13:57:27,747: INFO: roberta_kFold_initial_lstm: Training : batch 878 Loss: 0.003559852802299595]
[2024-04-20 13:57:28,403: INFO: roberta_kFold_initial_lstm: Training : batch 879 Loss: 0.011305009811310376]
[2024-04-20 13:57:29,054: INFO: roberta_kFold_initial_lstm: Training : batch 880 Loss: 0.005903246432999901]
[2024-04-20 13:57:29,709: INFO: roberta_kFold_initial_lstm: Training : batch 881 Loss: 0.014625724253648109]
[2024-04-20 13:57:30,367: INFO: roberta_kFold_initial_lstm: Training : batch 882 Loss: 0.0013380562447562851]
[2024-04-20 13:57:31,019: INFO: roberta_kFold_initial_lstm: Training : batch 883 Loss: 0.0007227671850457849]
[2024-04-20 13:57:31,674: INFO: roberta_kFold_initial_lstm: Training : batch 884 Loss: 0.004275178182817471]
[2024-04-20 13:57:32,329: INFO: roberta_kFold_initial_lstm: Training : batch 885 Loss: 0.002742855027281073]
[2024-04-20 13:57:32,984: INFO: roberta_kFold_initial_lstm: Training : batch 886 Loss: 0.008922936634545764]
[2024-04-20 13:57:33,635: INFO: roberta_kFold_initial_lstm: Training : batch 887 Loss: 0.0025066558040414207]
[2024-04-20 13:57:34,309: INFO: roberta_kFold_initial_lstm: Training : batch 888 Loss: 0.0033542684588183857]
[2024-04-20 13:57:34,979: INFO: roberta_kFold_initial_lstm: Training : batch 889 Loss: 0.0072715644263779385]
[2024-04-20 13:57:35,636: INFO: roberta_kFold_initial_lstm: Training : batch 890 Loss: 0.0027884411659520702]
[2024-04-20 13:57:36,297: INFO: roberta_kFold_initial_lstm: Training : batch 891 Loss: 0.0037319393200886835]
[2024-04-20 13:57:36,957: INFO: roberta_kFold_initial_lstm: Training : batch 892 Loss: 0.007210961528778938]
[2024-04-20 13:57:37,606: INFO: roberta_kFold_initial_lstm: Training : batch 893 Loss: 0.00228118538783045]
[2024-04-20 13:57:38,264: INFO: roberta_kFold_initial_lstm: Training : batch 894 Loss: 0.001507681566073977]
[2024-04-20 13:57:38,918: INFO: roberta_kFold_initial_lstm: Training : batch 895 Loss: 0.005371070091690106]
[2024-04-20 13:57:39,573: INFO: roberta_kFold_initial_lstm: Training : batch 896 Loss: 0.0039446672636954]
[2024-04-20 13:57:40,229: INFO: roberta_kFold_initial_lstm: Training : batch 897 Loss: 0.0027903504815269048]
[2024-04-20 13:57:40,882: INFO: roberta_kFold_initial_lstm: Training : batch 898 Loss: 0.001363009640959297]
[2024-04-20 13:57:41,535: INFO: roberta_kFold_initial_lstm: Training : batch 899 Loss: 0.0028444033779557753]
[2024-04-20 13:57:42,187: INFO: roberta_kFold_initial_lstm: Training : batch 900 Loss: 0.011158769253243285]
[2024-04-20 13:57:42,842: INFO: roberta_kFold_initial_lstm: Training : batch 901 Loss: 0.00597479681115336]
[2024-04-20 13:57:43,499: INFO: roberta_kFold_initial_lstm: Training : batch 902 Loss: 0.008335702152239003]
[2024-04-20 13:57:44,151: INFO: roberta_kFold_initial_lstm: Training : batch 903 Loss: 0.0005397383657834398]
[2024-04-20 13:57:44,810: INFO: roberta_kFold_initial_lstm: Training : batch 904 Loss: 0.0015266117160989518]
[2024-04-20 13:57:45,465: INFO: roberta_kFold_initial_lstm: Training : batch 905 Loss: 0.004071563233221998]
[2024-04-20 13:57:46,118: INFO: roberta_kFold_initial_lstm: Training : batch 906 Loss: 0.0036872629704593047]
[2024-04-20 13:57:46,771: INFO: roberta_kFold_initial_lstm: Training : batch 907 Loss: 0.0036547208229737683]
[2024-04-20 13:57:47,439: INFO: roberta_kFold_initial_lstm: Training : batch 908 Loss: 0.010130836555064204]
[2024-04-20 13:57:48,102: INFO: roberta_kFold_initial_lstm: Training : batch 909 Loss: 0.0003489956865051362]
[2024-04-20 13:57:48,764: INFO: roberta_kFold_initial_lstm: Training : batch 910 Loss: 0.0020069652925875283]
[2024-04-20 13:57:49,443: INFO: roberta_kFold_initial_lstm: Training : batch 911 Loss: 0.002198526029945866]
[2024-04-20 13:57:50,115: INFO: roberta_kFold_initial_lstm: Training : batch 912 Loss: 0.002849772687845012]
[2024-04-20 13:57:50,762: INFO: roberta_kFold_initial_lstm: Training : batch 913 Loss: 0.011235277682686071]
[2024-04-20 13:57:51,421: INFO: roberta_kFold_initial_lstm: Training : batch 914 Loss: 0.001959825489528379]
[2024-04-20 13:57:52,078: INFO: roberta_kFold_initial_lstm: Training : batch 915 Loss: 0.008378580318656353]
[2024-04-20 13:57:52,734: INFO: roberta_kFold_initial_lstm: Training : batch 916 Loss: 0.010395402318356292]
[2024-04-20 13:57:53,395: INFO: roberta_kFold_initial_lstm: Training : batch 917 Loss: 0.009739240230372953]
[2024-04-20 13:57:54,046: INFO: roberta_kFold_initial_lstm: Training : batch 918 Loss: 0.0006127733741817438]
[2024-04-20 13:57:54,700: INFO: roberta_kFold_initial_lstm: Training : batch 919 Loss: 0.0052220608534109085]
[2024-04-20 13:57:55,354: INFO: roberta_kFold_initial_lstm: Training : batch 920 Loss: 0.009644399135826686]
[2024-04-20 13:57:56,009: INFO: roberta_kFold_initial_lstm: Training : batch 921 Loss: 0.006256788109838964]
[2024-04-20 13:57:56,670: INFO: roberta_kFold_initial_lstm: Training : batch 922 Loss: 0.007673671510883082]
[2024-04-20 13:57:57,320: INFO: roberta_kFold_initial_lstm: Training : batch 923 Loss: 0.006459997900862094]
[2024-04-20 13:57:57,978: INFO: roberta_kFold_initial_lstm: Training : batch 924 Loss: 0.004656783846990344]
[2024-04-20 13:57:58,633: INFO: roberta_kFold_initial_lstm: Training : batch 925 Loss: 0.0014480992482589644]
[2024-04-20 13:57:59,285: INFO: roberta_kFold_initial_lstm: Training : batch 926 Loss: 0.003879557701723039]
[2024-04-20 13:57:59,941: INFO: roberta_kFold_initial_lstm: Training : batch 927 Loss: 0.010342571843499434]
[2024-04-20 13:58:00,599: INFO: roberta_kFold_initial_lstm: Training : batch 928 Loss: 0.0011707081419891254]
[2024-04-20 13:58:01,256: INFO: roberta_kFold_initial_lstm: Training : batch 929 Loss: 0.0021659893559970596]
[2024-04-20 13:58:01,915: INFO: roberta_kFold_initial_lstm: Training : batch 930 Loss: 0.00068325508088149]
[2024-04-20 13:58:02,581: INFO: roberta_kFold_initial_lstm: Training : batch 931 Loss: 0.0055396187881635705]
[2024-04-20 13:58:03,239: INFO: roberta_kFold_initial_lstm: Training : batch 932 Loss: 0.0004334986161335638]
[2024-04-20 13:58:03,897: INFO: roberta_kFold_initial_lstm: Training : batch 933 Loss: 0.004177351640278243]
[2024-04-20 13:58:04,553: INFO: roberta_kFold_initial_lstm: Training : batch 934 Loss: 0.0013038828950454918]
[2024-04-20 13:58:05,204: INFO: roberta_kFold_initial_lstm: Training : batch 935 Loss: 0.004356051113601472]
[2024-04-20 13:58:05,858: INFO: roberta_kFold_initial_lstm: Training : batch 936 Loss: 0.0029767109121206876]
[2024-04-20 13:58:06,515: INFO: roberta_kFold_initial_lstm: Training : batch 937 Loss: 0.005085019723639472]
[2024-04-20 13:58:07,167: INFO: roberta_kFold_initial_lstm: Training : batch 938 Loss: 0.003080250732531902]
[2024-04-20 13:58:07,820: INFO: roberta_kFold_initial_lstm: Training : batch 939 Loss: 0.001906105833949162]
[2024-04-20 13:58:08,475: INFO: roberta_kFold_initial_lstm: Training : batch 940 Loss: 0.002752167404839074]
[2024-04-20 13:58:09,128: INFO: roberta_kFold_initial_lstm: Training : batch 941 Loss: 0.008019252301585249]
[2024-04-20 13:58:09,783: INFO: roberta_kFold_initial_lstm: Training : batch 942 Loss: 0.0013708308412408504]
[2024-04-20 13:58:10,434: INFO: roberta_kFold_initial_lstm: Training : batch 943 Loss: 0.002362293669163325]
[2024-04-20 13:58:11,085: INFO: roberta_kFold_initial_lstm: Training : batch 944 Loss: 0.0012426863676018726]
[2024-04-20 13:58:11,740: INFO: roberta_kFold_initial_lstm: Training : batch 945 Loss: 0.0009777867377103013]
[2024-04-20 13:58:12,394: INFO: roberta_kFold_initial_lstm: Training : batch 946 Loss: 0.0016953386557997342]
[2024-04-20 13:58:13,048: INFO: roberta_kFold_initial_lstm: Training : batch 947 Loss: 0.0022867678935984837]
[2024-04-20 13:58:13,711: INFO: roberta_kFold_initial_lstm: Training : batch 948 Loss: 0.007260831358706573]
[2024-04-20 13:58:14,380: INFO: roberta_kFold_initial_lstm: Training : batch 949 Loss: 0.0002676424944221128]
[2024-04-20 13:58:15,036: INFO: roberta_kFold_initial_lstm: Training : batch 950 Loss: 0.0033709171741213703]
[2024-04-20 13:58:15,696: INFO: roberta_kFold_initial_lstm: Training : batch 951 Loss: 0.009311260500798519]
[2024-04-20 13:58:16,352: INFO: roberta_kFold_initial_lstm: Training : batch 952 Loss: 0.008201481170389525]
[2024-04-20 13:58:17,004: INFO: roberta_kFold_initial_lstm: Training : batch 953 Loss: 0.0007956791474190603]
[2024-04-20 13:58:17,657: INFO: roberta_kFold_initial_lstm: Training : batch 954 Loss: 0.0006669581370510007]
[2024-04-20 13:58:18,309: INFO: roberta_kFold_initial_lstm: Training : batch 955 Loss: 0.004419486531167502]
[2024-04-20 13:58:18,963: INFO: roberta_kFold_initial_lstm: Training : batch 956 Loss: 0.012362079366718702]
[2024-04-20 13:58:19,612: INFO: roberta_kFold_initial_lstm: Training : batch 957 Loss: 0.000870316426500104]
[2024-04-20 13:58:20,261: INFO: roberta_kFold_initial_lstm: Training : batch 958 Loss: 0.004047921681789812]
[2024-04-20 13:58:20,912: INFO: roberta_kFold_initial_lstm: Training : batch 959 Loss: 0.0035649858699910893]
[2024-04-20 13:58:21,567: INFO: roberta_kFold_initial_lstm: Training : batch 960 Loss: 0.0024596844110784063]
[2024-04-20 13:58:22,224: INFO: roberta_kFold_initial_lstm: Training : batch 961 Loss: 0.008481095074122893]
[2024-04-20 13:58:22,875: INFO: roberta_kFold_initial_lstm: Training : batch 962 Loss: 0.0015306089531254622]
[2024-04-20 13:58:23,530: INFO: roberta_kFold_initial_lstm: Training : batch 963 Loss: 0.0019992629555718867]
[2024-04-20 13:58:24,182: INFO: roberta_kFold_initial_lstm: Training : batch 964 Loss: 0.007718228611250139]
[2024-04-20 13:58:24,835: INFO: roberta_kFold_initial_lstm: Training : batch 965 Loss: 0.005926854939421016]
[2024-04-20 13:58:25,486: INFO: roberta_kFold_initial_lstm: Training : batch 966 Loss: 0.004886732497651807]
[2024-04-20 13:58:26,140: INFO: roberta_kFold_initial_lstm: Training : batch 967 Loss: 0.0006420526239609505]
[2024-04-20 13:58:26,810: INFO: roberta_kFold_initial_lstm: Training : batch 968 Loss: 0.0039606914407549175]
[2024-04-20 13:58:27,480: INFO: roberta_kFold_initial_lstm: Training : batch 969 Loss: 0.0020095540879979984]
[2024-04-20 13:58:28,139: INFO: roberta_kFold_initial_lstm: Training : batch 970 Loss: 0.002555900011598018]
[2024-04-20 13:58:28,807: INFO: roberta_kFold_initial_lstm: Training : batch 971 Loss: 0.00560704205011491]
[2024-04-20 13:58:29,474: INFO: roberta_kFold_initial_lstm: Training : batch 972 Loss: 0.0009304403174869899]
[2024-04-20 13:58:30,129: INFO: roberta_kFold_initial_lstm: Training : batch 973 Loss: 0.0012600325361175914]
[2024-04-20 13:58:30,785: INFO: roberta_kFold_initial_lstm: Training : batch 974 Loss: 0.002966869830634482]
[2024-04-20 13:58:31,437: INFO: roberta_kFold_initial_lstm: Training : batch 975 Loss: 0.0011925139851336549]
[2024-04-20 13:58:32,088: INFO: roberta_kFold_initial_lstm: Training : batch 976 Loss: 0.002885148195091905]
[2024-04-20 13:58:32,746: INFO: roberta_kFold_initial_lstm: Training : batch 977 Loss: 0.0016610132397211614]
[2024-04-20 13:58:33,406: INFO: roberta_kFold_initial_lstm: Training : batch 978 Loss: 0.006301658180747958]
[2024-04-20 13:58:34,061: INFO: roberta_kFold_initial_lstm: Training : batch 979 Loss: 0.00019604819390783485]
[2024-04-20 13:58:34,716: INFO: roberta_kFold_initial_lstm: Training : batch 980 Loss: 0.005100923833021562]
[2024-04-20 13:58:35,371: INFO: roberta_kFold_initial_lstm: Training : batch 981 Loss: 0.0047847956233006425]
[2024-04-20 13:58:36,024: INFO: roberta_kFold_initial_lstm: Training : batch 982 Loss: 0.0042869751655094475]
[2024-04-20 13:58:36,679: INFO: roberta_kFold_initial_lstm: Training : batch 983 Loss: 0.020697204181002495]
[2024-04-20 13:58:37,330: INFO: roberta_kFold_initial_lstm: Training : batch 984 Loss: 0.004000329854740864]
[2024-04-20 13:58:37,980: INFO: roberta_kFold_initial_lstm: Training : batch 985 Loss: 0.0028512299123595766]
[2024-04-20 13:58:38,632: INFO: roberta_kFold_initial_lstm: Training : batch 986 Loss: 0.0006571314152221742]
[2024-04-20 13:58:39,284: INFO: roberta_kFold_initial_lstm: Training : batch 987 Loss: 0.005744069714833526]
[2024-04-20 13:58:39,950: INFO: roberta_kFold_initial_lstm: Training : batch 988 Loss: 0.007925885920017358]
[2024-04-20 13:58:40,619: INFO: roberta_kFold_initial_lstm: Training : batch 989 Loss: 0.007287518203183358]
[2024-04-20 13:58:41,283: INFO: roberta_kFold_initial_lstm: Training : batch 990 Loss: 0.0022118989370865844]
[2024-04-20 13:58:41,955: INFO: roberta_kFold_initial_lstm: Training : batch 991 Loss: 0.0046936031080644074]
[2024-04-20 13:58:42,624: INFO: roberta_kFold_initial_lstm: Training : batch 992 Loss: 0.002297502335079818]
[2024-04-20 13:58:43,276: INFO: roberta_kFold_initial_lstm: Training : batch 993 Loss: 0.0013076661828401257]
[2024-04-20 13:58:43,936: INFO: roberta_kFold_initial_lstm: Training : batch 994 Loss: 0.010005717551233195]
[2024-04-20 13:58:44,594: INFO: roberta_kFold_initial_lstm: Training : batch 995 Loss: 0.0007878093857002033]
[2024-04-20 13:58:45,250: INFO: roberta_kFold_initial_lstm: Training : batch 996 Loss: 0.0016131248704421087]
[2024-04-20 13:58:45,908: INFO: roberta_kFold_initial_lstm: Training : batch 997 Loss: 0.002701401403567497]
[2024-04-20 13:58:46,564: INFO: roberta_kFold_initial_lstm: Training : batch 998 Loss: 0.002433293746288496]
[2024-04-20 13:58:47,226: INFO: roberta_kFold_initial_lstm: Training : batch 999 Loss: 0.0022444457552343706]
[2024-04-20 13:58:47,879: INFO: roberta_kFold_initial_lstm: Training : batch 1000 Loss: 0.000907678358835283]
[2024-04-20 13:58:48,534: INFO: roberta_kFold_initial_lstm: Training : batch 1001 Loss: 0.0008444747397058175]
[2024-04-20 13:58:49,188: INFO: roberta_kFold_initial_lstm: Training : batch 1002 Loss: 0.0024969454273839663]
[2024-04-20 13:58:49,843: INFO: roberta_kFold_initial_lstm: Training : batch 1003 Loss: 0.0009584495116622179]
[2024-04-20 13:58:50,495: INFO: roberta_kFold_initial_lstm: Training : batch 1004 Loss: 0.006231088507781927]
[2024-04-20 13:58:51,149: INFO: roberta_kFold_initial_lstm: Training : batch 1005 Loss: 0.003983179732260206]
[2024-04-20 13:58:51,805: INFO: roberta_kFold_initial_lstm: Training : batch 1006 Loss: 0.0009925107630312463]
[2024-04-20 13:58:52,456: INFO: roberta_kFold_initial_lstm: Training : batch 1007 Loss: 0.002540567565219702]
[2024-04-20 13:58:53,112: INFO: roberta_kFold_initial_lstm: Training : batch 1008 Loss: 0.015345862292201543]
[2024-04-20 13:58:53,793: INFO: roberta_kFold_initial_lstm: Training : batch 1009 Loss: 0.006222524020992776]
[2024-04-20 13:58:54,456: INFO: roberta_kFold_initial_lstm: Training : batch 1010 Loss: 0.0075955167255424665]
[2024-04-20 13:58:55,118: INFO: roberta_kFold_initial_lstm: Training : batch 1011 Loss: 0.0018465595509956291]
[2024-04-20 13:58:55,786: INFO: roberta_kFold_initial_lstm: Training : batch 1012 Loss: 0.0019333594563545737]
[2024-04-20 13:58:56,438: INFO: roberta_kFold_initial_lstm: Training : batch 1013 Loss: 0.001166352732691716]
[2024-04-20 13:58:57,096: INFO: roberta_kFold_initial_lstm: Training : batch 1014 Loss: 0.010182663774480709]
[2024-04-20 13:58:57,751: INFO: roberta_kFold_initial_lstm: Training : batch 1015 Loss: 0.0012930452276175538]
[2024-04-20 13:58:58,412: INFO: roberta_kFold_initial_lstm: Training : batch 1016 Loss: 0.003495811433662369]
[2024-04-20 13:58:59,072: INFO: roberta_kFold_initial_lstm: Training : batch 1017 Loss: 0.007718205830806322]
[2024-04-20 13:58:59,725: INFO: roberta_kFold_initial_lstm: Training : batch 1018 Loss: 0.007986803623741533]
[2024-04-20 13:59:00,380: INFO: roberta_kFold_initial_lstm: Training : batch 1019 Loss: 0.004332740281403299]
[2024-04-20 13:59:01,040: INFO: roberta_kFold_initial_lstm: Training : batch 1020 Loss: 0.003687443043235081]
[2024-04-20 13:59:01,695: INFO: roberta_kFold_initial_lstm: Training : batch 1021 Loss: 8.082748221707603e-05]
[2024-04-20 13:59:02,348: INFO: roberta_kFold_initial_lstm: Training : batch 1022 Loss: 0.00035632296242821894]
[2024-04-20 13:59:03,005: INFO: roberta_kFold_initial_lstm: Training : batch 1023 Loss: 0.005472745832049606]
[2024-04-20 13:59:03,663: INFO: roberta_kFold_initial_lstm: Training : batch 1024 Loss: 0.005972044144478753]
[2024-04-20 13:59:04,319: INFO: roberta_kFold_initial_lstm: Training : batch 1025 Loss: 0.0014378281579190326]
[2024-04-20 13:59:04,975: INFO: roberta_kFold_initial_lstm: Training : batch 1026 Loss: 0.008160373552254317]
[2024-04-20 13:59:05,643: INFO: roberta_kFold_initial_lstm: Training : batch 1027 Loss: 0.0021383550768523324]
[2024-04-20 13:59:06,312: INFO: roberta_kFold_initial_lstm: Training : batch 1028 Loss: 0.008787271256682706]
[2024-04-20 13:59:06,965: INFO: roberta_kFold_initial_lstm: Training : batch 1029 Loss: 0.0064377097763829464]
[2024-04-20 13:59:07,629: INFO: roberta_kFold_initial_lstm: Training : batch 1030 Loss: 0.007506926069152842]
[2024-04-20 13:59:08,290: INFO: roberta_kFold_initial_lstm: Training : batch 1031 Loss: 0.0014972094754073747]
[2024-04-20 13:59:08,958: INFO: roberta_kFold_initial_lstm: Training : batch 1032 Loss: 0.0113871381170148]
[2024-04-20 13:59:09,615: INFO: roberta_kFold_initial_lstm: Training : batch 1033 Loss: 0.0001281603483900559]
[2024-04-20 13:59:10,272: INFO: roberta_kFold_initial_lstm: Training : batch 1034 Loss: 0.002608314449163957]
[2024-04-20 13:59:10,926: INFO: roberta_kFold_initial_lstm: Training : batch 1035 Loss: 0.003753806186398551]
[2024-04-20 13:59:11,586: INFO: roberta_kFold_initial_lstm: Training : batch 1036 Loss: 0.017833217012057347]
[2024-04-20 13:59:12,241: INFO: roberta_kFold_initial_lstm: Training : batch 1037 Loss: 0.002805100468111005]
[2024-04-20 13:59:12,901: INFO: roberta_kFold_initial_lstm: Training : batch 1038 Loss: 0.0005938805020131669]
[2024-04-20 13:59:13,556: INFO: roberta_kFold_initial_lstm: Training : batch 1039 Loss: 0.0025286115908802194]
[2024-04-20 13:59:14,213: INFO: roberta_kFold_initial_lstm: Training : batch 1040 Loss: 0.0012529028711538855]
[2024-04-20 13:59:14,867: INFO: roberta_kFold_initial_lstm: Training : batch 1041 Loss: 0.007896170632643636]
[2024-04-20 13:59:15,522: INFO: roberta_kFold_initial_lstm: Training : batch 1042 Loss: 0.00513853900996508]
[2024-04-20 13:59:16,180: INFO: roberta_kFold_initial_lstm: Training : batch 1043 Loss: 0.0036133079492469255]
[2024-04-20 13:59:16,837: INFO: roberta_kFold_initial_lstm: Training : batch 1044 Loss: 0.016808534101998465]
[2024-04-20 13:59:17,496: INFO: roberta_kFold_initial_lstm: Training : batch 1045 Loss: 0.005420236225000446]
[2024-04-20 13:59:18,153: INFO: roberta_kFold_initial_lstm: Training : batch 1046 Loss: 0.013567483693014545]
[2024-04-20 13:59:18,807: INFO: roberta_kFold_initial_lstm: Training : batch 1047 Loss: 0.0007248981232513825]
[2024-04-20 13:59:19,475: INFO: roberta_kFold_initial_lstm: Training : batch 1048 Loss: 0.0022183874625394096]
[2024-04-20 13:59:20,140: INFO: roberta_kFold_initial_lstm: Training : batch 1049 Loss: 0.002200095734974293]
[2024-04-20 13:59:20,795: INFO: roberta_kFold_initial_lstm: Training : batch 1050 Loss: 0.01157339960535887]
[2024-04-20 13:59:21,457: INFO: roberta_kFold_initial_lstm: Training : batch 1051 Loss: 0.0037285035665284793]
[2024-04-20 13:59:22,119: INFO: roberta_kFold_initial_lstm: Training : batch 1052 Loss: 0.0009782992368965618]
[2024-04-20 13:59:22,776: INFO: roberta_kFold_initial_lstm: Training : batch 1053 Loss: 0.0016546726295062371]
[2024-04-20 13:59:23,442: INFO: roberta_kFold_initial_lstm: Training : batch 1054 Loss: 0.0005942785103654347]
[2024-04-20 13:59:24,100: INFO: roberta_kFold_initial_lstm: Training : batch 1055 Loss: 0.004414355983192508]
[2024-04-20 13:59:24,760: INFO: roberta_kFold_initial_lstm: Training : batch 1056 Loss: 0.001379424567264284]
[2024-04-20 13:59:25,414: INFO: roberta_kFold_initial_lstm: Training : batch 1057 Loss: 0.0017977412209257576]
[2024-04-20 13:59:26,071: INFO: roberta_kFold_initial_lstm: Training : batch 1058 Loss: 0.0002826811321652943]
[2024-04-20 13:59:26,721: INFO: roberta_kFold_initial_lstm: Training : batch 1059 Loss: 0.0008239527309996741]
[2024-04-20 13:59:27,376: INFO: roberta_kFold_initial_lstm: Training : batch 1060 Loss: 0.003855191313463109]
[2024-04-20 13:59:28,031: INFO: roberta_kFold_initial_lstm: Training : batch 1061 Loss: 0.0020610589173977708]
[2024-04-20 13:59:28,689: INFO: roberta_kFold_initial_lstm: Training : batch 1062 Loss: 0.006181807160618266]
[2024-04-20 13:59:29,348: INFO: roberta_kFold_initial_lstm: Training : batch 1063 Loss: 0.0005296209495028167]
[2024-04-20 13:59:30,007: INFO: roberta_kFold_initial_lstm: Training : batch 1064 Loss: 0.007767988553989008]
[2024-04-20 13:59:30,661: INFO: roberta_kFold_initial_lstm: Training : batch 1065 Loss: 0.004016832793442294]
[2024-04-20 13:59:31,318: INFO: roberta_kFold_initial_lstm: Training : batch 1066 Loss: 0.001168212729157592]
[2024-04-20 13:59:31,974: INFO: roberta_kFold_initial_lstm: Training : batch 1067 Loss: 0.004686801540309036]
[2024-04-20 13:59:32,638: INFO: roberta_kFold_initial_lstm: Training : batch 1068 Loss: 0.004932818172595429]
[2024-04-20 13:59:33,308: INFO: roberta_kFold_initial_lstm: Training : batch 1069 Loss: 0.0032544557156084664]
[2024-04-20 13:59:33,968: INFO: roberta_kFold_initial_lstm: Training : batch 1070 Loss: 0.00017288117571886806]
[2024-04-20 13:59:34,645: INFO: roberta_kFold_initial_lstm: Training : batch 1071 Loss: 0.006701892833974799]
[2024-04-20 13:59:35,308: INFO: roberta_kFold_initial_lstm: Training : batch 1072 Loss: 0.011791447908862744]
[2024-04-20 13:59:35,959: INFO: roberta_kFold_initial_lstm: Training : batch 1073 Loss: 0.006826841128150439]
[2024-04-20 13:59:36,624: INFO: roberta_kFold_initial_lstm: Training : batch 1074 Loss: 0.010316697465599968]
[2024-04-20 13:59:37,283: INFO: roberta_kFold_initial_lstm: Training : batch 1075 Loss: 0.004180649606510309]
[2024-04-20 13:59:37,935: INFO: roberta_kFold_initial_lstm: Training : batch 1076 Loss: 0.000467970021967095]
[2024-04-20 13:59:38,592: INFO: roberta_kFold_initial_lstm: Training : batch 1077 Loss: 0.00653363860599033]
[2024-04-20 13:59:39,253: INFO: roberta_kFold_initial_lstm: Training : batch 1078 Loss: 0.01483596491168025]
[2024-04-20 13:59:39,908: INFO: roberta_kFold_initial_lstm: Training : batch 1079 Loss: 0.0041015862003310755]
[2024-04-20 13:59:40,564: INFO: roberta_kFold_initial_lstm: Training : batch 1080 Loss: 0.005568664575147267]
[2024-04-20 13:59:41,222: INFO: roberta_kFold_initial_lstm: Training : batch 1081 Loss: 0.004293816672873608]
[2024-04-20 13:59:41,877: INFO: roberta_kFold_initial_lstm: Training : batch 1082 Loss: 0.0023704452548632777]
[2024-04-20 13:59:42,536: INFO: roberta_kFold_initial_lstm: Training : batch 1083 Loss: 0.000490425466062202]
[2024-04-20 13:59:43,192: INFO: roberta_kFold_initial_lstm: Training : batch 1084 Loss: 0.005870879123599128]
[2024-04-20 13:59:43,851: INFO: roberta_kFold_initial_lstm: Training : batch 1085 Loss: 0.005075640828745296]
[2024-04-20 13:59:44,512: INFO: roberta_kFold_initial_lstm: Training : batch 1086 Loss: 0.005029893441684334]
[2024-04-20 13:59:45,167: INFO: roberta_kFold_initial_lstm: Training : batch 1087 Loss: 0.006237157485755825]
[2024-04-20 13:59:45,830: INFO: roberta_kFold_initial_lstm: Training : batch 1088 Loss: 0.0014231463509556002]
[2024-04-20 13:59:46,494: INFO: roberta_kFold_initial_lstm: Training : batch 1089 Loss: 0.0028784783220358883]
[2024-04-20 13:59:47,150: INFO: roberta_kFold_initial_lstm: Training : batch 1090 Loss: 0.003310397023954016]
[2024-04-20 13:59:47,813: INFO: roberta_kFold_initial_lstm: Training : batch 1091 Loss: 0.009245645458444824]
[2024-04-20 13:59:48,472: INFO: roberta_kFold_initial_lstm: Training : batch 1092 Loss: 0.005633680378348673]
[2024-04-20 13:59:49,129: INFO: roberta_kFold_initial_lstm: Training : batch 1093 Loss: 0.0025758888829389096]
[2024-04-20 13:59:49,787: INFO: roberta_kFold_initial_lstm: Training : batch 1094 Loss: 0.006399723608260646]
[2024-04-20 13:59:50,445: INFO: roberta_kFold_initial_lstm: Training : batch 1095 Loss: 0.007531257755432113]
[2024-04-20 13:59:51,103: INFO: roberta_kFold_initial_lstm: Training : batch 1096 Loss: 0.003569634911133068]
[2024-04-20 13:59:51,757: INFO: roberta_kFold_initial_lstm: Training : batch 1097 Loss: 0.0002927670192141436]
[2024-04-20 13:59:52,418: INFO: roberta_kFold_initial_lstm: Training : batch 1098 Loss: 0.0068209539298905875]
[2024-04-20 13:59:53,073: INFO: roberta_kFold_initial_lstm: Training : batch 1099 Loss: 0.028210403908808388]
[2024-04-20 13:59:53,729: INFO: roberta_kFold_initial_lstm: Training : batch 1100 Loss: 0.012473567521513471]
[2024-04-20 13:59:54,382: INFO: roberta_kFold_initial_lstm: Training : batch 1101 Loss: 0.0007144913483870853]
[2024-04-20 13:59:55,036: INFO: roberta_kFold_initial_lstm: Training : batch 1102 Loss: 0.005463092587407929]
[2024-04-20 13:59:55,691: INFO: roberta_kFold_initial_lstm: Training : batch 1103 Loss: 0.0032417197423491705]
[2024-04-20 13:59:56,349: INFO: roberta_kFold_initial_lstm: Training : batch 1104 Loss: 0.0026888514912363926]
[2024-04-20 13:59:57,000: INFO: roberta_kFold_initial_lstm: Training : batch 1105 Loss: 0.005174599813426447]
[2024-04-20 13:59:57,660: INFO: roberta_kFold_initial_lstm: Training : batch 1106 Loss: 0.004865103790052015]
[2024-04-20 13:59:58,318: INFO: roberta_kFold_initial_lstm: Training : batch 1107 Loss: 0.0028992830193140836]
[2024-04-20 13:59:58,985: INFO: roberta_kFold_initial_lstm: Training : batch 1108 Loss: 0.0011883224173576932]
[2024-04-20 13:59:59,651: INFO: roberta_kFold_initial_lstm: Training : batch 1109 Loss: 0.002043008999489819]
[2024-04-20 14:00:00,335: INFO: roberta_kFold_initial_lstm: Training : batch 1110 Loss: 0.001411966600894951]
[2024-04-20 14:00:01,002: INFO: roberta_kFold_initial_lstm: Training : batch 1111 Loss: 0.0057059466771537505]
[2024-04-20 14:00:01,661: INFO: roberta_kFold_initial_lstm: Training : batch 1112 Loss: 0.008549734915838204]
[2024-04-20 14:00:02,319: INFO: roberta_kFold_initial_lstm: Training : batch 1113 Loss: 0.002708966774023821]
[2024-04-20 14:00:02,973: INFO: roberta_kFold_initial_lstm: Training : batch 1114 Loss: 0.0075308327297756005]
[2024-04-20 14:00:03,627: INFO: roberta_kFold_initial_lstm: Training : batch 1115 Loss: 0.0013514245515957465]
[2024-04-20 14:00:04,284: INFO: roberta_kFold_initial_lstm: Training : batch 1116 Loss: 0.00393824111968369]
[2024-04-20 14:00:04,940: INFO: roberta_kFold_initial_lstm: Training : batch 1117 Loss: 0.003395342046440283]
[2024-04-20 14:00:05,596: INFO: roberta_kFold_initial_lstm: Training : batch 1118 Loss: 0.00022084788438011394]
[2024-04-20 14:00:06,254: INFO: roberta_kFold_initial_lstm: Training : batch 1119 Loss: 0.001451426358314931]
[2024-04-20 14:00:06,913: INFO: roberta_kFold_initial_lstm: Training : batch 1120 Loss: 0.0015405008187491657]
[2024-04-20 14:00:07,569: INFO: roberta_kFold_initial_lstm: Training : batch 1121 Loss: 0.004331750181510957]
[2024-04-20 14:00:08,232: INFO: roberta_kFold_initial_lstm: Training : batch 1122 Loss: 0.0019590801572966386]
[2024-04-20 14:00:08,888: INFO: roberta_kFold_initial_lstm: Training : batch 1123 Loss: 0.0026095917431110793]
[2024-04-20 14:00:09,550: INFO: roberta_kFold_initial_lstm: Training : batch 1124 Loss: 0.004266883557447785]
[2024-04-20 14:00:10,203: INFO: roberta_kFold_initial_lstm: Training : batch 1125 Loss: 0.0033902741763871284]
[2024-04-20 14:00:10,857: INFO: roberta_kFold_initial_lstm: Training : batch 1126 Loss: 0.001591333057226215]
[2024-04-20 14:00:11,513: INFO: roberta_kFold_initial_lstm: Training : batch 1127 Loss: 0.005739151141754731]
[2024-04-20 14:00:12,187: INFO: roberta_kFold_initial_lstm: Training : batch 1128 Loss: 0.022753102324424963]
[2024-04-20 14:00:12,855: INFO: roberta_kFold_initial_lstm: Training : batch 1129 Loss: 0.00023727608126508643]
[2024-04-20 14:00:13,516: INFO: roberta_kFold_initial_lstm: Training : batch 1130 Loss: 0.0051833352547791854]
[2024-04-20 14:00:14,184: INFO: roberta_kFold_initial_lstm: Training : batch 1131 Loss: 0.0030966368785196536]
[2024-04-20 14:00:14,850: INFO: roberta_kFold_initial_lstm: Training : batch 1132 Loss: 0.0016070220373250444]
[2024-04-20 14:00:15,502: INFO: roberta_kFold_initial_lstm: Training : batch 1133 Loss: 0.0055090754412747455]
[2024-04-20 14:00:16,159: INFO: roberta_kFold_initial_lstm: Training : batch 1134 Loss: 0.009656446846296038]
[2024-04-20 14:00:16,814: INFO: roberta_kFold_initial_lstm: Training : batch 1135 Loss: 0.002644023055905092]
[2024-04-20 14:00:17,469: INFO: roberta_kFold_initial_lstm: Training : batch 1136 Loss: 0.000917431375980071]
[2024-04-20 14:00:18,127: INFO: roberta_kFold_initial_lstm: Training : batch 1137 Loss: 0.0012034182372594746]
[2024-04-20 14:00:18,785: INFO: roberta_kFold_initial_lstm: Training : batch 1138 Loss: 0.0018882760988018167]
[2024-04-20 14:00:19,440: INFO: roberta_kFold_initial_lstm: Training : batch 1139 Loss: 0.0002977619529008561]
[2024-04-20 14:00:20,095: INFO: roberta_kFold_initial_lstm: Training : batch 1140 Loss: 0.0036247193398099655]
[2024-04-20 14:00:20,751: INFO: roberta_kFold_initial_lstm: Training : batch 1141 Loss: 0.0007798467032554984]
[2024-04-20 14:00:21,401: INFO: roberta_kFold_initial_lstm: Training : batch 1142 Loss: 0.03537115034651338]
[2024-04-20 14:00:22,058: INFO: roberta_kFold_initial_lstm: Training : batch 1143 Loss: 0.0019445922950024085]
[2024-04-20 14:00:22,716: INFO: roberta_kFold_initial_lstm: Training : batch 1144 Loss: 0.006465353684153026]
[2024-04-20 14:00:23,374: INFO: roberta_kFold_initial_lstm: Training : batch 1145 Loss: 0.002953381809865257]
[2024-04-20 14:00:24,028: INFO: roberta_kFold_initial_lstm: Training : batch 1146 Loss: 0.002213561654146541]
[2024-04-20 14:00:24,685: INFO: roberta_kFold_initial_lstm: Training : batch 1147 Loss: 0.004259183011763439]
[2024-04-20 14:00:25,345: INFO: roberta_kFold_initial_lstm: Training : batch 1148 Loss: 0.0009775195165534214]
[2024-04-20 14:00:26,004: INFO: roberta_kFold_initial_lstm: Training : batch 1149 Loss: 0.0035049714066627343]
[2024-04-20 14:00:26,671: INFO: roberta_kFold_initial_lstm: Training : batch 1150 Loss: 0.00027716313503546456]
[2024-04-20 14:00:27,339: INFO: roberta_kFold_initial_lstm: Training : batch 1151 Loss: 0.0022600990075116916]
[2024-04-20 14:00:28,008: INFO: roberta_kFold_initial_lstm: Training : batch 1152 Loss: 0.0016687454192305285]
[2024-04-20 14:00:28,660: INFO: roberta_kFold_initial_lstm: Training : batch 1153 Loss: 0.006179693815837765]
[2024-04-20 14:00:29,318: INFO: roberta_kFold_initial_lstm: Training : batch 1154 Loss: 0.0022249716358335087]
[2024-04-20 14:00:29,975: INFO: roberta_kFold_initial_lstm: Training : batch 1155 Loss: 0.006623160130273801]
[2024-04-20 14:00:30,631: INFO: roberta_kFold_initial_lstm: Training : batch 1156 Loss: 0.006425501569558754]
[2024-04-20 14:00:31,288: INFO: roberta_kFold_initial_lstm: Training : batch 1157 Loss: 0.00047219414956891086]
[2024-04-20 14:00:31,942: INFO: roberta_kFold_initial_lstm: Training : batch 1158 Loss: 0.0015166582997067574]
[2024-04-20 14:00:32,598: INFO: roberta_kFold_initial_lstm: Training : batch 1159 Loss: 0.0003983811781677504]
[2024-04-20 14:00:33,251: INFO: roberta_kFold_initial_lstm: Training : batch 1160 Loss: 0.0002974858892321465]
[2024-04-20 14:00:33,910: INFO: roberta_kFold_initial_lstm: Training : batch 1161 Loss: 0.0035082483956852912]
[2024-04-20 14:00:34,562: INFO: roberta_kFold_initial_lstm: Training : batch 1162 Loss: 0.008118483644904742]
[2024-04-20 14:00:35,215: INFO: roberta_kFold_initial_lstm: Training : batch 1163 Loss: 0.005505145118235877]
[2024-04-20 14:00:35,870: INFO: roberta_kFold_initial_lstm: Training : batch 1164 Loss: 0.0014772224886952184]
[2024-04-20 14:00:36,521: INFO: roberta_kFold_initial_lstm: Training : batch 1165 Loss: 0.0007951873752178037]
[2024-04-20 14:00:37,175: INFO: roberta_kFold_initial_lstm: Training : batch 1166 Loss: 0.0013629916315819571]
[2024-04-20 14:00:37,827: INFO: roberta_kFold_initial_lstm: Training : batch 1167 Loss: 0.005353031820850896]
[2024-04-20 14:00:38,485: INFO: roberta_kFold_initial_lstm: Training : batch 1168 Loss: 0.0067902415719679286]
[2024-04-20 14:00:39,149: INFO: roberta_kFold_initial_lstm: Training : batch 1169 Loss: 2.9630429218938324e-05]
[2024-04-20 14:00:39,811: INFO: roberta_kFold_initial_lstm: Training : batch 1170 Loss: 0.010181301579607506]
[2024-04-20 14:00:40,468: INFO: roberta_kFold_initial_lstm: Training : batch 1171 Loss: 0.0033365980644183587]
[2024-04-20 14:00:41,128: INFO: roberta_kFold_initial_lstm: Training : batch 1172 Loss: 0.0018782786161596972]
[2024-04-20 14:00:41,785: INFO: roberta_kFold_initial_lstm: Training : batch 1173 Loss: 0.00026931044525371317]
[2024-04-20 14:00:42,442: INFO: roberta_kFold_initial_lstm: Training : batch 1174 Loss: 0.0011775553259237579]
[2024-04-20 14:00:43,100: INFO: roberta_kFold_initial_lstm: Training : batch 1175 Loss: 0.006637312276499021]
[2024-04-20 14:00:43,755: INFO: roberta_kFold_initial_lstm: Training : batch 1176 Loss: 0.007208712973794992]
[2024-04-20 14:00:44,407: INFO: roberta_kFold_initial_lstm: Training : batch 1177 Loss: 0.0009172356456080248]
[2024-04-20 14:00:45,063: INFO: roberta_kFold_initial_lstm: Training : batch 1178 Loss: 0.011280070630035803]
[2024-04-20 14:00:45,715: INFO: roberta_kFold_initial_lstm: Training : batch 1179 Loss: 0.006846165812673445]
[2024-04-20 14:00:46,370: INFO: roberta_kFold_initial_lstm: Training : batch 1180 Loss: 0.0005791145003874897]
[2024-04-20 14:00:47,022: INFO: roberta_kFold_initial_lstm: Training : batch 1181 Loss: 0.0020832864172142104]
[2024-04-20 14:00:47,681: INFO: roberta_kFold_initial_lstm: Training : batch 1182 Loss: 0.0162437615363213]
[2024-04-20 14:00:48,337: INFO: roberta_kFold_initial_lstm: Training : batch 1183 Loss: 0.009069997544203907]
[2024-04-20 14:00:48,994: INFO: roberta_kFold_initial_lstm: Training : batch 1184 Loss: 0.004626168774629694]
[2024-04-20 14:00:49,647: INFO: roberta_kFold_initial_lstm: Training : batch 1185 Loss: 0.00020477856978387687]
[2024-04-20 14:00:50,303: INFO: roberta_kFold_initial_lstm: Training : batch 1186 Loss: 0.0032188402464934577]
[2024-04-20 14:00:50,959: INFO: roberta_kFold_initial_lstm: Training : batch 1187 Loss: 0.010770821770652104]
[2024-04-20 14:00:51,620: INFO: roberta_kFold_initial_lstm: Training : batch 1188 Loss: 0.00015576801371462292]
[2024-04-20 14:00:52,283: INFO: roberta_kFold_initial_lstm: Training : batch 1189 Loss: 4.7412923028143196e-05]
[2024-04-20 14:00:52,950: INFO: roberta_kFold_initial_lstm: Training : batch 1190 Loss: 0.002714755889114391]
[2024-04-20 14:00:53,460: INFO: roberta_kFold_initial_lstm: Training : batch 1191 Loss: 0.006036742126058317]
[2024-04-20 14:00:53,674: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 0 Loss: 0.000875024467134287]
[2024-04-20 14:00:53,899: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 1 Loss: 0.00411543942777788]
[2024-04-20 14:00:54,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 2 Loss: 0.0005273006725118093]
[2024-04-20 14:00:54,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 3 Loss: 0.0018907835533038479]
[2024-04-20 14:00:54,515: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 4 Loss: 0.0034286418567706064]
[2024-04-20 14:00:54,728: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 5 Loss: 0.008049844054361571]
[2024-04-20 14:00:54,934: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 6 Loss: 0.010098994650925357]
[2024-04-20 14:00:55,138: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 7 Loss: 0.000942772555881031]
[2024-04-20 14:00:55,344: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 8 Loss: 0.003292601816481948]
[2024-04-20 14:00:55,552: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 9 Loss: 0.002912602210430285]
[2024-04-20 14:00:55,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 10 Loss: 0.0012056381952752064]
[2024-04-20 14:00:55,964: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 11 Loss: 0.000355821171443838]
[2024-04-20 14:00:56,172: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 12 Loss: 0.00469067886895546]
[2024-04-20 14:00:56,377: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 13 Loss: 0.010583590979874555]
[2024-04-20 14:00:56,585: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 14 Loss: 0.0026757058360322773]
[2024-04-20 14:00:56,792: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 15 Loss: 0.0006519993021151632]
[2024-04-20 14:00:56,999: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 16 Loss: 0.01479577409324588]
[2024-04-20 14:00:57,207: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 17 Loss: 0.005656156790824246]
[2024-04-20 14:00:57,416: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 18 Loss: 0.001095048658649585]
[2024-04-20 14:00:57,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 19 Loss: 0.0053062335199941]
[2024-04-20 14:00:57,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 20 Loss: 0.002278189481788392]
[2024-04-20 14:00:58,039: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 21 Loss: 0.00433815394303174]
[2024-04-20 14:00:58,246: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 22 Loss: 0.014483164944078475]
[2024-04-20 14:00:58,453: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 23 Loss: 0.005467930890169965]
[2024-04-20 14:00:58,660: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 24 Loss: 0.001950660144684062]
[2024-04-20 14:00:58,868: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 25 Loss: 0.003265879674666584]
[2024-04-20 14:00:59,073: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 26 Loss: 0.00752013376884215]
[2024-04-20 14:00:59,278: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 27 Loss: 0.003950817058807523]
[2024-04-20 14:00:59,483: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 28 Loss: 0.0012291612429229332]
[2024-04-20 14:00:59,686: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 29 Loss: 0.003580118534300809]
[2024-04-20 14:00:59,895: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 30 Loss: 0.0007392842308317392]
[2024-04-20 14:01:00,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 31 Loss: 0.0005086471273312394]
[2024-04-20 14:01:00,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 32 Loss: 0.0027154941948150275]
[2024-04-20 14:01:00,521: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 33 Loss: 0.0055899893240386215]
[2024-04-20 14:01:00,726: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 34 Loss: 0.0012903863232306785]
[2024-04-20 14:01:00,934: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 35 Loss: 0.0050089980985001175]
[2024-04-20 14:01:01,144: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 36 Loss: 0.0012721352020250828]
[2024-04-20 14:01:01,350: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 37 Loss: 0.002350013529576]
[2024-04-20 14:01:01,554: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 38 Loss: 0.0019165222485142408]
[2024-04-20 14:01:01,762: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 39 Loss: 0.017501028976760657]
[2024-04-20 14:01:01,970: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 40 Loss: 0.010900503525257376]
[2024-04-20 14:01:02,175: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 41 Loss: 0.01718004638319599]
[2024-04-20 14:01:02,383: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 42 Loss: 0.02766475291455703]
[2024-04-20 14:01:02,588: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 43 Loss: 0.005873650421975612]
[2024-04-20 14:01:02,795: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 44 Loss: 0.00511039242257305]
[2024-04-20 14:01:03,003: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 45 Loss: 0.004894346878886421]
[2024-04-20 14:01:03,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 46 Loss: 0.001465084066304857]
[2024-04-20 14:01:03,423: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 47 Loss: 0.0018031331411808079]
[2024-04-20 14:01:03,630: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 48 Loss: 0.006090860755786702]
[2024-04-20 14:01:03,837: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 49 Loss: 0.0019650256332913903]
[2024-04-20 14:01:04,048: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 50 Loss: 0.006284340916234427]
[2024-04-20 14:01:04,262: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 51 Loss: 0.004614631623745247]
[2024-04-20 14:01:04,470: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 52 Loss: 0.015261197114090977]
[2024-04-20 14:01:04,679: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 53 Loss: 0.0024660610735020637]
[2024-04-20 14:01:04,890: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 54 Loss: 0.005259442547505422]
[2024-04-20 14:01:05,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 55 Loss: 0.005617223593831042]
[2024-04-20 14:01:05,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 56 Loss: 0.01050645811720608]
[2024-04-20 14:01:05,526: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 57 Loss: 0.0018057691330120701]
[2024-04-20 14:01:05,735: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 58 Loss: 0.009596861468714229]
[2024-04-20 14:01:05,944: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 59 Loss: 0.0010218651522232234]
[2024-04-20 14:01:06,155: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 60 Loss: 0.0021576630570640074]
[2024-04-20 14:01:06,365: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 61 Loss: 0.009405657437299006]
[2024-04-20 14:01:06,581: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 62 Loss: 0.005657300872833889]
[2024-04-20 14:01:06,789: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 63 Loss: 0.006824500479955289]
[2024-04-20 14:01:07,001: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 64 Loss: 0.0023445187304016687]
[2024-04-20 14:01:07,216: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 65 Loss: 0.0003150810057540136]
[2024-04-20 14:01:07,426: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 66 Loss: 0.005002144566918922]
[2024-04-20 14:01:07,632: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 67 Loss: 0.01085299205990454]
[2024-04-20 14:01:07,838: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 68 Loss: 0.001883116439255609]
[2024-04-20 14:01:08,050: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 69 Loss: 0.0006174645852096228]
[2024-04-20 14:01:08,256: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 70 Loss: 0.00608988897496562]
[2024-04-20 14:01:08,464: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 71 Loss: 0.0023554646840569728]
[2024-04-20 14:01:08,670: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 72 Loss: 0.004218330992289663]
[2024-04-20 14:01:08,874: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 73 Loss: 0.0019741655855092066]
[2024-04-20 14:01:09,083: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 74 Loss: 0.00195599277763628]
[2024-04-20 14:01:09,290: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 75 Loss: 0.013307831144584127]
[2024-04-20 14:01:09,496: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 76 Loss: 0.0046314476940508345]
[2024-04-20 14:01:09,701: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 77 Loss: 0.0006548066709610769]
[2024-04-20 14:01:09,908: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 78 Loss: 0.0018950486131317395]
[2024-04-20 14:01:10,117: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 79 Loss: 0.00732166257881807]
[2024-04-20 14:01:10,322: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 80 Loss: 0.0009180645479285982]
[2024-04-20 14:01:10,529: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 81 Loss: 0.001589970464028767]
[2024-04-20 14:01:10,738: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 82 Loss: 0.0013487528925122255]
[2024-04-20 14:01:10,944: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 83 Loss: 0.0018583439562806648]
[2024-04-20 14:01:11,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 84 Loss: 0.007237789451120774]
[2024-04-20 14:01:11,356: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 85 Loss: 0.0021760922782729174]
[2024-04-20 14:01:11,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 86 Loss: 0.0029116576645103957]
[2024-04-20 14:01:11,773: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 87 Loss: 0.013962420543598798]
[2024-04-20 14:01:11,979: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 88 Loss: 0.004944626221667932]
[2024-04-20 14:01:12,183: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 89 Loss: 8.300051589632108e-05]
[2024-04-20 14:01:12,392: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 90 Loss: 0.009153257293042505]
[2024-04-20 14:01:12,597: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 91 Loss: 0.0030694698427612163]
[2024-04-20 14:01:12,804: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 92 Loss: 0.005218593106398064]
[2024-04-20 14:01:13,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 93 Loss: 0.015181317087274852]
[2024-04-20 14:01:13,216: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 94 Loss: 0.01227804366270467]
[2024-04-20 14:01:13,423: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 95 Loss: 0.0006075458303847988]
[2024-04-20 14:01:13,629: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 96 Loss: 0.0025109350143554692]
[2024-04-20 14:01:13,836: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 97 Loss: 0.004792704079526544]
[2024-04-20 14:01:14,044: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 98 Loss: 0.003498187440435647]
[2024-04-20 14:01:14,253: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 99 Loss: 0.0042973626168066265]
[2024-04-20 14:01:14,465: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 100 Loss: 0.0008240148703060723]
[2024-04-20 14:01:14,670: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 101 Loss: 0.0039048707742081615]
[2024-04-20 14:01:14,877: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 102 Loss: 0.003049883144528465]
[2024-04-20 14:01:15,082: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 103 Loss: 0.008818108782519042]
[2024-04-20 14:01:15,294: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 104 Loss: 0.004226276649325238]
[2024-04-20 14:01:15,501: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 105 Loss: 0.001838634503548677]
[2024-04-20 14:01:15,709: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 106 Loss: 0.0022594500399781654]
[2024-04-20 14:01:15,915: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 107 Loss: 0.00434893094699428]
[2024-04-20 14:01:16,121: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 108 Loss: 0.00018257026519529827]
[2024-04-20 14:01:16,326: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 109 Loss: 0.0015958532600850335]
[2024-04-20 14:01:16,535: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 110 Loss: 0.01837769293538381]
[2024-04-20 14:01:16,742: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 111 Loss: 0.003269693999355777]
[2024-04-20 14:01:16,949: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 112 Loss: 0.0004278887766836053]
[2024-04-20 14:01:17,156: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 113 Loss: 0.001350956293918231]
[2024-04-20 14:01:17,368: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 114 Loss: 0.0003932197715757307]
[2024-04-20 14:01:17,585: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 115 Loss: 0.0004977838942966159]
[2024-04-20 14:01:17,797: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 116 Loss: 0.01594753968009161]
[2024-04-20 14:01:18,008: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 117 Loss: 0.012581253406848276]
[2024-04-20 14:01:18,221: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 118 Loss: 0.018444704569196415]
[2024-04-20 14:01:18,439: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 119 Loss: 0.00035200847068089]
[2024-04-20 14:01:18,653: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 120 Loss: 0.017250344438502593]
[2024-04-20 14:01:18,865: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 121 Loss: 0.003921208169062448]
[2024-04-20 14:01:19,078: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 122 Loss: 0.020651319342784257]
[2024-04-20 14:01:19,288: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 123 Loss: 0.017994666277497167]
[2024-04-20 14:01:19,501: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 124 Loss: 0.002731615672312902]
[2024-04-20 14:01:19,713: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 125 Loss: 0.021084886666522692]
[2024-04-20 14:01:19,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 126 Loss: 0.0005442513789169589]
[2024-04-20 14:01:20,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 127 Loss: 0.002472705465518747]
[2024-04-20 14:01:20,348: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 128 Loss: 0.002673480253791202]
[2024-04-20 14:01:20,568: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 129 Loss: 0.013849244831603843]
[2024-04-20 14:01:20,779: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 130 Loss: 0.003163997842725254]
[2024-04-20 14:01:20,986: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 131 Loss: 0.0078309875058367]
[2024-04-20 14:01:21,197: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 132 Loss: 0.0009494993943359648]
[2024-04-20 14:01:21,402: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 133 Loss: 0.0031072321712809015]
[2024-04-20 14:01:21,610: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 134 Loss: 0.0010242441127159484]
[2024-04-20 14:01:21,815: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 135 Loss: 0.001428863872840694]
[2024-04-20 14:01:22,024: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 136 Loss: 0.0055239076413258125]
[2024-04-20 14:01:22,230: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 137 Loss: 0.007214524522955463]
[2024-04-20 14:01:22,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 138 Loss: 0.00023621166593483403]
[2024-04-20 14:01:22,644: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 139 Loss: 0.00155894835984339]
[2024-04-20 14:01:22,852: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 140 Loss: 0.0020970322645874843]
[2024-04-20 14:01:23,060: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 141 Loss: 0.00019688244192840964]
[2024-04-20 14:01:23,269: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 142 Loss: 0.008269897947631073]
[2024-04-20 14:01:23,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 143 Loss: 0.0006231168366675067]
[2024-04-20 14:01:23,680: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 144 Loss: 0.0007916113412035875]
[2024-04-20 14:01:23,889: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 145 Loss: 0.0025551590602307167]
[2024-04-20 14:01:24,097: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 146 Loss: 0.0029559897894691155]
[2024-04-20 14:01:24,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 147 Loss: 0.0030217373094520075]
[2024-04-20 14:01:24,514: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 148 Loss: 0.0046204417939576855]
[2024-04-20 14:01:24,718: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 149 Loss: 0.005118056908024837]
[2024-04-20 14:01:24,926: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 150 Loss: 0.003350207849631035]
[2024-04-20 14:01:25,135: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 151 Loss: 0.0014746869280692133]
[2024-04-20 14:01:25,342: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 152 Loss: 0.0018998732301276325]
[2024-04-20 14:01:25,548: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 153 Loss: 0.02904496850511787]
[2024-04-20 14:01:25,753: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 154 Loss: 0.01707042324378742]
[2024-04-20 14:01:25,961: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 155 Loss: 0.008270890584572118]
[2024-04-20 14:01:26,168: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 156 Loss: 0.0038390725361845458]
[2024-04-20 14:01:26,375: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 157 Loss: 0.0024204071804306533]
[2024-04-20 14:01:26,580: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 158 Loss: 0.0038736942660696824]
[2024-04-20 14:01:26,788: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 159 Loss: 0.004266326875753071]
[2024-04-20 14:01:26,991: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 160 Loss: 0.0016117912131498415]
[2024-04-20 14:01:27,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 161 Loss: 0.0013269727011516268]
[2024-04-20 14:01:27,407: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 162 Loss: 0.0016222863061262584]
[2024-04-20 14:01:27,610: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 163 Loss: 8.477192929290189e-05]
[2024-04-20 14:01:27,817: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 164 Loss: 0.013760562836742669]
[2024-04-20 14:01:28,020: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 165 Loss: 0.001275259912774291]
[2024-04-20 14:01:28,229: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 166 Loss: 0.013034931539447271]
[2024-04-20 14:01:28,434: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 167 Loss: 0.0037597205092024075]
[2024-04-20 14:01:28,638: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 168 Loss: 0.0044016396193316005]
[2024-04-20 14:01:28,842: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 169 Loss: 0.001775894471030303]
[2024-04-20 14:01:29,052: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 170 Loss: 0.004972501311231784]
[2024-04-20 14:01:29,261: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 171 Loss: 0.006736889427093615]
[2024-04-20 14:01:29,471: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 172 Loss: 0.002126832949515897]
[2024-04-20 14:01:29,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 173 Loss: 0.0013381969082511672]
[2024-04-20 14:01:29,889: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 174 Loss: 0.0012774632558889833]
[2024-04-20 14:01:30,095: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 175 Loss: 0.013855680562675804]
[2024-04-20 14:01:30,302: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 176 Loss: 0.0036687191931835733]
[2024-04-20 14:01:30,512: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 177 Loss: 0.0022625333845056354]
[2024-04-20 14:01:30,724: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 178 Loss: 0.001336279030714381]
[2024-04-20 14:01:30,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 179 Loss: 0.0005037909773841446]
[2024-04-20 14:01:31,142: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 180 Loss: 0.00019017053620092817]
[2024-04-20 14:01:31,349: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 181 Loss: 0.0008870292851078526]
[2024-04-20 14:01:31,559: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 182 Loss: 0.013002274681054781]
[2024-04-20 14:01:31,768: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 183 Loss: 0.0009666327497415422]
[2024-04-20 14:01:31,977: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 184 Loss: 0.0014503870070603111]
[2024-04-20 14:01:32,185: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 185 Loss: 0.0005938141670932026]
[2024-04-20 14:01:32,395: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 186 Loss: 0.0006617286748667877]
[2024-04-20 14:01:32,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 187 Loss: 0.000979887549180986]
[2024-04-20 14:01:32,821: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 188 Loss: 2.662425378375345e-05]
[2024-04-20 14:01:33,034: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 189 Loss: 0.003285123771804765]
[2024-04-20 14:01:33,265: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 190 Loss: 0.008698898553908136]
[2024-04-20 14:01:33,475: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 191 Loss: 0.0014156874463938454]
[2024-04-20 14:01:33,688: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 192 Loss: 0.00015828787607574668]
[2024-04-20 14:01:33,896: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 193 Loss: 0.00808872226148791]
[2024-04-20 14:01:34,110: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 194 Loss: 0.00025263251641148923]
[2024-04-20 14:01:34,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 195 Loss: 0.004226364799304868]
[2024-04-20 14:01:34,521: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 196 Loss: 0.0009231305106382276]
[2024-04-20 14:01:34,727: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 197 Loss: 9.461994340543587e-05]
[2024-04-20 14:01:34,936: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 198 Loss: 4.32178889602897e-05]
[2024-04-20 14:01:35,146: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 199 Loss: 0.0006070741723778462]
[2024-04-20 14:01:35,352: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 200 Loss: 0.00013124588438201317]
[2024-04-20 14:01:35,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 201 Loss: 0.0003648564068017204]
[2024-04-20 14:01:35,764: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 202 Loss: 0.0006384545415850005]
[2024-04-20 14:01:35,973: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 203 Loss: 0.0013783839770777492]
[2024-04-20 14:01:36,181: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 204 Loss: 0.0018897413023581918]
[2024-04-20 14:01:36,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 205 Loss: 0.010472029707043648]
[2024-04-20 14:01:36,597: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 206 Loss: 0.000549728561416837]
[2024-04-20 14:01:36,803: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 207 Loss: 0.000995861089391507]
[2024-04-20 14:01:37,011: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 208 Loss: 0.003879909181021228]
[2024-04-20 14:01:37,215: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 209 Loss: 0.0017839060678601442]
[2024-04-20 14:01:37,421: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 210 Loss: 0.01411933166064784]
[2024-04-20 14:01:37,628: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 211 Loss: 0.0002991828376976347]
[2024-04-20 14:01:37,834: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 212 Loss: 0.001895285982181384]
[2024-04-20 14:01:38,036: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 213 Loss: 0.0021125391367717026]
[2024-04-20 14:01:38,239: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 214 Loss: 0.004596980454720774]
[2024-04-20 14:01:38,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 215 Loss: 0.00011437660221889948]
[2024-04-20 14:01:38,650: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 216 Loss: 0.012710429513585485]
[2024-04-20 14:01:38,861: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 217 Loss: 0.0015219027141538805]
[2024-04-20 14:01:39,067: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 218 Loss: 0.004141332878196535]
[2024-04-20 14:01:39,278: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 219 Loss: 0.005288264371283174]
[2024-04-20 14:01:39,484: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 220 Loss: 0.0007526202300080273]
[2024-04-20 14:01:39,693: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 221 Loss: 0.01111837074015253]
[2024-04-20 14:01:39,900: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 222 Loss: 0.0031013517386256073]
[2024-04-20 14:01:40,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 223 Loss: 0.005018525690548177]
[2024-04-20 14:01:40,309: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 224 Loss: 0.0009951883409657642]
[2024-04-20 14:01:40,512: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 225 Loss: 0.013970497139445346]
[2024-04-20 14:01:40,720: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 226 Loss: 0.00285224118813447]
[2024-04-20 14:01:40,928: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 227 Loss: 0.0009638076108064884]
[2024-04-20 14:01:41,133: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 228 Loss: 0.005574492840772226]
[2024-04-20 14:01:41,337: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 229 Loss: 5.7487484775557994e-05]
[2024-04-20 14:01:41,543: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 230 Loss: 0.001691126964869756]
[2024-04-20 14:01:41,749: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 231 Loss: 5.2279236617517204e-05]
[2024-04-20 14:01:41,953: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 232 Loss: 0.0031721450787457884]
[2024-04-20 14:01:42,162: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 233 Loss: 0.0026855448970130066]
[2024-04-20 14:01:42,367: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 234 Loss: 0.0014931607257387986]
[2024-04-20 14:01:42,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 235 Loss: 0.00010914858295213534]
[2024-04-20 14:01:42,787: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 236 Loss: 0.01509277581873641]
[2024-04-20 14:01:42,996: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 237 Loss: 0.0020200337020085516]
[2024-04-20 14:01:43,201: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 238 Loss: 0.0071942635619464245]
[2024-04-20 14:01:43,409: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 239 Loss: 0.0006851530709711527]
[2024-04-20 14:01:43,620: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 240 Loss: 4.765423158883123e-05]
[2024-04-20 14:01:43,826: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 241 Loss: 0.00179210882101072]
[2024-04-20 14:01:44,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 242 Loss: 0.0008725305519557755]
[2024-04-20 14:01:44,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 243 Loss: 0.0009011555271691968]
[2024-04-20 14:01:44,445: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 244 Loss: 0.0015941099780717488]
[2024-04-20 14:01:44,658: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 245 Loss: 0.0011821925941045595]
[2024-04-20 14:01:44,869: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 246 Loss: 0.004584957942656616]
[2024-04-20 14:01:45,076: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 247 Loss: 0.0015756832811451608]
[2024-04-20 14:01:45,289: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 248 Loss: 8.692840058975492e-05]
[2024-04-20 14:01:45,505: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 249 Loss: 0.008610066443077803]
[2024-04-20 14:01:45,715: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 250 Loss: 0.0017409085239493852]
[2024-04-20 14:01:45,924: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 251 Loss: 0.011056224503600016]
[2024-04-20 14:01:46,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 252 Loss: 0.002455313768256439]
[2024-04-20 14:01:46,350: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 253 Loss: 0.005909522834913542]
[2024-04-20 14:01:46,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 254 Loss: 0.004131155636983399]
[2024-04-20 14:01:46,770: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 255 Loss: 0.009374399218645612]
[2024-04-20 14:01:46,981: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 256 Loss: 0.010097928769348135]
[2024-04-20 14:01:47,191: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 257 Loss: 0.01117261920475589]
[2024-04-20 14:01:47,408: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 258 Loss: 0.006567700142871652]
[2024-04-20 14:01:47,620: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 259 Loss: 0.0007787161802277684]
[2024-04-20 14:01:47,833: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 260 Loss: 0.00923640191390831]
[2024-04-20 14:01:48,038: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 261 Loss: 0.0001262034464556596]
[2024-04-20 14:01:48,247: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 262 Loss: 0.0017954217470140857]
[2024-04-20 14:01:48,455: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 263 Loss: 0.0024691767000860065]
[2024-04-20 14:01:48,661: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 264 Loss: 5.802541475958646e-05]
[2024-04-20 14:01:48,867: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 265 Loss: 0.006873370017477789]
[2024-04-20 14:01:49,071: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 266 Loss: 0.004237621466752496]
[2024-04-20 14:01:49,279: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 267 Loss: 0.007326225092383488]
[2024-04-20 14:01:49,486: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 268 Loss: 0.002421854998798404]
[2024-04-20 14:01:49,692: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 269 Loss: 0.01128487236745865]
[2024-04-20 14:01:49,898: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 270 Loss: 0.005715028483298899]
[2024-04-20 14:01:50,106: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 271 Loss: 0.006664607463290203]
[2024-04-20 14:01:50,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 272 Loss: 0.0025723194479338554]
[2024-04-20 14:01:50,525: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 273 Loss: 0.0023067575741074174]
[2024-04-20 14:01:50,728: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 274 Loss: 0.019278711127093968]
[2024-04-20 14:01:50,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 275 Loss: 0.003192590619843778]
[2024-04-20 14:01:51,143: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 276 Loss: 0.0005747683901828022]
[2024-04-20 14:01:51,348: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 277 Loss: 0.0005277016306050587]
[2024-04-20 14:01:51,555: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 278 Loss: 0.020100842207078057]
[2024-04-20 14:01:51,758: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 279 Loss: 5.886915801632765e-05]
[2024-04-20 14:01:51,963: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 280 Loss: 0.0010557494104846672]
[2024-04-20 14:01:52,170: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 281 Loss: 6.675346924926466e-05]
[2024-04-20 14:01:52,376: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 282 Loss: 0.001862597441834225]
[2024-04-20 14:01:52,583: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 283 Loss: 0.010250686580226752]
[2024-04-20 14:01:52,787: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 284 Loss: 0.021845610564606745]
[2024-04-20 14:01:52,995: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 285 Loss: 0.0011690905149622395]
[2024-04-20 14:01:53,202: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 286 Loss: 0.00897671096989018]
[2024-04-20 14:01:53,409: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 287 Loss: 0.0063016897981980355]
[2024-04-20 14:01:53,617: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 288 Loss: 0.009145346872250501]
[2024-04-20 14:01:53,822: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 289 Loss: 0.0056922487505074535]
[2024-04-20 14:01:54,029: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 290 Loss: 0.006378251862533307]
[2024-04-20 14:01:54,239: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 291 Loss: 0.022141814128972658]
[2024-04-20 14:01:54,446: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 292 Loss: 0.0013654178131169608]
[2024-04-20 14:01:54,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 293 Loss: 0.010001901615805]
[2024-04-20 14:01:54,857: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 294 Loss: 0.029558077121317423]
[2024-04-20 14:01:55,065: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 295 Loss: 0.011895693004207222]
[2024-04-20 14:01:55,271: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 296 Loss: 0.0042522856200311624]
[2024-04-20 14:01:55,477: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 297 Loss: 0.015887789330175952]
[2024-04-20 14:01:55,684: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 298 Loss: 0.0029055430889699495]
[2024-04-20 14:01:55,891: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 299 Loss: 0.0020910464704741506]
[2024-04-20 14:01:56,099: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 300 Loss: 0.008314829668929203]
[2024-04-20 14:01:56,306: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 301 Loss: 0.021739925342182855]
[2024-04-20 14:01:56,514: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 302 Loss: 0.0023374033735269104]
[2024-04-20 14:01:56,719: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 303 Loss: 0.010442591296820234]
[2024-04-20 14:01:56,925: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 304 Loss: 0.0020953814361924796]
[2024-04-20 14:01:57,131: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 305 Loss: 0.0041178791878641145]
[2024-04-20 14:01:57,341: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 306 Loss: 0.009087852832226342]
[2024-04-20 14:01:57,547: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 307 Loss: 0.03238387976657841]
[2024-04-20 14:01:57,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 308 Loss: 0.005302250329966476]
[2024-04-20 14:01:57,962: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 309 Loss: 0.003489949455956517]
[2024-04-20 14:01:58,174: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 310 Loss: 0.0258619040353471]
[2024-04-20 14:01:58,386: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 311 Loss: 0.0397875513174205]
[2024-04-20 14:01:58,600: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 312 Loss: 0.011754182320670067]
[2024-04-20 14:01:58,813: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 313 Loss: 0.00775646698211894]
[2024-04-20 14:01:59,021: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 314 Loss: 0.0015860744909895904]
[2024-04-20 14:01:59,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 315 Loss: 0.004482077571071964]
[2024-04-20 14:01:59,446: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 316 Loss: 0.006421299506355855]
[2024-04-20 14:01:59,665: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 317 Loss: 0.005467135720197377]
[2024-04-20 14:01:59,876: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 318 Loss: 0.011391532796469834]
[2024-04-20 14:02:00,087: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 319 Loss: 0.0037282118346214023]
[2024-04-20 14:02:00,297: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 320 Loss: 0.010801867111723804]
[2024-04-20 14:02:00,509: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 321 Loss: 0.006898082138347511]
[2024-04-20 14:02:00,723: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 322 Loss: 0.010388808867095497]
[2024-04-20 14:02:00,936: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 323 Loss: 0.006756460433560725]
[2024-04-20 14:02:01,146: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 324 Loss: 0.004374494903722924]
[2024-04-20 14:02:01,358: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 325 Loss: 0.005622745013190026]
[2024-04-20 14:02:01,564: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 326 Loss: 0.012446577512553628]
[2024-04-20 14:02:01,777: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 327 Loss: 0.006647777087557665]
[2024-04-20 14:02:01,984: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 328 Loss: 0.0057309165677275585]
[2024-04-20 14:02:02,192: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 329 Loss: 0.02518829015878284]
[2024-04-20 14:02:02,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 330 Loss: 0.008015835197787327]
[2024-04-20 14:02:02,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 331 Loss: 0.004624661299325947]
[2024-04-20 14:02:02,811: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 332 Loss: 0.003352593074525857]
[2024-04-20 14:02:03,016: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 333 Loss: 0.01487319336301671]
[2024-04-20 14:02:03,221: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 334 Loss: 0.03171400728664442]
[2024-04-20 14:02:03,426: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 335 Loss: 0.009080749590318475]
[2024-04-20 14:02:03,633: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 336 Loss: 0.00241969836631593]
[2024-04-20 14:02:03,841: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 337 Loss: 0.0035253519617106997]
[2024-04-20 14:02:04,049: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 338 Loss: 0.00710811665167328]
[2024-04-20 14:02:04,254: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 339 Loss: 0.011111661682255511]
[2024-04-20 14:02:04,460: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 340 Loss: 0.006681720933913438]
[2024-04-20 14:02:04,667: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 341 Loss: 0.0005553555317805492]
[2024-04-20 14:02:04,870: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 342 Loss: 0.016230189278372057]
[2024-04-20 14:02:05,079: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 343 Loss: 0.011331907756546187]
[2024-04-20 14:02:05,289: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 344 Loss: 0.011159474385958764]
[2024-04-20 14:02:05,497: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 345 Loss: 0.0032059466600720945]
[2024-04-20 14:02:05,702: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 346 Loss: 0.003491891974047072]
[2024-04-20 14:02:05,909: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 347 Loss: 0.00397099395796471]
[2024-04-20 14:02:06,118: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 348 Loss: 0.004097883582115314]
[2024-04-20 14:02:06,329: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 349 Loss: 0.004352478038549322]
[2024-04-20 14:02:06,538: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 350 Loss: 0.010570729672251696]
[2024-04-20 14:02:06,743: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 351 Loss: 0.024285583145770496]
[2024-04-20 14:02:06,946: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 352 Loss: 0.007339652880350357]
[2024-04-20 14:02:07,148: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 353 Loss: 0.01442672827151311]
[2024-04-20 14:02:07,352: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 354 Loss: 0.0055825763104790935]
[2024-04-20 14:02:07,559: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 355 Loss: 0.009281760526261826]
[2024-04-20 14:02:07,764: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 356 Loss: 0.0032362971835768685]
[2024-04-20 14:02:07,972: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 357 Loss: 0.006938779209150795]
[2024-04-20 14:02:08,177: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 358 Loss: 0.008559766100386076]
[2024-04-20 14:02:08,382: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 359 Loss: 0.007705244241152224]
[2024-04-20 14:02:08,587: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 360 Loss: 0.0007858518779642054]
[2024-04-20 14:02:08,794: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 361 Loss: 0.006117999797726609]
[2024-04-20 14:02:09,004: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 362 Loss: 0.0001833599714748615]
[2024-04-20 14:02:09,212: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 363 Loss: 0.0026170787927260134]
[2024-04-20 14:02:09,419: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 364 Loss: 0.0007033688794260384]
[2024-04-20 14:02:09,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 365 Loss: 0.0002577583374888361]
[2024-04-20 14:02:09,834: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 366 Loss: 0.007222200868018395]
[2024-04-20 14:02:10,042: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 367 Loss: 0.004577731656629812]
[2024-04-20 14:02:10,248: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 368 Loss: 0.00022529271309829386]
[2024-04-20 14:02:10,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 369 Loss: 0.021879509440009826]
[2024-04-20 14:02:10,662: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 370 Loss: 0.00012233650887307222]
[2024-04-20 14:02:10,870: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 371 Loss: 0.004146774088514811]
[2024-04-20 14:02:11,075: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 372 Loss: 0.004682765655183239]
[2024-04-20 14:02:11,279: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 373 Loss: 0.004468007876740199]
[2024-04-20 14:02:11,489: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 374 Loss: 0.0019254939020228172]
[2024-04-20 14:02:11,705: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 375 Loss: 0.021436540652778502]
[2024-04-20 14:02:11,926: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 376 Loss: 0.008438466631712441]
[2024-04-20 14:02:12,137: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 377 Loss: 0.006055775395278445]
[2024-04-20 14:02:12,348: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 378 Loss: 0.00014836334235441727]
[2024-04-20 14:02:12,559: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 379 Loss: 0.0016185673669342133]
[2024-04-20 14:02:12,771: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 380 Loss: 0.012007607758734556]
[2024-04-20 14:02:12,985: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 381 Loss: 0.005061047685170084]
[2024-04-20 14:02:13,197: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 382 Loss: 9.354816598665792e-05]
[2024-04-20 14:02:13,410: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 383 Loss: 0.003721009914353822]
[2024-04-20 14:02:13,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 384 Loss: 0.0017996564388352723]
[2024-04-20 14:02:13,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 385 Loss: 0.0008970278610148416]
[2024-04-20 14:02:14,045: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 386 Loss: 6.878917945512919e-05]
[2024-04-20 14:02:14,266: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 387 Loss: 0.0005116112383112231]
[2024-04-20 14:02:14,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 388 Loss: 0.003006706534270233]
[2024-04-20 14:02:14,683: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 389 Loss: 0.0006789364510772255]
[2024-04-20 14:02:14,892: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 390 Loss: 0.019924824130750356]
[2024-04-20 14:02:15,102: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 391 Loss: 0.0028845917084013217]
[2024-04-20 14:02:15,307: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 392 Loss: 0.0008061562795526014]
[2024-04-20 14:02:15,515: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 393 Loss: 0.00929926924053783]
[2024-04-20 14:02:15,724: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 394 Loss: 6.175644606209473e-05]
[2024-04-20 14:02:15,930: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 395 Loss: 0.007579517444804042]
[2024-04-20 14:02:16,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 396 Loss: 0.004933547205042531]
[2024-04-20 14:02:16,350: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 397 Loss: 0.0009725480015797201]
[2024-04-20 14:02:16,556: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 398 Loss: 0.0021847626019873404]
[2024-04-20 14:02:16,761: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 399 Loss: 0.018778919909669727]
[2024-04-20 14:02:16,971: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 400 Loss: 0.0026470563212944937]
[2024-04-20 14:02:17,179: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 401 Loss: 0.0016822394207064285]
[2024-04-20 14:02:17,385: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 402 Loss: 0.00198357652535455]
[2024-04-20 14:02:17,592: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 403 Loss: 0.013843943440890549]
[2024-04-20 14:02:17,797: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 404 Loss: 0.00490638777346008]
[2024-04-20 14:02:18,004: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 405 Loss: 0.00797725146124855]
[2024-04-20 14:02:18,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 406 Loss: 0.000117470703107233]
[2024-04-20 14:02:18,416: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 407 Loss: 0.005487071782210289]
[2024-04-20 14:02:18,622: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 408 Loss: 0.004264495038403645]
[2024-04-20 14:02:18,828: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 409 Loss: 0.001289144627755076]
[2024-04-20 14:02:19,035: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 410 Loss: 0.0027043266888561175]
[2024-04-20 14:02:19,242: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 411 Loss: 0.0004085397696506358]
[2024-04-20 14:02:19,451: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 412 Loss: 0.0022371929937031686]
[2024-04-20 14:02:19,664: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 413 Loss: 0.013586154702132262]
[2024-04-20 14:02:19,869: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 414 Loss: 0.011106726451024073]
[2024-04-20 14:02:20,075: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 415 Loss: 0.011572368563853113]
[2024-04-20 14:02:20,284: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 416 Loss: 0.0014330493723391045]
[2024-04-20 14:02:20,492: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 417 Loss: 0.007746807430614614]
[2024-04-20 14:02:20,698: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 418 Loss: 0.0014608948827170335]
[2024-04-20 14:02:20,905: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 419 Loss: 0.0068016874781271965]
[2024-04-20 14:02:21,114: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 420 Loss: 0.03293130846226892]
[2024-04-20 14:02:21,321: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 421 Loss: 0.005325327948569953]
[2024-04-20 14:02:21,527: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 422 Loss: 0.008638710168282052]
[2024-04-20 14:02:21,734: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 423 Loss: 0.0018169112845181992]
[2024-04-20 14:02:21,943: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 424 Loss: 0.009513896604928587]
[2024-04-20 14:02:22,150: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 425 Loss: 0.023091200164129088]
[2024-04-20 14:02:22,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 426 Loss: 0.006424550406903622]
[2024-04-20 14:02:22,563: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 427 Loss: 0.01185443834064605]
[2024-04-20 14:02:22,774: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 428 Loss: 0.0008073009913990913]
[2024-04-20 14:02:22,982: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 429 Loss: 0.0004438478895855632]
[2024-04-20 14:02:23,189: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 430 Loss: 0.013571648269399342]
[2024-04-20 14:02:23,396: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 431 Loss: 0.004344357147424649]
[2024-04-20 14:02:23,607: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 432 Loss: 0.008133741098279985]
[2024-04-20 14:02:23,814: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 433 Loss: 0.004075077586439931]
[2024-04-20 14:02:24,022: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 434 Loss: 0.009941831582634522]
[2024-04-20 14:02:24,228: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 435 Loss: 0.006890885792974558]
[2024-04-20 14:02:24,435: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 436 Loss: 0.004634249380706956]
[2024-04-20 14:02:24,643: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 437 Loss: 0.012407864965283828]
[2024-04-20 14:02:24,850: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 438 Loss: 0.003729537327914731]
[2024-04-20 14:02:25,056: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 439 Loss: 0.04459954649865905]
[2024-04-20 14:02:25,275: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 440 Loss: 0.010114548164827488]
[2024-04-20 14:02:25,494: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 441 Loss: 0.004465693302942562]
[2024-04-20 14:02:25,704: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 442 Loss: 0.010284422100125147]
[2024-04-20 14:02:25,911: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 443 Loss: 8.866714146457127e-05]
[2024-04-20 14:02:26,121: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 444 Loss: 0.008116444669176737]
[2024-04-20 14:02:26,334: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 445 Loss: 0.010682441345086937]
[2024-04-20 14:02:26,545: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 446 Loss: 0.01506158869775782]
[2024-04-20 14:02:26,761: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 447 Loss: 0.0028166150655746943]
[2024-04-20 14:02:26,974: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 448 Loss: 0.003113263636006448]
[2024-04-20 14:02:27,184: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 449 Loss: 0.007324302556728506]
[2024-04-20 14:02:27,412: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 450 Loss: 0.0011128941926321597]
[2024-04-20 14:02:27,621: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 451 Loss: 0.004482896769633565]
[2024-04-20 14:02:27,832: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 452 Loss: 0.0029533193961997634]
[2024-04-20 14:02:28,044: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 453 Loss: 0.0014618888430089393]
[2024-04-20 14:02:28,259: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 454 Loss: 0.00697402723892378]
[2024-04-20 14:02:28,474: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 455 Loss: 0.005897773644601451]
[2024-04-20 14:02:28,681: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 456 Loss: 7.614826423052767e-05]
[2024-04-20 14:02:28,893: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 457 Loss: 0.002151852820970875]
[2024-04-20 14:02:29,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 458 Loss: 0.0007443961657917162]
[2024-04-20 14:02:29,315: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 459 Loss: 0.0011580161810510403]
[2024-04-20 14:02:29,523: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 460 Loss: 3.793460159169928e-05]
[2024-04-20 14:02:29,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 461 Loss: 0.003279906336684181]
[2024-04-20 14:02:29,935: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 462 Loss: 0.00036620664970202536]
[2024-04-20 14:02:30,145: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 463 Loss: 0.002573371486149283]
[2024-04-20 14:02:30,352: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 464 Loss: 0.003597058634272483]
[2024-04-20 14:02:30,559: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 465 Loss: 0.00774724019755737]
[2024-04-20 14:02:30,766: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 466 Loss: 0.0004727688065421906]
[2024-04-20 14:02:30,974: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 467 Loss: 0.0027384897734730558]
[2024-04-20 14:02:31,181: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 468 Loss: 0.00012617220172145104]
[2024-04-20 14:02:31,390: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 469 Loss: 0.002237935673991636]
[2024-04-20 14:02:31,598: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 470 Loss: 0.0022284335917663774]
[2024-04-20 14:02:31,807: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 471 Loss: 0.001835298382671191]
[2024-04-20 14:02:32,016: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 472 Loss: 1.5634979334350628e-05]
[2024-04-20 14:02:32,222: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 473 Loss: 0.010992322513934128]
[2024-04-20 14:02:32,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 474 Loss: 0.006184832883501176]
[2024-04-20 14:02:32,645: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 475 Loss: 0.0007487883957852388]
[2024-04-20 14:02:32,856: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 476 Loss: 0.0014531837271477737]
[2024-04-20 14:02:33,064: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 477 Loss: 0.0023260434379855596]
[2024-04-20 14:02:33,274: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 478 Loss: 0.0005383035968026863]
[2024-04-20 14:02:33,482: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 479 Loss: 0.006363115708998416]
[2024-04-20 14:02:33,692: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 480 Loss: 0.005068539961317442]
[2024-04-20 14:02:33,898: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 481 Loss: 0.0037319100634153205]
[2024-04-20 14:02:34,103: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 482 Loss: 0.0007932061834053831]
[2024-04-20 14:02:34,316: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 483 Loss: 0.0012264837636085967]
[2024-04-20 14:02:34,524: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 484 Loss: 0.008280140234945338]
[2024-04-20 14:02:34,731: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 485 Loss: 0.001193894255116735]
[2024-04-20 14:02:34,938: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 486 Loss: 0.006082162109779841]
[2024-04-20 14:02:35,149: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 487 Loss: 0.0001172540722470882]
[2024-04-20 14:02:35,357: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 488 Loss: 0.005370728865863922]
[2024-04-20 14:02:35,566: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 489 Loss: 0.0011425229038686609]
[2024-04-20 14:02:35,774: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 490 Loss: 0.008653194269796357]
[2024-04-20 14:02:35,980: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 491 Loss: 0.004998224579650245]
[2024-04-20 14:02:36,187: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 492 Loss: 0.003673222272176078]
[2024-04-20 14:02:36,394: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 493 Loss: 0.002149012020452753]
[2024-04-20 14:02:36,601: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 494 Loss: 0.0018394608302434575]
[2024-04-20 14:02:36,811: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 495 Loss: 0.005049685794481124]
[2024-04-20 14:02:37,019: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 496 Loss: 0.0008894258114948888]
[2024-04-20 14:02:37,228: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 497 Loss: 0.007353101501181153]
[2024-04-20 14:02:37,440: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 498 Loss: 0.0006358234580387097]
[2024-04-20 14:02:37,649: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 499 Loss: 0.00022922066442265885]
[2024-04-20 14:02:37,855: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 500 Loss: 8.182335888980225e-05]
[2024-04-20 14:02:38,063: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 501 Loss: 0.0009257554063895517]
[2024-04-20 14:02:38,273: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 502 Loss: 0.00033693137254499345]
[2024-04-20 14:02:38,483: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 503 Loss: 0.009909131504121578]
[2024-04-20 14:02:38,696: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 504 Loss: 0.005571437642817961]
[2024-04-20 14:02:38,906: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 505 Loss: 0.0013015189664522312]
[2024-04-20 14:02:39,120: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 506 Loss: 0.004890610454943675]
[2024-04-20 14:02:39,330: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 507 Loss: 0.0002791711049088708]
[2024-04-20 14:02:39,545: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 508 Loss: 0.00569585246217299]
[2024-04-20 14:02:39,759: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 509 Loss: 0.007205414124207588]
[2024-04-20 14:02:39,970: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 510 Loss: 0.0009220750868701009]
[2024-04-20 14:02:40,188: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 511 Loss: 0.016326082736227]
[2024-04-20 14:02:40,398: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 512 Loss: 0.0004964944639715058]
[2024-04-20 14:02:40,605: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 513 Loss: 0.00010364207496783174]
[2024-04-20 14:02:40,812: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 514 Loss: 0.021938205101653653]
[2024-04-20 14:02:41,026: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 515 Loss: 0.0027147255764108764]
[2024-04-20 14:02:41,241: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 516 Loss: 0.00014440424792120892]
[2024-04-20 14:02:41,451: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 517 Loss: 0.0001920602889639495]
[2024-04-20 14:02:41,674: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 518 Loss: 0.00021390479064363225]
[2024-04-20 14:02:41,888: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 519 Loss: 0.004175224031545027]
[2024-04-20 14:02:42,104: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 520 Loss: 0.01078567790987388]
[2024-04-20 14:02:42,310: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 521 Loss: 0.0023144666772809764]
[2024-04-20 14:02:42,517: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 522 Loss: 0.00017489867176202686]
[2024-04-20 14:02:42,724: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 523 Loss: 0.00032515647943470076]
[2024-04-20 14:02:42,932: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 524 Loss: 5.762400574340128e-05]
[2024-04-20 14:02:43,138: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 525 Loss: 0.0010429775364627256]
[2024-04-20 14:02:43,347: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 526 Loss: 0.0011743972461401345]
[2024-04-20 14:02:43,557: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 527 Loss: 0.018335034412524022]
[2024-04-20 14:02:43,764: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 528 Loss: 0.003573496524643804]
[2024-04-20 14:02:43,971: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 529 Loss: 0.00010513492508566558]
[2024-04-20 14:02:44,182: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 530 Loss: 0.0003203399150392857]
[2024-04-20 14:02:44,388: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 531 Loss: 0.0006425298716939149]
[2024-04-20 14:02:44,594: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 532 Loss: 0.00016569402423615836]
[2024-04-20 14:02:44,802: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 533 Loss: 0.0011548077358239912]
[2024-04-20 14:02:45,005: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 534 Loss: 0.012555984733436682]
[2024-04-20 14:02:45,211: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 535 Loss: 0.0013449183609580185]
[2024-04-20 14:02:45,419: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 536 Loss: 0.0008938009717163677]
[2024-04-20 14:02:45,626: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 537 Loss: 0.002503627516621251]
[2024-04-20 14:02:45,829: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 538 Loss: 0.00409883604867203]
[2024-04-20 14:02:46,033: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 539 Loss: 0.006055546957467868]
[2024-04-20 14:02:46,240: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 540 Loss: 0.002496318392987288]
[2024-04-20 14:02:46,447: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 541 Loss: 0.0005456754753124317]
[2024-04-20 14:02:46,654: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 542 Loss: 0.002252849292601095]
[2024-04-20 14:02:46,859: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 543 Loss: 0.0004522718280969488]
[2024-04-20 14:02:47,063: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 544 Loss: 0.0022833167936423984]
[2024-04-20 14:02:47,272: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 545 Loss: 0.0025927119871985344]
[2024-04-20 14:02:47,481: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 546 Loss: 5.119521542259914e-05]
[2024-04-20 14:02:47,690: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 547 Loss: 0.00305325354691552]
[2024-04-20 14:02:47,898: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 548 Loss: 8.161552665742717e-05]
[2024-04-20 14:02:48,102: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 549 Loss: 0.005875613891018588]
[2024-04-20 14:02:48,307: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 550 Loss: 0.008417380655096422]
[2024-04-20 14:02:48,515: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 551 Loss: 0.00527939772232663]
[2024-04-20 14:02:48,719: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 552 Loss: 0.00020635127128129397]
[2024-04-20 14:02:48,925: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 553 Loss: 0.011868346582737709]
[2024-04-20 14:02:49,131: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 554 Loss: 0.0006787828209762703]
[2024-04-20 14:02:49,337: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 555 Loss: 0.007529983934920706]
[2024-04-20 14:02:49,545: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 556 Loss: 0.000272042225563979]
[2024-04-20 14:02:49,752: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 557 Loss: 0.0022146127665708497]
[2024-04-20 14:02:49,956: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 558 Loss: 0.03900825312999817]
[2024-04-20 14:02:50,163: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 559 Loss: 0.0005320451294181156]
[2024-04-20 14:02:50,371: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 560 Loss: 0.0018242854905669652]
[2024-04-20 14:02:50,577: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 561 Loss: 0.0019577122084946286]
[2024-04-20 14:02:50,783: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 562 Loss: 0.004631956805318863]
[2024-04-20 14:02:50,994: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 563 Loss: 0.0009067293923813287]
[2024-04-20 14:02:51,200: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 564 Loss: 0.006157003799577805]
[2024-04-20 14:02:51,406: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 565 Loss: 0.0012612757323577166]
[2024-04-20 14:02:51,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 566 Loss: 0.005364364300553864]
[2024-04-20 14:02:51,820: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 567 Loss: 0.0028287989325980695]
[2024-04-20 14:02:52,027: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 568 Loss: 8.874295764307984e-05]
[2024-04-20 14:02:52,232: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 569 Loss: 0.0038402887610419173]
[2024-04-20 14:02:52,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 570 Loss: 0.019846256337573732]
[2024-04-20 14:02:52,651: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 571 Loss: 0.009547264821153208]
[2024-04-20 14:02:52,861: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 572 Loss: 0.004246206406805403]
[2024-04-20 14:02:53,080: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 573 Loss: 0.0008850016970942952]
[2024-04-20 14:02:53,294: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 574 Loss: 0.00016036286842901592]
[2024-04-20 14:02:53,506: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 575 Loss: 0.002184368872073735]
[2024-04-20 14:02:53,717: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 576 Loss: 0.00034462672636110186]
[2024-04-20 14:02:53,925: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 577 Loss: 0.010458018959373665]
[2024-04-20 14:02:54,139: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 578 Loss: 0.006398990566799574]
[2024-04-20 14:02:54,348: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 579 Loss: 0.0008686323530422889]
[2024-04-20 14:02:54,560: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 580 Loss: 0.0016742068814123898]
[2024-04-20 14:02:54,770: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 581 Loss: 0.007072696726640074]
[2024-04-20 14:02:54,982: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 582 Loss: 0.004112559823256716]
[2024-04-20 14:02:55,190: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 583 Loss: 0.0027680843222310896]
[2024-04-20 14:02:55,399: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 584 Loss: 9.880322019729536e-05]
[2024-04-20 14:02:55,612: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 585 Loss: 0.0018269183900495704]
[2024-04-20 14:02:55,822: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 586 Loss: 0.0008699986989872596]
[2024-04-20 14:02:56,029: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 587 Loss: 0.0004710848506124321]
[2024-04-20 14:02:56,233: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 588 Loss: 0.0006913588246470138]
[2024-04-20 14:02:56,438: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 589 Loss: 0.0010358301598673658]
[2024-04-20 14:02:56,644: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 590 Loss: 8.756396296451298e-05]
[2024-04-20 14:02:56,846: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 591 Loss: 0.009709125581869253]
[2024-04-20 14:02:57,046: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 592 Loss: 0.0024836034878365264]
[2024-04-20 14:02:57,249: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 593 Loss: 0.008411546910174358]
[2024-04-20 14:02:57,454: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 594 Loss: 0.0027702326972461693]
[2024-04-20 14:02:57,611: INFO: roberta_kFold_initial_lstm: Eval Epoch : batch 595 Loss: 3.544070476135401e-05]
[2024-04-20 14:03:20,707: INFO: roberta_kFold_initial_lstm: The score of the eval model is {'Accuracy': 0.9961877957573044, 'precision': 0.81444064774922, 'recall': 0.9588945251005773, 'f1': 0.8807840616966581}]
