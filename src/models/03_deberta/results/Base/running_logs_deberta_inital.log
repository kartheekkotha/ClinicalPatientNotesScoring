[2024-04-18 14:21:58,911: INFO: utils: NumExpr defaulting to 2 threads.]
[2024-04-18 14:22:17,690: INFO: deberta_initial: Epoch: 1/10]
[2024-04-18 14:22:20,184: INFO: deberta_initial: Training : batch 0 Loss: 0.5991639019857672]
[2024-04-18 14:22:21,038: INFO: deberta_initial: Training : batch 1 Loss: 0.5230806230356414]
[2024-04-18 14:22:21,895: INFO: deberta_initial: Training : batch 2 Loss: 0.46478459438835107]
[2024-04-18 14:22:22,754: INFO: deberta_initial: Training : batch 3 Loss: 0.41052797387147116]
[2024-04-18 14:22:23,621: INFO: deberta_initial: Training : batch 4 Loss: 0.35828691103884897]
[2024-04-18 14:22:24,490: INFO: deberta_initial: Training : batch 5 Loss: 0.31343249107972815]
[2024-04-18 14:22:25,354: INFO: deberta_initial: Training : batch 6 Loss: 0.2623807772371194]
[2024-04-18 14:22:26,215: INFO: deberta_initial: Training : batch 7 Loss: 0.21386556031420983]
[2024-04-18 14:22:27,076: INFO: deberta_initial: Training : batch 8 Loss: 0.19177166230509446]
[2024-04-18 14:22:27,936: INFO: deberta_initial: Training : batch 9 Loss: 0.15151026505189386]
[2024-04-18 14:22:28,800: INFO: deberta_initial: Training : batch 10 Loss: 0.12145740791368263]
[2024-04-18 14:22:29,660: INFO: deberta_initial: Training : batch 11 Loss: 0.11611560619501181]
[2024-04-18 14:22:30,527: INFO: deberta_initial: Training : batch 12 Loss: 0.07113337551586418]
[2024-04-18 14:22:31,399: INFO: deberta_initial: Training : batch 13 Loss: 0.09782205095758885]
[2024-04-18 14:22:32,274: INFO: deberta_initial: Training : batch 14 Loss: 0.06874482935982304]
[2024-04-18 14:22:33,137: INFO: deberta_initial: Training : batch 15 Loss: 0.06318585795094132]
[2024-04-18 14:22:34,001: INFO: deberta_initial: Training : batch 16 Loss: 0.08047182522357438]
[2024-04-18 14:22:34,869: INFO: deberta_initial: Training : batch 17 Loss: 0.0660443712816792]
[2024-04-18 14:22:35,740: INFO: deberta_initial: Training : batch 18 Loss: 0.061682937949397366]
[2024-04-18 14:22:36,613: INFO: deberta_initial: Training : batch 19 Loss: 0.04873908778862965]
[2024-04-18 14:22:37,481: INFO: deberta_initial: Training : batch 20 Loss: 0.10363812958541323]
[2024-04-18 14:22:38,353: INFO: deberta_initial: Training : batch 21 Loss: 0.04025687772194033]
[2024-04-18 14:22:39,228: INFO: deberta_initial: Training : batch 22 Loss: 0.07197814963841073]
[2024-04-18 14:22:40,098: INFO: deberta_initial: Training : batch 23 Loss: 0.06092670759254346]
[2024-04-18 14:22:40,968: INFO: deberta_initial: Training : batch 24 Loss: 0.05468065774390855]
[2024-04-18 14:22:41,840: INFO: deberta_initial: Training : batch 25 Loss: 0.0661378301507097]
[2024-04-18 14:22:42,713: INFO: deberta_initial: Training : batch 26 Loss: 0.046539761885156114]
[2024-04-18 14:22:43,585: INFO: deberta_initial: Training : batch 27 Loss: 0.043269487942509746]
[2024-04-18 14:22:44,454: INFO: deberta_initial: Training : batch 28 Loss: 0.04052800519339818]
[2024-04-18 14:22:45,324: INFO: deberta_initial: Training : batch 29 Loss: 0.07906483651332363]
[2024-04-18 14:22:46,200: INFO: deberta_initial: Training : batch 30 Loss: 0.062182370739904506]
[2024-04-18 14:22:47,072: INFO: deberta_initial: Training : batch 31 Loss: 0.025688082616603963]
[2024-04-18 14:22:47,944: INFO: deberta_initial: Training : batch 32 Loss: 0.0428471508449764]
[2024-04-18 14:22:48,815: INFO: deberta_initial: Training : batch 33 Loss: 0.04504263265967386]
[2024-04-18 14:22:49,695: INFO: deberta_initial: Training : batch 34 Loss: 0.013711637947387223]
[2024-04-18 14:22:50,573: INFO: deberta_initial: Training : batch 35 Loss: 0.020229748989956883]
[2024-04-18 14:22:51,465: INFO: deberta_initial: Training : batch 36 Loss: 0.06972885429915009]
[2024-04-18 14:22:52,354: INFO: deberta_initial: Training : batch 37 Loss: 0.06652916045063498]
[2024-04-18 14:22:53,246: INFO: deberta_initial: Training : batch 38 Loss: 0.08088761665885964]
[2024-04-18 14:22:54,138: INFO: deberta_initial: Training : batch 39 Loss: 0.06835853324642673]
[2024-04-18 14:22:55,027: INFO: deberta_initial: Training : batch 40 Loss: 0.027364338377792632]
[2024-04-18 14:22:55,900: INFO: deberta_initial: Training : batch 41 Loss: 0.060744594889186224]
[2024-04-18 14:22:56,782: INFO: deberta_initial: Training : batch 42 Loss: 0.1093531479924604]
[2024-04-18 14:22:57,660: INFO: deberta_initial: Training : batch 43 Loss: 0.06160056461257696]
[2024-04-18 14:22:58,530: INFO: deberta_initial: Training : batch 44 Loss: 0.07417206051602389]
[2024-04-18 14:22:59,406: INFO: deberta_initial: Training : batch 45 Loss: 0.10703402148661752]
[2024-04-18 14:23:00,284: INFO: deberta_initial: Training : batch 46 Loss: 0.04774525160480594]
[2024-04-18 14:23:01,163: INFO: deberta_initial: Training : batch 47 Loss: 0.06193085900123704]
[2024-04-18 14:23:02,039: INFO: deberta_initial: Training : batch 48 Loss: 0.03630073975018433]
[2024-04-18 14:23:02,924: INFO: deberta_initial: Training : batch 49 Loss: 0.05926488942687181]
[2024-04-18 14:23:03,804: INFO: deberta_initial: Training : batch 50 Loss: 0.038985225114125166]
[2024-04-18 14:23:04,696: INFO: deberta_initial: Training : batch 51 Loss: 0.02135352319573148]
[2024-04-18 14:23:05,585: INFO: deberta_initial: Training : batch 52 Loss: 0.06233579237654823]
[2024-04-18 14:23:06,481: INFO: deberta_initial: Training : batch 53 Loss: 0.05333426609774104]
[2024-04-18 14:23:07,369: INFO: deberta_initial: Training : batch 54 Loss: 0.06693504671357602]
[2024-04-18 14:23:08,254: INFO: deberta_initial: Training : batch 55 Loss: 0.03537886961160749]
[2024-04-18 14:23:09,134: INFO: deberta_initial: Training : batch 56 Loss: 0.039123751334298885]
[2024-04-18 14:23:10,023: INFO: deberta_initial: Training : batch 57 Loss: 0.021402988567275547]
[2024-04-18 14:23:10,916: INFO: deberta_initial: Training : batch 58 Loss: 0.11253439852295063]
[2024-04-18 14:23:11,807: INFO: deberta_initial: Training : batch 59 Loss: 0.060542105569827136]
[2024-04-18 14:23:12,702: INFO: deberta_initial: Training : batch 60 Loss: 0.06843852980322958]
[2024-04-18 14:23:13,595: INFO: deberta_initial: Training : batch 61 Loss: 0.055824483401306406]
[2024-04-18 14:23:14,488: INFO: deberta_initial: Training : batch 62 Loss: 0.07346689691672492]
[2024-04-18 14:23:15,380: INFO: deberta_initial: Training : batch 63 Loss: 0.08450000684679508]
[2024-04-18 14:23:16,271: INFO: deberta_initial: Training : batch 64 Loss: 0.04429610815257051]
[2024-04-18 14:23:17,166: INFO: deberta_initial: Training : batch 65 Loss: 0.05268522446858356]
[2024-04-18 14:23:18,060: INFO: deberta_initial: Training : batch 66 Loss: 0.03604383162433067]
[2024-04-18 14:23:18,960: INFO: deberta_initial: Training : batch 67 Loss: 0.045304792754277234]
[2024-04-18 14:23:19,857: INFO: deberta_initial: Training : batch 68 Loss: 0.04796258692438949]
[2024-04-18 14:23:20,747: INFO: deberta_initial: Training : batch 69 Loss: 0.06571919706537462]
[2024-04-18 14:23:21,638: INFO: deberta_initial: Training : batch 70 Loss: 0.05196719955309217]
[2024-04-18 14:23:22,530: INFO: deberta_initial: Training : batch 71 Loss: 0.044851151902985296]
[2024-04-18 14:23:23,424: INFO: deberta_initial: Training : batch 72 Loss: 0.09900228955017351]
[2024-04-18 14:23:24,317: INFO: deberta_initial: Training : batch 73 Loss: 0.049768568197131095]
[2024-04-18 14:23:25,208: INFO: deberta_initial: Training : batch 74 Loss: 0.036494508687848835]
[2024-04-18 14:23:26,102: INFO: deberta_initial: Training : batch 75 Loss: 0.07597073341952362]
[2024-04-18 14:23:26,992: INFO: deberta_initial: Training : batch 76 Loss: 0.0720156380907863]
[2024-04-18 14:23:27,882: INFO: deberta_initial: Training : batch 77 Loss: 0.054481244452941925]
[2024-04-18 14:23:28,777: INFO: deberta_initial: Training : batch 78 Loss: 0.05391872318873325]
[2024-04-18 14:23:29,669: INFO: deberta_initial: Training : batch 79 Loss: 0.07212800789189656]
[2024-04-18 14:23:30,578: INFO: deberta_initial: Training : batch 80 Loss: 0.04587935783063433]
[2024-04-18 14:23:31,481: INFO: deberta_initial: Training : batch 81 Loss: 0.04524922117109404]
[2024-04-18 14:23:32,380: INFO: deberta_initial: Training : batch 82 Loss: 0.06526876117273171]
[2024-04-18 14:23:33,288: INFO: deberta_initial: Training : batch 83 Loss: 0.06036666874015158]
[2024-04-18 14:23:34,181: INFO: deberta_initial: Training : batch 84 Loss: 0.08280818136120346]
[2024-04-18 14:23:35,086: INFO: deberta_initial: Training : batch 85 Loss: 0.04706575800795741]
[2024-04-18 14:23:35,981: INFO: deberta_initial: Training : batch 86 Loss: 0.02247011735810932]
[2024-04-18 14:23:36,872: INFO: deberta_initial: Training : batch 87 Loss: 0.04635815369180852]
[2024-04-18 14:23:37,765: INFO: deberta_initial: Training : batch 88 Loss: 0.08177159598144296]
[2024-04-18 14:23:38,666: INFO: deberta_initial: Training : batch 89 Loss: 0.04780957442476375]
[2024-04-18 14:23:39,562: INFO: deberta_initial: Training : batch 90 Loss: 0.05150456904828455]
[2024-04-18 14:23:40,468: INFO: deberta_initial: Training : batch 91 Loss: 0.037929125879501736]
[2024-04-18 14:23:41,362: INFO: deberta_initial: Training : batch 92 Loss: 0.02999964961112365]
[2024-04-18 14:23:42,272: INFO: deberta_initial: Training : batch 93 Loss: 0.04759192822273132]
[2024-04-18 14:23:43,167: INFO: deberta_initial: Training : batch 94 Loss: 0.06943007062060233]
[2024-04-18 14:23:44,073: INFO: deberta_initial: Training : batch 95 Loss: 0.03466080765914361]
[2024-04-18 14:23:44,988: INFO: deberta_initial: Training : batch 96 Loss: 0.05608879412342874]
[2024-04-18 14:23:45,898: INFO: deberta_initial: Training : batch 97 Loss: 0.061642882467846674]
[2024-04-18 14:23:46,805: INFO: deberta_initial: Training : batch 98 Loss: 0.06519093359309251]
[2024-04-18 14:23:47,698: INFO: deberta_initial: Training : batch 99 Loss: 0.04704629414518929]
[2024-04-18 14:23:48,608: INFO: deberta_initial: Training : batch 100 Loss: 0.054959559169466474]
[2024-04-18 14:23:49,517: INFO: deberta_initial: Training : batch 101 Loss: 0.08420287232412495]
[2024-04-18 14:23:50,430: INFO: deberta_initial: Training : batch 102 Loss: 0.06860631362953291]
[2024-04-18 14:23:51,336: INFO: deberta_initial: Training : batch 103 Loss: 0.04011792825156097]
[2024-04-18 14:23:52,232: INFO: deberta_initial: Training : batch 104 Loss: 0.037739305710196534]
[2024-04-18 14:23:53,141: INFO: deberta_initial: Training : batch 105 Loss: 0.03646118272053032]
[2024-04-18 14:23:54,052: INFO: deberta_initial: Training : batch 106 Loss: 0.03729837898789865]
[2024-04-18 14:23:54,965: INFO: deberta_initial: Training : batch 107 Loss: 0.03410449257681117]
[2024-04-18 14:23:55,872: INFO: deberta_initial: Training : batch 108 Loss: 0.07827418776765083]
[2024-04-18 14:23:56,785: INFO: deberta_initial: Training : batch 109 Loss: 0.05266953854415559]
[2024-04-18 14:23:57,698: INFO: deberta_initial: Training : batch 110 Loss: 0.050296639679640646]
[2024-04-18 14:23:58,606: INFO: deberta_initial: Training : batch 111 Loss: 0.09122082821999258]
[2024-04-18 14:23:59,524: INFO: deberta_initial: Training : batch 112 Loss: 0.04460593564293749]
[2024-04-18 14:24:00,427: INFO: deberta_initial: Training : batch 113 Loss: 0.07936989800753193]
[2024-04-18 14:24:01,338: INFO: deberta_initial: Training : batch 114 Loss: 0.02963557287236508]
[2024-04-18 14:24:02,249: INFO: deberta_initial: Training : batch 115 Loss: 0.04271711732821463]
[2024-04-18 14:24:03,157: INFO: deberta_initial: Training : batch 116 Loss: 0.07463801723759422]
[2024-04-18 14:24:04,068: INFO: deberta_initial: Training : batch 117 Loss: 0.033662747003507354]
[2024-04-18 14:24:04,983: INFO: deberta_initial: Training : batch 118 Loss: 0.0451878695669533]
[2024-04-18 14:24:05,893: INFO: deberta_initial: Training : batch 119 Loss: 0.06319675618123474]
[2024-04-18 14:24:06,797: INFO: deberta_initial: Training : batch 120 Loss: 0.03822581097440411]
[2024-04-18 14:24:07,718: INFO: deberta_initial: Training : batch 121 Loss: 0.06242857496139746]
[2024-04-18 14:24:08,627: INFO: deberta_initial: Training : batch 122 Loss: 0.04526107073248604]
[2024-04-18 14:24:09,541: INFO: deberta_initial: Training : batch 123 Loss: 0.07765791686037571]
[2024-04-18 14:24:10,464: INFO: deberta_initial: Training : batch 124 Loss: 0.050163718560059876]
[2024-04-18 14:24:11,385: INFO: deberta_initial: Training : batch 125 Loss: 0.05346016201418452]
[2024-04-18 14:24:12,304: INFO: deberta_initial: Training : batch 126 Loss: 0.04740601742983104]
[2024-04-18 14:24:13,215: INFO: deberta_initial: Training : batch 127 Loss: 0.05149965984530855]
[2024-04-18 14:24:14,134: INFO: deberta_initial: Training : batch 128 Loss: 0.039709037201212986]
[2024-04-18 14:24:15,047: INFO: deberta_initial: Training : batch 129 Loss: 0.024594854766967777]
[2024-04-18 14:24:15,966: INFO: deberta_initial: Training : batch 130 Loss: 0.05489811407919386]
[2024-04-18 14:24:16,871: INFO: deberta_initial: Training : batch 131 Loss: 0.04872187208423281]
[2024-04-18 14:24:17,784: INFO: deberta_initial: Training : batch 132 Loss: 0.09877091551591825]
[2024-04-18 14:24:18,696: INFO: deberta_initial: Training : batch 133 Loss: 0.043328720456484004]
[2024-04-18 14:24:19,606: INFO: deberta_initial: Training : batch 134 Loss: 0.04645502086625687]
[2024-04-18 14:24:20,517: INFO: deberta_initial: Training : batch 135 Loss: 0.056257093220553646]
[2024-04-18 14:24:21,428: INFO: deberta_initial: Training : batch 136 Loss: 0.06144427820353567]
[2024-04-18 14:24:22,339: INFO: deberta_initial: Training : batch 137 Loss: 0.04281527969916666]
[2024-04-18 14:24:23,255: INFO: deberta_initial: Training : batch 138 Loss: 0.05771995303834896]
[2024-04-18 14:24:24,167: INFO: deberta_initial: Training : batch 139 Loss: 0.06187202991000118]
[2024-04-18 14:24:25,076: INFO: deberta_initial: Training : batch 140 Loss: 0.045326625779908765]
[2024-04-18 14:24:25,985: INFO: deberta_initial: Training : batch 141 Loss: 0.034473646265529075]
[2024-04-18 14:24:26,891: INFO: deberta_initial: Training : batch 142 Loss: 0.057936875374421895]
[2024-04-18 14:24:27,789: INFO: deberta_initial: Training : batch 143 Loss: 0.0440752006753689]
[2024-04-18 14:24:28,699: INFO: deberta_initial: Training : batch 144 Loss: 0.05059380613822807]
[2024-04-18 14:24:29,608: INFO: deberta_initial: Training : batch 145 Loss: 0.03877973088884734]
[2024-04-18 14:24:30,517: INFO: deberta_initial: Training : batch 146 Loss: 0.047850804612859774]
[2024-04-18 14:24:31,410: INFO: deberta_initial: Training : batch 147 Loss: 0.029879058960926696]
[2024-04-18 14:24:32,321: INFO: deberta_initial: Training : batch 148 Loss: 0.07775724571776342]
[2024-04-18 14:24:33,229: INFO: deberta_initial: Training : batch 149 Loss: 0.016282055503534374]
[2024-04-18 14:24:34,139: INFO: deberta_initial: Training : batch 150 Loss: 0.036243122065007405]
[2024-04-18 14:24:35,037: INFO: deberta_initial: Training : batch 151 Loss: 0.053435478508446994]
[2024-04-18 14:24:35,942: INFO: deberta_initial: Training : batch 152 Loss: 0.08715960214784012]
[2024-04-18 14:24:36,853: INFO: deberta_initial: Training : batch 153 Loss: 0.023647058586233605]
[2024-04-18 14:24:37,766: INFO: deberta_initial: Training : batch 154 Loss: 0.0352156058439929]
[2024-04-18 14:24:38,673: INFO: deberta_initial: Training : batch 155 Loss: 0.04321182176241141]
[2024-04-18 14:24:39,580: INFO: deberta_initial: Training : batch 156 Loss: 0.043366497530466105]
[2024-04-18 14:24:40,487: INFO: deberta_initial: Training : batch 157 Loss: 0.048886861517254646]
[2024-04-18 14:24:41,385: INFO: deberta_initial: Training : batch 158 Loss: 0.03627650759050737]
[2024-04-18 14:24:42,291: INFO: deberta_initial: Training : batch 159 Loss: 0.07450671034790243]
[2024-04-18 14:24:43,196: INFO: deberta_initial: Training : batch 160 Loss: 0.05695841367839528]
[2024-04-18 14:24:44,093: INFO: deberta_initial: Training : batch 161 Loss: 0.04981075083355849]
[2024-04-18 14:24:45,004: INFO: deberta_initial: Training : batch 162 Loss: 0.02565483436070571]
[2024-04-18 14:24:45,910: INFO: deberta_initial: Training : batch 163 Loss: 0.03293681337782075]
[2024-04-18 14:24:46,806: INFO: deberta_initial: Training : batch 164 Loss: 0.04382803586806987]
[2024-04-18 14:24:47,712: INFO: deberta_initial: Training : batch 165 Loss: 0.026937903315454387]
[2024-04-18 14:24:48,621: INFO: deberta_initial: Training : batch 166 Loss: 0.06953206095133632]
[2024-04-18 14:24:49,534: INFO: deberta_initial: Training : batch 167 Loss: 0.04695663682249104]
[2024-04-18 14:24:50,446: INFO: deberta_initial: Training : batch 168 Loss: 0.013558537143375937]
[2024-04-18 14:24:51,357: INFO: deberta_initial: Training : batch 169 Loss: 0.1261044386125663]
[2024-04-18 14:24:52,266: INFO: deberta_initial: Training : batch 170 Loss: 0.02877534255277378]
[2024-04-18 14:24:53,172: INFO: deberta_initial: Training : batch 171 Loss: 0.05190480982772]
[2024-04-18 14:24:54,069: INFO: deberta_initial: Training : batch 172 Loss: 0.021938826049840838]
[2024-04-18 14:24:54,977: INFO: deberta_initial: Training : batch 173 Loss: 0.023411523999915113]
[2024-04-18 14:24:55,873: INFO: deberta_initial: Training : batch 174 Loss: 0.05491525068189632]
[2024-04-18 14:24:56,784: INFO: deberta_initial: Training : batch 175 Loss: 0.026162831590914648]
[2024-04-18 14:24:57,692: INFO: deberta_initial: Training : batch 176 Loss: 0.05330566286705228]
[2024-04-18 14:24:58,599: INFO: deberta_initial: Training : batch 177 Loss: 0.03671793168677967]
[2024-04-18 14:24:59,496: INFO: deberta_initial: Training : batch 178 Loss: 0.04053968573142154]
[2024-04-18 14:25:00,405: INFO: deberta_initial: Training : batch 179 Loss: 0.05244206324454017]
[2024-04-18 14:25:01,314: INFO: deberta_initial: Training : batch 180 Loss: 0.01347287043581146]
[2024-04-18 14:25:02,216: INFO: deberta_initial: Training : batch 181 Loss: 0.03472338751937396]
[2024-04-18 14:25:03,129: INFO: deberta_initial: Training : batch 182 Loss: 0.019940760465690956]
[2024-04-18 14:25:04,046: INFO: deberta_initial: Training : batch 183 Loss: 0.06970390349926751]
[2024-04-18 14:25:04,960: INFO: deberta_initial: Training : batch 184 Loss: 0.06389553672545067]
[2024-04-18 14:25:05,871: INFO: deberta_initial: Training : batch 185 Loss: 0.03798267346800215]
[2024-04-18 14:25:06,783: INFO: deberta_initial: Training : batch 186 Loss: 0.02222678985085909]
[2024-04-18 14:25:07,695: INFO: deberta_initial: Training : batch 187 Loss: 0.03260744739917197]
[2024-04-18 14:25:08,606: INFO: deberta_initial: Training : batch 188 Loss: 0.020927945986767345]
[2024-04-18 14:25:09,514: INFO: deberta_initial: Training : batch 189 Loss: 0.03250531067256685]
[2024-04-18 14:25:10,425: INFO: deberta_initial: Training : batch 190 Loss: 0.06134994443437522]
[2024-04-18 14:25:11,335: INFO: deberta_initial: Training : batch 191 Loss: 0.024187828148228688]
[2024-04-18 14:25:12,250: INFO: deberta_initial: Training : batch 192 Loss: 0.020791692369809496]
[2024-04-18 14:25:13,156: INFO: deberta_initial: Training : batch 193 Loss: 0.026076011837277032]
[2024-04-18 14:25:14,067: INFO: deberta_initial: Training : batch 194 Loss: 0.041836111355509666]
[2024-04-18 14:25:14,977: INFO: deberta_initial: Training : batch 195 Loss: 0.05369632229315747]
[2024-04-18 14:25:15,891: INFO: deberta_initial: Training : batch 196 Loss: 0.08067481691506159]
[2024-04-18 14:25:16,805: INFO: deberta_initial: Training : batch 197 Loss: 0.02419405403230885]
[2024-04-18 14:25:17,715: INFO: deberta_initial: Training : batch 198 Loss: 0.019401272153713716]
[2024-04-18 14:25:18,624: INFO: deberta_initial: Training : batch 199 Loss: 0.037495837508957526]
[2024-04-18 14:25:19,534: INFO: deberta_initial: Training : batch 200 Loss: 0.014075865358897975]
[2024-04-18 14:25:20,445: INFO: deberta_initial: Training : batch 201 Loss: 0.09882530330190738]
[2024-04-18 14:25:21,349: INFO: deberta_initial: Training : batch 202 Loss: 0.03752500615096217]
[2024-04-18 14:25:22,250: INFO: deberta_initial: Training : batch 203 Loss: 0.01653168137329131]
[2024-04-18 14:25:23,165: INFO: deberta_initial: Training : batch 204 Loss: 0.02335280737971845]
[2024-04-18 14:25:24,073: INFO: deberta_initial: Training : batch 205 Loss: 0.01659862353405236]
[2024-04-18 14:25:24,986: INFO: deberta_initial: Training : batch 206 Loss: 0.016612295936610687]
[2024-04-18 14:25:25,897: INFO: deberta_initial: Training : batch 207 Loss: 0.09610191088553818]
[2024-04-18 14:25:26,809: INFO: deberta_initial: Training : batch 208 Loss: 0.06966860663180084]
[2024-04-18 14:25:27,722: INFO: deberta_initial: Training : batch 209 Loss: 0.047969451507435916]
[2024-04-18 14:25:28,634: INFO: deberta_initial: Training : batch 210 Loss: 0.02146405098021009]
[2024-04-18 14:25:29,546: INFO: deberta_initial: Training : batch 211 Loss: 0.023926900448018592]
[2024-04-18 14:25:30,455: INFO: deberta_initial: Training : batch 212 Loss: 0.02477043164930425]
[2024-04-18 14:25:31,371: INFO: deberta_initial: Training : batch 213 Loss: 0.02031043742380258]
[2024-04-18 14:25:32,279: INFO: deberta_initial: Training : batch 214 Loss: 0.03929813026706307]
[2024-04-18 14:25:33,191: INFO: deberta_initial: Training : batch 215 Loss: 0.04332856505032751]
[2024-04-18 14:25:34,098: INFO: deberta_initial: Training : batch 216 Loss: 0.024691718823091024]
[2024-04-18 14:25:35,009: INFO: deberta_initial: Training : batch 217 Loss: 0.02167005596533769]
[2024-04-18 14:25:35,918: INFO: deberta_initial: Training : batch 218 Loss: 0.025362356274310733]
[2024-04-18 14:25:36,827: INFO: deberta_initial: Training : batch 219 Loss: 0.011925127985744159]
[2024-04-18 14:25:37,723: INFO: deberta_initial: Training : batch 220 Loss: 0.027451754433065315]
[2024-04-18 14:25:38,630: INFO: deberta_initial: Training : batch 221 Loss: 0.013209688803326744]
[2024-04-18 14:25:39,542: INFO: deberta_initial: Training : batch 222 Loss: 0.04527023754666401]
[2024-04-18 14:25:40,451: INFO: deberta_initial: Training : batch 223 Loss: 0.0271769798594937]
[2024-04-18 14:25:41,362: INFO: deberta_initial: Training : batch 224 Loss: 0.04314966623900299]
[2024-04-18 14:25:42,283: INFO: deberta_initial: Training : batch 225 Loss: 0.014089740846231153]
[2024-04-18 14:25:43,189: INFO: deberta_initial: Training : batch 226 Loss: 0.026092629554714197]
[2024-04-18 14:25:44,094: INFO: deberta_initial: Training : batch 227 Loss: 0.016565230115070974]
[2024-04-18 14:25:45,004: INFO: deberta_initial: Training : batch 228 Loss: 0.03182066059641474]
[2024-04-18 14:25:45,914: INFO: deberta_initial: Training : batch 229 Loss: 0.03581904180202629]
[2024-04-18 14:25:46,824: INFO: deberta_initial: Training : batch 230 Loss: 0.015875774843052772]
[2024-04-18 14:25:47,735: INFO: deberta_initial: Training : batch 231 Loss: 0.03743468667257563]
[2024-04-18 14:25:48,640: INFO: deberta_initial: Training : batch 232 Loss: 0.02329138370105729]
[2024-04-18 14:25:49,550: INFO: deberta_initial: Training : batch 233 Loss: 0.04245580239877709]
[2024-04-18 14:25:50,452: INFO: deberta_initial: Training : batch 234 Loss: 0.05217774825212849]
[2024-04-18 14:25:51,359: INFO: deberta_initial: Training : batch 235 Loss: 0.02609240922723343]
[2024-04-18 14:25:52,269: INFO: deberta_initial: Training : batch 236 Loss: 0.014794166278851682]
[2024-04-18 14:25:53,177: INFO: deberta_initial: Training : batch 237 Loss: 0.012685585494628199]
[2024-04-18 14:25:54,074: INFO: deberta_initial: Training : batch 238 Loss: 0.038541270979950505]
[2024-04-18 14:25:54,986: INFO: deberta_initial: Training : batch 239 Loss: 0.051626700879505515]
[2024-04-18 14:25:55,891: INFO: deberta_initial: Training : batch 240 Loss: 0.05505432963972467]
[2024-04-18 14:25:56,807: INFO: deberta_initial: Training : batch 241 Loss: 0.023275551745414628]
[2024-04-18 14:25:57,725: INFO: deberta_initial: Training : batch 242 Loss: 0.012321730846190163]
[2024-04-18 14:25:58,621: INFO: deberta_initial: Training : batch 243 Loss: 0.030485949584875598]
[2024-04-18 14:25:59,530: INFO: deberta_initial: Training : batch 244 Loss: 0.02183492409181365]
[2024-04-18 14:26:00,438: INFO: deberta_initial: Training : batch 245 Loss: 0.06154993343136574]
[2024-04-18 14:26:01,348: INFO: deberta_initial: Training : batch 246 Loss: 0.03057393987902062]
[2024-04-18 14:26:02,241: INFO: deberta_initial: Training : batch 247 Loss: 0.01426883979081091]
[2024-04-18 14:26:03,151: INFO: deberta_initial: Training : batch 248 Loss: 0.01860404273134205]
[2024-04-18 14:26:04,059: INFO: deberta_initial: Training : batch 249 Loss: 0.06576526344887532]
[2024-04-18 14:26:04,959: INFO: deberta_initial: Training : batch 250 Loss: 0.014117812553828327]
[2024-04-18 14:26:05,861: INFO: deberta_initial: Training : batch 251 Loss: 0.08718768309921722]
[2024-04-18 14:26:06,771: INFO: deberta_initial: Training : batch 252 Loss: 0.05263931885069419]
[2024-04-18 14:26:07,681: INFO: deberta_initial: Training : batch 253 Loss: 0.01517709796455735]
[2024-04-18 14:26:08,596: INFO: deberta_initial: Training : batch 254 Loss: 0.03261632978624903]
[2024-04-18 14:26:09,506: INFO: deberta_initial: Training : batch 255 Loss: 0.010449118521557723]
[2024-04-18 14:26:10,412: INFO: deberta_initial: Training : batch 256 Loss: 0.01179422187022651]
[2024-04-18 14:26:11,322: INFO: deberta_initial: Training : batch 257 Loss: 0.024098417268816848]
[2024-04-18 14:26:12,233: INFO: deberta_initial: Training : batch 258 Loss: 0.02348430045072062]
[2024-04-18 14:26:13,143: INFO: deberta_initial: Training : batch 259 Loss: 0.024836151672869972]
[2024-04-18 14:26:14,054: INFO: deberta_initial: Training : batch 260 Loss: 0.00714427940242569]
[2024-04-18 14:26:14,964: INFO: deberta_initial: Training : batch 261 Loss: 0.016090694610034754]
[2024-04-18 14:26:15,875: INFO: deberta_initial: Training : batch 262 Loss: 0.020936601420254275]
[2024-04-18 14:26:16,784: INFO: deberta_initial: Training : batch 263 Loss: 0.048657690450538325]
[2024-04-18 14:26:17,691: INFO: deberta_initial: Training : batch 264 Loss: 0.018447795536497256]
[2024-04-18 14:26:18,589: INFO: deberta_initial: Training : batch 265 Loss: 0.03920748285398169]
[2024-04-18 14:26:19,498: INFO: deberta_initial: Training : batch 266 Loss: 0.011558555071376505]
[2024-04-18 14:26:20,408: INFO: deberta_initial: Training : batch 267 Loss: 0.022764780717932764]
[2024-04-18 14:26:21,320: INFO: deberta_initial: Training : batch 268 Loss: 0.01727723677378607]
[2024-04-18 14:26:22,235: INFO: deberta_initial: Training : batch 269 Loss: 0.010555741321706755]
[2024-04-18 14:26:23,151: INFO: deberta_initial: Training : batch 270 Loss: 0.03282835605368767]
[2024-04-18 14:26:24,058: INFO: deberta_initial: Training : batch 271 Loss: 0.015206839670262743]
[2024-04-18 14:26:24,965: INFO: deberta_initial: Training : batch 272 Loss: 0.011525999395062029]
[2024-04-18 14:26:25,875: INFO: deberta_initial: Training : batch 273 Loss: 0.026556349602913188]
[2024-04-18 14:26:26,785: INFO: deberta_initial: Training : batch 274 Loss: 0.008065691253429383]
[2024-04-18 14:26:27,696: INFO: deberta_initial: Training : batch 275 Loss: 0.06837359761507074]
[2024-04-18 14:26:28,604: INFO: deberta_initial: Training : batch 276 Loss: 0.01818046513539153]
[2024-04-18 14:26:29,511: INFO: deberta_initial: Training : batch 277 Loss: 0.025496759704397555]
[2024-04-18 14:26:30,413: INFO: deberta_initial: Training : batch 278 Loss: 0.008539597195705205]
[2024-04-18 14:26:31,323: INFO: deberta_initial: Training : batch 279 Loss: 0.05866836535510825]
[2024-04-18 14:26:32,235: INFO: deberta_initial: Training : batch 280 Loss: 0.018321277200071692]
[2024-04-18 14:26:33,145: INFO: deberta_initial: Training : batch 281 Loss: 0.015546948861817327]
[2024-04-18 14:26:34,049: INFO: deberta_initial: Training : batch 282 Loss: 0.03127741899252469]
[2024-04-18 14:26:34,965: INFO: deberta_initial: Training : batch 283 Loss: 0.024350209450585733]
[2024-04-18 14:26:35,883: INFO: deberta_initial: Training : batch 284 Loss: 0.018226640898787443]
[2024-04-18 14:26:36,795: INFO: deberta_initial: Training : batch 285 Loss: 0.0199363868387446]
[2024-04-18 14:26:37,706: INFO: deberta_initial: Training : batch 286 Loss: 0.027860547725503264]
[2024-04-18 14:26:38,618: INFO: deberta_initial: Training : batch 287 Loss: 0.04060498988229061]
[2024-04-18 14:26:39,530: INFO: deberta_initial: Training : batch 288 Loss: 0.013488812415291526]
[2024-04-18 14:26:40,441: INFO: deberta_initial: Training : batch 289 Loss: 0.03654728629372952]
[2024-04-18 14:26:41,351: INFO: deberta_initial: Training : batch 290 Loss: 0.00707508726024583]
[2024-04-18 14:26:42,264: INFO: deberta_initial: Training : batch 291 Loss: 0.028091185580625018]
[2024-04-18 14:26:43,172: INFO: deberta_initial: Training : batch 292 Loss: 0.02130414530622363]
[2024-04-18 14:26:44,081: INFO: deberta_initial: Training : batch 293 Loss: 0.02133102665503611]
[2024-04-18 14:26:44,991: INFO: deberta_initial: Training : batch 294 Loss: 0.05489616748113454]
[2024-04-18 14:26:45,902: INFO: deberta_initial: Training : batch 295 Loss: 0.010579610640136024]
[2024-04-18 14:26:46,814: INFO: deberta_initial: Training : batch 296 Loss: 0.021780741947087727]
[2024-04-18 14:26:47,731: INFO: deberta_initial: Training : batch 297 Loss: 0.030548527448012702]
[2024-04-18 14:26:48,636: INFO: deberta_initial: Training : batch 298 Loss: 0.09527302721712426]
[2024-04-18 14:26:49,549: INFO: deberta_initial: Training : batch 299 Loss: 0.021943972784250653]
[2024-04-18 14:26:50,454: INFO: deberta_initial: Training : batch 300 Loss: 0.02526498143281302]
[2024-04-18 14:26:51,365: INFO: deberta_initial: Training : batch 301 Loss: 0.02318243552128265]
[2024-04-18 14:26:52,277: INFO: deberta_initial: Training : batch 302 Loss: 0.02712041766145208]
[2024-04-18 14:26:53,195: INFO: deberta_initial: Training : batch 303 Loss: 0.0324118337846569]
[2024-04-18 14:26:54,098: INFO: deberta_initial: Training : batch 304 Loss: 0.044045288802575785]
[2024-04-18 14:26:55,007: INFO: deberta_initial: Training : batch 305 Loss: 0.01725708116363614]
[2024-04-18 14:26:55,916: INFO: deberta_initial: Training : batch 306 Loss: 0.013117042913226051]
[2024-04-18 14:26:56,828: INFO: deberta_initial: Training : batch 307 Loss: 0.013151768099256018]
[2024-04-18 14:26:57,735: INFO: deberta_initial: Training : batch 308 Loss: 0.02360879683574017]
[2024-04-18 14:26:58,645: INFO: deberta_initial: Training : batch 309 Loss: 0.009608312161155232]
[2024-04-18 14:26:59,553: INFO: deberta_initial: Training : batch 310 Loss: 0.020999692826933633]
[2024-04-18 14:27:00,463: INFO: deberta_initial: Training : batch 311 Loss: 0.011700960363686688]
[2024-04-18 14:27:01,379: INFO: deberta_initial: Training : batch 312 Loss: 0.013342865555228844]
[2024-04-18 14:27:02,288: INFO: deberta_initial: Training : batch 313 Loss: 0.01450327507783071]
[2024-04-18 14:27:03,198: INFO: deberta_initial: Training : batch 314 Loss: 0.049992009442025254]
[2024-04-18 14:27:04,119: INFO: deberta_initial: Training : batch 315 Loss: 0.06491093193309476]
[2024-04-18 14:27:05,018: INFO: deberta_initial: Training : batch 316 Loss: 0.013099586102772126]
[2024-04-18 14:27:05,927: INFO: deberta_initial: Training : batch 317 Loss: 0.01610502116826855]
[2024-04-18 14:27:06,837: INFO: deberta_initial: Training : batch 318 Loss: 0.021136429699118896]
[2024-04-18 14:27:07,752: INFO: deberta_initial: Training : batch 319 Loss: 0.01937014423573155]
[2024-04-18 14:27:08,665: INFO: deberta_initial: Training : batch 320 Loss: 0.014772182571866422]
[2024-04-18 14:27:09,571: INFO: deberta_initial: Training : batch 321 Loss: 0.06808563960714323]
[2024-04-18 14:27:10,480: INFO: deberta_initial: Training : batch 322 Loss: 0.007340794553010832]
[2024-04-18 14:27:11,390: INFO: deberta_initial: Training : batch 323 Loss: 0.00805414233259604]
[2024-04-18 14:27:12,302: INFO: deberta_initial: Training : batch 324 Loss: 0.02605807486116088]
[2024-04-18 14:27:13,201: INFO: deberta_initial: Training : batch 325 Loss: 0.02900314000741904]
[2024-04-18 14:27:14,104: INFO: deberta_initial: Training : batch 326 Loss: 0.03933232718600973]
[2024-04-18 14:27:15,013: INFO: deberta_initial: Training : batch 327 Loss: 0.015388989078273223]
[2024-04-18 14:27:15,932: INFO: deberta_initial: Training : batch 328 Loss: 0.015906780755125294]
[2024-04-18 14:27:16,834: INFO: deberta_initial: Training : batch 329 Loss: 0.010695290242448016]
[2024-04-18 14:27:17,745: INFO: deberta_initial: Training : batch 330 Loss: 0.02167152850068991]
[2024-04-18 14:27:18,654: INFO: deberta_initial: Training : batch 331 Loss: 0.007130131179791789]
[2024-04-18 14:27:19,567: INFO: deberta_initial: Training : batch 332 Loss: 0.010618404352427968]
[2024-04-18 14:27:20,480: INFO: deberta_initial: Training : batch 333 Loss: 0.028521969710270777]
[2024-04-18 14:27:21,387: INFO: deberta_initial: Training : batch 334 Loss: 0.010996770660841582]
[2024-04-18 14:27:22,296: INFO: deberta_initial: Training : batch 335 Loss: 0.012921954269331636]
[2024-04-18 14:27:23,204: INFO: deberta_initial: Training : batch 336 Loss: 0.09763641200938183]
[2024-04-18 14:27:24,114: INFO: deberta_initial: Training : batch 337 Loss: 0.007956165657617375]
[2024-04-18 14:27:25,025: INFO: deberta_initial: Training : batch 338 Loss: 0.016780720878537377]
[2024-04-18 14:27:25,934: INFO: deberta_initial: Training : batch 339 Loss: 0.009220108082745511]
[2024-04-18 14:27:26,845: INFO: deberta_initial: Training : batch 340 Loss: 0.03545977545557695]
[2024-04-18 14:27:27,758: INFO: deberta_initial: Training : batch 341 Loss: 0.012261961883632468]
[2024-04-18 14:27:28,669: INFO: deberta_initial: Training : batch 342 Loss: 0.021545132180778265]
[2024-04-18 14:27:29,580: INFO: deberta_initial: Training : batch 343 Loss: 0.015878902082556875]
[2024-04-18 14:27:30,491: INFO: deberta_initial: Training : batch 344 Loss: 0.011794911808232498]
[2024-04-18 14:27:31,402: INFO: deberta_initial: Training : batch 345 Loss: 0.02746843716686865]
[2024-04-18 14:27:32,312: INFO: deberta_initial: Training : batch 346 Loss: 0.01346724511160158]
[2024-04-18 14:27:33,210: INFO: deberta_initial: Training : batch 347 Loss: 0.01997100623618073]
[2024-04-18 14:27:34,120: INFO: deberta_initial: Training : batch 348 Loss: 0.030999216625082347]
[2024-04-18 14:27:35,031: INFO: deberta_initial: Training : batch 349 Loss: 0.051977897655427076]
[2024-04-18 14:27:35,942: INFO: deberta_initial: Training : batch 350 Loss: 0.04332265875288051]
[2024-04-18 14:27:36,851: INFO: deberta_initial: Training : batch 351 Loss: 0.012025635055613633]
[2024-04-18 14:27:37,762: INFO: deberta_initial: Training : batch 352 Loss: 0.010422565529606756]
[2024-04-18 14:27:38,656: INFO: deberta_initial: Training : batch 353 Loss: 0.015806888700464417]
[2024-04-18 14:27:39,568: INFO: deberta_initial: Training : batch 354 Loss: 0.02309040684000467]
[2024-04-18 14:27:40,478: INFO: deberta_initial: Training : batch 355 Loss: 0.017164925955306318]
[2024-04-18 14:27:41,392: INFO: deberta_initial: Training : batch 356 Loss: 0.014356957362682868]
[2024-04-18 14:27:42,302: INFO: deberta_initial: Training : batch 357 Loss: 0.007060242286733354]
[2024-04-18 14:27:43,218: INFO: deberta_initial: Training : batch 358 Loss: 0.009536292483089598]
[2024-04-18 14:27:44,123: INFO: deberta_initial: Training : batch 359 Loss: 0.015348856496124396]
[2024-04-18 14:27:45,042: INFO: deberta_initial: Training : batch 360 Loss: 0.03982688126396667]
[2024-04-18 14:27:45,957: INFO: deberta_initial: Training : batch 361 Loss: 0.010732234540658905]
[2024-04-18 14:27:46,874: INFO: deberta_initial: Training : batch 362 Loss: 0.010154670131826707]
[2024-04-18 14:27:47,766: INFO: deberta_initial: Training : batch 363 Loss: 0.014072221809399524]
[2024-04-18 14:27:48,675: INFO: deberta_initial: Training : batch 364 Loss: 0.02732659168582083]
[2024-04-18 14:27:49,585: INFO: deberta_initial: Training : batch 365 Loss: 0.02284836437260997]
[2024-04-18 14:27:50,487: INFO: deberta_initial: Training : batch 366 Loss: 0.02565897720774637]
[2024-04-18 14:27:51,397: INFO: deberta_initial: Training : batch 367 Loss: 0.016247805986951767]
[2024-04-18 14:27:52,299: INFO: deberta_initial: Training : batch 368 Loss: 0.04925050252909623]
[2024-04-18 14:27:53,208: INFO: deberta_initial: Training : batch 369 Loss: 0.052009791921211766]
[2024-04-18 14:27:54,116: INFO: deberta_initial: Training : batch 370 Loss: 0.016626258503526337]
[2024-04-18 14:27:55,027: INFO: deberta_initial: Training : batch 371 Loss: 0.01275861848203326]
[2024-04-18 14:27:55,942: INFO: deberta_initial: Training : batch 372 Loss: 0.016993002071070587]
[2024-04-18 14:27:56,846: INFO: deberta_initial: Training : batch 373 Loss: 0.013986636264919493]
[2024-04-18 14:27:57,756: INFO: deberta_initial: Training : batch 374 Loss: 0.017949881671699724]
[2024-04-18 14:27:58,666: INFO: deberta_initial: Training : batch 375 Loss: 0.007631242703021806]
[2024-04-18 14:27:59,571: INFO: deberta_initial: Training : batch 376 Loss: 0.01652125672446127]
[2024-04-18 14:28:00,485: INFO: deberta_initial: Training : batch 377 Loss: 0.007151690485234888]
[2024-04-18 14:28:01,393: INFO: deberta_initial: Training : batch 378 Loss: 0.00901617047624573]
[2024-04-18 14:28:02,293: INFO: deberta_initial: Training : batch 379 Loss: 0.013555972940857744]
[2024-04-18 14:28:03,204: INFO: deberta_initial: Training : batch 380 Loss: 0.014923280273718104]
[2024-04-18 14:28:04,109: INFO: deberta_initial: Training : batch 381 Loss: 0.03645599189463669]
[2024-04-18 14:28:05,021: INFO: deberta_initial: Training : batch 382 Loss: 0.00536798868362768]
[2024-04-18 14:28:05,929: INFO: deberta_initial: Training : batch 383 Loss: 0.03237691300675712]
[2024-04-18 14:28:06,845: INFO: deberta_initial: Training : batch 384 Loss: 0.04185606177173389]
[2024-04-18 14:28:07,768: INFO: deberta_initial: Training : batch 385 Loss: 0.019516739969707445]
[2024-04-18 14:28:08,678: INFO: deberta_initial: Training : batch 386 Loss: 0.03674138614820351]
[2024-04-18 14:28:09,595: INFO: deberta_initial: Training : batch 387 Loss: 0.03746822585033259]
[2024-04-18 14:28:10,510: INFO: deberta_initial: Training : batch 388 Loss: 0.014553776908927092]
[2024-04-18 14:28:11,413: INFO: deberta_initial: Training : batch 389 Loss: 0.01840235279837169]
[2024-04-18 14:28:12,325: INFO: deberta_initial: Training : batch 390 Loss: 0.01599505389398687]
[2024-04-18 14:28:13,232: INFO: deberta_initial: Training : batch 391 Loss: 0.016323967675173506]
[2024-04-18 14:28:14,142: INFO: deberta_initial: Training : batch 392 Loss: 0.013585357927213468]
[2024-04-18 14:28:15,051: INFO: deberta_initial: Training : batch 393 Loss: 0.019976377190424992]
[2024-04-18 14:28:15,960: INFO: deberta_initial: Training : batch 394 Loss: 0.02387658762670831]
[2024-04-18 14:28:16,869: INFO: deberta_initial: Training : batch 395 Loss: 0.016701494241081208]
[2024-04-18 14:28:17,780: INFO: deberta_initial: Training : batch 396 Loss: 0.01773901243977769]
[2024-04-18 14:28:18,688: INFO: deberta_initial: Training : batch 397 Loss: 0.012072749886875173]
[2024-04-18 14:28:19,596: INFO: deberta_initial: Training : batch 398 Loss: 0.020048146671480818]
[2024-04-18 14:28:20,506: INFO: deberta_initial: Training : batch 399 Loss: 0.013569162828927419]
[2024-04-18 14:28:21,424: INFO: deberta_initial: Training : batch 400 Loss: 0.030148797720006764]
[2024-04-18 14:28:22,334: INFO: deberta_initial: Training : batch 401 Loss: 0.014279194382532941]
[2024-04-18 14:28:23,245: INFO: deberta_initial: Training : batch 402 Loss: 0.049056153315768895]
[2024-04-18 14:28:24,153: INFO: deberta_initial: Training : batch 403 Loss: 0.009549488196856915]
[2024-04-18 14:28:25,061: INFO: deberta_initial: Training : batch 404 Loss: 0.010177993914444764]
[2024-04-18 14:28:25,970: INFO: deberta_initial: Training : batch 405 Loss: 0.018778294754756904]
[2024-04-18 14:28:26,877: INFO: deberta_initial: Training : batch 406 Loss: 0.01635739131405927]
[2024-04-18 14:28:27,773: INFO: deberta_initial: Training : batch 407 Loss: 0.018889010968381855]
[2024-04-18 14:28:28,683: INFO: deberta_initial: Training : batch 408 Loss: 0.0221027676401765]
[2024-04-18 14:28:29,592: INFO: deberta_initial: Training : batch 409 Loss: 0.031177916602600886]
[2024-04-18 14:28:30,504: INFO: deberta_initial: Training : batch 410 Loss: 0.017953975753839314]
[2024-04-18 14:28:31,411: INFO: deberta_initial: Training : batch 411 Loss: 0.021902689592849595]
[2024-04-18 14:28:32,306: INFO: deberta_initial: Training : batch 412 Loss: 0.02663531800105003]
[2024-04-18 14:28:33,215: INFO: deberta_initial: Training : batch 413 Loss: 0.02125868182396516]
[2024-04-18 14:28:34,123: INFO: deberta_initial: Training : batch 414 Loss: 0.026888791318234705]
[2024-04-18 14:28:35,037: INFO: deberta_initial: Training : batch 415 Loss: 0.009662027123774957]
[2024-04-18 14:28:35,947: INFO: deberta_initial: Training : batch 416 Loss: 0.023089865822071936]
[2024-04-18 14:28:36,861: INFO: deberta_initial: Training : batch 417 Loss: 0.021617036546611915]
[2024-04-18 14:28:37,769: INFO: deberta_initial: Training : batch 418 Loss: 0.006125547854347139]
[2024-04-18 14:28:38,681: INFO: deberta_initial: Training : batch 419 Loss: 0.036093398961969274]
[2024-04-18 14:28:39,590: INFO: deberta_initial: Training : batch 420 Loss: 0.010673824429564407]
[2024-04-18 14:28:40,502: INFO: deberta_initial: Training : batch 421 Loss: 0.009937929011369175]
[2024-04-18 14:28:41,412: INFO: deberta_initial: Training : batch 422 Loss: 0.022688126734760172]
[2024-04-18 14:28:42,322: INFO: deberta_initial: Training : batch 423 Loss: 0.02673558858319067]
[2024-04-18 14:28:43,227: INFO: deberta_initial: Training : batch 424 Loss: 0.004487322868661899]
[2024-04-18 14:28:44,129: INFO: deberta_initial: Training : batch 425 Loss: 0.012548217237068162]
[2024-04-18 14:28:45,040: INFO: deberta_initial: Training : batch 426 Loss: 0.020107343870600047]
[2024-04-18 14:28:45,953: INFO: deberta_initial: Training : batch 427 Loss: 0.03281617711408828]
[2024-04-18 14:28:46,863: INFO: deberta_initial: Training : batch 428 Loss: 0.04632645374531216]
[2024-04-18 14:28:47,776: INFO: deberta_initial: Training : batch 429 Loss: 0.016147590598933007]
[2024-04-18 14:28:48,690: INFO: deberta_initial: Training : batch 430 Loss: 0.011480776191678081]
[2024-04-18 14:28:49,600: INFO: deberta_initial: Training : batch 431 Loss: 0.01477689490150614]
[2024-04-18 14:28:50,517: INFO: deberta_initial: Training : batch 432 Loss: 0.017079753906874825]
[2024-04-18 14:28:51,425: INFO: deberta_initial: Training : batch 433 Loss: 0.026680008557540935]
[2024-04-18 14:28:52,335: INFO: deberta_initial: Training : batch 434 Loss: 0.011395653911574741]
[2024-04-18 14:28:53,246: INFO: deberta_initial: Training : batch 435 Loss: 0.00726818514467012]
[2024-04-18 14:28:54,158: INFO: deberta_initial: Training : batch 436 Loss: 0.012059353986125683]
[2024-04-18 14:28:55,067: INFO: deberta_initial: Training : batch 437 Loss: 0.011109977915456065]
[2024-04-18 14:28:55,977: INFO: deberta_initial: Training : batch 438 Loss: 0.016353741409238464]
[2024-04-18 14:28:56,884: INFO: deberta_initial: Training : batch 439 Loss: 0.014000441389441608]
[2024-04-18 14:28:57,783: INFO: deberta_initial: Training : batch 440 Loss: 0.01191390533235693]
[2024-04-18 14:28:58,693: INFO: deberta_initial: Training : batch 441 Loss: 0.02431876696346892]
[2024-04-18 14:28:59,601: INFO: deberta_initial: Training : batch 442 Loss: 0.02389318909233079]
[2024-04-18 14:29:00,511: INFO: deberta_initial: Training : batch 443 Loss: 0.020586278158607686]
[2024-04-18 14:29:01,426: INFO: deberta_initial: Training : batch 444 Loss: 0.058851556254478944]
[2024-04-18 14:29:02,340: INFO: deberta_initial: Training : batch 445 Loss: 0.010784617571645389]
[2024-04-18 14:29:03,253: INFO: deberta_initial: Training : batch 446 Loss: 0.024671667261044382]
[2024-04-18 14:29:04,164: INFO: deberta_initial: Training : batch 447 Loss: 0.011914715882195611]
[2024-04-18 14:29:05,073: INFO: deberta_initial: Training : batch 448 Loss: 0.08693542639810793]
[2024-04-18 14:29:05,978: INFO: deberta_initial: Training : batch 449 Loss: 0.034012278860786435]
[2024-04-18 14:29:06,883: INFO: deberta_initial: Training : batch 450 Loss: 0.002959069540928253]
[2024-04-18 14:29:07,794: INFO: deberta_initial: Training : batch 451 Loss: 0.025802722580895176]
[2024-04-18 14:29:08,706: INFO: deberta_initial: Training : batch 452 Loss: 0.027280237467280224]
[2024-04-18 14:29:09,616: INFO: deberta_initial: Training : batch 453 Loss: 0.030150588674411026]
[2024-04-18 14:29:10,526: INFO: deberta_initial: Training : batch 454 Loss: 0.02337650713494958]
[2024-04-18 14:29:11,438: INFO: deberta_initial: Training : batch 455 Loss: 0.009208448297864873]
[2024-04-18 14:29:12,346: INFO: deberta_initial: Training : batch 456 Loss: 0.01697743764475625]
[2024-04-18 14:29:13,253: INFO: deberta_initial: Training : batch 457 Loss: 0.017997209512515374]
[2024-04-18 14:29:14,163: INFO: deberta_initial: Training : batch 458 Loss: 0.012863579630740153]
[2024-04-18 14:29:15,080: INFO: deberta_initial: Training : batch 459 Loss: 0.01577106085521257]
[2024-04-18 14:29:15,983: INFO: deberta_initial: Training : batch 460 Loss: 0.03830035743265671]
[2024-04-18 14:29:16,892: INFO: deberta_initial: Training : batch 461 Loss: 0.008525232599307512]
[2024-04-18 14:29:17,800: INFO: deberta_initial: Training : batch 462 Loss: 0.012116129635459782]
[2024-04-18 14:29:18,714: INFO: deberta_initial: Training : batch 463 Loss: 0.01412879713057341]
[2024-04-18 14:29:19,621: INFO: deberta_initial: Training : batch 464 Loss: 0.029402356997780536]
[2024-04-18 14:29:20,531: INFO: deberta_initial: Training : batch 465 Loss: 0.014830667228635517]
[2024-04-18 14:29:21,441: INFO: deberta_initial: Training : batch 466 Loss: 0.012178232743367707]
[2024-04-18 14:29:22,348: INFO: deberta_initial: Training : batch 467 Loss: 0.004542144143038422]
[2024-04-18 14:29:23,249: INFO: deberta_initial: Training : batch 468 Loss: 0.015016560023648831]
[2024-04-18 14:29:24,162: INFO: deberta_initial: Training : batch 469 Loss: 0.03091317741097503]
[2024-04-18 14:29:25,081: INFO: deberta_initial: Training : batch 470 Loss: 0.026151280285428076]
[2024-04-18 14:29:25,992: INFO: deberta_initial: Training : batch 471 Loss: 0.0173727919544196]
[2024-04-18 14:29:26,901: INFO: deberta_initial: Training : batch 472 Loss: 0.016267781395095497]
[2024-04-18 14:29:27,816: INFO: deberta_initial: Training : batch 473 Loss: 0.016174775377559857]
[2024-04-18 14:29:28,728: INFO: deberta_initial: Training : batch 474 Loss: 0.016768796759406065]
[2024-04-18 14:29:29,638: INFO: deberta_initial: Training : batch 475 Loss: 0.011157869685097613]
[2024-04-18 14:29:30,548: INFO: deberta_initial: Training : batch 476 Loss: 0.020331420998580315]
[2024-04-18 14:29:31,460: INFO: deberta_initial: Training : batch 477 Loss: 0.0642441244186818]
[2024-04-18 14:29:32,372: INFO: deberta_initial: Training : batch 478 Loss: 0.02202576041507271]
[2024-04-18 14:29:33,281: INFO: deberta_initial: Training : batch 479 Loss: 0.014794547175709362]
[2024-04-18 14:29:34,190: INFO: deberta_initial: Training : batch 480 Loss: 0.01830125986268861]
[2024-04-18 14:29:35,083: INFO: deberta_initial: Training : batch 481 Loss: 0.010559497978966166]
[2024-04-18 14:29:35,994: INFO: deberta_initial: Training : batch 482 Loss: 0.02445602409287287]
[2024-04-18 14:29:36,904: INFO: deberta_initial: Training : batch 483 Loss: 0.00372949361403616]
[2024-04-18 14:29:37,815: INFO: deberta_initial: Training : batch 484 Loss: 0.0066254425237164336]
[2024-04-18 14:29:38,724: INFO: deberta_initial: Training : batch 485 Loss: 0.00685973961139278]
[2024-04-18 14:29:39,633: INFO: deberta_initial: Training : batch 486 Loss: 0.026579765001697158]
[2024-04-18 14:29:40,546: INFO: deberta_initial: Training : batch 487 Loss: 0.02498719949230066]
[2024-04-18 14:29:41,454: INFO: deberta_initial: Training : batch 488 Loss: 0.013025205396968208]
[2024-04-18 14:29:42,369: INFO: deberta_initial: Training : batch 489 Loss: 0.011347088559522095]
[2024-04-18 14:29:43,276: INFO: deberta_initial: Training : batch 490 Loss: 0.027383878671224566]
[2024-04-18 14:29:44,182: INFO: deberta_initial: Training : batch 491 Loss: 0.01436954091154692]
[2024-04-18 14:29:45,080: INFO: deberta_initial: Training : batch 492 Loss: 0.029285021713761867]
[2024-04-18 14:29:45,991: INFO: deberta_initial: Training : batch 493 Loss: 0.04425793446482689]
[2024-04-18 14:29:46,898: INFO: deberta_initial: Training : batch 494 Loss: 0.024915907740716243]
[2024-04-18 14:29:47,800: INFO: deberta_initial: Training : batch 495 Loss: 0.02976921162015999]
[2024-04-18 14:29:48,706: INFO: deberta_initial: Training : batch 496 Loss: 0.0025846294043251963]
[2024-04-18 14:29:49,615: INFO: deberta_initial: Training : batch 497 Loss: 0.004214443816763444]
[2024-04-18 14:29:50,529: INFO: deberta_initial: Training : batch 498 Loss: 0.016414770527051082]
[2024-04-18 14:29:51,440: INFO: deberta_initial: Training : batch 499 Loss: 0.02369704627487561]
[2024-04-18 14:29:52,350: INFO: deberta_initial: Training : batch 500 Loss: 0.005253133278086364]
[2024-04-18 14:29:53,266: INFO: deberta_initial: Training : batch 501 Loss: 0.0066332934437866265]
[2024-04-18 14:29:54,182: INFO: deberta_initial: Training : batch 502 Loss: 0.02507209565444495]
[2024-04-18 14:29:55,093: INFO: deberta_initial: Training : batch 503 Loss: 0.01531901237036573]
[2024-04-18 14:29:55,996: INFO: deberta_initial: Training : batch 504 Loss: 0.007007695203374576]
[2024-04-18 14:29:56,907: INFO: deberta_initial: Training : batch 505 Loss: 0.02560176406507233]
[2024-04-18 14:29:57,818: INFO: deberta_initial: Training : batch 506 Loss: 0.016561182448128636]
[2024-04-18 14:29:58,728: INFO: deberta_initial: Training : batch 507 Loss: 0.008658435589914632]
[2024-04-18 14:29:59,641: INFO: deberta_initial: Training : batch 508 Loss: 0.0334919304337705]
[2024-04-18 14:30:00,550: INFO: deberta_initial: Training : batch 509 Loss: 0.04732172696136717]
[2024-04-18 14:30:01,454: INFO: deberta_initial: Training : batch 510 Loss: 0.024303290983679962]
[2024-04-18 14:30:02,360: INFO: deberta_initial: Training : batch 511 Loss: 0.007410778229965471]
[2024-04-18 14:30:03,271: INFO: deberta_initial: Training : batch 512 Loss: 0.02595842316559686]
[2024-04-18 14:30:04,178: INFO: deberta_initial: Training : batch 513 Loss: 0.014593242187908445]
[2024-04-18 14:30:05,090: INFO: deberta_initial: Training : batch 514 Loss: 0.010398814861569931]
[2024-04-18 14:30:06,000: INFO: deberta_initial: Training : batch 515 Loss: 0.007867623830094745]
[2024-04-18 14:30:06,912: INFO: deberta_initial: Training : batch 516 Loss: 0.032222519881509704]
[2024-04-18 14:30:07,825: INFO: deberta_initial: Training : batch 517 Loss: 0.00935797169810075]
[2024-04-18 14:30:08,733: INFO: deberta_initial: Training : batch 518 Loss: 0.013411727535191398]
[2024-04-18 14:30:09,643: INFO: deberta_initial: Training : batch 519 Loss: 0.016450701713882313]
[2024-04-18 14:30:10,550: INFO: deberta_initial: Training : batch 520 Loss: 0.01679314395844516]
[2024-04-18 14:30:11,447: INFO: deberta_initial: Training : batch 521 Loss: 0.013262621641657016]
[2024-04-18 14:30:12,356: INFO: deberta_initial: Training : batch 522 Loss: 0.015497526878992892]
[2024-04-18 14:30:13,266: INFO: deberta_initial: Training : batch 523 Loss: 0.07698197832445286]
[2024-04-18 14:30:14,167: INFO: deberta_initial: Training : batch 524 Loss: 0.05525759625555814]
[2024-04-18 14:30:15,073: INFO: deberta_initial: Training : batch 525 Loss: 0.06651073526860546]
[2024-04-18 14:30:15,979: INFO: deberta_initial: Training : batch 526 Loss: 0.023014866996520413]
[2024-04-18 14:30:16,888: INFO: deberta_initial: Training : batch 527 Loss: 0.02616813095583101]
[2024-04-18 14:30:17,799: INFO: deberta_initial: Training : batch 528 Loss: 0.03934736296962082]
[2024-04-18 14:30:18,710: INFO: deberta_initial: Training : batch 529 Loss: 0.021219193329595154]
[2024-04-18 14:30:19,623: INFO: deberta_initial: Training : batch 530 Loss: 0.018689741704861186]
[2024-04-18 14:30:20,537: INFO: deberta_initial: Training : batch 531 Loss: 0.020195727724338728]
[2024-04-18 14:30:21,446: INFO: deberta_initial: Training : batch 532 Loss: 0.020152777551637493]
[2024-04-18 14:30:22,357: INFO: deberta_initial: Training : batch 533 Loss: 0.04835903950467949]
[2024-04-18 14:30:23,265: INFO: deberta_initial: Training : batch 534 Loss: 0.013366900428482374]
[2024-04-18 14:30:24,177: INFO: deberta_initial: Training : batch 535 Loss: 0.05130604864643032]
[2024-04-18 14:30:25,086: INFO: deberta_initial: Training : batch 536 Loss: 0.010776945029963948]
[2024-04-18 14:30:25,995: INFO: deberta_initial: Training : batch 537 Loss: 0.02857389449087646]
[2024-04-18 14:30:26,898: INFO: deberta_initial: Training : batch 538 Loss: 0.016974751867823427]
[2024-04-18 14:30:27,803: INFO: deberta_initial: Training : batch 539 Loss: 0.02275729250137184]
[2024-04-18 14:30:28,713: INFO: deberta_initial: Training : batch 540 Loss: 0.014237532647547336]
[2024-04-18 14:30:29,618: INFO: deberta_initial: Training : batch 541 Loss: 0.013645449891416507]
[2024-04-18 14:30:30,528: INFO: deberta_initial: Training : batch 542 Loss: 0.004695383063549611]
[2024-04-18 14:30:31,437: INFO: deberta_initial: Training : batch 543 Loss: 0.02813127680012224]
[2024-04-18 14:30:32,347: INFO: deberta_initial: Training : batch 544 Loss: 0.023861985724858065]
[2024-04-18 14:30:33,261: INFO: deberta_initial: Training : batch 545 Loss: 0.01658256184928136]
[2024-04-18 14:30:34,177: INFO: deberta_initial: Training : batch 546 Loss: 0.006546288642340555]
[2024-04-18 14:30:35,082: INFO: deberta_initial: Training : batch 547 Loss: 0.04775013830749811]
[2024-04-18 14:30:35,995: INFO: deberta_initial: Training : batch 548 Loss: 0.015219406860448766]
[2024-04-18 14:30:36,902: INFO: deberta_initial: Training : batch 549 Loss: 0.00451587002751328]
[2024-04-18 14:30:37,811: INFO: deberta_initial: Training : batch 550 Loss: 0.004980675456827829]
[2024-04-18 14:30:38,716: INFO: deberta_initial: Training : batch 551 Loss: 0.02201051044015202]
[2024-04-18 14:30:39,625: INFO: deberta_initial: Training : batch 552 Loss: 0.03004354428263337]
[2024-04-18 14:30:40,533: INFO: deberta_initial: Training : batch 553 Loss: 0.026488657848724378]
[2024-04-18 14:30:41,429: INFO: deberta_initial: Training : batch 554 Loss: 0.020522183633337774]
[2024-04-18 14:30:42,341: INFO: deberta_initial: Training : batch 555 Loss: 0.010545154926464333]
[2024-04-18 14:30:43,249: INFO: deberta_initial: Training : batch 556 Loss: 0.02298753901781196]
[2024-04-18 14:30:44,158: INFO: deberta_initial: Training : batch 557 Loss: 0.027444173117947678]
[2024-04-18 14:30:45,066: INFO: deberta_initial: Training : batch 558 Loss: 0.00697597411025193]
[2024-04-18 14:30:45,980: INFO: deberta_initial: Training : batch 559 Loss: 0.02082823008280998]
[2024-04-18 14:30:46,889: INFO: deberta_initial: Training : batch 560 Loss: 0.008752114383104848]
[2024-04-18 14:30:47,796: INFO: deberta_initial: Training : batch 561 Loss: 0.008044506949741362]
[2024-04-18 14:30:48,708: INFO: deberta_initial: Training : batch 562 Loss: 0.006989211668838068]
[2024-04-18 14:30:49,618: INFO: deberta_initial: Training : batch 563 Loss: 0.021480062909984023]
[2024-04-18 14:30:50,529: INFO: deberta_initial: Training : batch 564 Loss: 0.021422362425687468]
[2024-04-18 14:30:51,438: INFO: deberta_initial: Training : batch 565 Loss: 0.040370812347604125]
[2024-04-18 14:30:52,347: INFO: deberta_initial: Training : batch 566 Loss: 0.0032857893966754224]
[2024-04-18 14:30:53,244: INFO: deberta_initial: Training : batch 567 Loss: 0.005815630691824551]
[2024-04-18 14:30:54,155: INFO: deberta_initial: Training : batch 568 Loss: 0.021828869193114702]
[2024-04-18 14:30:55,066: INFO: deberta_initial: Training : batch 569 Loss: 0.05318012435672083]
[2024-04-18 14:30:55,978: INFO: deberta_initial: Training : batch 570 Loss: 0.011018897848264337]
[2024-04-18 14:30:56,888: INFO: deberta_initial: Training : batch 571 Loss: 0.0379343970537226]
[2024-04-18 14:30:57,787: INFO: deberta_initial: Training : batch 572 Loss: 0.011905069139166283]
[2024-04-18 14:30:58,695: INFO: deberta_initial: Training : batch 573 Loss: 0.03084771909063497]
[2024-04-18 14:30:59,607: INFO: deberta_initial: Training : batch 574 Loss: 0.006360528199129068]
[2024-04-18 14:31:00,519: INFO: deberta_initial: Training : batch 575 Loss: 0.012057778920787441]
[2024-04-18 14:31:01,435: INFO: deberta_initial: Training : batch 576 Loss: 0.011777169122919623]
[2024-04-18 14:31:02,344: INFO: deberta_initial: Training : batch 577 Loss: 0.019396962591950423]
[2024-04-18 14:31:03,256: INFO: deberta_initial: Training : batch 578 Loss: 0.022787171046625126]
[2024-04-18 14:31:04,165: INFO: deberta_initial: Training : batch 579 Loss: 0.008772402571837845]
[2024-04-18 14:31:05,077: INFO: deberta_initial: Training : batch 580 Loss: 0.006400368832771807]
[2024-04-18 14:31:05,988: INFO: deberta_initial: Training : batch 581 Loss: 0.007659420446474777]
[2024-04-18 14:31:06,883: INFO: deberta_initial: Training : batch 582 Loss: 0.00555264499888925]
[2024-04-18 14:31:07,793: INFO: deberta_initial: Training : batch 583 Loss: 0.018049457830548284]
[2024-04-18 14:31:08,707: INFO: deberta_initial: Training : batch 584 Loss: 0.00524476483927618]
[2024-04-18 14:31:09,619: INFO: deberta_initial: Training : batch 585 Loss: 0.04337293007261061]
[2024-04-18 14:31:10,528: INFO: deberta_initial: Training : batch 586 Loss: 0.028658222329290765]
[2024-04-18 14:31:11,430: INFO: deberta_initial: Training : batch 587 Loss: 0.019708108554489116]
[2024-04-18 14:31:12,332: INFO: deberta_initial: Training : batch 588 Loss: 0.030485504318352702]
[2024-04-18 14:31:13,246: INFO: deberta_initial: Training : batch 589 Loss: 0.01762508047098622]
[2024-04-18 14:31:14,157: INFO: deberta_initial: Training : batch 590 Loss: 0.008623739818930788]
[2024-04-18 14:31:15,067: INFO: deberta_initial: Training : batch 591 Loss: 0.01285053639646128]
[2024-04-18 14:31:15,975: INFO: deberta_initial: Training : batch 592 Loss: 0.016755538109088818]
[2024-04-18 14:31:16,884: INFO: deberta_initial: Training : batch 593 Loss: 0.009356391541634642]
[2024-04-18 14:31:17,796: INFO: deberta_initial: Training : batch 594 Loss: 0.006365440498142283]
[2024-04-18 14:31:18,706: INFO: deberta_initial: Training : batch 595 Loss: 0.0076413943104110945]
[2024-04-18 14:31:19,617: INFO: deberta_initial: Training : batch 596 Loss: 0.010967341838147727]
[2024-04-18 14:31:20,509: INFO: deberta_initial: Training : batch 597 Loss: 0.0189625947259879]
[2024-04-18 14:31:21,419: INFO: deberta_initial: Training : batch 598 Loss: 0.009451879127895088]
[2024-04-18 14:31:22,329: INFO: deberta_initial: Training : batch 599 Loss: 0.03471179762971534]
[2024-04-18 14:31:23,241: INFO: deberta_initial: Training : batch 600 Loss: 0.01529762288246996]
[2024-04-18 14:31:24,153: INFO: deberta_initial: Training : batch 601 Loss: 0.02308667368848832]
[2024-04-18 14:31:25,062: INFO: deberta_initial: Training : batch 602 Loss: 0.007049764864379771]
[2024-04-18 14:31:25,974: INFO: deberta_initial: Training : batch 603 Loss: 0.019073664811539867]
[2024-04-18 14:31:26,886: INFO: deberta_initial: Training : batch 604 Loss: 0.007941290325410823]
[2024-04-18 14:31:27,793: INFO: deberta_initial: Training : batch 605 Loss: 0.013963838857001068]
[2024-04-18 14:31:28,704: INFO: deberta_initial: Training : batch 606 Loss: 0.005331025513281811]
[2024-04-18 14:31:29,613: INFO: deberta_initial: Training : batch 607 Loss: 0.016893301263112274]
[2024-04-18 14:31:30,529: INFO: deberta_initial: Training : batch 608 Loss: 0.01307891279716608]
[2024-04-18 14:31:31,440: INFO: deberta_initial: Training : batch 609 Loss: 0.014677406140819695]
[2024-04-18 14:31:32,347: INFO: deberta_initial: Training : batch 610 Loss: 0.011133708650136315]
[2024-04-18 14:31:33,254: INFO: deberta_initial: Training : batch 611 Loss: 0.013955079790571213]
[2024-04-18 14:31:34,164: INFO: deberta_initial: Training : batch 612 Loss: 0.00765623049361525]
[2024-04-18 14:31:35,073: INFO: deberta_initial: Training : batch 613 Loss: 0.012836745286466764]
[2024-04-18 14:31:35,984: INFO: deberta_initial: Training : batch 614 Loss: 0.00944057950673923]
[2024-04-18 14:31:36,894: INFO: deberta_initial: Training : batch 615 Loss: 0.012232730063992916]
[2024-04-18 14:31:37,804: INFO: deberta_initial: Training : batch 616 Loss: 0.04392323077790597]
[2024-04-18 14:31:38,715: INFO: deberta_initial: Training : batch 617 Loss: 0.03758158838107757]
[2024-04-18 14:31:39,629: INFO: deberta_initial: Training : batch 618 Loss: 0.009772196015928929]
[2024-04-18 14:31:40,540: INFO: deberta_initial: Training : batch 619 Loss: 0.018294745100896643]
[2024-04-18 14:31:41,452: INFO: deberta_initial: Training : batch 620 Loss: 0.012765887037798428]
[2024-04-18 14:31:42,362: INFO: deberta_initial: Training : batch 621 Loss: 0.03919903578995789]
[2024-04-18 14:31:43,276: INFO: deberta_initial: Training : batch 622 Loss: 0.024997943614007572]
[2024-04-18 14:31:44,189: INFO: deberta_initial: Training : batch 623 Loss: 0.014646786783068248]
[2024-04-18 14:31:45,093: INFO: deberta_initial: Training : batch 624 Loss: 0.01577889923868964]
[2024-04-18 14:31:46,005: INFO: deberta_initial: Training : batch 625 Loss: 0.01896582385704674]
[2024-04-18 14:31:46,919: INFO: deberta_initial: Training : batch 626 Loss: 0.004193158940504792]
[2024-04-18 14:31:47,830: INFO: deberta_initial: Training : batch 627 Loss: 0.0035952990396507906]
[2024-04-18 14:31:48,733: INFO: deberta_initial: Training : batch 628 Loss: 0.010998482837414891]
[2024-04-18 14:31:49,639: INFO: deberta_initial: Training : batch 629 Loss: 0.016024890765362062]
[2024-04-18 14:31:50,549: INFO: deberta_initial: Training : batch 630 Loss: 0.0029937710831004077]
[2024-04-18 14:31:51,461: INFO: deberta_initial: Training : batch 631 Loss: 0.007933925642839255]
[2024-04-18 14:31:52,384: INFO: deberta_initial: Training : batch 632 Loss: 0.015344583862785859]
[2024-04-18 14:31:53,299: INFO: deberta_initial: Training : batch 633 Loss: 0.05060567050770283]
[2024-04-18 14:31:54,215: INFO: deberta_initial: Training : batch 634 Loss: 0.01186395036283896]
[2024-04-18 14:31:55,126: INFO: deberta_initial: Training : batch 635 Loss: 0.007165862168457665]
[2024-04-18 14:31:56,036: INFO: deberta_initial: Training : batch 636 Loss: 0.043058862377559334]
[2024-04-18 14:31:56,947: INFO: deberta_initial: Training : batch 637 Loss: 0.007799535500931402]
[2024-04-18 14:31:57,857: INFO: deberta_initial: Training : batch 638 Loss: 0.02604236316364881]
[2024-04-18 14:31:58,768: INFO: deberta_initial: Training : batch 639 Loss: 0.015961281550467794]
[2024-04-18 14:31:59,678: INFO: deberta_initial: Training : batch 640 Loss: 0.02381448883667906]
[2024-04-18 14:32:00,588: INFO: deberta_initial: Training : batch 641 Loss: 0.019819585012673762]
[2024-04-18 14:32:01,487: INFO: deberta_initial: Training : batch 642 Loss: 0.023363076444745338]
[2024-04-18 14:32:02,395: INFO: deberta_initial: Training : batch 643 Loss: 0.023309616795495213]
[2024-04-18 14:32:03,306: INFO: deberta_initial: Training : batch 644 Loss: 0.015268452232726246]
[2024-04-18 14:32:04,218: INFO: deberta_initial: Training : batch 645 Loss: 0.020795823151316156]
[2024-04-18 14:32:05,129: INFO: deberta_initial: Training : batch 646 Loss: 0.029346879256028736]
[2024-04-18 14:32:06,043: INFO: deberta_initial: Training : batch 647 Loss: 0.027036185452328273]
[2024-04-18 14:32:06,955: INFO: deberta_initial: Training : batch 648 Loss: 0.017579670306020468]
[2024-04-18 14:32:07,867: INFO: deberta_initial: Training : batch 649 Loss: 0.0027607091576824713]
[2024-04-18 14:32:08,772: INFO: deberta_initial: Training : batch 650 Loss: 0.006739957548412728]
[2024-04-18 14:32:09,684: INFO: deberta_initial: Training : batch 651 Loss: 0.02185075473313404]
[2024-04-18 14:32:10,595: INFO: deberta_initial: Training : batch 652 Loss: 0.018143701609056213]
[2024-04-18 14:32:11,508: INFO: deberta_initial: Training : batch 653 Loss: 0.018122811657053668]
[2024-04-18 14:32:12,419: INFO: deberta_initial: Training : batch 654 Loss: 0.016627412266898234]
[2024-04-18 14:32:13,329: INFO: deberta_initial: Training : batch 655 Loss: 0.01075999820207269]
[2024-04-18 14:32:14,240: INFO: deberta_initial: Training : batch 656 Loss: 0.004606374265502456]
[2024-04-18 14:32:15,151: INFO: deberta_initial: Training : batch 657 Loss: 0.007488066573122804]
[2024-04-18 14:32:16,060: INFO: deberta_initial: Training : batch 658 Loss: 0.0039540106607635]
[2024-04-18 14:32:16,968: INFO: deberta_initial: Training : batch 659 Loss: 0.011194377204909104]
[2024-04-18 14:32:17,864: INFO: deberta_initial: Training : batch 660 Loss: 0.026750431857983037]
[2024-04-18 14:32:18,775: INFO: deberta_initial: Training : batch 661 Loss: 0.02276126108148496]
[2024-04-18 14:32:19,695: INFO: deberta_initial: Training : batch 662 Loss: 0.025618473865345503]
[2024-04-18 14:32:20,593: INFO: deberta_initial: Training : batch 663 Loss: 0.007940318463440761]
[2024-04-18 14:32:21,503: INFO: deberta_initial: Training : batch 664 Loss: 0.014514688715568524]
[2024-04-18 14:32:22,412: INFO: deberta_initial: Training : batch 665 Loss: 0.03342370906138501]
[2024-04-18 14:32:23,307: INFO: deberta_initial: Training : batch 666 Loss: 0.007890959133451579]
[2024-04-18 14:32:24,216: INFO: deberta_initial: Training : batch 667 Loss: 0.03460273652969959]
[2024-04-18 14:32:25,126: INFO: deberta_initial: Training : batch 668 Loss: 0.01284715193464424]
[2024-04-18 14:32:26,035: INFO: deberta_initial: Training : batch 669 Loss: 0.012521198215221716]
[2024-04-18 14:32:26,932: INFO: deberta_initial: Training : batch 670 Loss: 0.006121447436141177]
[2024-04-18 14:32:27,840: INFO: deberta_initial: Training : batch 671 Loss: 0.0034102087955255834]
[2024-04-18 14:32:28,748: INFO: deberta_initial: Training : batch 672 Loss: 0.013573557307412328]
[2024-04-18 14:32:29,646: INFO: deberta_initial: Training : batch 673 Loss: 0.018169133945989683]
[2024-04-18 14:32:30,553: INFO: deberta_initial: Training : batch 674 Loss: 0.01615379026745692]
[2024-04-18 14:32:31,472: INFO: deberta_initial: Training : batch 675 Loss: 0.028142370449988335]
[2024-04-18 14:32:32,393: INFO: deberta_initial: Training : batch 676 Loss: 0.004513178610896]
[2024-04-18 14:32:33,303: INFO: deberta_initial: Training : batch 677 Loss: 0.018770143068170157]
[2024-04-18 14:32:34,214: INFO: deberta_initial: Training : batch 678 Loss: 0.017140947117636602]
[2024-04-18 14:32:35,124: INFO: deberta_initial: Training : batch 679 Loss: 0.026116661811306594]
[2024-04-18 14:32:36,034: INFO: deberta_initial: Training : batch 680 Loss: 0.041771276736031294]
[2024-04-18 14:32:36,945: INFO: deberta_initial: Training : batch 681 Loss: 0.030990051335030393]
[2024-04-18 14:32:37,854: INFO: deberta_initial: Training : batch 682 Loss: 0.0051148529379414324]
[2024-04-18 14:32:38,767: INFO: deberta_initial: Training : batch 683 Loss: 0.007247465441059368]
[2024-04-18 14:32:39,677: INFO: deberta_initial: Training : batch 684 Loss: 0.012552298294528176]
[2024-04-18 14:32:40,588: INFO: deberta_initial: Training : batch 685 Loss: 0.013503642709622907]
[2024-04-18 14:32:41,500: INFO: deberta_initial: Training : batch 686 Loss: 0.004628916433456343]
[2024-04-18 14:32:42,409: INFO: deberta_initial: Training : batch 687 Loss: 0.013367368866407351]
[2024-04-18 14:32:43,318: INFO: deberta_initial: Training : batch 688 Loss: 0.04341023358727123]
[2024-04-18 14:32:44,226: INFO: deberta_initial: Training : batch 689 Loss: 0.006246692073786969]
[2024-04-18 14:32:45,143: INFO: deberta_initial: Training : batch 690 Loss: 0.0132694483379656]
[2024-04-18 14:32:46,051: INFO: deberta_initial: Training : batch 691 Loss: 0.0037816306048255957]
[2024-04-18 14:32:46,963: INFO: deberta_initial: Training : batch 692 Loss: 0.019685885865962805]
[2024-04-18 14:32:47,872: INFO: deberta_initial: Training : batch 693 Loss: 0.010842944099936932]
[2024-04-18 14:32:48,782: INFO: deberta_initial: Training : batch 694 Loss: 0.007568869631616088]
[2024-04-18 14:32:49,674: INFO: deberta_initial: Training : batch 695 Loss: 0.0037365559093245643]
[2024-04-18 14:32:50,581: INFO: deberta_initial: Training : batch 696 Loss: 0.04524493259619377]
[2024-04-18 14:32:51,491: INFO: deberta_initial: Training : batch 697 Loss: 0.016612537195226897]
[2024-04-18 14:32:52,401: INFO: deberta_initial: Training : batch 698 Loss: 0.01016677668708715]
[2024-04-18 14:32:53,303: INFO: deberta_initial: Training : batch 699 Loss: 0.006306157130845569]
[2024-04-18 14:32:54,203: INFO: deberta_initial: Training : batch 700 Loss: 0.008251993024668221]
[2024-04-18 14:32:55,113: INFO: deberta_initial: Training : batch 701 Loss: 0.008090326372099853]
[2024-04-18 14:32:56,023: INFO: deberta_initial: Training : batch 702 Loss: 0.0037590259095732397]
[2024-04-18 14:32:56,933: INFO: deberta_initial: Training : batch 703 Loss: 0.013434363012611913]
[2024-04-18 14:32:57,847: INFO: deberta_initial: Training : batch 704 Loss: 0.009641971958287714]
[2024-04-18 14:32:58,767: INFO: deberta_initial: Training : batch 705 Loss: 0.027398898911853983]
[2024-04-18 14:32:59,689: INFO: deberta_initial: Training : batch 706 Loss: 0.005549004261689264]
[2024-04-18 14:33:00,615: INFO: deberta_initial: Training : batch 707 Loss: 0.009260047332165792]
[2024-04-18 14:33:01,538: INFO: deberta_initial: Training : batch 708 Loss: 0.010597706952282845]
[2024-04-18 14:33:02,458: INFO: deberta_initial: Training : batch 709 Loss: 0.012699607401538986]
[2024-04-18 14:33:03,367: INFO: deberta_initial: Training : batch 710 Loss: 0.03804629227738793]
[2024-04-18 14:33:04,276: INFO: deberta_initial: Training : batch 711 Loss: 0.010100189231988637]
[2024-04-18 14:33:05,186: INFO: deberta_initial: Training : batch 712 Loss: 0.018596867421137954]
[2024-04-18 14:33:06,097: INFO: deberta_initial: Training : batch 713 Loss: 0.029494491184297714]
[2024-04-18 14:33:07,011: INFO: deberta_initial: Training : batch 714 Loss: 0.03521899220015724]
[2024-04-18 14:33:07,918: INFO: deberta_initial: Training : batch 715 Loss: 0.025226919322638753]
[2024-04-18 14:33:08,817: INFO: deberta_initial: Training : batch 716 Loss: 0.0374646313537158]
[2024-04-18 14:33:09,725: INFO: deberta_initial: Training : batch 717 Loss: 0.015116021932578353]
[2024-04-18 14:33:10,637: INFO: deberta_initial: Training : batch 718 Loss: 0.018144064044876538]
[2024-04-18 14:33:11,542: INFO: deberta_initial: Training : batch 719 Loss: 0.015107127754034515]
[2024-04-18 14:33:12,440: INFO: deberta_initial: Training : batch 720 Loss: 0.021102982741729875]
[2024-04-18 14:33:13,354: INFO: deberta_initial: Training : batch 721 Loss: 0.0055726263621824895]
[2024-04-18 14:33:14,262: INFO: deberta_initial: Training : batch 722 Loss: 0.022194603817068025]
[2024-04-18 14:33:15,173: INFO: deberta_initial: Training : batch 723 Loss: 0.004884833061426176]
[2024-04-18 14:33:16,084: INFO: deberta_initial: Training : batch 724 Loss: 0.019129824564967087]
[2024-04-18 14:33:16,996: INFO: deberta_initial: Training : batch 725 Loss: 0.008520819411393555]
[2024-04-18 14:33:17,905: INFO: deberta_initial: Training : batch 726 Loss: 0.03635646351454836]
[2024-04-18 14:33:18,815: INFO: deberta_initial: Training : batch 727 Loss: 0.010341721649056317]
[2024-04-18 14:33:19,715: INFO: deberta_initial: Training : batch 728 Loss: 0.03177517260066252]
[2024-04-18 14:33:20,621: INFO: deberta_initial: Training : batch 729 Loss: 0.005993761069587926]
[2024-04-18 14:33:21,530: INFO: deberta_initial: Training : batch 730 Loss: 0.020290113107553444]
[2024-04-18 14:33:22,440: INFO: deberta_initial: Training : batch 731 Loss: 0.008234422800453799]
[2024-04-18 14:33:23,342: INFO: deberta_initial: Training : batch 732 Loss: 0.0026184822363500278]
[2024-04-18 14:33:24,246: INFO: deberta_initial: Training : batch 733 Loss: 0.019336160954786356]
[2024-04-18 14:33:25,157: INFO: deberta_initial: Training : batch 734 Loss: 0.008152770867935841]
[2024-04-18 14:33:26,067: INFO: deberta_initial: Training : batch 735 Loss: 0.03392637145923868]
[2024-04-18 14:33:26,982: INFO: deberta_initial: Training : batch 736 Loss: 0.005686539911496971]
[2024-04-18 14:33:27,894: INFO: deberta_initial: Training : batch 737 Loss: 0.010242813167184344]
[2024-04-18 14:33:28,805: INFO: deberta_initial: Training : batch 738 Loss: 0.011398015463058908]
[2024-04-18 14:33:29,715: INFO: deberta_initial: Training : batch 739 Loss: 0.01146856996567294]
[2024-04-18 14:33:30,616: INFO: deberta_initial: Training : batch 740 Loss: 0.018299075270148953]
[2024-04-18 14:33:31,527: INFO: deberta_initial: Training : batch 741 Loss: 0.00840311777414247]
[2024-04-18 14:33:32,435: INFO: deberta_initial: Training : batch 742 Loss: 0.01761951645097317]
[2024-04-18 14:33:33,344: INFO: deberta_initial: Training : batch 743 Loss: 0.03720643898057756]
[2024-04-18 14:33:34,253: INFO: deberta_initial: Training : batch 744 Loss: 0.03170155078905252]
[2024-04-18 14:33:35,152: INFO: deberta_initial: Training : batch 745 Loss: 0.018892178325051592]
[2024-04-18 14:33:36,056: INFO: deberta_initial: Training : batch 746 Loss: 0.008205815706710539]
[2024-04-18 14:33:36,965: INFO: deberta_initial: Training : batch 747 Loss: 0.008784098739172505]
[2024-04-18 14:33:37,875: INFO: deberta_initial: Training : batch 748 Loss: 0.01850962383848821]
[2024-04-18 14:33:38,786: INFO: deberta_initial: Training : batch 749 Loss: 0.010203338816262198]
[2024-04-18 14:33:39,702: INFO: deberta_initial: Training : batch 750 Loss: 0.041016295846901314]
[2024-04-18 14:33:40,606: INFO: deberta_initial: Training : batch 751 Loss: 0.016259469049247296]
[2024-04-18 14:33:41,520: INFO: deberta_initial: Training : batch 752 Loss: 0.02206032797453414]
[2024-04-18 14:33:42,427: INFO: deberta_initial: Training : batch 753 Loss: 0.030530823568775952]
[2024-04-18 14:33:43,335: INFO: deberta_initial: Training : batch 754 Loss: 0.01965087821131841]
[2024-04-18 14:33:44,245: INFO: deberta_initial: Training : batch 755 Loss: 0.015752032040400342]
[2024-04-18 14:33:45,153: INFO: deberta_initial: Training : batch 756 Loss: 0.027966859102986675]
[2024-04-18 14:33:46,064: INFO: deberta_initial: Training : batch 757 Loss: 0.0013383429025727105]
[2024-04-18 14:33:46,975: INFO: deberta_initial: Training : batch 758 Loss: 0.008972925094344905]
[2024-04-18 14:33:47,885: INFO: deberta_initial: Training : batch 759 Loss: 0.01268941975385234]
[2024-04-18 14:33:48,794: INFO: deberta_initial: Training : batch 760 Loss: 0.010607060221484662]
[2024-04-18 14:33:49,705: INFO: deberta_initial: Training : batch 761 Loss: 0.02248153232308138]
[2024-04-18 14:33:50,611: INFO: deberta_initial: Training : batch 762 Loss: 0.03185420397552581]
[2024-04-18 14:33:51,512: INFO: deberta_initial: Training : batch 763 Loss: 0.026305373705267383]
[2024-04-18 14:33:52,434: INFO: deberta_initial: Training : batch 764 Loss: 0.04185432843743053]
[2024-04-18 14:33:53,348: INFO: deberta_initial: Training : batch 765 Loss: 0.023085648949341623]
[2024-04-18 14:33:54,263: INFO: deberta_initial: Training : batch 766 Loss: 0.020518582472809622]
[2024-04-18 14:33:55,184: INFO: deberta_initial: Training : batch 767 Loss: 0.01541331256360625]
[2024-04-18 14:33:56,100: INFO: deberta_initial: Training : batch 768 Loss: 0.019992456069227473]
[2024-04-18 14:33:56,998: INFO: deberta_initial: Training : batch 769 Loss: 0.006961990714128396]
[2024-04-18 14:33:57,907: INFO: deberta_initial: Training : batch 770 Loss: 0.02716751388448981]
[2024-04-18 14:33:58,817: INFO: deberta_initial: Training : batch 771 Loss: 0.010237979102542892]
[2024-04-18 14:33:59,724: INFO: deberta_initial: Training : batch 772 Loss: 0.009231736875431525]
[2024-04-18 14:34:00,635: INFO: deberta_initial: Training : batch 773 Loss: 0.01564923208114256]
[2024-04-18 14:34:01,543: INFO: deberta_initial: Training : batch 774 Loss: 0.016588896749771292]
[2024-04-18 14:34:02,445: INFO: deberta_initial: Training : batch 775 Loss: 0.020373086368131805]
[2024-04-18 14:34:03,360: INFO: deberta_initial: Training : batch 776 Loss: 0.0040380780567770965]
[2024-04-18 14:34:04,275: INFO: deberta_initial: Training : batch 777 Loss: 0.008205023842373938]
[2024-04-18 14:34:05,184: INFO: deberta_initial: Training : batch 778 Loss: 0.006167280965580923]
[2024-04-18 14:34:06,101: INFO: deberta_initial: Training : batch 779 Loss: 0.011177588388561066]
[2024-04-18 14:34:07,015: INFO: deberta_initial: Training : batch 780 Loss: 0.01487943620888729]
[2024-04-18 14:34:07,922: INFO: deberta_initial: Training : batch 781 Loss: 0.007782424455455043]
[2024-04-18 14:34:08,832: INFO: deberta_initial: Training : batch 782 Loss: 0.003722710651552254]
[2024-04-18 14:34:09,739: INFO: deberta_initial: Training : batch 783 Loss: 0.025459086744984975]
[2024-04-18 14:34:10,651: INFO: deberta_initial: Training : batch 784 Loss: 0.02298302171930016]
[2024-04-18 14:34:11,565: INFO: deberta_initial: Training : batch 785 Loss: 0.004567971401833242]
[2024-04-18 14:34:12,477: INFO: deberta_initial: Training : batch 786 Loss: 0.010435975593439388]
[2024-04-18 14:34:13,384: INFO: deberta_initial: Training : batch 787 Loss: 0.02743572323490051]
[2024-04-18 14:34:14,293: INFO: deberta_initial: Training : batch 788 Loss: 0.01279866238697905]
[2024-04-18 14:34:15,204: INFO: deberta_initial: Training : batch 789 Loss: 0.005562633300277052]
[2024-04-18 14:34:16,113: INFO: deberta_initial: Training : batch 790 Loss: 0.009570896705209057]
[2024-04-18 14:34:17,025: INFO: deberta_initial: Training : batch 791 Loss: 0.044581516052310304]
[2024-04-18 14:34:17,938: INFO: deberta_initial: Training : batch 792 Loss: 0.01776130813921134]
[2024-04-18 14:34:18,852: INFO: deberta_initial: Training : batch 793 Loss: 0.01912338283960055]
[2024-04-18 14:34:19,766: INFO: deberta_initial: Training : batch 794 Loss: 0.02100801510648728]
[2024-04-18 14:34:20,688: INFO: deberta_initial: Training : batch 795 Loss: 0.01841430142969916]
[2024-04-18 14:34:21,604: INFO: deberta_initial: Training : batch 796 Loss: 0.0158032152123193]
[2024-04-18 14:34:22,514: INFO: deberta_initial: Training : batch 797 Loss: 0.0039408059000908355]
[2024-04-18 14:34:23,422: INFO: deberta_initial: Training : batch 798 Loss: 0.03139607556063037]
[2024-04-18 14:34:24,321: INFO: deberta_initial: Training : batch 799 Loss: 0.01252794842583667]
[2024-04-18 14:34:25,232: INFO: deberta_initial: Training : batch 800 Loss: 0.017406249270697217]
[2024-04-18 14:34:26,144: INFO: deberta_initial: Training : batch 801 Loss: 0.04173277000188322]
[2024-04-18 14:34:27,053: INFO: deberta_initial: Training : batch 802 Loss: 0.029409114543566667]
[2024-04-18 14:34:27,967: INFO: deberta_initial: Training : batch 803 Loss: 0.01563653336463446]
[2024-04-18 14:34:28,877: INFO: deberta_initial: Training : batch 804 Loss: 0.014131798279515415]
[2024-04-18 14:34:29,791: INFO: deberta_initial: Training : batch 805 Loss: 0.020378277074515384]
[2024-04-18 14:34:30,704: INFO: deberta_initial: Training : batch 806 Loss: 0.0027838030624908468]
[2024-04-18 14:34:31,615: INFO: deberta_initial: Training : batch 807 Loss: 0.009117665663520748]
[2024-04-18 14:34:32,530: INFO: deberta_initial: Training : batch 808 Loss: 0.008765472123724659]
[2024-04-18 14:34:33,444: INFO: deberta_initial: Training : batch 809 Loss: 0.015206723727313055]
[2024-04-18 14:34:34,360: INFO: deberta_initial: Training : batch 810 Loss: 0.011501344193500277]
[2024-04-18 14:34:35,271: INFO: deberta_initial: Training : batch 811 Loss: 0.004391965355781241]
[2024-04-18 14:34:36,182: INFO: deberta_initial: Training : batch 812 Loss: 0.052295520225406004]
[2024-04-18 14:34:37,078: INFO: deberta_initial: Training : batch 813 Loss: 0.005306314348831259]
[2024-04-18 14:34:37,990: INFO: deberta_initial: Training : batch 814 Loss: 0.0036290956580045317]
[2024-04-18 14:34:38,903: INFO: deberta_initial: Training : batch 815 Loss: 0.03588617129352816]
[2024-04-18 14:34:39,809: INFO: deberta_initial: Training : batch 816 Loss: 0.008421076370955339]
[2024-04-18 14:34:40,718: INFO: deberta_initial: Training : batch 817 Loss: 0.00764569021180438]
[2024-04-18 14:34:41,629: INFO: deberta_initial: Training : batch 818 Loss: 0.03629930089355312]
[2024-04-18 14:34:42,539: INFO: deberta_initial: Training : batch 819 Loss: 0.007442945237637243]
[2024-04-18 14:34:43,451: INFO: deberta_initial: Training : batch 820 Loss: 0.009657176857902808]
[2024-04-18 14:34:44,360: INFO: deberta_initial: Training : batch 821 Loss: 0.007512623186688415]
[2024-04-18 14:34:45,274: INFO: deberta_initial: Training : batch 822 Loss: 0.010361786214474629]
[2024-04-18 14:34:46,183: INFO: deberta_initial: Training : batch 823 Loss: 0.007405490145436875]
[2024-04-18 14:34:47,093: INFO: deberta_initial: Training : batch 824 Loss: 0.012459775242596418]
[2024-04-18 14:34:48,004: INFO: deberta_initial: Training : batch 825 Loss: 0.02707931862225558]
[2024-04-18 14:34:48,914: INFO: deberta_initial: Training : batch 826 Loss: 0.0459467119417058]
[2024-04-18 14:34:49,824: INFO: deberta_initial: Training : batch 827 Loss: 0.005574258737831058]
[2024-04-18 14:34:50,737: INFO: deberta_initial: Training : batch 828 Loss: 0.05784709105058494]
[2024-04-18 14:34:51,645: INFO: deberta_initial: Training : batch 829 Loss: 0.00392876957389543]
[2024-04-18 14:34:52,560: INFO: deberta_initial: Training : batch 830 Loss: 0.008411390690431371]
[2024-04-18 14:34:53,466: INFO: deberta_initial: Training : batch 831 Loss: 0.022750025542943968]
[2024-04-18 14:34:54,378: INFO: deberta_initial: Training : batch 832 Loss: 0.015763655498043875]
[2024-04-18 14:34:55,285: INFO: deberta_initial: Training : batch 833 Loss: 0.03285271914344294]
[2024-04-18 14:34:56,196: INFO: deberta_initial: Training : batch 834 Loss: 0.015852932077139278]
[2024-04-18 14:34:57,106: INFO: deberta_initial: Training : batch 835 Loss: 0.006543583266366425]
[2024-04-18 14:34:58,016: INFO: deberta_initial: Training : batch 836 Loss: 0.02032577499178213]
[2024-04-18 14:34:58,932: INFO: deberta_initial: Training : batch 837 Loss: 0.0033862398234083503]
[2024-04-18 14:34:59,839: INFO: deberta_initial: Training : batch 838 Loss: 0.031428918311453294]
[2024-04-18 14:35:00,748: INFO: deberta_initial: Training : batch 839 Loss: 0.006855607805605464]
[2024-04-18 14:35:01,659: INFO: deberta_initial: Training : batch 840 Loss: 0.012803954326357982]
[2024-04-18 14:35:02,569: INFO: deberta_initial: Training : batch 841 Loss: 0.004069146120011546]
[2024-04-18 14:35:03,480: INFO: deberta_initial: Training : batch 842 Loss: 0.012240348893376087]
[2024-04-18 14:35:04,388: INFO: deberta_initial: Training : batch 843 Loss: 0.036138377768120886]
[2024-04-18 14:35:05,293: INFO: deberta_initial: Training : batch 844 Loss: 0.004844448647607351]
[2024-04-18 14:35:06,196: INFO: deberta_initial: Training : batch 845 Loss: 0.015435285626889814]
[2024-04-18 14:35:07,103: INFO: deberta_initial: Training : batch 846 Loss: 0.03404467933803464]
[2024-04-18 14:35:08,012: INFO: deberta_initial: Training : batch 847 Loss: 0.018008485517513505]
[2024-04-18 14:35:08,921: INFO: deberta_initial: Training : batch 848 Loss: 0.012492343373814102]
[2024-04-18 14:35:09,832: INFO: deberta_initial: Training : batch 849 Loss: 0.011339424706668825]
[2024-04-18 14:35:10,742: INFO: deberta_initial: Training : batch 850 Loss: 0.01299773064227882]
[2024-04-18 14:35:11,657: INFO: deberta_initial: Training : batch 851 Loss: 0.027938856716894278]
[2024-04-18 14:35:12,566: INFO: deberta_initial: Training : batch 852 Loss: 0.009077032322218181]
[2024-04-18 14:35:13,476: INFO: deberta_initial: Training : batch 853 Loss: 0.015493857210045406]
[2024-04-18 14:35:14,396: INFO: deberta_initial: Training : batch 854 Loss: 0.01485204309540763]
[2024-04-18 14:35:15,297: INFO: deberta_initial: Training : batch 855 Loss: 0.01515292326484645]
[2024-04-18 14:35:16,205: INFO: deberta_initial: Training : batch 856 Loss: 0.02806852180478673]
[2024-04-18 14:35:17,117: INFO: deberta_initial: Training : batch 857 Loss: 0.01728699171911121]
[2024-04-18 14:35:18,026: INFO: deberta_initial: Training : batch 858 Loss: 0.006471696933926368]
[2024-04-18 14:35:18,931: INFO: deberta_initial: Training : batch 859 Loss: 0.001963526666230582]
[2024-04-18 14:35:19,836: INFO: deberta_initial: Training : batch 860 Loss: 0.016081692517584765]
[2024-04-18 14:35:20,738: INFO: deberta_initial: Training : batch 861 Loss: 0.017765955382360324]
[2024-04-18 14:35:21,646: INFO: deberta_initial: Training : batch 862 Loss: 0.009440846047173924]
[2024-04-18 14:35:22,546: INFO: deberta_initial: Training : batch 863 Loss: 0.04879099211690284]
[2024-04-18 14:35:23,454: INFO: deberta_initial: Training : batch 864 Loss: 0.02504745050788716]
[2024-04-18 14:35:24,363: INFO: deberta_initial: Training : batch 865 Loss: 0.009079506436081304]
[2024-04-18 14:35:25,282: INFO: deberta_initial: Training : batch 866 Loss: 0.059745510173282286]
[2024-04-18 14:35:26,190: INFO: deberta_initial: Training : batch 867 Loss: 0.0062331075974699675]
[2024-04-18 14:35:27,104: INFO: deberta_initial: Training : batch 868 Loss: 0.02557380994218693]
[2024-04-18 14:35:28,012: INFO: deberta_initial: Training : batch 869 Loss: 0.01085313523682334]
[2024-04-18 14:35:28,919: INFO: deberta_initial: Training : batch 870 Loss: 0.008346844172003121]
[2024-04-18 14:35:29,833: INFO: deberta_initial: Training : batch 871 Loss: 0.01643194513361155]
[2024-04-18 14:35:30,741: INFO: deberta_initial: Training : batch 872 Loss: 0.010533057480404062]
[2024-04-18 14:35:31,652: INFO: deberta_initial: Training : batch 873 Loss: 0.015593101688539703]
[2024-04-18 14:35:32,564: INFO: deberta_initial: Training : batch 874 Loss: 0.02630577631055869]
[2024-04-18 14:35:33,459: INFO: deberta_initial: Training : batch 875 Loss: 0.018540823041169767]
[2024-04-18 14:35:34,372: INFO: deberta_initial: Training : batch 876 Loss: 0.013135938952750883]
[2024-04-18 14:35:35,281: INFO: deberta_initial: Training : batch 877 Loss: 0.008322967384047511]
[2024-04-18 14:35:36,193: INFO: deberta_initial: Training : batch 878 Loss: 0.018685047746547816]
[2024-04-18 14:35:37,108: INFO: deberta_initial: Training : batch 879 Loss: 0.011305013933148332]
[2024-04-18 14:35:38,018: INFO: deberta_initial: Training : batch 880 Loss: 0.018254491238112763]
[2024-04-18 14:35:38,933: INFO: deberta_initial: Training : batch 881 Loss: 0.03051640418634221]
[2024-04-18 14:35:39,839: INFO: deberta_initial: Training : batch 882 Loss: 0.01630920432517839]
[2024-04-18 14:35:40,751: INFO: deberta_initial: Training : batch 883 Loss: 0.030926436153354504]
[2024-04-18 14:35:41,661: INFO: deberta_initial: Training : batch 884 Loss: 0.01099238945243374]
[2024-04-18 14:35:42,568: INFO: deberta_initial: Training : batch 885 Loss: 0.014061146629848798]
[2024-04-18 14:35:43,480: INFO: deberta_initial: Training : batch 886 Loss: 0.008523875190047846]
[2024-04-18 14:35:44,387: INFO: deberta_initial: Training : batch 887 Loss: 0.013101317239533488]
[2024-04-18 14:35:45,295: INFO: deberta_initial: Training : batch 888 Loss: 0.008107216510365327]
[2024-04-18 14:35:46,194: INFO: deberta_initial: Training : batch 889 Loss: 0.0057928974915004055]
[2024-04-18 14:35:47,103: INFO: deberta_initial: Training : batch 890 Loss: 0.004265983068699141]
[2024-04-18 14:35:48,009: INFO: deberta_initial: Training : batch 891 Loss: 0.01889348533894746]
[2024-04-18 14:35:48,912: INFO: deberta_initial: Training : batch 892 Loss: 0.01180727959008036]
[2024-04-18 14:35:49,814: INFO: deberta_initial: Training : batch 893 Loss: 0.00569819643351598]
[2024-04-18 14:35:50,725: INFO: deberta_initial: Training : batch 894 Loss: 0.02394797868077214]
[2024-04-18 14:35:51,647: INFO: deberta_initial: Training : batch 895 Loss: 0.017744137776552264]
[2024-04-18 14:35:52,552: INFO: deberta_initial: Training : batch 896 Loss: 0.009756382746134771]
[2024-04-18 14:35:53,474: INFO: deberta_initial: Training : batch 897 Loss: 0.012363193617538426]
[2024-04-18 14:35:54,383: INFO: deberta_initial: Training : batch 898 Loss: 0.02207859433469929]
[2024-04-18 14:35:55,294: INFO: deberta_initial: Training : batch 899 Loss: 0.02086616710878257]
[2024-04-18 14:35:56,204: INFO: deberta_initial: Training : batch 900 Loss: 0.011792541178350135]
[2024-04-18 14:35:57,115: INFO: deberta_initial: Training : batch 901 Loss: 0.005341663423697672]
[2024-04-18 14:35:58,016: INFO: deberta_initial: Training : batch 902 Loss: 0.007029631379306534]
[2024-04-18 14:35:58,918: INFO: deberta_initial: Training : batch 903 Loss: 0.015037957710806031]
[2024-04-18 14:35:59,826: INFO: deberta_initial: Training : batch 904 Loss: 0.021612193740358762]
[2024-04-18 14:36:00,734: INFO: deberta_initial: Training : batch 905 Loss: 0.0112572101002724]
[2024-04-18 14:36:01,645: INFO: deberta_initial: Training : batch 906 Loss: 0.013297548091445397]
[2024-04-18 14:36:02,538: INFO: deberta_initial: Training : batch 907 Loss: 0.005093479867440017]
[2024-04-18 14:36:03,448: INFO: deberta_initial: Training : batch 908 Loss: 0.003981646870617778]
[2024-04-18 14:36:04,361: INFO: deberta_initial: Training : batch 909 Loss: 0.014140048607544161]
[2024-04-18 14:36:05,272: INFO: deberta_initial: Training : batch 910 Loss: 0.0243581471707391]
[2024-04-18 14:36:06,178: INFO: deberta_initial: Training : batch 911 Loss: 0.025329792854278846]
[2024-04-18 14:36:07,089: INFO: deberta_initial: Training : batch 912 Loss: 0.00281258217839735]
[2024-04-18 14:36:08,000: INFO: deberta_initial: Training : batch 913 Loss: 0.00828835618642383]
[2024-04-18 14:36:08,914: INFO: deberta_initial: Training : batch 914 Loss: 0.0024847322730068306]
[2024-04-18 14:36:09,822: INFO: deberta_initial: Training : batch 915 Loss: 0.00997127730675873]
[2024-04-18 14:36:10,732: INFO: deberta_initial: Training : batch 916 Loss: 0.009641702865729502]
[2024-04-18 14:36:11,642: INFO: deberta_initial: Training : batch 917 Loss: 0.07908731976741552]
[2024-04-18 14:36:12,553: INFO: deberta_initial: Training : batch 918 Loss: 0.007452171158734569]
[2024-04-18 14:36:13,463: INFO: deberta_initial: Training : batch 919 Loss: 0.028060666490211453]
[2024-04-18 14:36:14,356: INFO: deberta_initial: Training : batch 920 Loss: 0.012099597116137997]
[2024-04-18 14:36:15,266: INFO: deberta_initial: Training : batch 921 Loss: 0.01663202653559091]
[2024-04-18 14:36:16,177: INFO: deberta_initial: Training : batch 922 Loss: 0.009439502868953314]
[2024-04-18 14:36:17,086: INFO: deberta_initial: Training : batch 923 Loss: 0.009568021154947447]
[2024-04-18 14:36:18,000: INFO: deberta_initial: Training : batch 924 Loss: 0.011581168439656698]
[2024-04-18 14:36:18,916: INFO: deberta_initial: Training : batch 925 Loss: 0.01622848587560809]
[2024-04-18 14:36:19,834: INFO: deberta_initial: Training : batch 926 Loss: 0.009492257031845903]
[2024-04-18 14:36:20,728: INFO: deberta_initial: Training : batch 927 Loss: 0.0036014321239019563]
[2024-04-18 14:36:21,639: INFO: deberta_initial: Training : batch 928 Loss: 0.0025629638484208263]
[2024-04-18 14:36:22,549: INFO: deberta_initial: Training : batch 929 Loss: 0.010665706428201797]
[2024-04-18 14:36:23,450: INFO: deberta_initial: Training : batch 930 Loss: 0.027312261632052765]
[2024-04-18 14:36:24,352: INFO: deberta_initial: Training : batch 931 Loss: 0.0025567854011470962]
[2024-04-18 14:36:25,260: INFO: deberta_initial: Training : batch 932 Loss: 0.015168604662976664]
[2024-04-18 14:36:26,169: INFO: deberta_initial: Training : batch 933 Loss: 0.01795225184688298]
[2024-04-18 14:36:27,070: INFO: deberta_initial: Training : batch 934 Loss: 0.023308275166128305]
[2024-04-18 14:36:27,976: INFO: deberta_initial: Training : batch 935 Loss: 0.01235903711005208]
[2024-04-18 14:36:28,880: INFO: deberta_initial: Training : batch 936 Loss: 0.026865109746647294]
[2024-04-18 14:36:29,790: INFO: deberta_initial: Training : batch 937 Loss: 0.0023992002860838873]
[2024-04-18 14:36:30,705: INFO: deberta_initial: Training : batch 938 Loss: 0.01122860930123526]
[2024-04-18 14:36:31,616: INFO: deberta_initial: Training : batch 939 Loss: 0.02101389274644095]
[2024-04-18 14:36:32,527: INFO: deberta_initial: Training : batch 940 Loss: 0.025277936346837428]
[2024-04-18 14:36:33,436: INFO: deberta_initial: Training : batch 941 Loss: 0.00407146577992218]
[2024-04-18 14:36:34,339: INFO: deberta_initial: Training : batch 942 Loss: 0.0021967999443887093]
[2024-04-18 14:36:35,243: INFO: deberta_initial: Training : batch 943 Loss: 0.01657292988565875]
[2024-04-18 14:36:36,153: INFO: deberta_initial: Training : batch 944 Loss: 0.015044449843715947]
[2024-04-18 14:36:37,066: INFO: deberta_initial: Training : batch 945 Loss: 0.010952767501508146]
[2024-04-18 14:36:37,977: INFO: deberta_initial: Training : batch 946 Loss: 0.003071125223472499]
[2024-04-18 14:36:38,886: INFO: deberta_initial: Training : batch 947 Loss: 0.03055702776025403]
[2024-04-18 14:36:39,797: INFO: deberta_initial: Training : batch 948 Loss: 0.013198892155858262]
[2024-04-18 14:36:40,709: INFO: deberta_initial: Training : batch 949 Loss: 0.004965237054377112]
[2024-04-18 14:36:41,616: INFO: deberta_initial: Training : batch 950 Loss: 0.006611973603866027]
[2024-04-18 14:36:42,515: INFO: deberta_initial: Training : batch 951 Loss: 0.01091730273938127]
[2024-04-18 14:36:43,420: INFO: deberta_initial: Training : batch 952 Loss: 0.004794673493668462]
[2024-04-18 14:36:44,331: INFO: deberta_initial: Training : batch 953 Loss: 0.014003793854278683]
[2024-04-18 14:36:45,245: INFO: deberta_initial: Training : batch 954 Loss: 0.01824665361126379]
[2024-04-18 14:36:46,157: INFO: deberta_initial: Training : batch 955 Loss: 0.026293053731470454]
[2024-04-18 14:36:47,069: INFO: deberta_initial: Training : batch 956 Loss: 0.003194956234953799]
[2024-04-18 14:36:47,980: INFO: deberta_initial: Training : batch 957 Loss: 0.030954285482262235]
[2024-04-18 14:36:48,889: INFO: deberta_initial: Training : batch 958 Loss: 0.009899244800148196]
[2024-04-18 14:36:49,799: INFO: deberta_initial: Training : batch 959 Loss: 0.011649210892135128]
[2024-04-18 14:36:50,706: INFO: deberta_initial: Training : batch 960 Loss: 0.016330703024618334]
[2024-04-18 14:36:51,617: INFO: deberta_initial: Training : batch 961 Loss: 0.03667842663099304]
[2024-04-18 14:36:52,520: INFO: deberta_initial: Training : batch 962 Loss: 0.026877149255453224]
[2024-04-18 14:36:53,428: INFO: deberta_initial: Training : batch 963 Loss: 0.004876181307996045]
[2024-04-18 14:36:54,329: INFO: deberta_initial: Training : batch 964 Loss: 0.026253535535999566]
[2024-04-18 14:36:55,240: INFO: deberta_initial: Training : batch 965 Loss: 0.016555651771694765]
[2024-04-18 14:36:56,150: INFO: deberta_initial: Training : batch 966 Loss: 0.009600397084494386]
[2024-04-18 14:36:57,063: INFO: deberta_initial: Training : batch 967 Loss: 0.017027540718395143]
[2024-04-18 14:36:57,970: INFO: deberta_initial: Training : batch 968 Loss: 0.021966063350208485]
[2024-04-18 14:36:58,882: INFO: deberta_initial: Training : batch 969 Loss: 0.0052016072730987255]
[2024-04-18 14:36:59,790: INFO: deberta_initial: Training : batch 970 Loss: 0.005643795665755025]
[2024-04-18 14:37:00,692: INFO: deberta_initial: Training : batch 971 Loss: 0.00900959984980869]
[2024-04-18 14:37:01,596: INFO: deberta_initial: Training : batch 972 Loss: 0.0115534709718949]
[2024-04-18 14:37:02,504: INFO: deberta_initial: Training : batch 973 Loss: 0.007475423449499812]
[2024-04-18 14:37:03,413: INFO: deberta_initial: Training : batch 974 Loss: 0.009448278213117882]
[2024-04-18 14:37:04,323: INFO: deberta_initial: Training : batch 975 Loss: 0.013053114839947474]
[2024-04-18 14:37:05,222: INFO: deberta_initial: Training : batch 976 Loss: 0.006323180941110388]
[2024-04-18 14:37:06,125: INFO: deberta_initial: Training : batch 977 Loss: 0.013741961116751689]
[2024-04-18 14:37:07,035: INFO: deberta_initial: Training : batch 978 Loss: 0.005820268135306476]
[2024-04-18 14:37:07,944: INFO: deberta_initial: Training : batch 979 Loss: 0.014553668403967823]
[2024-04-18 14:37:08,856: INFO: deberta_initial: Training : batch 980 Loss: 0.01207080168928054]
[2024-04-18 14:37:09,770: INFO: deberta_initial: Training : batch 981 Loss: 0.003424849487878568]
[2024-04-18 14:37:10,687: INFO: deberta_initial: Training : batch 982 Loss: 0.028815233530223527]
[2024-04-18 14:37:11,602: INFO: deberta_initial: Training : batch 983 Loss: 0.00869875078396491]
[2024-04-18 14:37:12,516: INFO: deberta_initial: Training : batch 984 Loss: 0.007103466592865677]
[2024-04-18 14:37:13,426: INFO: deberta_initial: Training : batch 985 Loss: 0.00411417970760598]
[2024-04-18 14:37:14,335: INFO: deberta_initial: Training : batch 986 Loss: 0.008554326482526119]
[2024-04-18 14:37:15,247: INFO: deberta_initial: Training : batch 987 Loss: 0.003909001612441313]
[2024-04-18 14:37:16,155: INFO: deberta_initial: Training : batch 988 Loss: 0.04035719272870988]
[2024-04-18 14:37:17,053: INFO: deberta_initial: Training : batch 989 Loss: 0.006883012322844108]
[2024-04-18 14:37:17,963: INFO: deberta_initial: Training : batch 990 Loss: 0.015707077541425724]
[2024-04-18 14:37:18,869: INFO: deberta_initial: Training : batch 991 Loss: 0.007812675468396762]
[2024-04-18 14:37:19,779: INFO: deberta_initial: Training : batch 992 Loss: 0.02130771555816961]
[2024-04-18 14:37:20,688: INFO: deberta_initial: Training : batch 993 Loss: 0.013018097583398235]
[2024-04-18 14:37:21,595: INFO: deberta_initial: Training : batch 994 Loss: 0.012954071362158976]
[2024-04-18 14:37:22,504: INFO: deberta_initial: Training : batch 995 Loss: 0.013796476624925851]
[2024-04-18 14:37:23,419: INFO: deberta_initial: Training : batch 996 Loss: 0.026216948642419795]
[2024-04-18 14:37:24,330: INFO: deberta_initial: Training : batch 997 Loss: 0.0016203895722928141]
[2024-04-18 14:37:25,246: INFO: deberta_initial: Training : batch 998 Loss: 0.018048147684866577]
[2024-04-18 14:37:26,156: INFO: deberta_initial: Training : batch 999 Loss: 0.007100064452082834]
[2024-04-18 14:37:27,064: INFO: deberta_initial: Training : batch 1000 Loss: 0.010746554577451346]
[2024-04-18 14:37:27,973: INFO: deberta_initial: Training : batch 1001 Loss: 0.003809406378240353]
[2024-04-18 14:37:28,884: INFO: deberta_initial: Training : batch 1002 Loss: 0.049624168504344875]
[2024-04-18 14:37:29,788: INFO: deberta_initial: Training : batch 1003 Loss: 0.007487382906147427]
[2024-04-18 14:37:30,698: INFO: deberta_initial: Training : batch 1004 Loss: 0.0037631921833086103]
[2024-04-18 14:37:31,608: INFO: deberta_initial: Training : batch 1005 Loss: 0.019640471258842718]
[2024-04-18 14:37:32,515: INFO: deberta_initial: Training : batch 1006 Loss: 0.013470919327173104]
[2024-04-18 14:37:33,410: INFO: deberta_initial: Training : batch 1007 Loss: 0.020701149545666642]
[2024-04-18 14:37:34,323: INFO: deberta_initial: Training : batch 1008 Loss: 0.02772462979507543]
[2024-04-18 14:37:35,235: INFO: deberta_initial: Training : batch 1009 Loss: 0.011542175908987297]
[2024-04-18 14:37:36,164: INFO: deberta_initial: Training : batch 1010 Loss: 0.00898637460784585]
[2024-04-18 14:37:37,079: INFO: deberta_initial: Training : batch 1011 Loss: 0.005482523122542038]
[2024-04-18 14:37:37,993: INFO: deberta_initial: Training : batch 1012 Loss: 0.0027389839210411244]
[2024-04-18 14:37:38,899: INFO: deberta_initial: Training : batch 1013 Loss: 0.0064867483122095105]
[2024-04-18 14:37:39,805: INFO: deberta_initial: Training : batch 1014 Loss: 0.0076994282664358355]
[2024-04-18 14:37:40,717: INFO: deberta_initial: Training : batch 1015 Loss: 0.007782363084873859]
[2024-04-18 14:37:41,629: INFO: deberta_initial: Training : batch 1016 Loss: 0.042691665905988385]
[2024-04-18 14:37:42,540: INFO: deberta_initial: Training : batch 1017 Loss: 0.029221187059808116]
[2024-04-18 14:37:43,450: INFO: deberta_initial: Training : batch 1018 Loss: 0.0073227467977180554]
[2024-04-18 14:37:44,358: INFO: deberta_initial: Training : batch 1019 Loss: 0.0027542347831852813]
[2024-04-18 14:37:45,259: INFO: deberta_initial: Training : batch 1020 Loss: 0.006847053281019579]
[2024-04-18 14:37:46,171: INFO: deberta_initial: Training : batch 1021 Loss: 0.02101313552028599]
[2024-04-18 14:37:47,079: INFO: deberta_initial: Training : batch 1022 Loss: 0.008731953681133886]
[2024-04-18 14:37:47,992: INFO: deberta_initial: Training : batch 1023 Loss: 0.0023193498898343113]
[2024-04-18 14:37:48,900: INFO: deberta_initial: Training : batch 1024 Loss: 0.016310999087226066]
[2024-04-18 14:37:49,816: INFO: deberta_initial: Training : batch 1025 Loss: 0.0033892834100003114]
[2024-04-18 14:37:50,723: INFO: deberta_initial: Training : batch 1026 Loss: 0.005455323388989871]
[2024-04-18 14:37:51,634: INFO: deberta_initial: Training : batch 1027 Loss: 0.005730556793013074]
[2024-04-18 14:37:52,549: INFO: deberta_initial: Training : batch 1028 Loss: 0.01130246144934124]
[2024-04-18 14:37:53,454: INFO: deberta_initial: Training : batch 1029 Loss: 0.024752415887277113]
[2024-04-18 14:37:54,368: INFO: deberta_initial: Training : batch 1030 Loss: 0.014814850210026044]
[2024-04-18 14:37:55,286: INFO: deberta_initial: Training : batch 1031 Loss: 0.011841073777204263]
[2024-04-18 14:37:56,204: INFO: deberta_initial: Training : batch 1032 Loss: 0.011112525901792174]
[2024-04-18 14:37:57,118: INFO: deberta_initial: Training : batch 1033 Loss: 0.007342805725804141]
[2024-04-18 14:37:58,027: INFO: deberta_initial: Training : batch 1034 Loss: 0.0078619305588255]
[2024-04-18 14:37:58,938: INFO: deberta_initial: Training : batch 1035 Loss: 0.00375141829909466]
[2024-04-18 14:37:59,848: INFO: deberta_initial: Training : batch 1036 Loss: 0.015085401325385784]
[2024-04-18 14:38:00,762: INFO: deberta_initial: Training : batch 1037 Loss: 0.009065979032349326]
[2024-04-18 14:38:01,672: INFO: deberta_initial: Training : batch 1038 Loss: 0.004867760240918518]
[2024-04-18 14:38:02,583: INFO: deberta_initial: Training : batch 1039 Loss: 0.015862830254760114]
[2024-04-18 14:38:03,494: INFO: deberta_initial: Training : batch 1040 Loss: 0.006539478264239315]
[2024-04-18 14:38:04,406: INFO: deberta_initial: Training : batch 1041 Loss: 0.05487285823126926]
[2024-04-18 14:38:05,318: INFO: deberta_initial: Training : batch 1042 Loss: 0.01450286719355676]
[2024-04-18 14:38:06,222: INFO: deberta_initial: Training : batch 1043 Loss: 0.010175862104808689]
[2024-04-18 14:38:07,132: INFO: deberta_initial: Training : batch 1044 Loss: 0.005233188148589863]
[2024-04-18 14:38:08,042: INFO: deberta_initial: Training : batch 1045 Loss: 0.017223741252726757]
[2024-04-18 14:38:08,954: INFO: deberta_initial: Training : batch 1046 Loss: 0.012749622415227129]
[2024-04-18 14:38:09,865: INFO: deberta_initial: Training : batch 1047 Loss: 0.00792430433030891]
[2024-04-18 14:38:10,778: INFO: deberta_initial: Training : batch 1048 Loss: 0.006602831527419727]
[2024-04-18 14:38:11,687: INFO: deberta_initial: Training : batch 1049 Loss: 0.027260507989579543]
[2024-04-18 14:38:12,596: INFO: deberta_initial: Training : batch 1050 Loss: 0.014283264851053367]
[2024-04-18 14:38:13,504: INFO: deberta_initial: Training : batch 1051 Loss: 0.016602582067257704]
[2024-04-18 14:38:14,407: INFO: deberta_initial: Training : batch 1052 Loss: 0.007005061984969831]
[2024-04-18 14:38:15,315: INFO: deberta_initial: Training : batch 1053 Loss: 0.005145826056146372]
[2024-04-18 14:38:16,224: INFO: deberta_initial: Training : batch 1054 Loss: 0.009608174288692383]
[2024-04-18 14:38:17,136: INFO: deberta_initial: Training : batch 1055 Loss: 0.010514038283761995]
[2024-04-18 14:38:18,051: INFO: deberta_initial: Training : batch 1056 Loss: 0.02415024314816249]
[2024-04-18 14:38:18,967: INFO: deberta_initial: Training : batch 1057 Loss: 0.03471381138049103]
[2024-04-18 14:38:19,876: INFO: deberta_initial: Training : batch 1058 Loss: 0.015008539447283432]
[2024-04-18 14:38:20,789: INFO: deberta_initial: Training : batch 1059 Loss: 0.007905542852314467]
[2024-04-18 14:38:21,696: INFO: deberta_initial: Training : batch 1060 Loss: 0.015438543901578285]
[2024-04-18 14:38:22,607: INFO: deberta_initial: Training : batch 1061 Loss: 0.018118018839441773]
[2024-04-18 14:38:23,513: INFO: deberta_initial: Training : batch 1062 Loss: 0.011178131928991064]
[2024-04-18 14:38:24,411: INFO: deberta_initial: Training : batch 1063 Loss: 0.007055238144516188]
[2024-04-18 14:38:25,320: INFO: deberta_initial: Training : batch 1064 Loss: 0.016811403939190873]
[2024-04-18 14:38:26,233: INFO: deberta_initial: Training : batch 1065 Loss: 0.015056594638256465]
[2024-04-18 14:38:27,143: INFO: deberta_initial: Training : batch 1066 Loss: 0.007865071560398212]
[2024-04-18 14:38:28,052: INFO: deberta_initial: Training : batch 1067 Loss: 0.014115034843947147]
[2024-04-18 14:38:28,966: INFO: deberta_initial: Training : batch 1068 Loss: 0.010194632914970978]
[2024-04-18 14:38:29,872: INFO: deberta_initial: Training : batch 1069 Loss: 0.010477395254298453]
[2024-04-18 14:38:30,786: INFO: deberta_initial: Training : batch 1070 Loss: 0.013180515875492755]
[2024-04-18 14:38:31,705: INFO: deberta_initial: Training : batch 1071 Loss: 0.0319713431353445]
[2024-04-18 14:38:32,608: INFO: deberta_initial: Training : batch 1072 Loss: 0.005092693820576208]
[2024-04-18 14:38:33,517: INFO: deberta_initial: Training : batch 1073 Loss: 0.07099178789296538]
[2024-04-18 14:38:34,428: INFO: deberta_initial: Training : batch 1074 Loss: 0.01980487658424905]
[2024-04-18 14:38:35,338: INFO: deberta_initial: Training : batch 1075 Loss: 0.014465907682437409]
[2024-04-18 14:38:36,246: INFO: deberta_initial: Training : batch 1076 Loss: 0.02436348892166622]
[2024-04-18 14:38:37,143: INFO: deberta_initial: Training : batch 1077 Loss: 0.03128413545149043]
[2024-04-18 14:38:38,054: INFO: deberta_initial: Training : batch 1078 Loss: 0.01328103550707067]
[2024-04-18 14:38:38,968: INFO: deberta_initial: Training : batch 1079 Loss: 0.00521469926196231]
[2024-04-18 14:38:39,870: INFO: deberta_initial: Training : batch 1080 Loss: 0.009132034497729105]
[2024-04-18 14:38:40,782: INFO: deberta_initial: Training : batch 1081 Loss: 0.003957491210983511]
[2024-04-18 14:38:41,689: INFO: deberta_initial: Training : batch 1082 Loss: 0.01759131702299515]
[2024-04-18 14:38:42,603: INFO: deberta_initial: Training : batch 1083 Loss: 0.004603085809414545]
[2024-04-18 14:38:43,513: INFO: deberta_initial: Training : batch 1084 Loss: 0.011706103300684185]
[2024-04-18 14:38:44,422: INFO: deberta_initial: Training : batch 1085 Loss: 0.0059455648186341765]
[2024-04-18 14:38:45,338: INFO: deberta_initial: Training : batch 1086 Loss: 0.008356646097137394]
[2024-04-18 14:38:46,243: INFO: deberta_initial: Training : batch 1087 Loss: 0.005137664369942026]
[2024-04-18 14:38:47,153: INFO: deberta_initial: Training : batch 1088 Loss: 0.004107673502621427]
[2024-04-18 14:38:48,064: INFO: deberta_initial: Training : batch 1089 Loss: 0.037073045005494965]
[2024-04-18 14:38:48,974: INFO: deberta_initial: Training : batch 1090 Loss: 0.007322023281147533]
[2024-04-18 14:38:49,876: INFO: deberta_initial: Training : batch 1091 Loss: 0.002108141539760554]
[2024-04-18 14:38:50,778: INFO: deberta_initial: Training : batch 1092 Loss: 0.012413377871612686]
[2024-04-18 14:38:51,690: INFO: deberta_initial: Training : batch 1093 Loss: 0.012690593544344164]
[2024-04-18 14:38:52,601: INFO: deberta_initial: Training : batch 1094 Loss: 0.015938150851318392]
[2024-04-18 14:38:53,512: INFO: deberta_initial: Training : batch 1095 Loss: 0.02525048007994308]
[2024-04-18 14:38:54,420: INFO: deberta_initial: Training : batch 1096 Loss: 0.017870116519346144]
[2024-04-18 14:38:55,326: INFO: deberta_initial: Training : batch 1097 Loss: 0.011044788812236622]
[2024-04-18 14:38:56,244: INFO: deberta_initial: Training : batch 1098 Loss: 0.013479808530261738]
[2024-04-18 14:38:57,158: INFO: deberta_initial: Training : batch 1099 Loss: 0.007698032740570135]
[2024-04-18 14:38:58,071: INFO: deberta_initial: Training : batch 1100 Loss: 0.006679408428003223]
[2024-04-18 14:38:58,981: INFO: deberta_initial: Training : batch 1101 Loss: 0.006116404655832582]
[2024-04-18 14:38:59,893: INFO: deberta_initial: Training : batch 1102 Loss: 0.01327728842687484]
[2024-04-18 14:39:00,806: INFO: deberta_initial: Training : batch 1103 Loss: 0.006957866386751024]
[2024-04-18 14:39:01,718: INFO: deberta_initial: Training : batch 1104 Loss: 0.02968681777579288]
[2024-04-18 14:39:02,630: INFO: deberta_initial: Training : batch 1105 Loss: 0.025743895874411876]
[2024-04-18 14:39:03,540: INFO: deberta_initial: Training : batch 1106 Loss: 0.0072864053396427585]
[2024-04-18 14:39:04,451: INFO: deberta_initial: Training : batch 1107 Loss: 0.013534882002859943]
[2024-04-18 14:39:05,361: INFO: deberta_initial: Training : batch 1108 Loss: 0.013944791579153477]
[2024-04-18 14:39:06,266: INFO: deberta_initial: Training : batch 1109 Loss: 0.004749663363019473]
[2024-04-18 14:39:07,169: INFO: deberta_initial: Training : batch 1110 Loss: 0.006238680017421702]
[2024-04-18 14:39:08,074: INFO: deberta_initial: Training : batch 1111 Loss: 0.024851575931281115]
[2024-04-18 14:39:08,996: INFO: deberta_initial: Training : batch 1112 Loss: 0.007327615012611621]
[2024-04-18 14:39:09,913: INFO: deberta_initial: Training : batch 1113 Loss: 0.05356658803381765]
[2024-04-18 14:39:10,831: INFO: deberta_initial: Training : batch 1114 Loss: 0.0031201746147172865]
[2024-04-18 14:39:11,742: INFO: deberta_initial: Training : batch 1115 Loss: 0.007539772333755225]
[2024-04-18 14:39:12,657: INFO: deberta_initial: Training : batch 1116 Loss: 0.016440716297745652]
[2024-04-18 14:39:13,559: INFO: deberta_initial: Training : batch 1117 Loss: 0.008629883525696483]
[2024-04-18 14:39:14,468: INFO: deberta_initial: Training : batch 1118 Loss: 0.009091876745884154]
[2024-04-18 14:39:15,379: INFO: deberta_initial: Training : batch 1119 Loss: 0.012714051568511867]
[2024-04-18 14:39:16,290: INFO: deberta_initial: Training : batch 1120 Loss: 0.01271707927357428]
[2024-04-18 14:39:17,202: INFO: deberta_initial: Training : batch 1121 Loss: 0.019308586141741742]
[2024-04-18 14:39:18,109: INFO: deberta_initial: Training : batch 1122 Loss: 0.0061088438951906986]
[2024-04-18 14:39:19,020: INFO: deberta_initial: Training : batch 1123 Loss: 0.007847626436122197]
[2024-04-18 14:39:19,928: INFO: deberta_initial: Training : batch 1124 Loss: 0.0054828165518993974]
[2024-04-18 14:39:20,836: INFO: deberta_initial: Training : batch 1125 Loss: 0.024365891879123178]
[2024-04-18 14:39:21,751: INFO: deberta_initial: Training : batch 1126 Loss: 0.01634560394618997]
[2024-04-18 14:39:22,667: INFO: deberta_initial: Training : batch 1127 Loss: 0.009377311753234531]
[2024-04-18 14:39:23,589: INFO: deberta_initial: Training : batch 1128 Loss: 0.0082859789896595]
[2024-04-18 14:39:24,506: INFO: deberta_initial: Training : batch 1129 Loss: 0.007498258142155145]
[2024-04-18 14:39:25,416: INFO: deberta_initial: Training : batch 1130 Loss: 0.007284612920145903]
[2024-04-18 14:39:26,326: INFO: deberta_initial: Training : batch 1131 Loss: 0.010193513158757175]
[2024-04-18 14:39:27,233: INFO: deberta_initial: Training : batch 1132 Loss: 0.01418983322005046]
[2024-04-18 14:39:28,135: INFO: deberta_initial: Training : batch 1133 Loss: 0.005875706162596056]
[2024-04-18 14:39:29,046: INFO: deberta_initial: Training : batch 1134 Loss: 0.015791969856373086]
[2024-04-18 14:39:29,956: INFO: deberta_initial: Training : batch 1135 Loss: 0.044331658745832205]
[2024-04-18 14:39:30,864: INFO: deberta_initial: Training : batch 1136 Loss: 0.019824087183616872]
[2024-04-18 14:39:31,775: INFO: deberta_initial: Training : batch 1137 Loss: 0.010968096754199106]
[2024-04-18 14:39:32,689: INFO: deberta_initial: Training : batch 1138 Loss: 0.00652835703733293]
[2024-04-18 14:39:33,588: INFO: deberta_initial: Training : batch 1139 Loss: 0.0018431859598682535]
[2024-04-18 14:39:34,500: INFO: deberta_initial: Training : batch 1140 Loss: 0.007839411589003862]
[2024-04-18 14:39:35,419: INFO: deberta_initial: Training : batch 1141 Loss: 0.024301425569363197]
[2024-04-18 14:39:36,335: INFO: deberta_initial: Training : batch 1142 Loss: 0.01982414454742743]
[2024-04-18 14:39:37,254: INFO: deberta_initial: Training : batch 1143 Loss: 0.0015521705377334407]
[2024-04-18 14:39:38,162: INFO: deberta_initial: Training : batch 1144 Loss: 0.01098476852056449]
[2024-04-18 14:39:39,071: INFO: deberta_initial: Training : batch 1145 Loss: 0.02192557316383208]
[2024-04-18 14:39:39,982: INFO: deberta_initial: Training : batch 1146 Loss: 0.00697005335262555]
[2024-04-18 14:39:40,892: INFO: deberta_initial: Training : batch 1147 Loss: 0.007433114559351785]
[2024-04-18 14:39:41,802: INFO: deberta_initial: Training : batch 1148 Loss: 0.03030400801622288]
[2024-04-18 14:39:42,712: INFO: deberta_initial: Training : batch 1149 Loss: 0.010285277853131086]
[2024-04-18 14:39:43,623: INFO: deberta_initial: Training : batch 1150 Loss: 0.010890068755512869]
[2024-04-18 14:39:44,534: INFO: deberta_initial: Training : batch 1151 Loss: 0.030366796661153307]
[2024-04-18 14:39:45,441: INFO: deberta_initial: Training : batch 1152 Loss: 0.0024670841911633066]
[2024-04-18 14:39:46,351: INFO: deberta_initial: Training : batch 1153 Loss: 0.008980012005431349]
[2024-04-18 14:39:47,248: INFO: deberta_initial: Training : batch 1154 Loss: 0.022278536869682546]
[2024-04-18 14:39:48,157: INFO: deberta_initial: Training : batch 1155 Loss: 0.015469646891325023]
[2024-04-18 14:39:49,079: INFO: deberta_initial: Training : batch 1156 Loss: 0.01101227891584779]
[2024-04-18 14:39:49,995: INFO: deberta_initial: Training : batch 1157 Loss: 0.004806380642840428]
[2024-04-18 14:39:50,910: INFO: deberta_initial: Training : batch 1158 Loss: 0.04240263680088548]
[2024-04-18 14:39:51,821: INFO: deberta_initial: Training : batch 1159 Loss: 0.013447240283999538]
[2024-04-18 14:39:52,735: INFO: deberta_initial: Training : batch 1160 Loss: 0.05197010558245411]
[2024-04-18 14:39:53,646: INFO: deberta_initial: Training : batch 1161 Loss: 0.02202089631485005]
[2024-04-18 14:39:54,553: INFO: deberta_initial: Training : batch 1162 Loss: 0.010168826614186421]
[2024-04-18 14:39:55,456: INFO: deberta_initial: Training : batch 1163 Loss: 0.014526178878961302]
[2024-04-18 14:39:56,360: INFO: deberta_initial: Training : batch 1164 Loss: 0.004714372053950268]
[2024-04-18 14:39:57,270: INFO: deberta_initial: Training : batch 1165 Loss: 0.003855785405479676]
[2024-04-18 14:39:58,170: INFO: deberta_initial: Training : batch 1166 Loss: 0.008330306157370385]
[2024-04-18 14:39:59,076: INFO: deberta_initial: Training : batch 1167 Loss: 0.009677441594886179]
[2024-04-18 14:39:59,987: INFO: deberta_initial: Training : batch 1168 Loss: 0.026483204142560595]
[2024-04-18 14:40:00,899: INFO: deberta_initial: Training : batch 1169 Loss: 0.010203026010118599]
[2024-04-18 14:40:01,815: INFO: deberta_initial: Training : batch 1170 Loss: 0.008982813189243195]
[2024-04-18 14:40:02,728: INFO: deberta_initial: Training : batch 1171 Loss: 0.013726799085372957]
[2024-04-18 14:40:03,639: INFO: deberta_initial: Training : batch 1172 Loss: 0.008881715373954097]
[2024-04-18 14:40:04,548: INFO: deberta_initial: Training : batch 1173 Loss: 0.037220752458600126]
[2024-04-18 14:40:05,458: INFO: deberta_initial: Training : batch 1174 Loss: 0.005135949123757367]
[2024-04-18 14:40:06,366: INFO: deberta_initial: Training : batch 1175 Loss: 0.00897812992772878]
[2024-04-18 14:40:07,277: INFO: deberta_initial: Training : batch 1176 Loss: 0.008865850523546591]
[2024-04-18 14:40:08,188: INFO: deberta_initial: Training : batch 1177 Loss: 0.008543086920171167]
[2024-04-18 14:40:09,083: INFO: deberta_initial: Training : batch 1178 Loss: 0.01307028480081454]
[2024-04-18 14:40:09,993: INFO: deberta_initial: Training : batch 1179 Loss: 0.02917833422644904]
[2024-04-18 14:40:10,904: INFO: deberta_initial: Training : batch 1180 Loss: 0.00866339498310455]
[2024-04-18 14:40:11,816: INFO: deberta_initial: Training : batch 1181 Loss: 0.02073895228923096]
[2024-04-18 14:40:12,730: INFO: deberta_initial: Training : batch 1182 Loss: 0.030209093654275748]
[2024-04-18 14:40:13,638: INFO: deberta_initial: Training : batch 1183 Loss: 0.022600366271728612]
[2024-04-18 14:40:14,547: INFO: deberta_initial: Training : batch 1184 Loss: 0.01207406880760445]
[2024-04-18 14:40:15,463: INFO: deberta_initial: Training : batch 1185 Loss: 0.012288280973044017]
[2024-04-18 14:40:16,367: INFO: deberta_initial: Training : batch 1186 Loss: 0.020098117664711264]
[2024-04-18 14:40:17,284: INFO: deberta_initial: Training : batch 1187 Loss: 0.00837554692956402]
[2024-04-18 14:40:18,192: INFO: deberta_initial: Training : batch 1188 Loss: 0.008493611364894493]
[2024-04-18 14:40:19,099: INFO: deberta_initial: Training : batch 1189 Loss: 0.030438081945027645]
[2024-04-18 14:40:20,008: INFO: deberta_initial: Training : batch 1190 Loss: 0.012280171306429643]
[2024-04-18 14:40:20,918: INFO: deberta_initial: Training : batch 1191 Loss: 0.030728599962583557]
[2024-04-18 14:40:21,827: INFO: deberta_initial: Training : batch 1192 Loss: 0.014652595645630647]
[2024-04-18 14:40:22,733: INFO: deberta_initial: Training : batch 1193 Loss: 0.02144320933560721]
[2024-04-18 14:40:23,645: INFO: deberta_initial: Training : batch 1194 Loss: 0.0041438672449020325]
[2024-04-18 14:40:24,556: INFO: deberta_initial: Training : batch 1195 Loss: 0.0035263226025786017]
[2024-04-18 14:40:25,468: INFO: deberta_initial: Training : batch 1196 Loss: 0.0027282274533342184]
[2024-04-18 14:40:26,377: INFO: deberta_initial: Training : batch 1197 Loss: 0.008385257724436095]
[2024-04-18 14:40:27,287: INFO: deberta_initial: Training : batch 1198 Loss: 0.01497870427100306]
[2024-04-18 14:40:28,204: INFO: deberta_initial: Training : batch 1199 Loss: 0.028315755196236823]
[2024-04-18 14:40:29,111: INFO: deberta_initial: Training : batch 1200 Loss: 0.01673886301166328]
[2024-04-18 14:40:30,025: INFO: deberta_initial: Training : batch 1201 Loss: 0.005056141511603829]
[2024-04-18 14:40:30,931: INFO: deberta_initial: Training : batch 1202 Loss: 0.014868034825762669]
[2024-04-18 14:40:31,845: INFO: deberta_initial: Training : batch 1203 Loss: 0.011365397261829939]
[2024-04-18 14:40:32,755: INFO: deberta_initial: Training : batch 1204 Loss: 0.012714412854230157]
[2024-04-18 14:40:33,664: INFO: deberta_initial: Training : batch 1205 Loss: 0.005714199741384852]
[2024-04-18 14:40:34,575: INFO: deberta_initial: Training : batch 1206 Loss: 0.0037774122050280635]
[2024-04-18 14:40:35,478: INFO: deberta_initial: Training : batch 1207 Loss: 0.04627810514259228]
[2024-04-18 14:40:36,389: INFO: deberta_initial: Training : batch 1208 Loss: 0.0171129576609103]
[2024-04-18 14:40:37,299: INFO: deberta_initial: Training : batch 1209 Loss: 0.019583867254585267]
[2024-04-18 14:40:38,210: INFO: deberta_initial: Training : batch 1210 Loss: 0.0016815558556648495]
[2024-04-18 14:40:39,120: INFO: deberta_initial: Training : batch 1211 Loss: 0.021869438405244385]
[2024-04-18 14:40:40,029: INFO: deberta_initial: Training : batch 1212 Loss: 0.00974921980810375]
[2024-04-18 14:40:40,944: INFO: deberta_initial: Training : batch 1213 Loss: 0.01534318301948933]
[2024-04-18 14:40:41,856: INFO: deberta_initial: Training : batch 1214 Loss: 0.015395173103722572]
[2024-04-18 14:40:42,772: INFO: deberta_initial: Training : batch 1215 Loss: 0.01780365336207903]
[2024-04-18 14:40:43,674: INFO: deberta_initial: Training : batch 1216 Loss: 0.008740624927585207]
[2024-04-18 14:40:44,585: INFO: deberta_initial: Training : batch 1217 Loss: 0.05720683429607571]
[2024-04-18 14:40:45,496: INFO: deberta_initial: Training : batch 1218 Loss: 0.01288211467027758]
[2024-04-18 14:40:46,407: INFO: deberta_initial: Training : batch 1219 Loss: 0.004919688292816555]
[2024-04-18 14:40:47,319: INFO: deberta_initial: Training : batch 1220 Loss: 0.00417781867612514]
[2024-04-18 14:40:48,226: INFO: deberta_initial: Training : batch 1221 Loss: 0.008399977500426559]
[2024-04-18 14:40:49,133: INFO: deberta_initial: Training : batch 1222 Loss: 0.008217647966917423]
[2024-04-18 14:40:50,032: INFO: deberta_initial: Training : batch 1223 Loss: 0.008363080215337543]
[2024-04-18 14:40:50,941: INFO: deberta_initial: Training : batch 1224 Loss: 0.012916168834629031]
[2024-04-18 14:40:51,851: INFO: deberta_initial: Training : batch 1225 Loss: 0.012729519659100281]
[2024-04-18 14:40:52,761: INFO: deberta_initial: Training : batch 1226 Loss: 0.015722363456367724]
[2024-04-18 14:40:53,684: INFO: deberta_initial: Training : batch 1227 Loss: 0.028173181070016776]
[2024-04-18 14:40:54,604: INFO: deberta_initial: Training : batch 1228 Loss: 0.02687382072689098]
[2024-04-18 14:40:55,520: INFO: deberta_initial: Training : batch 1229 Loss: 0.027066030976527062]
[2024-04-18 14:40:56,433: INFO: deberta_initial: Training : batch 1230 Loss: 0.012247023736887434]
[2024-04-18 14:40:57,334: INFO: deberta_initial: Training : batch 1231 Loss: 0.009376308318009768]
[2024-04-18 14:40:58,243: INFO: deberta_initial: Training : batch 1232 Loss: 0.007382779887394753]
[2024-04-18 14:40:59,154: INFO: deberta_initial: Training : batch 1233 Loss: 0.028333537931104064]
[2024-04-18 14:41:00,064: INFO: deberta_initial: Training : batch 1234 Loss: 0.009843955336435204]
[2024-04-18 14:41:00,970: INFO: deberta_initial: Training : batch 1235 Loss: 0.01189669783643464]
[2024-04-18 14:41:01,870: INFO: deberta_initial: Training : batch 1236 Loss: 0.005209519529269467]
[2024-04-18 14:41:02,784: INFO: deberta_initial: Training : batch 1237 Loss: 0.003944029294135284]
[2024-04-18 14:41:03,694: INFO: deberta_initial: Training : batch 1238 Loss: 0.01209687806871207]
[2024-04-18 14:41:04,600: INFO: deberta_initial: Training : batch 1239 Loss: 0.004554413271724347]
[2024-04-18 14:41:05,511: INFO: deberta_initial: Training : batch 1240 Loss: 0.016161264242538474]
[2024-04-18 14:41:06,426: INFO: deberta_initial: Training : batch 1241 Loss: 0.00718575319206432]
[2024-04-18 14:41:07,340: INFO: deberta_initial: Training : batch 1242 Loss: 0.00983538902888713]
[2024-04-18 14:41:08,252: INFO: deberta_initial: Training : batch 1243 Loss: 0.008994988715383241]
[2024-04-18 14:41:09,160: INFO: deberta_initial: Training : batch 1244 Loss: 0.021059220574802272]
[2024-04-18 14:41:10,069: INFO: deberta_initial: Training : batch 1245 Loss: 0.006043578572111807]
[2024-04-18 14:41:10,978: INFO: deberta_initial: Training : batch 1246 Loss: 0.007752210604006929]
[2024-04-18 14:41:11,892: INFO: deberta_initial: Training : batch 1247 Loss: 0.01648786839683443]
[2024-04-18 14:41:12,803: INFO: deberta_initial: Training : batch 1248 Loss: 0.024247098000657857]
[2024-04-18 14:41:13,712: INFO: deberta_initial: Training : batch 1249 Loss: 0.013203566594910296]
[2024-04-18 14:41:14,617: INFO: deberta_initial: Training : batch 1250 Loss: 0.01276094838267083]
[2024-04-18 14:41:15,525: INFO: deberta_initial: Training : batch 1251 Loss: 0.01656585186928803]
[2024-04-18 14:41:16,428: INFO: deberta_initial: Training : batch 1252 Loss: 0.005361884346260986]
[2024-04-18 14:41:17,338: INFO: deberta_initial: Training : batch 1253 Loss: 0.008563237686445676]
[2024-04-18 14:41:18,249: INFO: deberta_initial: Training : batch 1254 Loss: 0.05789183722626754]
[2024-04-18 14:41:19,164: INFO: deberta_initial: Training : batch 1255 Loss: 0.004303032811761779]
[2024-04-18 14:41:20,071: INFO: deberta_initial: Training : batch 1256 Loss: 0.013707519463373704]
[2024-04-18 14:41:20,980: INFO: deberta_initial: Training : batch 1257 Loss: 0.01388641981799556]
[2024-04-18 14:41:21,889: INFO: deberta_initial: Training : batch 1258 Loss: 0.015415235025625341]
[2024-04-18 14:41:22,803: INFO: deberta_initial: Training : batch 1259 Loss: 0.012406239757592072]
[2024-04-18 14:41:23,716: INFO: deberta_initial: Training : batch 1260 Loss: 0.010613522116284697]
[2024-04-18 14:41:24,621: INFO: deberta_initial: Training : batch 1261 Loss: 0.01824535546609659]
[2024-04-18 14:41:25,531: INFO: deberta_initial: Training : batch 1262 Loss: 0.005892022318035075]
[2024-04-18 14:41:26,443: INFO: deberta_initial: Training : batch 1263 Loss: 0.008831763605634157]
[2024-04-18 14:41:27,353: INFO: deberta_initial: Training : batch 1264 Loss: 0.011669184579923756]
[2024-04-18 14:41:28,263: INFO: deberta_initial: Training : batch 1265 Loss: 0.03177083467608044]
[2024-04-18 14:41:29,175: INFO: deberta_initial: Training : batch 1266 Loss: 0.025573776523977285]
[2024-04-18 14:41:30,084: INFO: deberta_initial: Training : batch 1267 Loss: 0.016779826535356448]
[2024-04-18 14:41:30,995: INFO: deberta_initial: Training : batch 1268 Loss: 0.012226867735215965]
[2024-04-18 14:41:31,904: INFO: deberta_initial: Training : batch 1269 Loss: 0.003246606482797735]
[2024-04-18 14:41:32,809: INFO: deberta_initial: Training : batch 1270 Loss: 0.011373737214820786]
[2024-04-18 14:41:33,725: INFO: deberta_initial: Training : batch 1271 Loss: 0.027406129094829042]
[2024-04-18 14:41:34,639: INFO: deberta_initial: Training : batch 1272 Loss: 0.0045981079067582325]
[2024-04-18 14:41:35,551: INFO: deberta_initial: Training : batch 1273 Loss: 0.00999378857682475]
[2024-04-18 14:41:36,460: INFO: deberta_initial: Training : batch 1274 Loss: 0.013478910177111142]
[2024-04-18 14:41:37,372: INFO: deberta_initial: Training : batch 1275 Loss: 0.0022902281479489786]
[2024-04-18 14:41:38,281: INFO: deberta_initial: Training : batch 1276 Loss: 0.016023628771253542]
[2024-04-18 14:41:39,193: INFO: deberta_initial: Training : batch 1277 Loss: 0.034954071522770296]
[2024-04-18 14:41:40,103: INFO: deberta_initial: Training : batch 1278 Loss: 0.007146782788119553]
[2024-04-18 14:41:41,014: INFO: deberta_initial: Training : batch 1279 Loss: 0.017345042725150327]
[2024-04-18 14:41:41,924: INFO: deberta_initial: Training : batch 1280 Loss: 0.009788129792918272]
[2024-04-18 14:41:42,832: INFO: deberta_initial: Training : batch 1281 Loss: 0.022075954723645083]
[2024-04-18 14:41:43,740: INFO: deberta_initial: Training : batch 1282 Loss: 0.009110279045338503]
[2024-04-18 14:41:44,639: INFO: deberta_initial: Training : batch 1283 Loss: 0.016672069973293804]
[2024-04-18 14:41:45,550: INFO: deberta_initial: Training : batch 1284 Loss: 0.014544720644865023]
[2024-04-18 14:41:46,458: INFO: deberta_initial: Training : batch 1285 Loss: 0.005536755603282778]
[2024-04-18 14:41:47,365: INFO: deberta_initial: Training : batch 1286 Loss: 0.011864464843861892]
[2024-04-18 14:41:48,276: INFO: deberta_initial: Training : batch 1287 Loss: 0.02210527339125645]
[2024-04-18 14:41:49,193: INFO: deberta_initial: Training : batch 1288 Loss: 0.015172083096524538]
[2024-04-18 14:41:50,098: INFO: deberta_initial: Training : batch 1289 Loss: 0.01723082686114905]
[2024-04-18 14:41:51,010: INFO: deberta_initial: Training : batch 1290 Loss: 0.01522847169617081]
[2024-04-18 14:41:51,918: INFO: deberta_initial: Training : batch 1291 Loss: 0.007446184424394936]
[2024-04-18 14:41:52,824: INFO: deberta_initial: Training : batch 1292 Loss: 0.008279075140343444]
[2024-04-18 14:41:53,735: INFO: deberta_initial: Training : batch 1293 Loss: 0.010288042120856386]
[2024-04-18 14:41:54,645: INFO: deberta_initial: Training : batch 1294 Loss: 0.003937466201584054]
[2024-04-18 14:41:55,555: INFO: deberta_initial: Training : batch 1295 Loss: 0.005403215975366302]
[2024-04-18 14:41:56,465: INFO: deberta_initial: Training : batch 1296 Loss: 0.01922430030206492]
[2024-04-18 14:41:57,376: INFO: deberta_initial: Training : batch 1297 Loss: 0.01727295454045956]
[2024-04-18 14:41:58,285: INFO: deberta_initial: Training : batch 1298 Loss: 0.008047987459794877]
[2024-04-18 14:41:59,184: INFO: deberta_initial: Training : batch 1299 Loss: 0.007119404620068971]
[2024-04-18 14:42:00,100: INFO: deberta_initial: Training : batch 1300 Loss: 0.016664056100843996]
[2024-04-18 14:42:01,016: INFO: deberta_initial: Training : batch 1301 Loss: 0.008538498965082854]
[2024-04-18 14:42:01,931: INFO: deberta_initial: Training : batch 1302 Loss: 0.012737566215267468]
[2024-04-18 14:42:02,842: INFO: deberta_initial: Training : batch 1303 Loss: 0.016125587678650775]
[2024-04-18 14:42:03,753: INFO: deberta_initial: Training : batch 1304 Loss: 0.007509853330615153]
[2024-04-18 14:42:04,662: INFO: deberta_initial: Training : batch 1305 Loss: 0.0046456571697499095]
[2024-04-18 14:42:05,574: INFO: deberta_initial: Training : batch 1306 Loss: 0.03549244088145605]
[2024-04-18 14:42:06,485: INFO: deberta_initial: Training : batch 1307 Loss: 0.02383489819465905]
[2024-04-18 14:42:07,394: INFO: deberta_initial: Training : batch 1308 Loss: 0.008326205408273153]
[2024-04-18 14:42:08,306: INFO: deberta_initial: Training : batch 1309 Loss: 0.013721630266163133]
[2024-04-18 14:42:09,219: INFO: deberta_initial: Training : batch 1310 Loss: 0.012043815547022496]
[2024-04-18 14:42:10,127: INFO: deberta_initial: Training : batch 1311 Loss: 0.016712717281541212]
[2024-04-18 14:42:11,031: INFO: deberta_initial: Training : batch 1312 Loss: 0.0020598529269988224]
[2024-04-18 14:42:11,934: INFO: deberta_initial: Training : batch 1313 Loss: 0.0022320005742108677]
[2024-04-18 14:42:12,846: INFO: deberta_initial: Training : batch 1314 Loss: 0.006376875510246432]
[2024-04-18 14:42:13,772: INFO: deberta_initial: Training : batch 1315 Loss: 0.030462660630643856]
[2024-04-18 14:42:14,690: INFO: deberta_initial: Training : batch 1316 Loss: 0.0035033345049942976]
[2024-04-18 14:42:15,602: INFO: deberta_initial: Training : batch 1317 Loss: 0.006787333583116532]
[2024-04-18 14:42:16,513: INFO: deberta_initial: Training : batch 1318 Loss: 0.023802611079227796]
[2024-04-18 14:42:17,424: INFO: deberta_initial: Training : batch 1319 Loss: 0.005964730120483249]
[2024-04-18 14:42:18,318: INFO: deberta_initial: Training : batch 1320 Loss: 0.0004933989904796959]
[2024-04-18 14:42:19,231: INFO: deberta_initial: Training : batch 1321 Loss: 0.01701456192093023]
[2024-04-18 14:42:20,140: INFO: deberta_initial: Training : batch 1322 Loss: 0.0052478394062570825]
[2024-04-18 14:42:21,051: INFO: deberta_initial: Training : batch 1323 Loss: 0.007699990448378761]
[2024-04-18 14:42:21,958: INFO: deberta_initial: Training : batch 1324 Loss: 0.00849445673988084]
[2024-04-18 14:42:22,863: INFO: deberta_initial: Training : batch 1325 Loss: 0.0117612960356673]
[2024-04-18 14:42:23,771: INFO: deberta_initial: Training : batch 1326 Loss: 0.007036465959274037]
[2024-04-18 14:42:24,679: INFO: deberta_initial: Training : batch 1327 Loss: 0.01727581717351053]
[2024-04-18 14:42:25,590: INFO: deberta_initial: Training : batch 1328 Loss: 0.010194389815094275]
[2024-04-18 14:42:26,507: INFO: deberta_initial: Training : batch 1329 Loss: 0.01983541300471574]
[2024-04-18 14:42:27,411: INFO: deberta_initial: Training : batch 1330 Loss: 0.027239772258093525]
[2024-04-18 14:42:28,325: INFO: deberta_initial: Training : batch 1331 Loss: 0.0263578971799098]
[2024-04-18 14:42:29,251: INFO: deberta_initial: Training : batch 1332 Loss: 0.02170817890824494]
[2024-04-18 14:42:30,162: INFO: deberta_initial: Training : batch 1333 Loss: 0.008083909296409808]
[2024-04-18 14:42:31,073: INFO: deberta_initial: Training : batch 1334 Loss: 0.014854813709100502]
[2024-04-18 14:42:31,985: INFO: deberta_initial: Training : batch 1335 Loss: 0.03156566715816234]
[2024-04-18 14:42:32,894: INFO: deberta_initial: Training : batch 1336 Loss: 0.012156035987534616]
[2024-04-18 14:42:33,804: INFO: deberta_initial: Training : batch 1337 Loss: 0.012092086249104642]
[2024-04-18 14:42:34,710: INFO: deberta_initial: Training : batch 1338 Loss: 0.010266056899933708]
[2024-04-18 14:42:35,617: INFO: deberta_initial: Training : batch 1339 Loss: 0.005732224508046423]
[2024-04-18 14:42:36,525: INFO: deberta_initial: Training : batch 1340 Loss: 0.013177278993010612]
[2024-04-18 14:42:37,423: INFO: deberta_initial: Training : batch 1341 Loss: 0.01172861840548393]
[2024-04-18 14:42:38,335: INFO: deberta_initial: Training : batch 1342 Loss: 0.007665108514111167]
[2024-04-18 14:42:39,243: INFO: deberta_initial: Training : batch 1343 Loss: 0.0048531567454609525]
[2024-04-18 14:42:40,157: INFO: deberta_initial: Training : batch 1344 Loss: 0.025414885536138184]
[2024-04-18 14:42:41,066: INFO: deberta_initial: Training : batch 1345 Loss: 0.03717763514581293]
[2024-04-18 14:42:41,977: INFO: deberta_initial: Training : batch 1346 Loss: 0.006784607948083218]
[2024-04-18 14:42:42,890: INFO: deberta_initial: Training : batch 1347 Loss: 0.007971012344188334]
[2024-04-18 14:42:43,804: INFO: deberta_initial: Training : batch 1348 Loss: 0.03809452991518603]
[2024-04-18 14:42:44,712: INFO: deberta_initial: Training : batch 1349 Loss: 0.0028495910937239833]
[2024-04-18 14:42:45,618: INFO: deberta_initial: Training : batch 1350 Loss: 0.007226457263204705]
[2024-04-18 14:42:46,525: INFO: deberta_initial: Training : batch 1351 Loss: 0.01341123562087777]
[2024-04-18 14:42:47,436: INFO: deberta_initial: Training : batch 1352 Loss: 0.008960961722376565]
[2024-04-18 14:42:48,346: INFO: deberta_initial: Training : batch 1353 Loss: 0.00681698728157145]
[2024-04-18 14:42:49,256: INFO: deberta_initial: Training : batch 1354 Loss: 0.0012508722281080397]
[2024-04-18 14:42:50,171: INFO: deberta_initial: Training : batch 1355 Loss: 0.021941907857918823]
[2024-04-18 14:42:51,076: INFO: deberta_initial: Training : batch 1356 Loss: 0.021244585938769652]
[2024-04-18 14:42:51,987: INFO: deberta_initial: Training : batch 1357 Loss: 0.016745802508568906]
[2024-04-18 14:42:52,898: INFO: deberta_initial: Training : batch 1358 Loss: 0.01344725642705817]
[2024-04-18 14:42:53,816: INFO: deberta_initial: Training : batch 1359 Loss: 0.013801437299485667]
[2024-04-18 14:42:54,734: INFO: deberta_initial: Training : batch 1360 Loss: 0.0030184217872653656]
[2024-04-18 14:42:55,652: INFO: deberta_initial: Training : batch 1361 Loss: 0.024931525699866033]
[2024-04-18 14:42:56,560: INFO: deberta_initial: Training : batch 1362 Loss: 0.004856596963081516]
[2024-04-18 14:42:57,470: INFO: deberta_initial: Training : batch 1363 Loss: 0.013098938378159111]
[2024-04-18 14:42:58,379: INFO: deberta_initial: Training : batch 1364 Loss: 0.0035542276245860305]
[2024-04-18 14:42:59,291: INFO: deberta_initial: Training : batch 1365 Loss: 0.01123211113645084]
[2024-04-18 14:43:00,201: INFO: deberta_initial: Training : batch 1366 Loss: 0.007429655705333404]
[2024-04-18 14:43:01,107: INFO: deberta_initial: Training : batch 1367 Loss: 0.024463546877527408]
[2024-04-18 14:43:02,008: INFO: deberta_initial: Training : batch 1368 Loss: 0.010563117338129225]
[2024-04-18 14:43:02,918: INFO: deberta_initial: Training : batch 1369 Loss: 0.008567784248849575]
[2024-04-18 14:43:03,825: INFO: deberta_initial: Training : batch 1370 Loss: 0.013896856303346233]
[2024-04-18 14:43:04,735: INFO: deberta_initial: Training : batch 1371 Loss: 0.004603381578603961]
[2024-04-18 14:43:05,644: INFO: deberta_initial: Training : batch 1372 Loss: 0.006445233010720246]
[2024-04-18 14:43:06,560: INFO: deberta_initial: Training : batch 1373 Loss: 0.011585550105672762]
[2024-04-18 14:43:07,473: INFO: deberta_initial: Training : batch 1374 Loss: 0.02308876395518634]
[2024-04-18 14:43:08,387: INFO: deberta_initial: Training : batch 1375 Loss: 0.011359915555756429]
[2024-04-18 14:43:09,288: INFO: deberta_initial: Training : batch 1376 Loss: 0.006991396363205345]
[2024-04-18 14:43:10,198: INFO: deberta_initial: Training : batch 1377 Loss: 0.020386346524195832]
[2024-04-18 14:43:11,105: INFO: deberta_initial: Training : batch 1378 Loss: 0.009845670080145278]
[2024-04-18 14:43:12,015: INFO: deberta_initial: Training : batch 1379 Loss: 0.014856975775032435]
[2024-04-18 14:43:12,925: INFO: deberta_initial: Training : batch 1380 Loss: 0.008979423413723356]
[2024-04-18 14:43:13,825: INFO: deberta_initial: Training : batch 1381 Loss: 0.007709829150136672]
[2024-04-18 14:43:14,729: INFO: deberta_initial: Training : batch 1382 Loss: 0.006738474405585599]
[2024-04-18 14:43:15,640: INFO: deberta_initial: Training : batch 1383 Loss: 0.01373117132014875]
[2024-04-18 14:43:16,554: INFO: deberta_initial: Training : batch 1384 Loss: 0.047707354027044735]
[2024-04-18 14:43:17,464: INFO: deberta_initial: Training : batch 1385 Loss: 0.013726792602652383]
[2024-04-18 14:43:18,372: INFO: deberta_initial: Training : batch 1386 Loss: 0.0017779700479717375]
[2024-04-18 14:43:19,283: INFO: deberta_initial: Training : batch 1387 Loss: 0.008827257339549794]
[2024-04-18 14:43:20,198: INFO: deberta_initial: Training : batch 1388 Loss: 0.016635623757743856]
[2024-04-18 14:43:21,111: INFO: deberta_initial: Training : batch 1389 Loss: 0.005899403047745485]
[2024-04-18 14:43:22,026: INFO: deberta_initial: Training : batch 1390 Loss: 0.006288893563691725]
[2024-04-18 14:43:22,935: INFO: deberta_initial: Training : batch 1391 Loss: 0.015941287379145012]
[2024-04-18 14:43:23,845: INFO: deberta_initial: Training : batch 1392 Loss: 0.010222541199733958]
[2024-04-18 14:43:24,758: INFO: deberta_initial: Training : batch 1393 Loss: 0.008698295991554195]
[2024-04-18 14:43:25,667: INFO: deberta_initial: Training : batch 1394 Loss: 0.030145846511651687]
[2024-04-18 14:43:26,577: INFO: deberta_initial: Training : batch 1395 Loss: 0.007383498249869606]
[2024-04-18 14:43:27,473: INFO: deberta_initial: Training : batch 1396 Loss: 0.011446789962326325]
[2024-04-18 14:43:28,385: INFO: deberta_initial: Training : batch 1397 Loss: 0.012815440995412345]
[2024-04-18 14:43:29,295: INFO: deberta_initial: Training : batch 1398 Loss: 0.013304032075362696]
[2024-04-18 14:43:30,203: INFO: deberta_initial: Training : batch 1399 Loss: 0.011443210073106695]
[2024-04-18 14:43:31,106: INFO: deberta_initial: Training : batch 1400 Loss: 0.014726749541211115]
[2024-04-18 14:43:32,012: INFO: deberta_initial: Training : batch 1401 Loss: 0.012694170732427675]
[2024-04-18 14:43:32,924: INFO: deberta_initial: Training : batch 1402 Loss: 0.019906117667161983]
[2024-04-18 14:43:33,845: INFO: deberta_initial: Training : batch 1403 Loss: 0.019165443641180342]
[2024-04-18 14:43:34,760: INFO: deberta_initial: Training : batch 1404 Loss: 0.013113754368453082]
[2024-04-18 14:43:35,676: INFO: deberta_initial: Training : batch 1405 Loss: 0.017082716190289615]
[2024-04-18 14:43:36,584: INFO: deberta_initial: Training : batch 1406 Loss: 0.0033911403564936115]
[2024-04-18 14:43:37,493: INFO: deberta_initial: Training : batch 1407 Loss: 0.011908764187806273]
[2024-04-18 14:43:38,402: INFO: deberta_initial: Training : batch 1408 Loss: 0.007018821726151867]
[2024-04-18 14:43:39,313: INFO: deberta_initial: Training : batch 1409 Loss: 0.020796282221933672]
[2024-04-18 14:43:40,222: INFO: deberta_initial: Training : batch 1410 Loss: 0.010922027894460567]
[2024-04-18 14:43:41,133: INFO: deberta_initial: Training : batch 1411 Loss: 0.002432697316118089]
[2024-04-18 14:43:42,044: INFO: deberta_initial: Training : batch 1412 Loss: 0.0030444423485767582]
[2024-04-18 14:43:42,955: INFO: deberta_initial: Training : batch 1413 Loss: 0.011114442254562306]
[2024-04-18 14:43:43,865: INFO: deberta_initial: Training : batch 1414 Loss: 0.020589991640513797]
[2024-04-18 14:43:44,776: INFO: deberta_initial: Training : batch 1415 Loss: 0.010936491677909405]
[2024-04-18 14:43:45,684: INFO: deberta_initial: Training : batch 1416 Loss: 0.005324894305728908]
[2024-04-18 14:43:46,602: INFO: deberta_initial: Training : batch 1417 Loss: 0.0017716718573241408]
[2024-04-18 14:43:47,511: INFO: deberta_initial: Training : batch 1418 Loss: 0.011162969236720624]
[2024-04-18 14:43:48,422: INFO: deberta_initial: Training : batch 1419 Loss: 0.004766335020871649]
[2024-04-18 14:43:49,333: INFO: deberta_initial: Training : batch 1420 Loss: 0.0170850402138545]
[2024-04-18 14:43:50,242: INFO: deberta_initial: Training : batch 1421 Loss: 0.01745280298862919]
[2024-04-18 14:43:51,151: INFO: deberta_initial: Training : batch 1422 Loss: 0.010438866743749218]
[2024-04-18 14:43:52,055: INFO: deberta_initial: Training : batch 1423 Loss: 0.019453049076038634]
[2024-04-18 14:43:52,954: INFO: deberta_initial: Training : batch 1424 Loss: 0.007252907625200857]
[2024-04-18 14:43:53,864: INFO: deberta_initial: Training : batch 1425 Loss: 0.00846092737706535]
[2024-04-18 14:43:54,773: INFO: deberta_initial: Training : batch 1426 Loss: 0.0018840959741399281]
[2024-04-18 14:43:55,682: INFO: deberta_initial: Training : batch 1427 Loss: 0.005193418802891978]
[2024-04-18 14:43:56,577: INFO: deberta_initial: Training : batch 1428 Loss: 0.021261854011931015]
[2024-04-18 14:43:57,486: INFO: deberta_initial: Training : batch 1429 Loss: 0.0073005526389983335]
[2024-04-18 14:43:57,789: INFO: deberta_initial: Eval Epoch : batch 0 Loss: 0.005043589780910197]
